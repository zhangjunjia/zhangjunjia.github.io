{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/2015-11-14-hbase-java-api-example.markdown","hash":"cfe780097f4633fe629ad39c79b4cfc2bd23ce39","modified":1660057320588},{"_id":"source/_posts/2015-11-21-computer-systems.markdown","hash":"9dba885566e7a8536c546fb6bb2d8db3c8cbb47e","modified":1660057320590},{"_id":"source/_posts/2015-11-23-cplusplus-primer-v5.markdown","hash":"72bb72c539d6ba73167a6a474847aafd0c8c0432","modified":1660057320590},{"_id":"source/_posts/2015-12-20-maven-howto.markdown","hash":"2f0879c435720e106b8ef018ed0ce52792f5d224","modified":1660057320590},{"_id":"source/_posts/2016-01-23-sth-about-spring-boot.markdown","hash":"f68413a71f95e0858282183af93a4e11b79449a3","modified":1660057320594},{"_id":"source/_posts/2016-04-22-advanced-linux-programing.markdown","hash":"26a2950195f5dc1cc6722b737a2d49892abef1b8","modified":1660057320595},{"_id":"source/_posts/2016-05-05-svn-that-i-used.markdown","hash":"46d352271bec849d299129a36efb8e035957bf22","modified":1660057320598},{"_id":"source/_posts/2016-05-09-after-my-machine-was-attacked.markdown","hash":"3dee4794ea50541f8452d51858def41d674f5f35","modified":1660057320600},{"_id":"source/_posts/2016-05-09-lvm-that-i-used.markdown","hash":"72ccff7d0b0119b836faf1daa412193ed08c3052","modified":1660057320602},{"_id":"source/_posts/2016-05-11-2015-work-summary.markdown","hash":"9a0e276d0b5cc982a6aa8ad280d3546cb0620476","modified":1660057320604},{"_id":"source/_posts/2016-05-11-hbase-incremental-backup.markdown","hash":"fc99ceb6114580e5fb5eb8bed7c86b01ebc54df4","modified":1660057320604},{"_id":"source/_posts/2016-06-22-autossh-helper.markdown","hash":"4f72363e5bdc0c15cce093d924d1225ec4aa7198","modified":1660057320606},{"_id":"source/_posts/2016-06-22-svn-hooks.markdown","hash":"3cea1853fdcd223318e1fe90d228c1e1ac593c85","modified":1660057320608},{"_id":"source/_posts/2016-06-28-ant-war-task.markdown","hash":"ebe32e070b8324a199c6fa3e63b6e8f7522f6a2f","modified":1660057320615},{"_id":"source/_posts/2016-06-29-bugzilla-in-docker.markdown","hash":"9aa4568748a8619e0604b8f72e6ebb210dd296ec","modified":1660057320615},{"_id":"source/_posts/2016-07-04-generate-core-file.markdown","hash":"f004451b3e38605237041065c484c0acf9a26ca9","modified":1660057320620},{"_id":"source/_posts/2016-08-02-qa-of-unp.markdown","hash":"cf700a5cc49e89a7822195f9ae0f5575172829fe","modified":1660057320620},{"_id":"source/_posts/2016-08-02-summary-of-const.markdown","hash":"cfe9cf268e644ff754d28a20d7bdd77094e3ce76","modified":1660057320622},{"_id":"source/_posts/2016-08-05-about-sigpipe.markdown","hash":"898294c7692dce5b9c48afe2bc6bbc41c033b7c6","modified":1660057320623},{"_id":"source/_posts/2016-08-13-c-sendmail.markdown","hash":"da752ff6b956610e4ad6b30f92d8052ec33f087c","modified":1660057320624},{"_id":"source/_posts/2017-05-04-puzzle-of-c-pointer.md","hash":"16c072ee257a1ae0990021498cb188e3409a8ccd","modified":1660057320628},{"_id":"source/_posts/2017-04-20-rx-8025.md","hash":"e37d93ed65c5ac7d8e5b700331bcf2249054353e","modified":1660057320627},{"_id":"source/_posts/2017-05-09-power-adjustment.md","hash":"e5b70d08960abcb142947aee13524a0b18cf7b35","modified":1660057320629},{"_id":"source/_posts/2016-08-17-tomcat-multi-virtual-host.markdown","hash":"098c89bb5a36eb28499160c7b521424b7997cf23","modified":1660057320625},{"_id":"source/_posts/2017-07-07-sth-about-fread.md","hash":"316d89df9977e8c40ca0ac8d9aefbb82492b68d4","modified":1660057320631},{"_id":"source/_posts/2017-07-28-left-shift.md","hash":"901574b8855309d7c7ee9fe8ffde8bd29e5e3dea","modified":1660057320632},{"_id":"source/_posts/2018-06-07-core-java-equals.md","hash":"2aba0c2cd6ef93ab5e85783d8bf4c3ea6b6c3a38","modified":1660057320634},{"_id":"source/_posts/2018-06-14-close-wait-issue.md","hash":"096b465f9b1e370722e2159aeddaeef935626fed","modified":1660057320636},{"_id":"source/_posts/2018-06-16-too-many-open-files.md","hash":"1d10debf8796e4a443f01f50454a17a35f7a6b9d","modified":1660057320639},{"_id":"source/_posts/2018-07-07-jvmtop-profile.md","hash":"43638ee8c775ab10e08e3e0dbfec614652531caa","modified":1660057320639},{"_id":"source/_posts/2018-09-12-use-jmc-jfr-jprofile.md","hash":"8fe61d447d7bdb0f10f5cd0834795f1adb6cdfdc","modified":1660057320640},{"_id":"source/_posts/2018-09-13-basic-concept-of-mysql-1.md","hash":"5cbc94a694a5697960598eaaa86bd7909159000b","modified":1660057320642},{"_id":"source/_posts/2018-09-20-tcp-state.md","hash":"4d8dc4b4ef548e399681e7c96406a5997962a609","modified":1660057320645},{"_id":"source/_posts/2019-03-16-mysql-mmm-mha.md","hash":"f5fde6942f84c1bdc259651e376f32fcf9d97395","modified":1660057320647},{"_id":"source/_posts/2019-03-31-beyond-resharding.md","hash":"de8a93ee7a3f77d81c72d1e4c204abb005c2ef04","modified":1660057320648},{"_id":"source/_posts/2019-03-31-beyond-sharding.md","hash":"00f0087730b40e180d33af273b9b01906b670f30","modified":1660057320648},{"_id":"source/_posts/2019-08-21-redlock-algorithm.md","hash":"5b36737cb57800ac7c67bcfdcf5f4915c31208d3","modified":1660057320651},{"_id":"source/_posts/2019-12-27-algorithm-04-summary.md","hash":"72607b7a7cb8c010ae3119cad24dc04b336c0df3","modified":1660057320654},{"_id":"source/_posts/2019-12-27-b-tree.md","hash":"ab6537aa88edb65e3c4cfaeebebd165cc9c6bdb3","modified":1660057320655},{"_id":"source/_posts/2019-12-27-juejin-juc-blog-note.md","hash":"87cb8c0c00b65c89c1d6b8e1733d9d83d58b5abf","modified":1660057320655},{"_id":"source/_posts/2019-12-27-stock-dp.md","hash":"34ef89ca0059c7d317ac34ae29eb9c1f7dac1559","modified":1660057320659},{"_id":"source/_posts/2020-01-12-kafka-geekbang-note.md","hash":"7a766195ad2c9ef2ee8e922800691c124753fa09","modified":1660057320659},{"_id":"source/_posts/2020-01-14-chenhao-resilience-design.md","hash":"5a53ed53fe0ce17f46cf9844c0d5d7fa808bfde6","modified":1660057320663},{"_id":"source/_posts/2020-01-15-chenhao-manage-design.md","hash":"ab1e9923df0102ade4c7a541ff2a3d9b44671341","modified":1660057320663},{"_id":"source/_posts/2020-02-09-chat-root-design.md","hash":"9df485926ac82eb8da83173c721d6aee22322fe8","modified":1660057320667},{"_id":"source/_posts/2020-02-15-chenhao-performance-design.md","hash":"3412e807731f8b9ca7ec9658627e008f59de6718","modified":1660057320670},{"_id":"source/_posts/2020-03-16-mysql-redis-kafka-high-availability.md","hash":"38a970da47f545c3ce08cb4ff11350c0ac6362b1","modified":1660057320670},{"_id":"source/_posts/2020-03-31-Scaling-Memcache-at-Facebook.md","hash":"bb8a0f7c26158ffd91eb6ed5474c5f941437f674","modified":1660057320672},{"_id":"source/_posts/2020-05-25-chronicle-map-and-ignite.md","hash":"125c241bca62b80a145f4f13fb97e5798efa5fb7","modified":1660057320672},{"_id":"source/_posts/2020-05-25-event-sc-and-cqrs.md","hash":"65ed80185d837d1141f4ff5f474cc64ee1eb25ec","modified":1660057320677},{"_id":"source/_posts/2020-05-25-java-stateful-deploy.md","hash":"3bea856ef34b510846a0163d77aba1ec5b3a19b9","modified":1660057320677},{"_id":"source/_posts/2020-06-04-kafka-paper.md","hash":"0ad1a9c904d9b97063c03cd31e61fb18fa05fd13","modified":1660057320679},{"_id":"source/_posts/2020-07-08-google-file-system-paper.md","hash":"7fe06bfb9022e8739e9ac8f23c5a0c6ecf710d20","modified":1660057320681},{"_id":"source/_posts/2020-10-09-mq-page-cache.md","hash":"dadf0a6be3640e063514f149d9dd4e35d99b0bd7","modified":1660057320683},{"_id":"source/_posts/2020-11-03-mq-read-diff.md","hash":"d1369644d22dc83a48e119a05b32eeaf4f6fe80a","modified":1660057320684},{"_id":"source/tags/index.md","hash":"a391f6d8eb202f685c169aaba74239cf36177daa","modified":1660057320688},{"_id":"source/categories/index.md","hash":"ef391c160b85dcb90f3b7693dcadce55fd9b396c","modified":1660057320688},{"_id":"public/tags/index.html","hash":"d1b633d91ebaf2e33be0b4915941f0c3204533da","modified":1660144216818},{"_id":"public/categories/index.html","hash":"3fe12bbd85d0b0bd834d51084cae766e805fe4d4","modified":1660144216818},{"_id":"public/2020/01/15/chenhao-manage-design/index.html","hash":"91df03e9efd19dfe77b6a8cf2af602fdeee0499e","modified":1660144216818},{"_id":"public/2019/12/27/b-tree/index.html","hash":"01e61b3a79ba9ced66f9421b0f7792fe599d690b","modified":1660144216818},{"_id":"public/2020/01/14/chenhao-resilience-design/index.html","hash":"6643dd761cb5132c49410c2b74e802cfe90191c9","modified":1660144216818},{"_id":"public/2020/01/03/kafka-geekbang-note/index.html","hash":"3dea9f6c715b0a2df69b4d563fc46f6007fadf5f","modified":1660144216818},{"_id":"public/2019/12/27/stock-dp/index.html","hash":"694d53790cf32c13399010b41e454cf4b768f95f","modified":1660144216818},{"_id":"public/2019/12/27/algorithm-04-summary/index.html","hash":"3003e44976fe6eec0ee2f3fd188d9a80d1c60fe4","modified":1660144216818},{"_id":"public/2019/12/27/juejin-juc-blog-note/index.html","hash":"3f9ef53af7fd73eb2b99e9670d200c058a23e2d4","modified":1660144216818},{"_id":"public/2019/08/21/redlock-algorithm/index.html","hash":"a1285f20251a1bf46fb531d00cbe28ccf44dac3f","modified":1660144216818},{"_id":"public/2019/03/31/beyond-sharding/index.html","hash":"a989ebd95fc27cf9b76ea3dfb9d882c1119ff0f3","modified":1660144216818},{"_id":"public/2019/03/31/beyond-resharding/index.html","hash":"8b6ec29d5ae35a000f009a65e2543753a30226a2","modified":1660144216818},{"_id":"public/2018/09/12/use-jmc-jfr-jprofile/index.html","hash":"26bb7ba504792ef248301be41b69ff0e2179840c","modified":1660144216818},{"_id":"public/2019/03/16/mysql-mmm-mha/index.html","hash":"7b45e36fed7d3bd26e45dd76bb6f51e92c262c42","modified":1660144216818},{"_id":"public/2018/09/20/tcp-state/index.html","hash":"46e47bb8bad9b80f4539662df7a325385584bcdf","modified":1660144216818},{"_id":"public/2018/09/13/basic-concept-of-mysql-1/index.html","hash":"26e9f1fd95e5c52b233f6f81f9a626391b97c8ae","modified":1660144216818},{"_id":"public/2018/07/07/jvmtop-profile/index.html","hash":"e6a716e4f1d4ee29fd2ac914754f04677cc28ad8","modified":1660144216818},{"_id":"public/2018/06/16/too-many-open-files/index.html","hash":"e1c6c7375ee0e8818644b9b7a8f7cbc9e55a55e8","modified":1660144216818},{"_id":"public/2018/06/07/core-java-equals/index.html","hash":"93d775015493277341979fff819330ecdf4c143b","modified":1660144216818},{"_id":"public/2018/06/14/close-wait-issue/index.html","hash":"8d21b4fab1080725074a3e7a56c062de170f3e6f","modified":1660144216818},{"_id":"public/2017/07/28/left-shift/index.html","hash":"c3ce6b63e8a3f14f0f4f4146e2bd17b3502d20e7","modified":1660144216818},{"_id":"public/2017/05/09/power-adjustment/index.html","hash":"aa54fcbb2755260280b3bcf638c34100618f946d","modified":1660144216818},{"_id":"public/2017/07/07/sth-about-fread/index.html","hash":"5310aeb890611c282d8d727dabb51dc4349dd2be","modified":1660144216818},{"_id":"public/2017/05/04/puzzle-of-c-pointer/index.html","hash":"b7bdef4676fa404bbab3c1b1e2d3fec6e6960667","modified":1660144216818},{"_id":"public/2017/04/20/rx-8025/index.html","hash":"0125cc6f87732dc26076b7f280be9835aa6b2f8f","modified":1660144216818},{"_id":"public/2016/08/17/tomcat-multi-virtual-host/index.html","hash":"ffbde62d569f5179916c3306875296fc65ded1de","modified":1660144216818},{"_id":"public/2016/08/13/c-sendmail/index.html","hash":"29242abca219d2c92d06a34209bc7ed019a99a74","modified":1660144216818},{"_id":"public/2016/08/02/summary-of-const/index.html","hash":"480c52b80c4c0d3ecc9623d3e72b299ea0021dc6","modified":1660144216818},{"_id":"public/2016/08/05/about-sigpipe/index.html","hash":"b7839929b0d0d48113333b7029b6a27dac5139dd","modified":1660144216818},{"_id":"public/2016/08/02/qa-of-unp/index.html","hash":"ff9afa86af1d4a06231a3a5ea94498490fbde637","modified":1660144216818},{"_id":"public/2016/07/04/generate-core-file/index.html","hash":"e80caf4f24cb5fe6340b6eb59354d78b016610df","modified":1660144216818},{"_id":"public/2016/06/29/bugzilla-in-docker/index.html","hash":"9cb41d65fd90eb3bbbbf3f81904d89dd57a8a3b4","modified":1660144216818},{"_id":"public/2016/06/22/autossh-helper/index.html","hash":"08186a73433b3e128b3a81e01d07ce0ffabcddec","modified":1660144216818},{"_id":"public/2016/06/28/ant-war-task/index.html","hash":"524e1b0c81a5c878050387416373f52a487555c9","modified":1660144216818},{"_id":"public/2016/06/22/svn-hooks/index.html","hash":"a9597609a38e9c2828da31faf3c8c41665ce8985","modified":1660144216818},{"_id":"public/2016/05/11/hbase-incremental-backup/index.html","hash":"966a8068aef21c38c4931ff143b84b277e7d13b1","modified":1660144216818},{"_id":"public/2016/05/11/2015-work-summary/index.html","hash":"662d92716f714c14dca2cd6aa7696f459f3798ce","modified":1660144216818},{"_id":"public/2016/05/09/lvm-that-i-used/index.html","hash":"a2f91f0e94da679dafd745c245bdd0b50be5ba90","modified":1660144216818},{"_id":"public/2016/05/09/after-my-machine-was-attacked/index.html","hash":"e4ddf757e0c9f4c763fa6670a29130638716d3ba","modified":1660144216818},{"_id":"public/2016/05/05/svn-that-i-used/index.html","hash":"79512008784f34f6d52add76a7c0584b9fc58ed6","modified":1660144216818},{"_id":"public/2016/04/22/advanced-linux-programing/index.html","hash":"0e2aa1ac6cf9414a93dacf13260ac9d98b38950d","modified":1660144216818},{"_id":"public/2015/12/20/maven-howto/index.html","hash":"3e5ff82b390269364713b471116e834778d85950","modified":1660144216818},{"_id":"public/2016/01/23/sth-about-spring-boot/index.html","hash":"2ad58d365cfb3c6615338c6d525a6f66bb389e0c","modified":1660144216818},{"_id":"public/2015/11/23/cplusplus-primer-v5/index.html","hash":"4b730b64e1bd24a8a88404a59398eccfe69dfddf","modified":1660144216818},{"_id":"public/2015/11/21/computer-systems/index.html","hash":"a4b1be5e92c909df150ea91bce091863667501f5","modified":1660144216818},{"_id":"public/2015/11/14/hbase-java-api-example/index.html","hash":"615e3921097b3d0dfd7cc062f3ae47da790eb288","modified":1660144216818},{"_id":"public/categories/编程语言/index.html","hash":"49f26bdcd5ee6742ca1d6a1a7b5705863efaeb09","modified":1660144216818},{"_id":"public/categories/编程实践/index.html","hash":"59b366ccca96f47ce153968c08ff5f7241b3d744","modified":1660144216818},{"_id":"public/categories/工具篇/index.html","hash":"a3a257b0fb867a04d9044ffe806b1887bec4312d","modified":1660144216818},{"_id":"public/categories/操作系统/index.html","hash":"47aa7f9a009f14e25b9f2b0a09832610cc63036c","modified":1660144216818},{"_id":"public/categories/网络安全/index.html","hash":"5512dffa6830f72bf4518d214533eeb2f5703999","modified":1660144216818},{"_id":"public/categories/职场感悟/index.html","hash":"e69943a3810c8aa9678dbe4025c3323258fdaff6","modified":1660144216818},{"_id":"public/categories/计算机网络/index.html","hash":"cd01cc2648b735ecbfed4af75fda77ac9dc5edd3","modified":1660144216818},{"_id":"public/categories/算法/index.html","hash":"82bdee14f00f350c7f380c77b7496e7dbb58f28b","modified":1660144216818},{"_id":"public/categories/数据库/index.html","hash":"4ed76ca21ae7a7a554bea422d5620e1392505dc1","modified":1660144216818},{"_id":"public/categories/系统设计/index.html","hash":"c092811e845d04a013d6d2186777435c4eb9bc1d","modified":1660144216818},{"_id":"public/categories/分布式系统/index.html","hash":"cce10a16d4e20b4e2459b386d98eba5cde89c09e","modified":1660144216818},{"_id":"public/categories/数据结构/index.html","hash":"3949f80cdc48c808e773df975f59330907f2d532","modified":1660144216818},{"_id":"public/archives/index.html","hash":"e38c85888af0463857dd2c36e43b6aee7d3459f9","modified":1660144216818},{"_id":"public/archives/2015/12/index.html","hash":"9d5246ac80d738077fc6b0957de1baccdf5e3961","modified":1660144216818},{"_id":"public/archives/2016/index.html","hash":"b2b7e2616f9bce61d554b718154e08dfcdda4798","modified":1660144216818},{"_id":"public/archives/2015/11/index.html","hash":"87214245a086703bc4903508d0079d4250232768","modified":1660144216818},{"_id":"public/archives/2015/index.html","hash":"ac9f97e5052cb39a7f626c69165da163c455af3a","modified":1660144216818},{"_id":"public/archives/2016/01/index.html","hash":"9cb1be8c63dda154584df6b8d5254dfa8e8306d4","modified":1660144216818},{"_id":"public/archives/2016/04/index.html","hash":"4c0a3c6231f48d3a78c5815389a8257cfceeee7e","modified":1660144216818},{"_id":"public/archives/2016/05/index.html","hash":"2dc8fb7cd3ac150aeff7325a8a63039a11aad17b","modified":1660144216818},{"_id":"public/archives/2016/06/index.html","hash":"6d8ec5deb85f43755813957661b31379093414bc","modified":1660144216818},{"_id":"public/archives/2016/07/index.html","hash":"83e8cdfafd041c5523209772a3a34ffd98edb8d0","modified":1660144216818},{"_id":"public/archives/2016/08/index.html","hash":"5a4c9a674f2420b79b906d32f7db5982d4ad3cb6","modified":1660144216818},{"_id":"public/archives/2017/index.html","hash":"72ea5e60c4fabb7bdfad13dc1f0a3a7bfb9482b4","modified":1660144216818},{"_id":"public/archives/2017/04/index.html","hash":"67aadabbc4a9df50b1d54ed44ba6f0ef4fb394ce","modified":1660144216818},{"_id":"public/archives/2017/05/index.html","hash":"75b44c441203991fc48c3d55ccf9548cd1f14f38","modified":1660144216818},{"_id":"public/archives/2017/07/index.html","hash":"3154ae4591de329deef6eb2d9da417ef59b455fd","modified":1660144216818},{"_id":"public/archives/2018/06/index.html","hash":"4c13749f1e5b2dfd822b44d8b7d37c6d1042ca60","modified":1660144216818},{"_id":"public/archives/2018/index.html","hash":"d5f819f2a82c7451a85b541c2caf3171d9fcf017","modified":1660144216818},{"_id":"public/archives/2018/07/index.html","hash":"c25481cee04aee0c7fe2ccd87b761458a2122390","modified":1660144216818},{"_id":"public/archives/2019/index.html","hash":"0ed03d4a1b47d4c021430c167db0b5db2279698d","modified":1660144216818},{"_id":"public/archives/2019/03/index.html","hash":"7eec7a810cf425dd24f8f41d4e272ce0c080f1dc","modified":1660144216818},{"_id":"public/archives/2018/09/index.html","hash":"9adb4cb49500f2da8c318bdb16fe1fb9d9c4f0ef","modified":1660144216818},{"_id":"public/archives/2019/08/index.html","hash":"fc14548179ed3d93b6c7d5a73bb40fb3a26fd5dd","modified":1660144216818},{"_id":"public/archives/2020/index.html","hash":"588386002f7d4db3558cf76e9735dfaa26e376dc","modified":1660144216818},{"_id":"public/archives/2019/12/index.html","hash":"e2d29af4d6ae85828bd1d4e76d427b0e52d96e0c","modified":1660144216818},{"_id":"public/archives/2020/01/index.html","hash":"b2fb6892fdb6beb8c3a862a73e640bcbb070bb30","modified":1660144216818},{"_id":"public/tags/C-C/index.html","hash":"efc00ff4b7a219703da270d64088bc072b760ec5","modified":1660144216818},{"_id":"public/tags/HBase/index.html","hash":"1e0bcd12c76e0889ab4ee32aef0a9e52a3035b01","modified":1660144216818},{"_id":"public/tags/Java/index.html","hash":"d11bd8e00c7f2fe6524a1d17335db1bd80c64450","modified":1660144216818},{"_id":"public/tags/Maven/index.html","hash":"40d5343cbc577d8b86601bc1e05c7b9e1246e3ae","modified":1660144216818},{"_id":"public/tags/Spring/index.html","hash":"3883b9cf1c38a71600959b28ed3495297eb6fc38","modified":1660144216818},{"_id":"public/tags/操作系统/index.html","hash":"ef31ef5186bc6804dfc3dce93a86baf39c12e980","modified":1660144216818},{"_id":"public/tags/Linux/index.html","hash":"ca22c418171f0716a0aa1c2f5aa6beb8e8233027","modified":1660144216818},{"_id":"public/tags/LVM/index.html","hash":"682d3ea938d0f3998515184a1b880b2d10eb6122","modified":1660144216818},{"_id":"public/tags/SVN/index.html","hash":"578b84cbeb21e92c68e00aabb048156d96f39c8e","modified":1660144216818},{"_id":"public/tags/Network/index.html","hash":"8758fa76b9b7f570f457dd7f9844b9fd80b89bfe","modified":1660144216818},{"_id":"public/tags/信息安全/index.html","hash":"d796d8fd6bce9fa798999e5539262c94d15df536","modified":1660144216818},{"_id":"public/tags/Hadoop/index.html","hash":"f81caa7caa56c03ee4db772e7d0429f7ad6f2a91","modified":1660144216818},{"_id":"public/tags/职场/index.html","hash":"9088977d60c4a1cef132d9edbdb17e16ec8205a8","modified":1660144216818},{"_id":"public/tags/Docker/index.html","hash":"ba7e8a502a326dbcbec27380a1833d84c62c42cd","modified":1660144216818},{"_id":"public/tags/TCP-IP/index.html","hash":"637178d603e6e4ebf6c0e916f11cf9786097d8f4","modified":1660144216818},{"_id":"public/tags/Eclipse/index.html","hash":"da26388d247d7a88e9b1a2d45c80fa909bb0101f","modified":1660144216818},{"_id":"public/tags/动态规划/index.html","hash":"b33d30bd8258a221d066a03f3e3e7d190c5ab6af","modified":1660144216818},{"_id":"public/tags/Beaglebone/index.html","hash":"acbf98730b5ee1ed718ea7e20ba8f4b99352fae9","modified":1660144216818},{"_id":"public/tags/Tomcat/index.html","hash":"70a5f91dc8533e950f69a2875616397c00182211","modified":1660144216818},{"_id":"public/tags/Mina/index.html","hash":"0649cb5a3a9fd8d995a1254c1994802b3c836f21","modified":1660144216818},{"_id":"public/tags/MySQL/index.html","hash":"6f7129ea7be8c255764fcfb61f11d45b602b5211","modified":1660144216818},{"_id":"public/tags/Redis/index.html","hash":"e60638ff3e321140a8280f05a1c992f184157ff3","modified":1660144216818},{"_id":"public/tags/HDFS/index.html","hash":"d06b18acd5645e9f20e44cfa4e044c0ab29b161d","modified":1660144216818},{"_id":"public/tags/数据库/index.html","hash":"b54c7cb4a7cc60854773938df56b74942c7a89a4","modified":1660144216818},{"_id":"public/tags/Kafka/index.html","hash":"380beec3e781eaf46d5903ba09f794c7d7f18f68","modified":1660144216818},{"_id":"public/tags/Algorithm/index.html","hash":"e1263cd6e35a5c1d2b86e777e03ce41d32be762e","modified":1660144216818},{"_id":"public/tags/B-Tree/index.html","hash":"cde56b1e9915d4d62f839f769bcaf7eb8fff3833","modified":1660144216818},{"_id":"public/2020/11/03/mq-read-diff/index.html","hash":"68813190052ba2cced1694539b049589c4dac8b8","modified":1660144216818},{"_id":"public/2020/10/09/mq-page-cache/index.html","hash":"f6944d75a88dde94fecfbe384447de3bbe139d29","modified":1660144216818},{"_id":"public/2020/07/08/google-file-system-paper/index.html","hash":"dc942ea6d5eede8d4407c40be715d54d6039329e","modified":1660144216818},{"_id":"public/2020/06/04/kafka-paper/index.html","hash":"95c5216761f3162178cb7a3195240d2da5598fe2","modified":1660144216818},{"_id":"public/2020/05/25/chronicle-map-and-ignite/index.html","hash":"142c467cecf110cd110c610f223cf68353a25e9d","modified":1660144216818},{"_id":"public/2020/05/07/event-sc-and-cqrs/index.html","hash":"73a851a9a327bc67d83feb95d0ef9e81c6675933","modified":1660144216818},{"_id":"public/2020/04/25/java-stateful-deploy/index.html","hash":"adcae35c6a9e1880a3ae81dae3351ac32035095f","modified":1660144216818},{"_id":"public/2020/03/31/Scaling-Memcache-at-Facebook/index.html","hash":"66da849e9bf8bceba9f49b19fb1f08c40d892b0f","modified":1660144216818},{"_id":"public/2020/03/16/mysql-redis-kafka-high-availability/index.html","hash":"cd234ff34145ee728d6d357b9e35f499f444a5e1","modified":1660144216818},{"_id":"public/2020/02/15/chenhao-performance-design/index.html","hash":"42c52a72ea074ff79f2dde7adc932290a5e49b39","modified":1660144216818},{"_id":"public/2020/02/09/chat-root-design/index.html","hash":"d17f1feee70fd6825883288759fb1358aa55180e","modified":1660144216818},{"_id":"public/archives/2020/02/index.html","hash":"7996649706f11782cce1906857f5449892085de0","modified":1660144216818},{"_id":"public/archives/2020/04/index.html","hash":"a407ba7cb9085b95b6bfb4b040bb661437db412d","modified":1660144216818},{"_id":"public/archives/2020/03/index.html","hash":"b044766151156baa83e92b1dd6e46de8ab21b63a","modified":1660144216818},{"_id":"public/archives/2020/05/index.html","hash":"7d4fbf19b31ddda28e0ffb863386d1839c813a75","modified":1660144216818},{"_id":"public/archives/2020/06/index.html","hash":"fb32ad422752f92e8b69a9aee02bbc8b61776f9e","modified":1660144216818},{"_id":"public/archives/2020/07/index.html","hash":"dfff03e4f3f3aa252af6702b52c58b374231fe2d","modified":1660144216818},{"_id":"public/archives/2020/10/index.html","hash":"c79b705c4ca6db889a6583b2803e2e4f23da8dc6","modified":1660144216818},{"_id":"public/archives/2020/11/index.html","hash":"e1032c20eede770dd293e9decde8df035c66343e","modified":1660144216818},{"_id":"public/tags/系统设计/index.html","hash":"f3af2f191f2baf963d2eeaf16713a114e27bdbce","modified":1660144216818},{"_id":"public/tags/Paper阅读/index.html","hash":"e7282187157b9df059c83cef9c82e5dcecd6b19a","modified":1660144216818},{"_id":"public/tags/ChronicleMap/index.html","hash":"7d3792f63da1542230373aa3f41a484728cd8ff9","modified":1660144216818},{"_id":"public/tags/Memcached/index.html","hash":"c7ca6a6c0f8a74d223dd924064728cfaccda351e","modified":1660144216818},{"_id":"public/index.html","hash":"854c2d22c49789b06f1420d72a8832bb9a1cffd5","modified":1660144216818},{"_id":"public/tags/ApacheIgnite/index.html","hash":"d5e30dc0b822d8f6d56d2725c544687683a1202c","modified":1660144216818},{"_id":"public/tags/CQRS/index.html","hash":"cfb3058fe4087fd9dd9f1cceb091c97d6b2d23d1","modified":1660144216818},{"_id":"public/tags/EventSourcing/index.html","hash":"ae18f94c72b13b76444637b4027ffc2827d1bc27","modified":1660144216818},{"_id":"themes/next/.editorconfig","hash":"731c650ddad6eb0fc7c3d4a91cad1698fe7ad311","modified":1660139513691},{"_id":"themes/next/.eslintrc.json","hash":"d3c11de434171d55d70daadd3914bc33544b74b8","modified":1660139513692},{"_id":"themes/next/.gitattributes","hash":"3e00e1fb043438cd820d94ee3dc9ffb6718996f3","modified":1660139513692},{"_id":"themes/next/.gitignore","hash":"83418530da80e6a78501e1d62a89c3bf5cbaec3d","modified":1660139513708},{"_id":"themes/next/.stylintrc","hash":"6259e2a0b65d46865ab89564b88fc67638668295","modified":1660139513710},{"_id":"themes/next/.travis.yml","hash":"379f31a140ce41e441442add6f673bf397d863ea","modified":1660139513710},{"_id":"themes/next/LICENSE.md","hash":"0a9c7399f102b4eb0a6950dd31264be421557c7d","modified":1660139513711},{"_id":"themes/next/_config.yml","hash":"ccd41ed5fc3027f81834c30fe4b67c0dac742dea","modified":1660144701331},{"_id":"themes/next/crowdin.yml","hash":"4a53f5985e545c635cb56b2a57ed290cb8cf8942","modified":1660139513716},{"_id":"themes/next/README.md","hash":"7d56751b580d042559b2acf904fca4b42bcb30a7","modified":1660139513712},{"_id":"themes/next/gulpfile.js","hash":"0c76a1ac610ee8cbe8e2cc9cca1c925ffd0edf98","modified":1660139513746},{"_id":"themes/next/package.json","hash":"b099e7cea4406e209130410d13de87988ba37b2a","modified":1660139513840},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1660139513663},{"_id":"themes/next/.git/config","hash":"f1969a9b2e1128a528f7b846c2bc39a7f0984cdf","modified":1660139513671},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1660139363189},{"_id":"themes/next/.git/index","hash":"01c0f5f1b7be8748df0103536c999f5b74897372","modified":1660139513996},{"_id":"themes/next/.git/packed-refs","hash":"8f022ae3bfcfd2352c82de1a0deaed75e09819e6","modified":1660139513648},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"778b7e052993ed59f21ed266ba7119ee2e5253fb","modified":1660139513694},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ddde54fb50d11dc08cec899a3588addb56aa386","modified":1660139513695},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"d2f8e6b65783e31787feb05d2ccea86151f53f35","modified":1660139513701},{"_id":"themes/next/.github/issue-close-app.yml","hash":"b14756e65546eb9ecc9d4393f0c9a84a3dac1824","modified":1660139513702},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"533fbe6b2f87d7e7ec6949063bb7ea7eb4fbe52d","modified":1660139513703},{"_id":"themes/next/.github/config.yml","hash":"df3d970700e6b409edc3d23be8d553db78d5ba3f","modified":1660139513701},{"_id":"themes/next/.github/lock.yml","hash":"3ce3d0a26030a1cd52b273cc6a6d444d7c8d85c2","modified":1660139513703},{"_id":"themes/next/.github/mergeable.yml","hash":"1c1cb77a62df1e3654b151c2da34b4a10d351170","modified":1660139513703},{"_id":"themes/next/.github/release-drafter.yml","hash":"09c3352b2d643acdc6839601ceb38abc38ab97c5","modified":1660139513703},{"_id":"themes/next/.github/stale.yml","hash":"590b65aca710e0fba75d3cf5361a64d13b6b0f63","modified":1660139513707},{"_id":"themes/next/.github/support.yml","hash":"7ce2722d6904c31a086444c422dc49b6aa310651","modified":1660139513708},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"60c7e9ef0c578deebad43e9395c958fa61096baf","modified":1660139513720},{"_id":"themes/next/docs/AGPL3.md","hash":"f463f95b169d64983f59fa6f3e4b6760290a0e6b","modified":1660139513719},{"_id":"themes/next/docs/AUTHORS.md","hash":"cde7cc095ac31b421a573042cf61060f90d9ad0d","modified":1660139513720},{"_id":"themes/next/docs/DATA-FILES.md","hash":"980fb8d37701f7fd96b30bb911519de3bbb473d1","modified":1660139513722},{"_id":"themes/next/docs/INSTALLATION.md","hash":"07ea00bee149a1bdc9073e903ee6b411e9f2f818","modified":1660139513722},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"6cc663db5e99fd86bb993c10d446ad26ada88e58","modified":1660139513726},{"_id":"themes/next/docs/MATH.md","hash":"f56946053ade0915ff7efa74d43c38b8dd9e63bb","modified":1660139513726},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"1e86d32063b490d204baa9d45d8d3cb22c24a37d","modified":1660139513726},{"_id":"themes/next/docs/LICENSE.txt","hash":"ae5ad07e4f4106bad55535dba042221539e6c7f9","modified":1660139513726},{"_id":"themes/next/languages/ar.yml","hash":"abcf220bd615cec0dd50e4d98da56580169d77e1","modified":1660139513747},{"_id":"themes/next/languages/de.yml","hash":"15078b7ede1b084e8a6a15d271f0db9c325bd698","modified":1660139513747},{"_id":"themes/next/languages/en.yml","hash":"dbb64776f9c001c54d0058256c415a9a0724ed5d","modified":1660139513747},{"_id":"themes/next/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1660139513747},{"_id":"themes/next/languages/es.yml","hash":"f064c793d56a5e0f20cda93b6f0e355044efc7d8","modified":1660139513747},{"_id":"themes/next/languages/fa.yml","hash":"6c0a7d5bcc26eb45a9f3e02f13117c668e77fffd","modified":1660139513747},{"_id":"themes/next/languages/fr.yml","hash":"3e2f89d4bb4441d33ecc7b5a4ee114f627603391","modified":1660139513747},{"_id":"themes/next/languages/hu.yml","hash":"0ea89ffaefd02a10494995f05a2a59d5e5679a28","modified":1660139513747},{"_id":"themes/next/languages/id.yml","hash":"7599bb0ecf278beb8fde3d17bfc148a3241aef82","modified":1660139513747},{"_id":"themes/next/languages/it.yml","hash":"46222f468e66789e9ba13095809eb5e5b63edf30","modified":1660139513747},{"_id":"themes/next/languages/nl.yml","hash":"9749cf90b250e631dd550a4f32ada3bb20f66dd0","modified":1660139513757},{"_id":"themes/next/languages/ko.yml","hash":"af4be6cb394abd4e2e9a728418897d2ed4cc5315","modified":1660139513756},{"_id":"themes/next/languages/ja.yml","hash":"bf279d0eb1911806d01a12f27261fbc76a3bb3f9","modified":1660139513756},{"_id":"themes/next/languages/pt-BR.yml","hash":"69aa3bef5710b61dc9a0f3b3a8f52f88c4d08c00","modified":1660139513758},{"_id":"themes/next/languages/pt.yml","hash":"f6606dd0b916a465c233f24bd9a70adce34dc8d6","modified":1660139513759},{"_id":"themes/next/languages/ru.yml","hash":"012abc694cf9de281a0610f95f79c594f0a16562","modified":1660139513759},{"_id":"themes/next/languages/uk.yml","hash":"69ef00b1b8225920fcefff6a6b6f2f3aad00b4ce","modified":1660139513761},{"_id":"themes/next/languages/tr.yml","hash":"c4e9ab7e047ae13a19f147c6bec163c3ba2c6898","modified":1660139513760},{"_id":"themes/next/languages/vi.yml","hash":"6a578cc28773bd764f4418110500478f185d6efa","modified":1660139513762},{"_id":"themes/next/languages/zh-HK.yml","hash":"92ccee40c234626bf0142152949811ebe39fcef2","modified":1660139513765},{"_id":"themes/next/languages/zh-CN.yml","hash":"81d73e21402dad729053a3041390435f43136a68","modified":1660139513764},{"_id":"themes/next/layout/_layout.swig","hash":"9554bd0f5c5a0438aa7b64065be5561c374d260e","modified":1660139513765},{"_id":"themes/next/languages/zh-TW.yml","hash":"cf0740648725983fb88409d6501876f8b79db41d","modified":1660139513765},{"_id":"themes/next/layout/archive.swig","hash":"d9bca77f6dcfef71e300a294f731bead11ce199f","modified":1660139513834},{"_id":"themes/next/layout/index.swig","hash":"8dfd96fb6f833dd5d037de800813105654e8e8e6","modified":1660139513837},{"_id":"themes/next/layout/category.swig","hash":"c546b017a956faaa5f5643c7c8a363af7ac9d6b9","modified":1660139513836},{"_id":"themes/next/layout/page.swig","hash":"357d916694d4c9a0fd1140fa56d3d17e067d8b52","modified":1660139513838},{"_id":"themes/next/layout/tag.swig","hash":"d44ff8755727f6532e86fc9fc8dc631200ffe161","modified":1660139513839},{"_id":"themes/next/layout/post.swig","hash":"5f0b5ba2e0a5b763be5e7e96611865e33bba24d7","modified":1660139513839},{"_id":"themes/next/scripts/renderer.js","hash":"e3658eea97b1183ee2e9f676231e53f7994741f6","modified":1660139513863},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1660139363191},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1660139363191},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1660139363191},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1660139363190},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1660139363191},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1660139363191},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1660139363191},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1660139363191},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1660139363191},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1660139363199},{"_id":"themes/next/.git/logs/HEAD","hash":"2e6a1dfb1e04b60b373b60be9ba9d0191868a09f","modified":1660139513669},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.md","hash":"e67146befddec3a0dc47dc80d1109070c71d5d04","modified":1660139513696},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.md","hash":"6beeca0f45a429cd932b6e648617f548ff64c27c","modified":1660139513698},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.md","hash":"d5aa1a3323639a36bcd9a401484b67537043cd3c","modified":1660139513699},{"_id":"themes/next/.github/ISSUE_TEMPLATE/question.md","hash":"59275aa0582f793fee7be67904dcf52ad33a7181","modified":1660139513700},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"a9cfe5ac9ef727a8650b2b6584482751a26b1460","modified":1660139513726},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"54e6a067ed95268eab6be2ba040a7e9b1907928e","modified":1660139513726},{"_id":"themes/next/docs/ru/README.md","hash":"1e5ddb26ad6f931f8c06ce2120f257ff38b74fdf","modified":1660139513726},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"3202be9a8d31986caac640e7a4c7ce22e99917eb","modified":1660139513736},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"cb8e39c377fc4a14aaf133b4d1338a48560e9e65","modified":1660139513735},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"7e6f227f2aaf30f400d4c065650a4e3d0d61b9e1","modified":1660139513738},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"2d868cd271d78b08775e28c5b976de8836da4455","modified":1660139513740},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"611f2930c2b281b80543531b1bf33d082531456a","modified":1660139513738},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"716111dd36d276f463c707dfcc9937fea2a1cf7a","modified":1660139513740},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"50ab381c27611d5bf97bb3907b5ca9998f28187d","modified":1660139513740},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"0d46f9f50cf2e4183970adce705d1041155b0d37","modified":1660139513740},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"b3201934b966bc731eaf8a4dad4ba4bdcd300c10","modified":1660139513740},{"_id":"themes/next/docs/zh-CN/README.md","hash":"8f7c0d0b766024152591d4ccfac715c8e18b37f3","modified":1660139513740},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"5bffdb1448caca7db7b1f84e1693e6657a106d50","modified":1660139513770},{"_id":"themes/next/layout/_macro/post.swig","hash":"c3fd56bac90ce45a0c79ddfe68beb223ad0d72b4","modified":1660139513769},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"30ade8c806d7826cc50a4a3e46a9e6213fddf333","modified":1660139513769},{"_id":"themes/next/layout/_partials/footer.swig","hash":"e031914c98f082d918ece4c35fdd0a5be1c4e845","modified":1660139513772},{"_id":"themes/next/layout/_partials/comments.swig","hash":"142efb4c6b73d8f736f6784804b40d5871333172","modified":1660139513771},{"_id":"themes/next/layout/_partials/languages.swig","hash":"c3ea82604a5853fb44c5f4e4663cbe912aa5dcf8","modified":1660139513780},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"2de77d533c91532a8a4052000244d0c1693370df","modified":1660139513783},{"_id":"themes/next/layout/_scripts/index.swig","hash":"1822eaf55bbb4bec88871c324fc18ad95580ccb4","modified":1660139513799},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"5392dcbb504266f0f61d5b8219914068ef9cdc25","modified":1660139513797},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"7b9e0f776a5be6c3f95bc7f394e1424ba02ba93b","modified":1660139513799},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"ccff5a773644d33ff22f6b45b6734f52b048f22b","modified":1660139513801},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"244ca2d74ee0d497c87572c6a26b43c62a952673","modified":1660139513805},{"_id":"themes/next/layout/_scripts/three.swig","hash":"6b092c6d882b2dfa5273e1b3f60b244cb7c29fcd","modified":1660139513805},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"28b0a7e843ec4365db1963646659a153753cd746","modified":1660139513812},{"_id":"themes/next/layout/_third-party/index.swig","hash":"c6b63cbc80938e6e09578b8c67e01adf13a9e3bd","modified":1660139513820},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"5ae5adcd6f63ed98b2071e4f7e5e38c4d7d24e1b","modified":1660139513823},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"269102fc5e46bd1ce75abdcce161f0570ae70e2f","modified":1660139513824},{"_id":"themes/next/scripts/events/index.js","hash":"5c355f10fe8c948a7f7cd28bd8120adb7595ebde","modified":1660139513842},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"ad321db012cea520066deb0639335e9bc0dcc343","modified":1660139513854},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"305d03c1e45782988809298c3e3b3c5d5ee438aa","modified":1660139513855},{"_id":"themes/next/scripts/filters/minify.js","hash":"21196a48cb127bf476ce598f25f24e8a53ef50c2","modified":1660139513857},{"_id":"themes/next/scripts/filters/locals.js","hash":"a5e7d05d3bd2ae6dcffad5a8ea0f72c6e55dbd02","modified":1660139513855},{"_id":"themes/next/scripts/helpers/engine.js","hash":"eb6b8bbc1dce4846cd5e0fac0452dbff56d07b5d","modified":1660139513859},{"_id":"themes/next/scripts/filters/post.js","hash":"57f2d817578dd97e206942604365e936a49854de","modified":1660139513857},{"_id":"themes/next/scripts/helpers/font.js","hash":"8fb1c0fc745df28e20b96222974402aab6d13a79","modified":1660139513861},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"b8d7ddfa4baa9b8d6b9066a634aa81c6243beec9","modified":1660139513861},{"_id":"themes/next/scripts/tags/button.js","hash":"bb0e8abbc0a6d5b3a1a75a23976f2ac3075aab31","modified":1660139513864},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"4044129368d0e2811859a9661cad8ab47118bc32","modified":1660139513862},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"840536754121e0da5968f5ad235f29200fc5d769","modified":1660139513865},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"e2d0184bc4a557e1017395b80ff46880078d8537","modified":1660139513866},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"93ccd3f99d3cb42674f29183c756df63acb5d7f8","modified":1660139513867},{"_id":"themes/next/scripts/tags/label.js","hash":"fc83f4e1be2c34e81cb79938f4f99973eba1ea60","modified":1660139513867},{"_id":"themes/next/scripts/tags/pdf.js","hash":"37b53661ad00a01a2ca7d2e4a5ad3a926073f8e2","modified":1660139513870},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"81134494ff0134c0dae1b3815caf6606fccd4e46","modified":1660139513868},{"_id":"themes/next/scripts/tags/note.js","hash":"1fdf4f95810fdb983bfd5ad4c4f13fedd4ea2f8d","modified":1660139513869},{"_id":"themes/next/scripts/tags/tabs.js","hash":"c70a4a66fd0c28c98ccb6c5d5f398972e5574d28","modified":1660139513871},{"_id":"themes/next/scripts/tags/video.js","hash":"944293fec96e568d9b09bc1280d5dbc9ee1bbd17","modified":1660139513871},{"_id":"themes/next/source/css/_mixins.styl","hash":"072a3fa473c19b20ccd7536a656cda044dbdae0a","modified":1660139513930},{"_id":"themes/next/source/css/main.styl","hash":"815ef30987d02f3d76dbe4b5ee3a72135a152678","modified":1660139513951},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1660139513952},{"_id":"themes/next/source/css/_colors.styl","hash":"11aef31a8e76f0f332a274a8bfd4537b73d4f88f","modified":1660139513873},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1660139513953},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1660139513953},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1660139513953},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1660139513958},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1660139513953},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1660139513958},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1660139513958},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1660139513958},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1660139513958},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1660139513958},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1660139513958},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1660139513958},{"_id":"themes/next/source/lib/anime.min.js","hash":"960be51132134acd65c2017cc8a5d69cb419a0cd","modified":1660139513978},{"_id":"themes/next/source/js/algolia-search.js","hash":"6a813410e33824d7acc65a369a2983912bb3420c","modified":1660139513958},{"_id":"themes/next/source/js/bookmark.js","hash":"9f05fd3672789311dc0cf5b37e40dc654cb04a2a","modified":1660139513967},{"_id":"themes/next/source/js/local-search.js","hash":"cfa6a0f3f9c2bc759ee507668a21f4e8f250f42a","modified":1660139513968},{"_id":"themes/next/source/js/next-boot.js","hash":"250d8dcd6322e69e3fbadd0f3e37081c97b47c52","modified":1660139513971},{"_id":"themes/next/source/js/motion.js","hash":"d5aa1a08cdf3c8d1d8d550fb1801274cc41e5874","modified":1660139513968},{"_id":"themes/next/source/js/utils.js","hash":"26a82e46fdcadc7c3c2c56a7267284b61a26f7f3","modified":1660139513976},{"_id":"themes/next/.git/refs/heads/master","hash":"1f55c26e44a15c914143917709c7008edfd94073","modified":1660139513666},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"91056a6c98cca63ff8cc6956e531ee3faf4b8ad9","modified":1660139513775},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"0dd316f153c492c0a03bd0273d50fa322bc81f11","modified":1660139513776},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"4baa86ca631168fc6388d27f4b1b501b40c877a8","modified":1660139513777},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"90d3eaba6fbe69bee465ddd67c467fd2c0239dc4","modified":1660139513778},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"bed6cc2b48cf2655036ba39c9bae73a295228a4d","modified":1660139513778},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"7d638e413f2548fc990c4a467dd03de6c81fc960","modified":1660139513773},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"90cce9f407e9490756ba99580e3eb09f55b05eaa","modified":1660139513774},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"91c0addb33006619faa4c32e5d66874e25f1e9b3","modified":1660139513782},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"a6c761d5193cb6f22e9422dbbcf209e05471b0ed","modified":1660139513790},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"128f7d679bb4d53b29203d598d217f029a66dee7","modified":1660139513790},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"98fd1f5df044f4534e1d4ca9ab092ba5761739a9","modified":1660139513790},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"8d4e3dd0d3631ce0b21bc15c259f6ac886de631d","modified":1660139513783},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"f2eb455c8bf13533427254f0c9b4b17b2498168b","modified":1660139513785},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"f349a226e5370075bb6924e60da8b0170c7cfcc1","modified":1660139513790},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"bc7b047a6246df07767373644b1637d91c3a88b1","modified":1660139513790},{"_id":"themes/next/layout/_partials/post/post-followme.swig","hash":"d8f785c062c6b0763a778bd4a252e6f5fee0e432","modified":1660139513785},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"ce712c110b5ce8aacba7a86b0558ff89700675c9","modified":1660139513788},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"7b2ef5db9615267a24b884388925de1e9b447c1f","modified":1660139513790},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"34c05e9d73b0f081db70990c296b6d6a0f8ea2ca","modified":1660139513800},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"34495d408e8467555afee489500b8aad98c52079","modified":1660139513802},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"0b44f400ec00d2b5add5ee96c11d22465c432376","modified":1660139513803},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"0b44f400ec00d2b5add5ee96c11d22465c432376","modified":1660139513804},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"34495d408e8467555afee489500b8aad98c52079","modified":1660139513805},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"91c2cb900c76224c5814eeb842d1d5f517f9bf05","modified":1660139513811},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"84adaadd83ce447fa9da2cff19006334c9fcbff9","modified":1660139513807},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b8819bd056f8a580c5556d4415836a906ed5d7a4","modified":1660139513809},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"9298e6d6c4a62a0862fc0f4060ed99779d7b68cb","modified":1660139513816},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"85b60e222712ca3b2c4dc2039de2dc36b8d82940","modified":1660139513811},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"1b29b99fa921f12c25d3dc95facdf84ef7bb1b5c","modified":1660139513816},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"a42f97eda3748583bac2253c47fe5dfa54f07b8f","modified":1660139513817},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"606ad14a29320157df9b8f33738282c51bb393d9","modified":1660139513818},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"3d91899ca079e84d95087b882526d291e6f53918","modified":1660139513818},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"2642e8aef5afbe23a2a76efdc955dab2ee04ed48","modified":1660139513814},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"ae2707d6e47582bb470c075649ec7bad86a6d5a9","modified":1660139513819},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"fb94ee487d75e484e59b7fba96e989f699ff8a83","modified":1660139513814},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"276f523e414d4aa7f350a8f2fd3df8a3d8ea9656","modified":1660139513822},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"59df21fcfe9d0ada8cee3188cb1075529c1c3eb8","modified":1660139513821},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"1f34b2d3c753a3589ab6c462880bd4eb7df09914","modified":1660139513822},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"fd726aad77a57b288f07d6998ec29291c67c7cbb","modified":1660139513826},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"58296a5c1883f26464c2a5ccf734c19f5fbf395a","modified":1660139513826},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"aa6ab95b8b76611694613defb4bf25003d1b927f","modified":1660139513827},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"619338ddacf01e3df812e66a997e778f672f4726","modified":1660139513834},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"5a223b60406cee7438cfe3a5e41d1284425aa7a5","modified":1660139513834},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"01d94354d07e72cad47100482068b6be69fcc033","modified":1660139513831},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"d2f0e4c598410ec33785abe302c7ea7492bb791a","modified":1660139513829},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"53a0760c75d5aaabb3ce8e8aa8e003510d59807f","modified":1660139513830},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"c171ea94e9afbba97f06856904264da331559463","modified":1660139513832},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"964cd6bac668cf6d211a2624fbef3948cfdece55","modified":1660139513832},{"_id":"themes/next/scripts/events/lib/config.js","hash":"aefe3b38a22bc155d485e39187f23e4f2ee5680a","modified":1660139513844},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"e73f697bb160b223fdde783237148be5f41c1d78","modified":1660139513845},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"08496b71c9939718e7955704d219e44d7109247b","modified":1660139513845},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"2f22f48f7370470cef78561a47c2a47c78035385","modified":1660139513847},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"713056d33dbcd8e9748205c5680b456c21174f4e","modified":1660139513848},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"0c3bea89d64bc12c1bbe6f208a83773c6fb5375a","modified":1660139513848},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"3a80559df0b670ccb065ea9d3bb587d0b61be3a4","modified":1660139513849},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"67cf90d9a2428c14eb113a64bdd213c22a019aef","modified":1660139513850},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"323a47df6ded894944a2647db44556d6163e67c4","modified":1660139513851},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"a4f3153ac76a7ffdf6cc70f52f1b2cc218ed393e","modified":1660139513852},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"851359f5ff90f733a9bd7fe677edbee8b8ac714c","modified":1660139513852},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"583ff1e7a2ca889f1f54eb0ca793894466823c7c","modified":1660139513945},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"5980abbbbeacd8541121f436fa414d24ad5e97c2","modified":1660139513948},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"c22b58af3327236ec54d5706501aa5a20e15012e","modified":1660139513949},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4e33774b1fe6d0a51f3a428c54c5e600e83bf154","modified":1660139513950},{"_id":"themes/next/source/css/_variables/base.styl","hash":"ad680efdfb2f86546182bf3f59886efbcf3c1b2d","modified":1660139513950},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1660139513992},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1660139513994},{"_id":"themes/next/source/js/schemes/muse.js","hash":"a18559a9c332199efad0100cf84bb0c23fc0f17a","modified":1660139513973},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"b85a6e2af1387fe64b51e7cd3e2da8616e6f5a3f","modified":1660139513974},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"2e6a1dfb1e04b60b373b60be9ba9d0191868a09f","modified":1660139513669},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1660139513660},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"7a95c27762e1303bf06ee808c63f616cb192fcaf","modified":1660139513908},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"510a6f0ba7485dd54ce347cca890ab52c4957081","modified":1660139513874},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"a2ee16cac29a82cfce26804c160286fcbee94161","modified":1660139513907},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"0534b329d279a6f255112b3305ff92c810f31724","modified":1660139513874},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"d17236df3b4d6def1e4e81133ef4729c390de3ac","modified":1660139513874},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"c52648a7b09f9fe37858f5694fcc1ffc709ad147","modified":1660139513894},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5540c9259cb7895a5f10a289c7937e5470a7c134","modified":1660139513918},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"45f4badac6ec45cf24355f6157aece1d4d3f1134","modified":1660139513919},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"4b068d0d898f4e624937503f0e1428993050bd65","modified":1660139513919},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"6d740699fb6a7640647a8fd77c4ea4992d8d6437","modified":1660139513923},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"43045d115f8fe95732c446aa45bf1c97609ff2a5","modified":1660139513925},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"b619f39e18398422e0ac4999d8f042a5eaebe9cd","modified":1660139513924},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"f317d2e3886e94f5fbb8781c2e68edd19669ff58","modified":1660139513926},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"20e0e3e3eba384930c022e21511214d244b4c9e7","modified":1660139513929},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"e342b8f8e11a3a6aa5a029912c9778c25bf5d135","modified":1660139513931},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"b9e87d32da24264bda247c1526afe140c858b0ef","modified":1660139513932},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"12b265f82840f27112ca2b1be497677f20f87545","modified":1660139513932},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"716e8b0f056bf6393e6bc6969ac84598ab8e7a6f","modified":1660139513933},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"558794fced306339b98dc2b0ee7f0576802f1355","modified":1660139513940},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"c5142739e01e9f25c8b32b2209af85c787bb2b42","modified":1660139513934},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"e1c29b81a32273a0dedd926cda199a71aea72624","modified":1660139513933},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5de34e1d8a290751641ae456c942410852d5e809","modified":1660139513941},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"dc9318992ce2eb086ebaa2fe56b325e56d24098b","modified":1660139513943},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"0a9f0d9eb042595502d200fb8c65efb0e6c89aa9","modified":1660139513941},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"b69ac38b9da8c9c1b7de696fdeea7f9d7705213a","modified":1660139513944},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"25c2a7930da14f023329df20f38df2728057fb4d","modified":1660139513944},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"8674bd88df076a1dfe4023ed6750ded1f5b00223","modified":1660139513935},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"49c76bc723d3952abb613d9d68398ed7305da999","modified":1660139513936},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4b7f057dbb53efd7cbe7eac7835a793ab3cbb135","modified":1660139513937},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"9898323ee5a7ac2a5d4f633c653112280beb2643","modified":1660139513937},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"2d3e05015796a790abd9d68957a5c698c0c9f9b6","modified":1660139513938},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"25c2a7930da14f023329df20f38df2728057fb4d","modified":1660139513940},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","hash":"82e34d28f8a1169b20b60101d5bb0446deba3514","modified":1660139513982},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1660139513985},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1660139513984},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1660139513988},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"2e6a1dfb1e04b60b373b60be9ba9d0191868a09f","modified":1660139513660},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"b31c86d1a4f89837f9187bed646bda96b2cd286c","modified":1660139513902},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"6d5f26646e2914474f295de8bf6dc327d4acd529","modified":1660139513904},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"300058ca12e81013e77ba01fe66ac210525768b6","modified":1660139513903},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"b4f4bae437d4f994af93cf142494ffcd86bae46b","modified":1660139513902},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"3d16ac0f4ccaeed868c246d4d49bde543d1f62cb","modified":1660139513905},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"7a3a56b10ab714c0e2ed240d0939deeecdcad167","modified":1660139513904},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"7eeb22c5696f8e0c95161dc57703973cf81c8c12","modified":1660139513901},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b8c816fba0a9b4a35fbae03ba5b1b2da96ba2687","modified":1660139513906},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"357f825f0a649b2e28cba1481d4c9a0cb402e43a","modified":1660139513911},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"49722d555a2edb18094bb2cb3d7336dd72051b93","modified":1660139513910},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"096f908c08ce553e482aadfd3e767a0145191093","modified":1660139513912},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"525242ce9e912c4adfe5134347c67dbdb9e98e3d","modified":1660139513912},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"12f7eaf6b56624cbc411528562d6bb848ff97039","modified":1660139513913},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"fa0a2ea57b7b4ce75b5d18c264af2d92ea3192f9","modified":1660139513915},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"b11b04737a1a0fea3bd9f0081d96ee6c015358d4","modified":1660139513914},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"098b4bdf49c7300490f959386d5d1185a32543f6","modified":1660139513915},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"5d540f683018745a5ed1d6f635df28ea610c1244","modified":1660139513915},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"67a1fcb33535122d41acd24f1f49cf02c89b88fa","modified":1660139513917},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"236a039b0900f4267de566b46f62314ad967d30f","modified":1660139513878},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"6cf78a379bb656cc0abb4ab80fcae60152ce41ad","modified":1660139513879},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"18edddb2ffb3f85a68e4367f81e06c461e07bc25","modified":1660139513878},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"97974c231b4659b8aa5e9321c4d54db5c816d0db","modified":1660139513881},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"a52f8cae599099231866298ed831fdf76c9b6717","modified":1660139513881},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"f6f05f02d50f742c84ee5122016c0563a8bb2cf9","modified":1660139513879},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"9af620eba5ccceea21a0e3bc69f6f1fa7637c2f3","modified":1660139513881},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"70b3eb9d36543ab92796ac163544e9cf51b7c1e6","modified":1660139513884},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"57b9a179675f1536e017cba457b6ac575e397c4f","modified":1660139513885},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"97dec98d0403097d66822f1c90b50b2890c84698","modified":1660139513885},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"93ba8172c0d2c37d738e6dbd44fcd5a2e23b92f3","modified":1660139513887},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"2c24829d95c742eb9e8316ebf2fbe9f2c168b59a","modified":1660139513888},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"0dfb97703a519d9438f64f9e41ab1dd37381f733","modified":1660139513886},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"09dda2667628d1f91b2e37d8fc6df1413f961b64","modified":1660139513889},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"66fc406796b6efe6cea76550573b7a632112406a","modified":1660139513888},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5cc9e7394c927065c688cba5edd6e0a27587f1d8","modified":1660139513890},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"fcd64c23d17775b3635325f6758b648d932e79b5","modified":1660139513893},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"b87f4a06c0db893df4f756f24be182e1a4751f24","modified":1660139513894},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"b266d2ce5e2b117be01537889e839a69004dc0bb","modified":1660139513891},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"8ed7a9d5dfac592de703421b543978095129aa5b","modified":1660139513897},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1f6b0d3ab227697ca115e57fd61122ea7950e19d","modified":1660139513899},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"d83102771df652769e51ddfd041cf5f4ca1a041d","modified":1660139513896},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"bad99f4cccb93b3cefe990a2c85124e60698d32e","modified":1660139513897},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"4079e616fbf36112dec0674c1e0713d1d9769068","modified":1660139513920},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"80488259271bcfe38031f4c2e902463daba9336b","modified":1660139513921},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"83bd737f663a8461e66985af8ddbfc0a731fc939","modified":1660139513921},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"c911045b2ce9a66e38d9dd30c7ed078abbc10cbf","modified":1660139513923},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"aca7bb220fc14ef2a8f96282d2a95a96a9238d46","modified":1660139513926},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"03a5bcecc0b12231462ef6ffe432fa77ee71beff","modified":1660139513928},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"8b7aafb911850c73074cdb6cc87abe4ac8c12e99","modified":1660139513927},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"adaf0f580fccf4158169eeaf534a18005b39a760","modified":1660139513928},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"ceacfa6218f6084c71a230b086e5d2708d29927e","modified":1660139513926},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"3256e39f281f06751a1c0145d9806a0e56d68170","modified":1660139513928},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"51d46fa3c7c6b691c61a2c2b0ac005c97cfbf72b","modified":1660139513929},{"_id":"themes/next/.git/objects/pack/pack-eceb874ccc1663233238cf9fdbbbe476e5814c5a.idx","hash":"27bd61b317020f3c1e9cd8535d127e168b33fe00","modified":1660139513551},{"_id":"themes/next/.git/objects/pack/pack-eceb874ccc1663233238cf9fdbbbe476e5814c5a.pack","hash":"292dda6189d346699757288aaeaf5d922d2f3bd7","modified":1660139513543},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1660144216818},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1660144216818},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1660144216818},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1660144216818},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1660144216818},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1660144216818},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1660144216818},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1660144216818},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1660144216818},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1660144216818},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1660144216818},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1660144216818},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1660144216818},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1660144216818},{"_id":"public/css/main.css","hash":"0b27fbc94375b556591188df438ab1bcca4a2d50","modified":1660144216818},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1660144216818},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1660144216818},{"_id":"public/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1660144216818},{"_id":"public/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1660144216818},{"_id":"public/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1660144216818},{"_id":"public/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1660144216818},{"_id":"public/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1660144216818},{"_id":"public/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1660144216818},{"_id":"public/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1660144216818},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1660144216818},{"_id":"public/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1660144216818},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1660144216818},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1660144216818},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1660144216818}],"Category":[{"name":"编程语言","_id":"cl6mbc11i0002igu8aorsae0e"},{"name":"编程实践","_id":"cl6mbc11z0007igu8f851dyc6"},{"name":"工具篇","_id":"cl6mbc129000digu8a8972l4u"},{"name":"操作系统","_id":"cl6mbc12t000qigu8brjdhe8g"},{"name":"网络安全","_id":"cl6mbc1330014igu8lmd5euz4"},{"name":"职场感悟","_id":"cl6mbc13a001digu822mcfrjx"},{"name":"计算机网络","_id":"cl6mbc13h001qigu87zjfcchw"},{"name":"算法","_id":"cl6mbc13q0025igu87o476n81"},{"name":"数据库","_id":"cl6mbc148002xigu8vp3r7m51"},{"name":"系统设计","_id":"cl6mbc14e0036igu85zusy7y0"},{"name":"分布式系统","_id":"cl6mbc14j003figu8fuadmhca"},{"name":"数据结构","_id":"cl6mbc14u003vigu89075fcxo"}],"Data":[],"Page":[{"title":"tags","date":"2018-06-07T05:41:06.000Z","type":"tags","_content":"\n\n","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-06-07 13:41:06\ntype: \"tags\"\n---\n\n\n","updated":"2022-08-09T15:02:00.688Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cl6mbc16i0072igu8w79gvarp","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2020-04-12T03:15:52.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2020-04-12 11:15:52\ntype: \"categories\"\ncomments: false\n---\n","updated":"2022-08-09T15:02:00.688Z","path":"categories/index.html","layout":"page","_id":"cl6mbc16l0074igu8jelhff5i","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"layout":"post","title":"《C++ Primer v5》读书笔记","date":"2015-11-23T12:31:00.000Z","comments":1,"_content":"\n《C++ Primer v5》的读书笔记。\n\n<!--more-->\n\n## CHAPTER 1 GETTING STARTED\n\n- Variable type: when we wrote`T t`, we sayed that \"t has type T\", or \"t is a T\"\n- gcc/g++ warning all options: `-Wall` for *nix, `/W4` for windows\n- Flush the stream: we should always put `std::cout << std::endl;` at the end of `std::cout` to flush the stream of std-out, or else it won't output immediately\n- Left operating left: `std::cout << \"text 1\" << \" and text 2\" << std::endl;` equals to\n```c++\nstd::cout << \"text 1\";\nstd::cout << \" and text 2\";\nstd::cout << std:endl;\n```\n\n<!--more-->\n\n- istream hits invalid state: `while (std::cin >> value)` will end at\n\t1. hit the **end-of-file**\n\t1. encounter an invalid input, such as reading a value is not a integer\n\n## CHAPTER 2 VARIABLES AND BASIC TYPES\n\n### Primitive built-in types\n\n- Signed and unsigned types\n\t1. except for bool and extended character types, the integral types may be signed or unsigned(float is not integral types)\n\t1. there are three character types (two in real usage): char, signed char and unsigned char\n\t\t- char is signed in some machine and unsiged in others\n\t1. use an unsigned when you are sure of it's usage\n\t1. don't use plain char or bool in arithmetic experssions\n\t1. double is better for float, float has not enough precison and in some machines double computation is faster than float\n\n- Type conversions\n\t1. when assign a float to int, \n\t\t- the fractional part of float is truncated as temp\n\t\t- give temp to the int mentioned above\n\t1. when assign an out-of-value to unsigned type, the lower bits doesn't change, the higher bit out-of-range is truncated, this is same to modulo\n\t1. when assign an out-of-value to signed type, the result is undefined\n\n### Variables\n\n- List initialization\n```c++\nint sold = 0;   // ok\nint sold = {0}; // ok\nint sold{0};    // ok\nint sold(0);    // ok\nint sold(1d);   // ok but truncated\nint sold{1d};   // error:narrowing conversation required\n```\n\n- Default initialization: built-in type defined outside any function body are initialized to zero, inside the function is uninitialized\n\n- declaration and definition are different\n\t1. declaration secifies the type and name of a variable\n\t1. definition inits the variable\n\t1. to use the same variable in multiple files, you must only have one definition and multi declaration\n```c++\n// declaration but not definition, must be outside the function\nextern int j; \n// declaration and definition\nint j;        \n// only definition, declaration is override, must be outside the function\nextern double pi = 3.14; \n```\n\n- illegal variable names\n```c++\nint __a; // contains 2 underscores\nint _Ab; // start with underscore, and follow with a upper letter immediately\n```\n\n- get variables outer scope\n```c++\nstd::cout << ::reused << std::endl; // use '::'\n```\n\n### Compound Types\n\n- Reference: \n\t1. a reference to object, it's not an object\n\t1. must be initialized, can't re-bind\n```c++\nint val1 = 1024;\ndouble val2 = 123;\nint &relVal1 = val1; // ok\nint &relVal2;        // error, must be init\nint &relVal3 = val2; // error, type error\n```\n\n- Pointers\n\t- different to reference\n\t\t1. it's an object\n\t\t1. can be rebind\n\t\t1. needn't initialized when defined\n\t\t1. like built-in types, it has undefined value in function if it's not defined\n\t- pointer value state\n\t\t1. point to an object\n\t\t1. point to the location just immediately past the end of an object (illegal pointer)\n\t\t1. null pointer\n\t\t1. invalid pointer (not initialized)\n\t- special\n\t\t1. same type valid pointers can use in comparation (address compare)\n\t\t1. void pointers\n\t\t\t- can compare to another pointer\n\t\t\t- pass or return it from a function\n\t\t\t- assign it to another void* pointer\n\t\t1. define two pointer in a line: `int *p1, *p2`, '*' only works for the variable name\n\t\t1. reference to pointers (example below)\n\n```c++\n// normal\ndouble val = 123;\ndouble *pd1 = &val; \n             // ok, give the pointer itself a new value\nint *pd2 = &val;    // error, types differ\npd2 = pd1;   // error, types differ\npd1 = val;   // error, can't assign object to pointer\n\n// special\nint *p1, p2; // only p1 is pointer\nint i=0;\nint *p;\nint *&r = p; // read from right to left: r is a reference to pointer\nr = &i;\n*r = 0;      // set i to 0\n```\n\n### const Qualifer\n\n- local to file\n\t1. default internal linkage in C++\n\t\t- if we define `const int ivv = 0` in source file, and `extern const int ivv` in header file, 'ivv' only works in that source file, this is the so-called 'local-to-file', differ to the normal case\n\t\t- to use 'ivv' in multi files, we should declare `extern const int ivv` in header file, and define `extern const int ivv = 0` in source file\n\t1. default external linkage in C\n\t\t- in C, const variable's scope is the same to normal case\n\n- reference to const\n\t1. const reference to const object/normal/plain/expression/double, means read only\n\t1. if reference to double, it's a tempory value, if the origin double changes, the reference to const will never know that\n```c++ \n// ok initialization\nconst int ci = 1024;\nint i = 1024;\ndouble dval = 3.14;\nconst int &r1 = ci; // from const object\nconst int &r2 = i;  // from normal int\nconst int &r3 = 12; // from plain int\nconst int &r4 = r1 * 2; // from expression\nconst int &r5 = dval; // dval --> temp int --> r5\n// error case\nr1 = 123; // can't rebind\nint &r6 = ci; // only const reference can reference to const object\n```\n\n- pointer to const(**can't change the memory the address points to**)\n\t1. similar to 'reference to const', it stores the address of a object and has read access but not write access to the address\n\t1. **can rebind**\n\n- const pointers(**can't change the address**)\n\t1. can't rebind, must be initialized at first time\n\t1. itself const, always point to the same address\n\t1. **can change the address's real value**\n```c++\nint errNumb = 0;\nint *const curErr = &errNumb; // const pointers\nconst int *curPnt = &errNumb; // pointer to const\nconst int i = 123;\nconst int *const curNor = &i; // a const pointer to a const int\n```\n\n- top-level & low-level const\n\t1. top-level: itself const, const objects(pointers)\n\t1. low-level: pointer or reference to const\n\t1. when we copy a object, top-level is ignored and low-level will never be ignored\n```c++\nconst int a = 0;\nint b = a; // ok: top-level ignore\nint const *m = 0;\nint *n = m; // error: low-level can't be ignore\n```\n\n- constexpr:**applies to the pointer** but not the type to which the pointer points\n```c++\nconst int *p = 0; // pointer to const\nconstexpr int *q = 0; // a const pointer to int\n```\n\n### Dealing with type\n\n- type alias\n\t1. typedef is the alias of an object\n```c++\ntypedef double wages; // `wages` is same to double\nusing wages = double;\n// pointer\ntypedef char *pstring; // pstring is an object: char*, pointer to char\nconst pstring cstr = 0; // same to `const (char*) cstr = 0`, cstr is a const pointer to char\n```\n\n- auto: automatically determines the type, **ignores the top-level**\n- decltype: similar to auto, but **top-level is keeped**\n\t1. decltype((v)) is always a reference type\n```c++\nconst int i = 0;\nauto a = i; // normal int \ndecltype(i) b = 0; // const int\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n## CHAPTER 3 STRINGS, VECTORS, AND ARRAYS\n\n### Namespace using Declarations\n\n```c++\n// main.cpp\nusing std::cout; // 只使用于本源文件，引入另外一个命名空间的成员到当前作用域\nint main(){\n    cout << \"hello\" << endl;\n    return 0;\n}\n```\n\n<!--more-->\n\n### Library string Type\n\n使用前提：\n\n- 头文件引入：`#include <string>`\n- 作用域引入：`using std::string`\n\n#### 定义\n\n```c++\n// 默认实例化为空\nstring s1;\n// 直接实例化为指定值\nstring s1(10, 'c');\nstring s2(\"haha\");\n// 复制实例化\nstring s3 = \"haha\";\n```\n\n#### 字符串操作\n\n几个特殊的字符串操作举例如下：\n\n- 输入和输出\n\n```c++\nstring word;\nwhile(cin >> word) // is>>s，返回is\n    cout << word << endl; // os << s，返回os\nwhile(getline(cin, word)) // 返回is\n    cout << word << endl;\n```\n- 比较：比较从左到右第一个不同的字符的ASCII值，如从左到右无不同字符则长度较长的字符串大\n```c++\n// s2大s1，s3大于前两个字符串\nstring s1 = \"hello\";\nstring s2 = \"hello, world\";\nstring s3 = \"hexo\";\n```\n- size()\n```c++\nstring s1;\nauto size = s1.size(); // string::size_type，一个无符号整型\n```\n- 拼接\n```c++\n// string类型间可自由拼接\nstring s1 = \"t\";\nstring s2 = \"x\";\ns1 += s2;\n// string和literals\nstring s3 = \"t\" + \"x\"; // error：字面量不可相加\nstring s4 = \"t\" + s1 + \"x\"; // 合法，运算顺序从左到右\n```\n\n#### 处理字符串内的字符\n\n一共有两类操作，\n\n- 字符串遍历（copy和reference）\n- 数组下标（reference）\n\n```c++\nstring s1 = \"test\";\n// 字符串遍历\nfor(auto c : s1) // c是copy，改变c的值不影响字符串\n    // do sth\nfor(auto &c : s1) // c是reference\n    // do sth\ns1[0] = 'y'; // 引用第0个数组下标的字符\n```\n\n### Library vector Type\n\n使用前提：\n- 头文件引入：`#include <vector>`\n- 作用域引入：`using std::vector`\n\n#### 定义\n\n*注意括号和花括号的不同*：\n```c++\n// 默认实例化为空\nvector<string> v1; \n// 指定元素数量\nvector<int> v2(10); // 10个0\nvector<int> v3(10, 1); // 10个1\n// 列表实例化\nvector<int> {10, 1}; // 10和1两个元素\n```\n\n#### 操作\n\n注意：\n\n- 数组下标可操作vector的尺寸之外的元素如`vector[size+1] = 3`，但这并不会向vector新增一个元素，而且会产生越界异常\n```c++\nvector<int> v1(10, 1);\nv1.push_back(2); // 插入\nv1[0] = 3; // 数组下标引用\nv1.size(); // vector::size_type\n// 比较操作需要装相同元素，且相同元素间可比较\n```\n\n### Introducing Iterators\n\n#### 定义\n\nstring有两种iterator类型，指向某个具体字符：\n\n- string::iterator指向的元素可读写\n- string::const_iterator指向的元素只可以读\n\nvector有两种iterator类型，指向某个具体元素：\n\n- vector::iterator\n- vector::const_iterator\n\n```c++\nstring s1(\"123\");\nauto i1 = s1.begin(); // 指向第一个元素\nauto i2 = s1.end(); // 指向最后一个元素的尾部\nauto i3 = s1.cbegin(); // 只可读\n```\n\n#### 操作\n\n常用操作如下：\n```c++\nvector s1{\"123\"};\nauto i1 = s1.begin();\n*i1 = \"345\"; // dereference，取得引用\n(*i1).size(); // 调用第一个元素的成员size()\n*i1.size(); // error：调用顺序是*(i1.size())\ni1++; // 可进行加减运算，指向不同成员\n// 比较运算符规则：出现在容器前面的元素较小\n```\n\n注意：在使用iterator遍历vector时不能使用push_back，它会使得之前指向它的iterator都无效\n\n### Arrays\n\n#### 定义\n\n```c++\n// 默认实例化\nint arr[10]; // 10个int值，在函数外int值默认为0，函数内int值为undefined，与built-in类型的默认值规则相同\n// 显示实例化\nint arr2[10] = {0, 1, 2}; // 后七个元素的值同上\n// 字符数组\nchar c1[] = \"C++\"; // 共4个元素，最后一个为'\\0'\n// 不能复制和赋值\nint arr3 [] = arr; // error\narr2 = arr; // error\n// 复杂的定义\nint *ptr[10]; // ptr是一个数组，该数组含有10个int型指针\nint (*ptr)[10]; // ptr是一个指针，指向含有10个int元素的数组\n```\n\n#### 操纵数组\n\n1. 使用数组下标\n2. 使用for-each，如`for(auto tmp : arr)或for(auto &tmp : arr)`\n\n#### 数组与指针\n\n- 数组名指向第一个元素\n```c++\nstring nums[] = {\"one\", \"two\", \"three\"};\n// 下面两个式子等效\nstring *ptr = nums;\nptr = &nums[0];\n```\n\n- auto和decltype具有不同效果\n```c++\nint ia[] = {1,2,3};\nauto ia2(ia); // 等效于&ia[0]\ndecltype(ia) ia3 = {4,5,6}; // 具有与ia一样的类型\n```\n\n- 指针与数组\n```c++\nint arr[] = {1,2,3};\nint *ptr = 0; // 指针状态1：空指针\nptr = arr; // 指针状态2：指向某个对象\nptr = arr[3]; // 指针状态3：指向一块内存的结束地址，指针本身有效，不能使用*号取值\nptr = arr[4]; // 指针状态4：这是一个无效的指针，指针地址未定义，不能使用*号取值\n```\n\n- begin和end函数取数组首尾\n```c++\nint ia[] = {1,2,3};\nint *begin = begin(ia);\nint *end = end(ia);\nvector<int> ivec(begin(ia), end(ia)); // 将ia的内容复制到ivec\n```\n\n- 数组指针运算\n    - 指向相同数组的指针才可使用关系运算符；\n    - built-in数组指针下标可使用负数，如：`p[-2]`，p指向一个数组的元素；vector等library type的数组下标必须是正数；\n\n#### c类型字符串\n\n```c++\nstring s = \"c++\"; // 可使用c类型字符串为string类型赋值\nconst char *str = s; // error：反之则不行，应使用s.c_str()\n```\n\n### 多维数组\n\n```c++\nint ia[3][4];\n// 指针p为类型int (*p)[4]，指向含有4个int的数组\nfor(auto p = begin(ia); p != end(ia); ++p) {\n    // q指向int[4]的第一个元素\n    for(auto q = begin(*p); q != end(*p); ++q) {\n        cout << *q << '';\n    } \n}\n```\n","source":"_posts/2015-11-23-cplusplus-primer-v5.markdown","raw":"---\nlayout: post\ntitle: 《C++ Primer v5》读书笔记\ndate: '2015-11-23 20:31'\ncomments: true\ncategories: ['编程语言']  \ntags: ['C/C++']\n---\n\n《C++ Primer v5》的读书笔记。\n\n<!--more-->\n\n## CHAPTER 1 GETTING STARTED\n\n- Variable type: when we wrote`T t`, we sayed that \"t has type T\", or \"t is a T\"\n- gcc/g++ warning all options: `-Wall` for *nix, `/W4` for windows\n- Flush the stream: we should always put `std::cout << std::endl;` at the end of `std::cout` to flush the stream of std-out, or else it won't output immediately\n- Left operating left: `std::cout << \"text 1\" << \" and text 2\" << std::endl;` equals to\n```c++\nstd::cout << \"text 1\";\nstd::cout << \" and text 2\";\nstd::cout << std:endl;\n```\n\n<!--more-->\n\n- istream hits invalid state: `while (std::cin >> value)` will end at\n\t1. hit the **end-of-file**\n\t1. encounter an invalid input, such as reading a value is not a integer\n\n## CHAPTER 2 VARIABLES AND BASIC TYPES\n\n### Primitive built-in types\n\n- Signed and unsigned types\n\t1. except for bool and extended character types, the integral types may be signed or unsigned(float is not integral types)\n\t1. there are three character types (two in real usage): char, signed char and unsigned char\n\t\t- char is signed in some machine and unsiged in others\n\t1. use an unsigned when you are sure of it's usage\n\t1. don't use plain char or bool in arithmetic experssions\n\t1. double is better for float, float has not enough precison and in some machines double computation is faster than float\n\n- Type conversions\n\t1. when assign a float to int, \n\t\t- the fractional part of float is truncated as temp\n\t\t- give temp to the int mentioned above\n\t1. when assign an out-of-value to unsigned type, the lower bits doesn't change, the higher bit out-of-range is truncated, this is same to modulo\n\t1. when assign an out-of-value to signed type, the result is undefined\n\n### Variables\n\n- List initialization\n```c++\nint sold = 0;   // ok\nint sold = {0}; // ok\nint sold{0};    // ok\nint sold(0);    // ok\nint sold(1d);   // ok but truncated\nint sold{1d};   // error:narrowing conversation required\n```\n\n- Default initialization: built-in type defined outside any function body are initialized to zero, inside the function is uninitialized\n\n- declaration and definition are different\n\t1. declaration secifies the type and name of a variable\n\t1. definition inits the variable\n\t1. to use the same variable in multiple files, you must only have one definition and multi declaration\n```c++\n// declaration but not definition, must be outside the function\nextern int j; \n// declaration and definition\nint j;        \n// only definition, declaration is override, must be outside the function\nextern double pi = 3.14; \n```\n\n- illegal variable names\n```c++\nint __a; // contains 2 underscores\nint _Ab; // start with underscore, and follow with a upper letter immediately\n```\n\n- get variables outer scope\n```c++\nstd::cout << ::reused << std::endl; // use '::'\n```\n\n### Compound Types\n\n- Reference: \n\t1. a reference to object, it's not an object\n\t1. must be initialized, can't re-bind\n```c++\nint val1 = 1024;\ndouble val2 = 123;\nint &relVal1 = val1; // ok\nint &relVal2;        // error, must be init\nint &relVal3 = val2; // error, type error\n```\n\n- Pointers\n\t- different to reference\n\t\t1. it's an object\n\t\t1. can be rebind\n\t\t1. needn't initialized when defined\n\t\t1. like built-in types, it has undefined value in function if it's not defined\n\t- pointer value state\n\t\t1. point to an object\n\t\t1. point to the location just immediately past the end of an object (illegal pointer)\n\t\t1. null pointer\n\t\t1. invalid pointer (not initialized)\n\t- special\n\t\t1. same type valid pointers can use in comparation (address compare)\n\t\t1. void pointers\n\t\t\t- can compare to another pointer\n\t\t\t- pass or return it from a function\n\t\t\t- assign it to another void* pointer\n\t\t1. define two pointer in a line: `int *p1, *p2`, '*' only works for the variable name\n\t\t1. reference to pointers (example below)\n\n```c++\n// normal\ndouble val = 123;\ndouble *pd1 = &val; \n             // ok, give the pointer itself a new value\nint *pd2 = &val;    // error, types differ\npd2 = pd1;   // error, types differ\npd1 = val;   // error, can't assign object to pointer\n\n// special\nint *p1, p2; // only p1 is pointer\nint i=0;\nint *p;\nint *&r = p; // read from right to left: r is a reference to pointer\nr = &i;\n*r = 0;      // set i to 0\n```\n\n### const Qualifer\n\n- local to file\n\t1. default internal linkage in C++\n\t\t- if we define `const int ivv = 0` in source file, and `extern const int ivv` in header file, 'ivv' only works in that source file, this is the so-called 'local-to-file', differ to the normal case\n\t\t- to use 'ivv' in multi files, we should declare `extern const int ivv` in header file, and define `extern const int ivv = 0` in source file\n\t1. default external linkage in C\n\t\t- in C, const variable's scope is the same to normal case\n\n- reference to const\n\t1. const reference to const object/normal/plain/expression/double, means read only\n\t1. if reference to double, it's a tempory value, if the origin double changes, the reference to const will never know that\n```c++ \n// ok initialization\nconst int ci = 1024;\nint i = 1024;\ndouble dval = 3.14;\nconst int &r1 = ci; // from const object\nconst int &r2 = i;  // from normal int\nconst int &r3 = 12; // from plain int\nconst int &r4 = r1 * 2; // from expression\nconst int &r5 = dval; // dval --> temp int --> r5\n// error case\nr1 = 123; // can't rebind\nint &r6 = ci; // only const reference can reference to const object\n```\n\n- pointer to const(**can't change the memory the address points to**)\n\t1. similar to 'reference to const', it stores the address of a object and has read access but not write access to the address\n\t1. **can rebind**\n\n- const pointers(**can't change the address**)\n\t1. can't rebind, must be initialized at first time\n\t1. itself const, always point to the same address\n\t1. **can change the address's real value**\n```c++\nint errNumb = 0;\nint *const curErr = &errNumb; // const pointers\nconst int *curPnt = &errNumb; // pointer to const\nconst int i = 123;\nconst int *const curNor = &i; // a const pointer to a const int\n```\n\n- top-level & low-level const\n\t1. top-level: itself const, const objects(pointers)\n\t1. low-level: pointer or reference to const\n\t1. when we copy a object, top-level is ignored and low-level will never be ignored\n```c++\nconst int a = 0;\nint b = a; // ok: top-level ignore\nint const *m = 0;\nint *n = m; // error: low-level can't be ignore\n```\n\n- constexpr:**applies to the pointer** but not the type to which the pointer points\n```c++\nconst int *p = 0; // pointer to const\nconstexpr int *q = 0; // a const pointer to int\n```\n\n### Dealing with type\n\n- type alias\n\t1. typedef is the alias of an object\n```c++\ntypedef double wages; // `wages` is same to double\nusing wages = double;\n// pointer\ntypedef char *pstring; // pstring is an object: char*, pointer to char\nconst pstring cstr = 0; // same to `const (char*) cstr = 0`, cstr is a const pointer to char\n```\n\n- auto: automatically determines the type, **ignores the top-level**\n- decltype: similar to auto, but **top-level is keeped**\n\t1. decltype((v)) is always a reference type\n```c++\nconst int i = 0;\nauto a = i; // normal int \ndecltype(i) b = 0; // const int\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n## CHAPTER 3 STRINGS, VECTORS, AND ARRAYS\n\n### Namespace using Declarations\n\n```c++\n// main.cpp\nusing std::cout; // 只使用于本源文件，引入另外一个命名空间的成员到当前作用域\nint main(){\n    cout << \"hello\" << endl;\n    return 0;\n}\n```\n\n<!--more-->\n\n### Library string Type\n\n使用前提：\n\n- 头文件引入：`#include <string>`\n- 作用域引入：`using std::string`\n\n#### 定义\n\n```c++\n// 默认实例化为空\nstring s1;\n// 直接实例化为指定值\nstring s1(10, 'c');\nstring s2(\"haha\");\n// 复制实例化\nstring s3 = \"haha\";\n```\n\n#### 字符串操作\n\n几个特殊的字符串操作举例如下：\n\n- 输入和输出\n\n```c++\nstring word;\nwhile(cin >> word) // is>>s，返回is\n    cout << word << endl; // os << s，返回os\nwhile(getline(cin, word)) // 返回is\n    cout << word << endl;\n```\n- 比较：比较从左到右第一个不同的字符的ASCII值，如从左到右无不同字符则长度较长的字符串大\n```c++\n// s2大s1，s3大于前两个字符串\nstring s1 = \"hello\";\nstring s2 = \"hello, world\";\nstring s3 = \"hexo\";\n```\n- size()\n```c++\nstring s1;\nauto size = s1.size(); // string::size_type，一个无符号整型\n```\n- 拼接\n```c++\n// string类型间可自由拼接\nstring s1 = \"t\";\nstring s2 = \"x\";\ns1 += s2;\n// string和literals\nstring s3 = \"t\" + \"x\"; // error：字面量不可相加\nstring s4 = \"t\" + s1 + \"x\"; // 合法，运算顺序从左到右\n```\n\n#### 处理字符串内的字符\n\n一共有两类操作，\n\n- 字符串遍历（copy和reference）\n- 数组下标（reference）\n\n```c++\nstring s1 = \"test\";\n// 字符串遍历\nfor(auto c : s1) // c是copy，改变c的值不影响字符串\n    // do sth\nfor(auto &c : s1) // c是reference\n    // do sth\ns1[0] = 'y'; // 引用第0个数组下标的字符\n```\n\n### Library vector Type\n\n使用前提：\n- 头文件引入：`#include <vector>`\n- 作用域引入：`using std::vector`\n\n#### 定义\n\n*注意括号和花括号的不同*：\n```c++\n// 默认实例化为空\nvector<string> v1; \n// 指定元素数量\nvector<int> v2(10); // 10个0\nvector<int> v3(10, 1); // 10个1\n// 列表实例化\nvector<int> {10, 1}; // 10和1两个元素\n```\n\n#### 操作\n\n注意：\n\n- 数组下标可操作vector的尺寸之外的元素如`vector[size+1] = 3`，但这并不会向vector新增一个元素，而且会产生越界异常\n```c++\nvector<int> v1(10, 1);\nv1.push_back(2); // 插入\nv1[0] = 3; // 数组下标引用\nv1.size(); // vector::size_type\n// 比较操作需要装相同元素，且相同元素间可比较\n```\n\n### Introducing Iterators\n\n#### 定义\n\nstring有两种iterator类型，指向某个具体字符：\n\n- string::iterator指向的元素可读写\n- string::const_iterator指向的元素只可以读\n\nvector有两种iterator类型，指向某个具体元素：\n\n- vector::iterator\n- vector::const_iterator\n\n```c++\nstring s1(\"123\");\nauto i1 = s1.begin(); // 指向第一个元素\nauto i2 = s1.end(); // 指向最后一个元素的尾部\nauto i3 = s1.cbegin(); // 只可读\n```\n\n#### 操作\n\n常用操作如下：\n```c++\nvector s1{\"123\"};\nauto i1 = s1.begin();\n*i1 = \"345\"; // dereference，取得引用\n(*i1).size(); // 调用第一个元素的成员size()\n*i1.size(); // error：调用顺序是*(i1.size())\ni1++; // 可进行加减运算，指向不同成员\n// 比较运算符规则：出现在容器前面的元素较小\n```\n\n注意：在使用iterator遍历vector时不能使用push_back，它会使得之前指向它的iterator都无效\n\n### Arrays\n\n#### 定义\n\n```c++\n// 默认实例化\nint arr[10]; // 10个int值，在函数外int值默认为0，函数内int值为undefined，与built-in类型的默认值规则相同\n// 显示实例化\nint arr2[10] = {0, 1, 2}; // 后七个元素的值同上\n// 字符数组\nchar c1[] = \"C++\"; // 共4个元素，最后一个为'\\0'\n// 不能复制和赋值\nint arr3 [] = arr; // error\narr2 = arr; // error\n// 复杂的定义\nint *ptr[10]; // ptr是一个数组，该数组含有10个int型指针\nint (*ptr)[10]; // ptr是一个指针，指向含有10个int元素的数组\n```\n\n#### 操纵数组\n\n1. 使用数组下标\n2. 使用for-each，如`for(auto tmp : arr)或for(auto &tmp : arr)`\n\n#### 数组与指针\n\n- 数组名指向第一个元素\n```c++\nstring nums[] = {\"one\", \"two\", \"three\"};\n// 下面两个式子等效\nstring *ptr = nums;\nptr = &nums[0];\n```\n\n- auto和decltype具有不同效果\n```c++\nint ia[] = {1,2,3};\nauto ia2(ia); // 等效于&ia[0]\ndecltype(ia) ia3 = {4,5,6}; // 具有与ia一样的类型\n```\n\n- 指针与数组\n```c++\nint arr[] = {1,2,3};\nint *ptr = 0; // 指针状态1：空指针\nptr = arr; // 指针状态2：指向某个对象\nptr = arr[3]; // 指针状态3：指向一块内存的结束地址，指针本身有效，不能使用*号取值\nptr = arr[4]; // 指针状态4：这是一个无效的指针，指针地址未定义，不能使用*号取值\n```\n\n- begin和end函数取数组首尾\n```c++\nint ia[] = {1,2,3};\nint *begin = begin(ia);\nint *end = end(ia);\nvector<int> ivec(begin(ia), end(ia)); // 将ia的内容复制到ivec\n```\n\n- 数组指针运算\n    - 指向相同数组的指针才可使用关系运算符；\n    - built-in数组指针下标可使用负数，如：`p[-2]`，p指向一个数组的元素；vector等library type的数组下标必须是正数；\n\n#### c类型字符串\n\n```c++\nstring s = \"c++\"; // 可使用c类型字符串为string类型赋值\nconst char *str = s; // error：反之则不行，应使用s.c_str()\n```\n\n### 多维数组\n\n```c++\nint ia[3][4];\n// 指针p为类型int (*p)[4]，指向含有4个int的数组\nfor(auto p = begin(ia); p != end(ia); ++p) {\n    // q指向int[4]的第一个元素\n    for(auto q = begin(*p); q != end(*p); ++q) {\n        cout << *q << '';\n    } \n}\n```\n","slug":"cplusplus-primer-v5","published":1,"updated":"2022-08-09T15:02:00.590Z","photos":[],"link":"","_id":"cl6mbc1140000igu8btsx9tt2","content":"<p>《C++ Primer v5》的读书笔记。</p>\n<a id=\"more\"></a>\n<h2 id=\"CHAPTER-1-GETTING-STARTED\"><a href=\"#CHAPTER-1-GETTING-STARTED\" class=\"headerlink\" title=\"CHAPTER 1 GETTING STARTED\"></a>CHAPTER 1 GETTING STARTED</h2><ul>\n<li>Variable type: when we wrote<code>T t</code>, we sayed that “t has type T”, or “t is a T”</li>\n<li>gcc/g++ warning all options: <code>-Wall</code> for *nix, <code>/W4</code> for windows</li>\n<li>Flush the stream: we should always put <code>std::cout &lt;&lt; std::endl;</code> at the end of <code>std::cout</code> to flush the stream of std-out, or else it won’t output immediately</li>\n<li>Left operating left: <code>std::cout &lt;&lt; &quot;text 1&quot; &lt;&lt; &quot; and text 2&quot; &lt;&lt; std::endl;</code> equals to<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"text 1\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\" and text 2\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">std</span>:<span class=\"built_in\">endl</span>;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<!--more-->\n<ul>\n<li>istream hits invalid state: <code>while (std::cin &gt;&gt; value)</code> will end at<ol>\n<li>hit the <strong>end-of-file</strong></li>\n<li>encounter an invalid input, such as reading a value is not a integer</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"CHAPTER-2-VARIABLES-AND-BASIC-TYPES\"><a href=\"#CHAPTER-2-VARIABLES-AND-BASIC-TYPES\" class=\"headerlink\" title=\"CHAPTER 2 VARIABLES AND BASIC TYPES\"></a>CHAPTER 2 VARIABLES AND BASIC TYPES</h2><h3 id=\"Primitive-built-in-types\"><a href=\"#Primitive-built-in-types\" class=\"headerlink\" title=\"Primitive built-in types\"></a>Primitive built-in types</h3><ul>\n<li><p>Signed and unsigned types</p>\n<ol>\n<li>except for bool and extended character types, the integral types may be signed or unsigned(float is not integral types)</li>\n<li>there are three character types (two in real usage): char, signed char and unsigned char<ul>\n<li>char is signed in some machine and unsiged in others</li>\n</ul>\n</li>\n<li>use an unsigned when you are sure of it’s usage</li>\n<li>don’t use plain char or bool in arithmetic experssions</li>\n<li>double is better for float, float has not enough precison and in some machines double computation is faster than float</li>\n</ol>\n</li>\n<li><p>Type conversions</p>\n<ol>\n<li>when assign a float to int, <ul>\n<li>the fractional part of float is truncated as temp</li>\n<li>give temp to the int mentioned above</li>\n</ul>\n</li>\n<li>when assign an out-of-value to unsigned type, the lower bits doesn’t change, the higher bit out-of-range is truncated, this is same to modulo</li>\n<li>when assign an out-of-value to signed type, the result is undefined</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"Variables\"><a href=\"#Variables\" class=\"headerlink\" title=\"Variables\"></a>Variables</h3><ul>\n<li><p>List initialization</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> sold = <span class=\"number\">0</span>;   <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> sold = &#123;<span class=\"number\">0</span>&#125;; <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> sold&#123;<span class=\"number\">0</span>&#125;;    <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">sold</span><span class=\"params\">(<span class=\"number\">0</span>)</span></span>;    <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">sold</span><span class=\"params\">(<span class=\"number\">1</span>d)</span></span>;   <span class=\"comment\">// ok but truncated</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> sold&#123;<span class=\"number\">1</span>d&#125;;   <span class=\"comment\">// error:narrowing conversation required</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Default initialization: built-in type defined outside any function body are initialized to zero, inside the function is uninitialized</p>\n</li>\n<li><p>declaration and definition are different</p>\n<ol>\n<li>declaration secifies the type and name of a variable</li>\n<li>definition inits the variable</li>\n<li>to use the same variable in multiple files, you must only have one definition and multi declaration<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// declaration but not definition, must be outside the function</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">int</span> j; </span><br><span class=\"line\"><span class=\"comment\">// declaration and definition</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> j;        </span><br><span class=\"line\"><span class=\"comment\">// only definition, declaration is override, must be outside the function</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">double</span> pi = <span class=\"number\">3.14</span>;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>illegal variable names</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> __a; <span class=\"comment\">// contains 2 underscores</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> _Ab; <span class=\"comment\">// start with underscore, and follow with a upper letter immediately</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>get variables outer scope</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; ::reused &lt;&lt; <span class=\"built_in\">std</span>::<span class=\"built_in\">endl</span>; <span class=\"comment\">// use '::'</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Compound-Types\"><a href=\"#Compound-Types\" class=\"headerlink\" title=\"Compound Types\"></a>Compound Types</h3><ul>\n<li><p>Reference: </p>\n<ol>\n<li>a reference to object, it’s not an object</li>\n<li>must be initialized, can’t re-bind<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> val1 = <span class=\"number\">1024</span>;</span><br><span class=\"line\"><span class=\"keyword\">double</span> val2 = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> &amp;relVal1 = val1; <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> &amp;relVal2;        <span class=\"comment\">// error, must be init</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> &amp;relVal3 = val2; <span class=\"comment\">// error, type error</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>Pointers</p>\n<ul>\n<li>different to reference<ol>\n<li>it’s an object</li>\n<li>can be rebind</li>\n<li>needn’t initialized when defined</li>\n<li>like built-in types, it has undefined value in function if it’s not defined</li>\n</ol>\n</li>\n<li>pointer value state<ol>\n<li>point to an object</li>\n<li>point to the location just immediately past the end of an object (illegal pointer)</li>\n<li>null pointer</li>\n<li>invalid pointer (not initialized)</li>\n</ol>\n</li>\n<li>special<ol>\n<li>same type valid pointers can use in comparation (address compare)</li>\n<li>void pointers<ul>\n<li>can compare to another pointer</li>\n<li>pass or return it from a function</li>\n<li>assign it to another void* pointer</li>\n</ul>\n</li>\n<li>define two pointer in a line: <code>int *p1, *p2</code>, ‘*’ only works for the variable name</li>\n<li>reference to pointers (example below)</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// normal</span></span><br><span class=\"line\"><span class=\"keyword\">double</span> val = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">double</span> *pd1 = &amp;val; </span><br><span class=\"line\">             <span class=\"comment\">// ok, give the pointer itself a new value</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> *pd2 = &amp;val;    <span class=\"comment\">// error, types differ</span></span><br><span class=\"line\">pd2 = pd1;   <span class=\"comment\">// error, types differ</span></span><br><span class=\"line\">pd1 = val;   <span class=\"comment\">// error, can't assign object to pointer</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// special</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> *p1, p2; <span class=\"comment\">// only p1 is pointer</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *p;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *&amp;r = p; <span class=\"comment\">// read from right to left: r is a reference to pointer</span></span><br><span class=\"line\">r = &amp;i;</span><br><span class=\"line\">*r = <span class=\"number\">0</span>;      <span class=\"comment\">// set i to 0</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"const-Qualifer\"><a href=\"#const-Qualifer\" class=\"headerlink\" title=\"const Qualifer\"></a>const Qualifer</h3><ul>\n<li><p>local to file</p>\n<ol>\n<li>default internal linkage in C++<ul>\n<li>if we define <code>const int ivv = 0</code> in source file, and <code>extern const int ivv</code> in header file, ‘ivv’ only works in that source file, this is the so-called ‘local-to-file’, differ to the normal case</li>\n<li>to use ‘ivv’ in multi files, we should declare <code>extern const int ivv</code> in header file, and define <code>extern const int ivv = 0</code> in source file</li>\n</ul>\n</li>\n<li>default external linkage in C<ul>\n<li>in C, const variable’s scope is the same to normal case</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>reference to const</p>\n<ol>\n<li>const reference to const object/normal/plain/expression/double, means read only</li>\n<li>if reference to double, it’s a tempory value, if the origin double changes, the reference to const will never know that<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ok initialization</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> ci = <span class=\"number\">1024</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> i = <span class=\"number\">1024</span>;</span><br><span class=\"line\"><span class=\"keyword\">double</span> dval = <span class=\"number\">3.14</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r1 = ci; <span class=\"comment\">// from const object</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r2 = i;  <span class=\"comment\">// from normal int</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r3 = <span class=\"number\">12</span>; <span class=\"comment\">// from plain int</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r4 = r1 * <span class=\"number\">2</span>; <span class=\"comment\">// from expression</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r5 = dval; <span class=\"comment\">// dval --&gt; temp int --&gt; r5</span></span><br><span class=\"line\"><span class=\"comment\">// error case</span></span><br><span class=\"line\">r1 = <span class=\"number\">123</span>; <span class=\"comment\">// can't rebind</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> &amp;r6 = ci; <span class=\"comment\">// only const reference can reference to const object</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>pointer to const(<strong>can’t change the memory the address points to</strong>)</p>\n<ol>\n<li>similar to ‘reference to const’, it stores the address of a object and has read access but not write access to the address</li>\n<li><strong>can rebind</strong></li>\n</ol>\n</li>\n<li><p>const pointers(<strong>can’t change the address</strong>)</p>\n<ol>\n<li>can’t rebind, must be initialized at first time</li>\n<li>itself const, always point to the same address</li>\n<li><strong>can change the address’s real value</strong><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> errNumb = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *<span class=\"keyword\">const</span> curErr = &amp;errNumb; <span class=\"comment\">// const pointers</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *curPnt = &amp;errNumb; <span class=\"comment\">// pointer to const</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *<span class=\"keyword\">const</span> curNor = &amp;i; <span class=\"comment\">// a const pointer to a const int</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>top-level &amp; low-level const</p>\n<ol>\n<li>top-level: itself const, const objects(pointers)</li>\n<li>low-level: pointer or reference to const</li>\n<li>when we copy a object, top-level is ignored and low-level will never be ignored<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> b = a; <span class=\"comment\">// ok: top-level ignore</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> <span class=\"keyword\">const</span> *m = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *n = m; <span class=\"comment\">// error: low-level can't be ignore</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>constexpr:<strong>applies to the pointer</strong> but not the type to which the pointer points</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *p = <span class=\"number\">0</span>; <span class=\"comment\">// pointer to const</span></span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> <span class=\"keyword\">int</span> *q = <span class=\"number\">0</span>; <span class=\"comment\">// a const pointer to int</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Dealing-with-type\"><a href=\"#Dealing-with-type\" class=\"headerlink\" title=\"Dealing with type\"></a>Dealing with type</h3><ul>\n<li><p>type alias</p>\n<ol>\n<li>typedef is the alias of an object<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">double</span> wages; <span class=\"comment\">// `wages` is same to double</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> wages = <span class=\"keyword\">double</span>;</span><br><span class=\"line\"><span class=\"comment\">// pointer</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">char</span> *pstring; <span class=\"comment\">// pstring is an object: char*, pointer to char</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> pstring cstr = <span class=\"number\">0</span>; <span class=\"comment\">// same to `const (char*) cstr = 0`, cstr is a const pointer to char</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>auto: automatically determines the type, <strong>ignores the top-level</strong></p>\n</li>\n<li>decltype: similar to auto, but <strong>top-level is keeped</strong><ol>\n<li>decltype((v)) is always a reference type<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> a = i; <span class=\"comment\">// normal int </span></span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(i) b = <span class=\"number\">0</span>; <span class=\"comment\">// const int</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"CHAPTER-3-STRINGS-VECTORS-AND-ARRAYS\"><a href=\"#CHAPTER-3-STRINGS-VECTORS-AND-ARRAYS\" class=\"headerlink\" title=\"CHAPTER 3 STRINGS, VECTORS, AND ARRAYS\"></a>CHAPTER 3 STRINGS, VECTORS, AND ARRAYS</h2><h3 id=\"Namespace-using-Declarations\"><a href=\"#Namespace-using-Declarations\" class=\"headerlink\" title=\"Namespace using Declarations\"></a>Namespace using Declarations</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span>; <span class=\"comment\">// 只使用于本源文件，引入另外一个命名空间的成员到当前作用域</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"hello\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<!--more-->\n<h3 id=\"Library-string-Type\"><a href=\"#Library-string-Type\" class=\"headerlink\" title=\"Library string Type\"></a>Library string Type</h3><p>使用前提：</p>\n<ul>\n<li>头文件引入：<code>#include &lt;string&gt;</code></li>\n<li>作用域引入：<code>using std::string</code></li>\n</ul>\n<h4 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认实例化为空</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s1;</span><br><span class=\"line\"><span class=\"comment\">// 直接实例化为指定值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">s1</span><span class=\"params\">(<span class=\"number\">10</span>, <span class=\"string\">'c'</span>)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">s2</span><span class=\"params\">(<span class=\"string\">\"haha\"</span>)</span></span>;</span><br><span class=\"line\"><span class=\"comment\">// 复制实例化</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s3 = <span class=\"string\">\"haha\"</span>;</span><br></pre></td></tr></table></figure>\n<h4 id=\"字符串操作\"><a href=\"#字符串操作\" class=\"headerlink\" title=\"字符串操作\"></a>字符串操作</h4><p>几个特殊的字符串操作举例如下：</p>\n<ul>\n<li>输入和输出</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> word;</span><br><span class=\"line\"><span class=\"keyword\">while</span>(<span class=\"built_in\">cin</span> &gt;&gt; word) <span class=\"comment\">// is&gt;&gt;s，返回is</span></span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; word &lt;&lt; <span class=\"built_in\">endl</span>; <span class=\"comment\">// os &lt;&lt; s，返回os</span></span><br><span class=\"line\"><span class=\"keyword\">while</span>(getline(<span class=\"built_in\">cin</span>, word)) <span class=\"comment\">// 返回is</span></span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; word &lt;&lt; <span class=\"built_in\">endl</span>;</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>比较：比较从左到右第一个不同的字符的ASCII值，如从左到右无不同字符则长度较长的字符串大</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// s2大s1，s3大于前两个字符串</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s1 = <span class=\"string\">\"hello\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">string</span> s2 = <span class=\"string\">\"hello, world\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">string</span> s3 = <span class=\"string\">\"hexo\"</span>;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>size()</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> s1;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> size = s1.size(); <span class=\"comment\">// string::size_type，一个无符号整型</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>拼接</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// string类型间可自由拼接</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s1 = <span class=\"string\">\"t\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">string</span> s2 = <span class=\"string\">\"x\"</span>;</span><br><span class=\"line\">s1 += s2;</span><br><span class=\"line\"><span class=\"comment\">// string和literals</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s3 = <span class=\"string\">\"t\"</span> + <span class=\"string\">\"x\"</span>; <span class=\"comment\">// error：字面量不可相加</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s4 = <span class=\"string\">\"t\"</span> + s1 + <span class=\"string\">\"x\"</span>; <span class=\"comment\">// 合法，运算顺序从左到右</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"处理字符串内的字符\"><a href=\"#处理字符串内的字符\" class=\"headerlink\" title=\"处理字符串内的字符\"></a>处理字符串内的字符</h4><p>一共有两类操作，</p>\n<ul>\n<li>字符串遍历（copy和reference）</li>\n<li>数组下标（reference）</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> s1 = <span class=\"string\">\"test\"</span>;</span><br><span class=\"line\"><span class=\"comment\">// 字符串遍历</span></span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">auto</span> c : s1) <span class=\"comment\">// c是copy，改变c的值不影响字符串</span></span><br><span class=\"line\">    <span class=\"comment\">// do sth</span></span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">auto</span> &amp;c : s1) <span class=\"comment\">// c是reference</span></span><br><span class=\"line\">    <span class=\"comment\">// do sth</span></span><br><span class=\"line\">s1[<span class=\"number\">0</span>] = <span class=\"string\">'y'</span>; <span class=\"comment\">// 引用第0个数组下标的字符</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Library-vector-Type\"><a href=\"#Library-vector-Type\" class=\"headerlink\" title=\"Library vector Type\"></a>Library vector Type</h3><p>使用前提：</p>\n<ul>\n<li>头文件引入：<code>#include &lt;vector&gt;</code></li>\n<li>作用域引入：<code>using std::vector</code></li>\n</ul>\n<h4 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h4><p><em>注意括号和花括号的不同</em>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认实例化为空</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; v1; </span><br><span class=\"line\"><span class=\"comment\">// 指定元素数量</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v2(<span class=\"number\">10</span>); <span class=\"comment\">// 10个0</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v3(<span class=\"number\">10</span>, <span class=\"number\">1</span>); <span class=\"comment\">// 10个1</span></span><br><span class=\"line\"><span class=\"comment\">// 列表实例化</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &#123;<span class=\"number\">10</span>, <span class=\"number\">1</span>&#125;; <span class=\"comment\">// 10和1两个元素</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h4><p>注意：</p>\n<ul>\n<li>数组下标可操作vector的尺寸之外的元素如<code>vector[size+1] = 3</code>，但这并不会向vector新增一个元素，而且会产生越界异常<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v1(<span class=\"number\">10</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">v1.push_back(<span class=\"number\">2</span>); <span class=\"comment\">// 插入</span></span><br><span class=\"line\">v1[<span class=\"number\">0</span>] = <span class=\"number\">3</span>; <span class=\"comment\">// 数组下标引用</span></span><br><span class=\"line\">v1.size(); <span class=\"comment\">// vector::size_type</span></span><br><span class=\"line\"><span class=\"comment\">// 比较操作需要装相同元素，且相同元素间可比较</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Introducing-Iterators\"><a href=\"#Introducing-Iterators\" class=\"headerlink\" title=\"Introducing Iterators\"></a>Introducing Iterators</h3><h4 id=\"定义-2\"><a href=\"#定义-2\" class=\"headerlink\" title=\"定义\"></a>定义</h4><p>string有两种iterator类型，指向某个具体字符：</p>\n<ul>\n<li>string::iterator指向的元素可读写</li>\n<li>string::const_iterator指向的元素只可以读</li>\n</ul>\n<p>vector有两种iterator类型，指向某个具体元素：</p>\n<ul>\n<li>vector::iterator</li>\n<li>vector::const_iterator</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">s1</span><span class=\"params\">(<span class=\"string\">\"123\"</span>)</span></span>;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> i1 = s1.begin(); <span class=\"comment\">// 指向第一个元素</span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> i2 = s1.end(); <span class=\"comment\">// 指向最后一个元素的尾部</span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> i3 = s1.cbegin(); <span class=\"comment\">// 只可读</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"操作-1\"><a href=\"#操作-1\" class=\"headerlink\" title=\"操作\"></a>操作</h4><p>常用操作如下：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">vector</span> s1&#123;<span class=\"string\">\"123\"</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> i1 = s1.begin();</span><br><span class=\"line\">*i1 = <span class=\"string\">\"345\"</span>; <span class=\"comment\">// dereference，取得引用</span></span><br><span class=\"line\">(*i1).size(); <span class=\"comment\">// 调用第一个元素的成员size()</span></span><br><span class=\"line\">*i1.size(); <span class=\"comment\">// error：调用顺序是*(i1.size())</span></span><br><span class=\"line\">i1++; <span class=\"comment\">// 可进行加减运算，指向不同成员</span></span><br><span class=\"line\"><span class=\"comment\">// 比较运算符规则：出现在容器前面的元素较小</span></span><br></pre></td></tr></table></figure></p>\n<p>注意：在使用iterator遍历vector时不能使用push_back，它会使得之前指向它的iterator都无效</p>\n<h3 id=\"Arrays\"><a href=\"#Arrays\" class=\"headerlink\" title=\"Arrays\"></a>Arrays</h3><h4 id=\"定义-3\"><a href=\"#定义-3\" class=\"headerlink\" title=\"定义\"></a>定义</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认实例化</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> arr[<span class=\"number\">10</span>]; <span class=\"comment\">// 10个int值，在函数外int值默认为0，函数内int值为undefined，与built-in类型的默认值规则相同</span></span><br><span class=\"line\"><span class=\"comment\">// 显示实例化</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> arr2[<span class=\"number\">10</span>] = &#123;<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>&#125;; <span class=\"comment\">// 后七个元素的值同上</span></span><br><span class=\"line\"><span class=\"comment\">// 字符数组</span></span><br><span class=\"line\"><span class=\"keyword\">char</span> c1[] = <span class=\"string\">\"C++\"</span>; <span class=\"comment\">// 共4个元素，最后一个为'\\0'</span></span><br><span class=\"line\"><span class=\"comment\">// 不能复制和赋值</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> arr3 [] = arr; <span class=\"comment\">// error</span></span><br><span class=\"line\">arr2 = arr; <span class=\"comment\">// error</span></span><br><span class=\"line\"><span class=\"comment\">// 复杂的定义</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> *ptr[<span class=\"number\">10</span>]; <span class=\"comment\">// ptr是一个数组，该数组含有10个int型指针</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> (*ptr)[<span class=\"number\">10</span>]; <span class=\"comment\">// ptr是一个指针，指向含有10个int元素的数组</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"操纵数组\"><a href=\"#操纵数组\" class=\"headerlink\" title=\"操纵数组\"></a>操纵数组</h4><ol>\n<li>使用数组下标</li>\n<li>使用for-each，如<code>for(auto tmp : arr)或for(auto &amp;tmp : arr)</code></li>\n</ol>\n<h4 id=\"数组与指针\"><a href=\"#数组与指针\" class=\"headerlink\" title=\"数组与指针\"></a>数组与指针</h4><ul>\n<li><p>数组名指向第一个元素</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> nums[] = &#123;<span class=\"string\">\"one\"</span>, <span class=\"string\">\"two\"</span>, <span class=\"string\">\"three\"</span>&#125;;</span><br><span class=\"line\"><span class=\"comment\">// 下面两个式子等效</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> *ptr = nums;</span><br><span class=\"line\">ptr = &amp;nums[<span class=\"number\">0</span>];</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>auto和decltype具有不同效果</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> ia[] = &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">auto</span> <span class=\"title\">ia2</span><span class=\"params\">(ia)</span></span>; <span class=\"comment\">// 等效于&amp;ia[0]</span></span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(ia) ia3 = &#123;<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>&#125;; <span class=\"comment\">// 具有与ia一样的类型</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指针与数组</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> arr[] = &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *ptr = <span class=\"number\">0</span>; <span class=\"comment\">// 指针状态1：空指针</span></span><br><span class=\"line\">ptr = arr; <span class=\"comment\">// 指针状态2：指向某个对象</span></span><br><span class=\"line\">ptr = arr[<span class=\"number\">3</span>]; <span class=\"comment\">// 指针状态3：指向一块内存的结束地址，指针本身有效，不能使用*号取值</span></span><br><span class=\"line\">ptr = arr[<span class=\"number\">4</span>]; <span class=\"comment\">// 指针状态4：这是一个无效的指针，指针地址未定义，不能使用*号取值</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>begin和end函数取数组首尾</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> ia[] = &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *begin = begin(ia);</span><br><span class=\"line\"><span class=\"keyword\">int</span> *end = end(ia);</span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; ivec(begin(ia), end(ia)); <span class=\"comment\">// 将ia的内容复制到ivec</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>数组指针运算</p>\n<ul>\n<li>指向相同数组的指针才可使用关系运算符；</li>\n<li>built-in数组指针下标可使用负数，如：<code>p[-2]</code>，p指向一个数组的元素；vector等library type的数组下标必须是正数；</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"c类型字符串\"><a href=\"#c类型字符串\" class=\"headerlink\" title=\"c类型字符串\"></a>c类型字符串</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> s = <span class=\"string\">\"c++\"</span>; <span class=\"comment\">// 可使用c类型字符串为string类型赋值</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *str = s; <span class=\"comment\">// error：反之则不行，应使用s.c_str()</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"多维数组\"><a href=\"#多维数组\" class=\"headerlink\" title=\"多维数组\"></a>多维数组</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> ia[<span class=\"number\">3</span>][<span class=\"number\">4</span>];</span><br><span class=\"line\"><span class=\"comment\">// 指针p为类型int (*p)[4]，指向含有4个int的数组</span></span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">auto</span> p = begin(ia); p != end(ia); ++p) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// q指向int[4]的第一个元素</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">auto</span> q = begin(*p); q != end(*p); ++q) &#123;</span><br><span class=\"line\">        cout &lt;&lt; *q &lt;&lt; '';</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>《C++ Primer v5》的读书笔记。</p>","more":"<h2 id=\"CHAPTER-1-GETTING-STARTED\"><a href=\"#CHAPTER-1-GETTING-STARTED\" class=\"headerlink\" title=\"CHAPTER 1 GETTING STARTED\"></a>CHAPTER 1 GETTING STARTED</h2><ul>\n<li>Variable type: when we wrote<code>T t</code>, we sayed that “t has type T”, or “t is a T”</li>\n<li>gcc/g++ warning all options: <code>-Wall</code> for *nix, <code>/W4</code> for windows</li>\n<li>Flush the stream: we should always put <code>std::cout &lt;&lt; std::endl;</code> at the end of <code>std::cout</code> to flush the stream of std-out, or else it won’t output immediately</li>\n<li>Left operating left: <code>std::cout &lt;&lt; &quot;text 1&quot; &lt;&lt; &quot; and text 2&quot; &lt;&lt; std::endl;</code> equals to<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"text 1\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\" and text 2\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">std</span>:<span class=\"built_in\">endl</span>;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<!--more-->\n<ul>\n<li>istream hits invalid state: <code>while (std::cin &gt;&gt; value)</code> will end at<ol>\n<li>hit the <strong>end-of-file</strong></li>\n<li>encounter an invalid input, such as reading a value is not a integer</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"CHAPTER-2-VARIABLES-AND-BASIC-TYPES\"><a href=\"#CHAPTER-2-VARIABLES-AND-BASIC-TYPES\" class=\"headerlink\" title=\"CHAPTER 2 VARIABLES AND BASIC TYPES\"></a>CHAPTER 2 VARIABLES AND BASIC TYPES</h2><h3 id=\"Primitive-built-in-types\"><a href=\"#Primitive-built-in-types\" class=\"headerlink\" title=\"Primitive built-in types\"></a>Primitive built-in types</h3><ul>\n<li><p>Signed and unsigned types</p>\n<ol>\n<li>except for bool and extended character types, the integral types may be signed or unsigned(float is not integral types)</li>\n<li>there are three character types (two in real usage): char, signed char and unsigned char<ul>\n<li>char is signed in some machine and unsiged in others</li>\n</ul>\n</li>\n<li>use an unsigned when you are sure of it’s usage</li>\n<li>don’t use plain char or bool in arithmetic experssions</li>\n<li>double is better for float, float has not enough precison and in some machines double computation is faster than float</li>\n</ol>\n</li>\n<li><p>Type conversions</p>\n<ol>\n<li>when assign a float to int, <ul>\n<li>the fractional part of float is truncated as temp</li>\n<li>give temp to the int mentioned above</li>\n</ul>\n</li>\n<li>when assign an out-of-value to unsigned type, the lower bits doesn’t change, the higher bit out-of-range is truncated, this is same to modulo</li>\n<li>when assign an out-of-value to signed type, the result is undefined</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"Variables\"><a href=\"#Variables\" class=\"headerlink\" title=\"Variables\"></a>Variables</h3><ul>\n<li><p>List initialization</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> sold = <span class=\"number\">0</span>;   <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> sold = &#123;<span class=\"number\">0</span>&#125;; <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> sold&#123;<span class=\"number\">0</span>&#125;;    <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">sold</span><span class=\"params\">(<span class=\"number\">0</span>)</span></span>;    <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">sold</span><span class=\"params\">(<span class=\"number\">1</span>d)</span></span>;   <span class=\"comment\">// ok but truncated</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> sold&#123;<span class=\"number\">1</span>d&#125;;   <span class=\"comment\">// error:narrowing conversation required</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Default initialization: built-in type defined outside any function body are initialized to zero, inside the function is uninitialized</p>\n</li>\n<li><p>declaration and definition are different</p>\n<ol>\n<li>declaration secifies the type and name of a variable</li>\n<li>definition inits the variable</li>\n<li>to use the same variable in multiple files, you must only have one definition and multi declaration<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// declaration but not definition, must be outside the function</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">int</span> j; </span><br><span class=\"line\"><span class=\"comment\">// declaration and definition</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> j;        </span><br><span class=\"line\"><span class=\"comment\">// only definition, declaration is override, must be outside the function</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">double</span> pi = <span class=\"number\">3.14</span>;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>illegal variable names</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> __a; <span class=\"comment\">// contains 2 underscores</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> _Ab; <span class=\"comment\">// start with underscore, and follow with a upper letter immediately</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>get variables outer scope</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; ::reused &lt;&lt; <span class=\"built_in\">std</span>::<span class=\"built_in\">endl</span>; <span class=\"comment\">// use '::'</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Compound-Types\"><a href=\"#Compound-Types\" class=\"headerlink\" title=\"Compound Types\"></a>Compound Types</h3><ul>\n<li><p>Reference: </p>\n<ol>\n<li>a reference to object, it’s not an object</li>\n<li>must be initialized, can’t re-bind<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> val1 = <span class=\"number\">1024</span>;</span><br><span class=\"line\"><span class=\"keyword\">double</span> val2 = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> &amp;relVal1 = val1; <span class=\"comment\">// ok</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> &amp;relVal2;        <span class=\"comment\">// error, must be init</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> &amp;relVal3 = val2; <span class=\"comment\">// error, type error</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>Pointers</p>\n<ul>\n<li>different to reference<ol>\n<li>it’s an object</li>\n<li>can be rebind</li>\n<li>needn’t initialized when defined</li>\n<li>like built-in types, it has undefined value in function if it’s not defined</li>\n</ol>\n</li>\n<li>pointer value state<ol>\n<li>point to an object</li>\n<li>point to the location just immediately past the end of an object (illegal pointer)</li>\n<li>null pointer</li>\n<li>invalid pointer (not initialized)</li>\n</ol>\n</li>\n<li>special<ol>\n<li>same type valid pointers can use in comparation (address compare)</li>\n<li>void pointers<ul>\n<li>can compare to another pointer</li>\n<li>pass or return it from a function</li>\n<li>assign it to another void* pointer</li>\n</ul>\n</li>\n<li>define two pointer in a line: <code>int *p1, *p2</code>, ‘*’ only works for the variable name</li>\n<li>reference to pointers (example below)</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// normal</span></span><br><span class=\"line\"><span class=\"keyword\">double</span> val = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">double</span> *pd1 = &amp;val; </span><br><span class=\"line\">             <span class=\"comment\">// ok, give the pointer itself a new value</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> *pd2 = &amp;val;    <span class=\"comment\">// error, types differ</span></span><br><span class=\"line\">pd2 = pd1;   <span class=\"comment\">// error, types differ</span></span><br><span class=\"line\">pd1 = val;   <span class=\"comment\">// error, can't assign object to pointer</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// special</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> *p1, p2; <span class=\"comment\">// only p1 is pointer</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *p;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *&amp;r = p; <span class=\"comment\">// read from right to left: r is a reference to pointer</span></span><br><span class=\"line\">r = &amp;i;</span><br><span class=\"line\">*r = <span class=\"number\">0</span>;      <span class=\"comment\">// set i to 0</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"const-Qualifer\"><a href=\"#const-Qualifer\" class=\"headerlink\" title=\"const Qualifer\"></a>const Qualifer</h3><ul>\n<li><p>local to file</p>\n<ol>\n<li>default internal linkage in C++<ul>\n<li>if we define <code>const int ivv = 0</code> in source file, and <code>extern const int ivv</code> in header file, ‘ivv’ only works in that source file, this is the so-called ‘local-to-file’, differ to the normal case</li>\n<li>to use ‘ivv’ in multi files, we should declare <code>extern const int ivv</code> in header file, and define <code>extern const int ivv = 0</code> in source file</li>\n</ul>\n</li>\n<li>default external linkage in C<ul>\n<li>in C, const variable’s scope is the same to normal case</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>reference to const</p>\n<ol>\n<li>const reference to const object/normal/plain/expression/double, means read only</li>\n<li>if reference to double, it’s a tempory value, if the origin double changes, the reference to const will never know that<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ok initialization</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> ci = <span class=\"number\">1024</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> i = <span class=\"number\">1024</span>;</span><br><span class=\"line\"><span class=\"keyword\">double</span> dval = <span class=\"number\">3.14</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r1 = ci; <span class=\"comment\">// from const object</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r2 = i;  <span class=\"comment\">// from normal int</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r3 = <span class=\"number\">12</span>; <span class=\"comment\">// from plain int</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r4 = r1 * <span class=\"number\">2</span>; <span class=\"comment\">// from expression</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> &amp;r5 = dval; <span class=\"comment\">// dval --&gt; temp int --&gt; r5</span></span><br><span class=\"line\"><span class=\"comment\">// error case</span></span><br><span class=\"line\">r1 = <span class=\"number\">123</span>; <span class=\"comment\">// can't rebind</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> &amp;r6 = ci; <span class=\"comment\">// only const reference can reference to const object</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>pointer to const(<strong>can’t change the memory the address points to</strong>)</p>\n<ol>\n<li>similar to ‘reference to const’, it stores the address of a object and has read access but not write access to the address</li>\n<li><strong>can rebind</strong></li>\n</ol>\n</li>\n<li><p>const pointers(<strong>can’t change the address</strong>)</p>\n<ol>\n<li>can’t rebind, must be initialized at first time</li>\n<li>itself const, always point to the same address</li>\n<li><strong>can change the address’s real value</strong><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> errNumb = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *<span class=\"keyword\">const</span> curErr = &amp;errNumb; <span class=\"comment\">// const pointers</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *curPnt = &amp;errNumb; <span class=\"comment\">// pointer to const</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *<span class=\"keyword\">const</span> curNor = &amp;i; <span class=\"comment\">// a const pointer to a const int</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>top-level &amp; low-level const</p>\n<ol>\n<li>top-level: itself const, const objects(pointers)</li>\n<li>low-level: pointer or reference to const</li>\n<li>when we copy a object, top-level is ignored and low-level will never be ignored<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> b = a; <span class=\"comment\">// ok: top-level ignore</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> <span class=\"keyword\">const</span> *m = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *n = m; <span class=\"comment\">// error: low-level can't be ignore</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>constexpr:<strong>applies to the pointer</strong> but not the type to which the pointer points</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *p = <span class=\"number\">0</span>; <span class=\"comment\">// pointer to const</span></span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> <span class=\"keyword\">int</span> *q = <span class=\"number\">0</span>; <span class=\"comment\">// a const pointer to int</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Dealing-with-type\"><a href=\"#Dealing-with-type\" class=\"headerlink\" title=\"Dealing with type\"></a>Dealing with type</h3><ul>\n<li><p>type alias</p>\n<ol>\n<li>typedef is the alias of an object<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">double</span> wages; <span class=\"comment\">// `wages` is same to double</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> wages = <span class=\"keyword\">double</span>;</span><br><span class=\"line\"><span class=\"comment\">// pointer</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">char</span> *pstring; <span class=\"comment\">// pstring is an object: char*, pointer to char</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> pstring cstr = <span class=\"number\">0</span>; <span class=\"comment\">// same to `const (char*) cstr = 0`, cstr is a const pointer to char</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>auto: automatically determines the type, <strong>ignores the top-level</strong></p>\n</li>\n<li>decltype: similar to auto, but <strong>top-level is keeped</strong><ol>\n<li>decltype((v)) is always a reference type<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> a = i; <span class=\"comment\">// normal int </span></span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(i) b = <span class=\"number\">0</span>; <span class=\"comment\">// const int</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"CHAPTER-3-STRINGS-VECTORS-AND-ARRAYS\"><a href=\"#CHAPTER-3-STRINGS-VECTORS-AND-ARRAYS\" class=\"headerlink\" title=\"CHAPTER 3 STRINGS, VECTORS, AND ARRAYS\"></a>CHAPTER 3 STRINGS, VECTORS, AND ARRAYS</h2><h3 id=\"Namespace-using-Declarations\"><a href=\"#Namespace-using-Declarations\" class=\"headerlink\" title=\"Namespace using Declarations\"></a>Namespace using Declarations</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span>; <span class=\"comment\">// 只使用于本源文件，引入另外一个命名空间的成员到当前作用域</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"hello\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<!--more-->\n<h3 id=\"Library-string-Type\"><a href=\"#Library-string-Type\" class=\"headerlink\" title=\"Library string Type\"></a>Library string Type</h3><p>使用前提：</p>\n<ul>\n<li>头文件引入：<code>#include &lt;string&gt;</code></li>\n<li>作用域引入：<code>using std::string</code></li>\n</ul>\n<h4 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认实例化为空</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s1;</span><br><span class=\"line\"><span class=\"comment\">// 直接实例化为指定值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">s1</span><span class=\"params\">(<span class=\"number\">10</span>, <span class=\"string\">'c'</span>)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">s2</span><span class=\"params\">(<span class=\"string\">\"haha\"</span>)</span></span>;</span><br><span class=\"line\"><span class=\"comment\">// 复制实例化</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s3 = <span class=\"string\">\"haha\"</span>;</span><br></pre></td></tr></table></figure>\n<h4 id=\"字符串操作\"><a href=\"#字符串操作\" class=\"headerlink\" title=\"字符串操作\"></a>字符串操作</h4><p>几个特殊的字符串操作举例如下：</p>\n<ul>\n<li>输入和输出</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> word;</span><br><span class=\"line\"><span class=\"keyword\">while</span>(<span class=\"built_in\">cin</span> &gt;&gt; word) <span class=\"comment\">// is&gt;&gt;s，返回is</span></span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; word &lt;&lt; <span class=\"built_in\">endl</span>; <span class=\"comment\">// os &lt;&lt; s，返回os</span></span><br><span class=\"line\"><span class=\"keyword\">while</span>(getline(<span class=\"built_in\">cin</span>, word)) <span class=\"comment\">// 返回is</span></span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; word &lt;&lt; <span class=\"built_in\">endl</span>;</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>比较：比较从左到右第一个不同的字符的ASCII值，如从左到右无不同字符则长度较长的字符串大</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// s2大s1，s3大于前两个字符串</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s1 = <span class=\"string\">\"hello\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">string</span> s2 = <span class=\"string\">\"hello, world\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">string</span> s3 = <span class=\"string\">\"hexo\"</span>;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>size()</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> s1;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> size = s1.size(); <span class=\"comment\">// string::size_type，一个无符号整型</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>拼接</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// string类型间可自由拼接</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s1 = <span class=\"string\">\"t\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">string</span> s2 = <span class=\"string\">\"x\"</span>;</span><br><span class=\"line\">s1 += s2;</span><br><span class=\"line\"><span class=\"comment\">// string和literals</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s3 = <span class=\"string\">\"t\"</span> + <span class=\"string\">\"x\"</span>; <span class=\"comment\">// error：字面量不可相加</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> s4 = <span class=\"string\">\"t\"</span> + s1 + <span class=\"string\">\"x\"</span>; <span class=\"comment\">// 合法，运算顺序从左到右</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"处理字符串内的字符\"><a href=\"#处理字符串内的字符\" class=\"headerlink\" title=\"处理字符串内的字符\"></a>处理字符串内的字符</h4><p>一共有两类操作，</p>\n<ul>\n<li>字符串遍历（copy和reference）</li>\n<li>数组下标（reference）</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> s1 = <span class=\"string\">\"test\"</span>;</span><br><span class=\"line\"><span class=\"comment\">// 字符串遍历</span></span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">auto</span> c : s1) <span class=\"comment\">// c是copy，改变c的值不影响字符串</span></span><br><span class=\"line\">    <span class=\"comment\">// do sth</span></span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">auto</span> &amp;c : s1) <span class=\"comment\">// c是reference</span></span><br><span class=\"line\">    <span class=\"comment\">// do sth</span></span><br><span class=\"line\">s1[<span class=\"number\">0</span>] = <span class=\"string\">'y'</span>; <span class=\"comment\">// 引用第0个数组下标的字符</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Library-vector-Type\"><a href=\"#Library-vector-Type\" class=\"headerlink\" title=\"Library vector Type\"></a>Library vector Type</h3><p>使用前提：</p>\n<ul>\n<li>头文件引入：<code>#include &lt;vector&gt;</code></li>\n<li>作用域引入：<code>using std::vector</code></li>\n</ul>\n<h4 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h4><p><em>注意括号和花括号的不同</em>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认实例化为空</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; v1; </span><br><span class=\"line\"><span class=\"comment\">// 指定元素数量</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v2(<span class=\"number\">10</span>); <span class=\"comment\">// 10个0</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v3(<span class=\"number\">10</span>, <span class=\"number\">1</span>); <span class=\"comment\">// 10个1</span></span><br><span class=\"line\"><span class=\"comment\">// 列表实例化</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &#123;<span class=\"number\">10</span>, <span class=\"number\">1</span>&#125;; <span class=\"comment\">// 10和1两个元素</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h4><p>注意：</p>\n<ul>\n<li>数组下标可操作vector的尺寸之外的元素如<code>vector[size+1] = 3</code>，但这并不会向vector新增一个元素，而且会产生越界异常<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v1(<span class=\"number\">10</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">v1.push_back(<span class=\"number\">2</span>); <span class=\"comment\">// 插入</span></span><br><span class=\"line\">v1[<span class=\"number\">0</span>] = <span class=\"number\">3</span>; <span class=\"comment\">// 数组下标引用</span></span><br><span class=\"line\">v1.size(); <span class=\"comment\">// vector::size_type</span></span><br><span class=\"line\"><span class=\"comment\">// 比较操作需要装相同元素，且相同元素间可比较</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Introducing-Iterators\"><a href=\"#Introducing-Iterators\" class=\"headerlink\" title=\"Introducing Iterators\"></a>Introducing Iterators</h3><h4 id=\"定义-2\"><a href=\"#定义-2\" class=\"headerlink\" title=\"定义\"></a>定义</h4><p>string有两种iterator类型，指向某个具体字符：</p>\n<ul>\n<li>string::iterator指向的元素可读写</li>\n<li>string::const_iterator指向的元素只可以读</li>\n</ul>\n<p>vector有两种iterator类型，指向某个具体元素：</p>\n<ul>\n<li>vector::iterator</li>\n<li>vector::const_iterator</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">s1</span><span class=\"params\">(<span class=\"string\">\"123\"</span>)</span></span>;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> i1 = s1.begin(); <span class=\"comment\">// 指向第一个元素</span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> i2 = s1.end(); <span class=\"comment\">// 指向最后一个元素的尾部</span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> i3 = s1.cbegin(); <span class=\"comment\">// 只可读</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"操作-1\"><a href=\"#操作-1\" class=\"headerlink\" title=\"操作\"></a>操作</h4><p>常用操作如下：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">vector</span> s1&#123;<span class=\"string\">\"123\"</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> i1 = s1.begin();</span><br><span class=\"line\">*i1 = <span class=\"string\">\"345\"</span>; <span class=\"comment\">// dereference，取得引用</span></span><br><span class=\"line\">(*i1).size(); <span class=\"comment\">// 调用第一个元素的成员size()</span></span><br><span class=\"line\">*i1.size(); <span class=\"comment\">// error：调用顺序是*(i1.size())</span></span><br><span class=\"line\">i1++; <span class=\"comment\">// 可进行加减运算，指向不同成员</span></span><br><span class=\"line\"><span class=\"comment\">// 比较运算符规则：出现在容器前面的元素较小</span></span><br></pre></td></tr></table></figure></p>\n<p>注意：在使用iterator遍历vector时不能使用push_back，它会使得之前指向它的iterator都无效</p>\n<h3 id=\"Arrays\"><a href=\"#Arrays\" class=\"headerlink\" title=\"Arrays\"></a>Arrays</h3><h4 id=\"定义-3\"><a href=\"#定义-3\" class=\"headerlink\" title=\"定义\"></a>定义</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认实例化</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> arr[<span class=\"number\">10</span>]; <span class=\"comment\">// 10个int值，在函数外int值默认为0，函数内int值为undefined，与built-in类型的默认值规则相同</span></span><br><span class=\"line\"><span class=\"comment\">// 显示实例化</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> arr2[<span class=\"number\">10</span>] = &#123;<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>&#125;; <span class=\"comment\">// 后七个元素的值同上</span></span><br><span class=\"line\"><span class=\"comment\">// 字符数组</span></span><br><span class=\"line\"><span class=\"keyword\">char</span> c1[] = <span class=\"string\">\"C++\"</span>; <span class=\"comment\">// 共4个元素，最后一个为'\\0'</span></span><br><span class=\"line\"><span class=\"comment\">// 不能复制和赋值</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> arr3 [] = arr; <span class=\"comment\">// error</span></span><br><span class=\"line\">arr2 = arr; <span class=\"comment\">// error</span></span><br><span class=\"line\"><span class=\"comment\">// 复杂的定义</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> *ptr[<span class=\"number\">10</span>]; <span class=\"comment\">// ptr是一个数组，该数组含有10个int型指针</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> (*ptr)[<span class=\"number\">10</span>]; <span class=\"comment\">// ptr是一个指针，指向含有10个int元素的数组</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"操纵数组\"><a href=\"#操纵数组\" class=\"headerlink\" title=\"操纵数组\"></a>操纵数组</h4><ol>\n<li>使用数组下标</li>\n<li>使用for-each，如<code>for(auto tmp : arr)或for(auto &amp;tmp : arr)</code></li>\n</ol>\n<h4 id=\"数组与指针\"><a href=\"#数组与指针\" class=\"headerlink\" title=\"数组与指针\"></a>数组与指针</h4><ul>\n<li><p>数组名指向第一个元素</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> nums[] = &#123;<span class=\"string\">\"one\"</span>, <span class=\"string\">\"two\"</span>, <span class=\"string\">\"three\"</span>&#125;;</span><br><span class=\"line\"><span class=\"comment\">// 下面两个式子等效</span></span><br><span class=\"line\"><span class=\"built_in\">string</span> *ptr = nums;</span><br><span class=\"line\">ptr = &amp;nums[<span class=\"number\">0</span>];</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>auto和decltype具有不同效果</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> ia[] = &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">auto</span> <span class=\"title\">ia2</span><span class=\"params\">(ia)</span></span>; <span class=\"comment\">// 等效于&amp;ia[0]</span></span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(ia) ia3 = &#123;<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>&#125;; <span class=\"comment\">// 具有与ia一样的类型</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指针与数组</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> arr[] = &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *ptr = <span class=\"number\">0</span>; <span class=\"comment\">// 指针状态1：空指针</span></span><br><span class=\"line\">ptr = arr; <span class=\"comment\">// 指针状态2：指向某个对象</span></span><br><span class=\"line\">ptr = arr[<span class=\"number\">3</span>]; <span class=\"comment\">// 指针状态3：指向一块内存的结束地址，指针本身有效，不能使用*号取值</span></span><br><span class=\"line\">ptr = arr[<span class=\"number\">4</span>]; <span class=\"comment\">// 指针状态4：这是一个无效的指针，指针地址未定义，不能使用*号取值</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>begin和end函数取数组首尾</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> ia[] = &#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *begin = begin(ia);</span><br><span class=\"line\"><span class=\"keyword\">int</span> *end = end(ia);</span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; ivec(begin(ia), end(ia)); <span class=\"comment\">// 将ia的内容复制到ivec</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>数组指针运算</p>\n<ul>\n<li>指向相同数组的指针才可使用关系运算符；</li>\n<li>built-in数组指针下标可使用负数，如：<code>p[-2]</code>，p指向一个数组的元素；vector等library type的数组下标必须是正数；</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"c类型字符串\"><a href=\"#c类型字符串\" class=\"headerlink\" title=\"c类型字符串\"></a>c类型字符串</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> s = <span class=\"string\">\"c++\"</span>; <span class=\"comment\">// 可使用c类型字符串为string类型赋值</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *str = s; <span class=\"comment\">// error：反之则不行，应使用s.c_str()</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"多维数组\"><a href=\"#多维数组\" class=\"headerlink\" title=\"多维数组\"></a>多维数组</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> ia[<span class=\"number\">3</span>][<span class=\"number\">4</span>];</span><br><span class=\"line\"><span class=\"comment\">// 指针p为类型int (*p)[4]，指向含有4个int的数组</span></span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">auto</span> p = begin(ia); p != end(ia); ++p) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// q指向int[4]的第一个元素</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">auto</span> q = begin(*p); q != end(*p); ++q) &#123;</span><br><span class=\"line\">        cout &lt;&lt; *q &lt;&lt; '';</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"layout":"post","title":"HBase Java API用到的一些特性","date":"2015-11-14T15:13:00.000Z","comments":1,"_content":"\n本文介绍用到的一些HBase Java API。\n\n<!--more-->\n\n## 已知rowkey∈[startRow, stopRow)，timestamp为0，查询第一条记录和最后一条记录\n\n关键：使用PageFilter设置返回行数，使用scan.setReversed(true)设置反向扫描；\n\n- 查询第一条记录\n\n```java\n// 已知变量\nbyte[] startRow, stopRow;\n// TODO 在这里实例化startRow和stopRow\nScan scan = new Scan();\nscan.setStartRow(startRow);\nscan.setStopRow(stopRow);\ntry {\n\t// 限定timestamp\n\tscan.setTimeStamp(0l);\n\t// 使用new PageFilter(num)限定返回结果行数，num为1表示只返回一行记录\n\tscan.setFilter(new PageFilter(1));\n} catch (IOException e) {\n\t// TODO 处理异常\n}\n// TODO 在这里添加要查询的colum family和qualifier并执行查询和结果解析\n```\n\n- 查询最后一条记录\n\n```java\n// 已知变量\nbyte[] startRow, stopRow;\n// TODO 在这里实例化startRow和stopRow\nScan scan = new Scan();\n// 由于设置了反向扫描，stopRow和startRow需要调转位置\nscan.setStartRow(stopRow);\nscan.setStopRow(startRow);\ntry {\n\t// 反向扫描\n\tscan.setReversed(true);\n\t// 限定timestamp\n\tscan.setTimeStamp(0l);\n\t// 使用new PageFilter(num)限定返回结果行数，num为1表示只返回一行记录\n\tscan.setFilter(new PageFilter(1));\n} catch (IOException e) {\n\t// TODO 处理异常\n}\n// TODO 在这里添加要查询的colum family和qualifier并执行查询和结果解析\n```\n","source":"_posts/2015-11-14-hbase-java-api-example.markdown","raw":"---\nlayout: post\ntitle: HBase Java API用到的一些特性\ndate: '2015-11-14 23:13'\ncomments: true\ncategories: ['编程实践']  \ntags: ['HBase', 'Java']\n---\n\n本文介绍用到的一些HBase Java API。\n\n<!--more-->\n\n## 已知rowkey∈[startRow, stopRow)，timestamp为0，查询第一条记录和最后一条记录\n\n关键：使用PageFilter设置返回行数，使用scan.setReversed(true)设置反向扫描；\n\n- 查询第一条记录\n\n```java\n// 已知变量\nbyte[] startRow, stopRow;\n// TODO 在这里实例化startRow和stopRow\nScan scan = new Scan();\nscan.setStartRow(startRow);\nscan.setStopRow(stopRow);\ntry {\n\t// 限定timestamp\n\tscan.setTimeStamp(0l);\n\t// 使用new PageFilter(num)限定返回结果行数，num为1表示只返回一行记录\n\tscan.setFilter(new PageFilter(1));\n} catch (IOException e) {\n\t// TODO 处理异常\n}\n// TODO 在这里添加要查询的colum family和qualifier并执行查询和结果解析\n```\n\n- 查询最后一条记录\n\n```java\n// 已知变量\nbyte[] startRow, stopRow;\n// TODO 在这里实例化startRow和stopRow\nScan scan = new Scan();\n// 由于设置了反向扫描，stopRow和startRow需要调转位置\nscan.setStartRow(stopRow);\nscan.setStopRow(startRow);\ntry {\n\t// 反向扫描\n\tscan.setReversed(true);\n\t// 限定timestamp\n\tscan.setTimeStamp(0l);\n\t// 使用new PageFilter(num)限定返回结果行数，num为1表示只返回一行记录\n\tscan.setFilter(new PageFilter(1));\n} catch (IOException e) {\n\t// TODO 处理异常\n}\n// TODO 在这里添加要查询的colum family和qualifier并执行查询和结果解析\n```\n","slug":"hbase-java-api-example","published":1,"updated":"2022-08-09T15:02:00.588Z","photos":[],"link":"","_id":"cl6mbc11d0001igu8nqkm1ee9","content":"<p>本文介绍用到的一些HBase Java API。</p>\n<a id=\"more\"></a>\n<h2 id=\"已知rowkey∈-startRow-stopRow-，timestamp为0，查询第一条记录和最后一条记录\"><a href=\"#已知rowkey∈-startRow-stopRow-，timestamp为0，查询第一条记录和最后一条记录\" class=\"headerlink\" title=\"已知rowkey∈[startRow, stopRow)，timestamp为0，查询第一条记录和最后一条记录\"></a>已知rowkey∈[startRow, stopRow)，timestamp为0，查询第一条记录和最后一条记录</h2><p>关键：使用PageFilter设置返回行数，使用scan.setReversed(true)设置反向扫描；</p>\n<ul>\n<li>查询第一条记录</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 已知变量</span></span><br><span class=\"line\"><span class=\"keyword\">byte</span>[] startRow, stopRow;</span><br><span class=\"line\"><span class=\"comment\">// TODO 在这里实例化startRow和stopRow</span></span><br><span class=\"line\">Scan scan = <span class=\"keyword\">new</span> Scan();</span><br><span class=\"line\">scan.setStartRow(startRow);</span><br><span class=\"line\">scan.setStopRow(stopRow);</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// 限定timestamp</span></span><br><span class=\"line\">\tscan.setTimeStamp(<span class=\"number\">0l</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// 使用new PageFilter(num)限定返回结果行数，num为1表示只返回一行记录</span></span><br><span class=\"line\">\tscan.setFilter(<span class=\"keyword\">new</span> PageFilter(<span class=\"number\">1</span>));</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// TODO 处理异常</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// TODO 在这里添加要查询的colum family和qualifier并执行查询和结果解析</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>查询最后一条记录</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 已知变量</span></span><br><span class=\"line\"><span class=\"keyword\">byte</span>[] startRow, stopRow;</span><br><span class=\"line\"><span class=\"comment\">// TODO 在这里实例化startRow和stopRow</span></span><br><span class=\"line\">Scan scan = <span class=\"keyword\">new</span> Scan();</span><br><span class=\"line\"><span class=\"comment\">// 由于设置了反向扫描，stopRow和startRow需要调转位置</span></span><br><span class=\"line\">scan.setStartRow(stopRow);</span><br><span class=\"line\">scan.setStopRow(startRow);</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// 反向扫描</span></span><br><span class=\"line\">\tscan.setReversed(<span class=\"keyword\">true</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// 限定timestamp</span></span><br><span class=\"line\">\tscan.setTimeStamp(<span class=\"number\">0l</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// 使用new PageFilter(num)限定返回结果行数，num为1表示只返回一行记录</span></span><br><span class=\"line\">\tscan.setFilter(<span class=\"keyword\">new</span> PageFilter(<span class=\"number\">1</span>));</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// TODO 处理异常</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// TODO 在这里添加要查询的colum family和qualifier并执行查询和结果解析</span></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>本文介绍用到的一些HBase Java API。</p>","more":"<h2 id=\"已知rowkey∈-startRow-stopRow-，timestamp为0，查询第一条记录和最后一条记录\"><a href=\"#已知rowkey∈-startRow-stopRow-，timestamp为0，查询第一条记录和最后一条记录\" class=\"headerlink\" title=\"已知rowkey∈[startRow, stopRow)，timestamp为0，查询第一条记录和最后一条记录\"></a>已知rowkey∈[startRow, stopRow)，timestamp为0，查询第一条记录和最后一条记录</h2><p>关键：使用PageFilter设置返回行数，使用scan.setReversed(true)设置反向扫描；</p>\n<ul>\n<li>查询第一条记录</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 已知变量</span></span><br><span class=\"line\"><span class=\"keyword\">byte</span>[] startRow, stopRow;</span><br><span class=\"line\"><span class=\"comment\">// TODO 在这里实例化startRow和stopRow</span></span><br><span class=\"line\">Scan scan = <span class=\"keyword\">new</span> Scan();</span><br><span class=\"line\">scan.setStartRow(startRow);</span><br><span class=\"line\">scan.setStopRow(stopRow);</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// 限定timestamp</span></span><br><span class=\"line\">\tscan.setTimeStamp(<span class=\"number\">0l</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// 使用new PageFilter(num)限定返回结果行数，num为1表示只返回一行记录</span></span><br><span class=\"line\">\tscan.setFilter(<span class=\"keyword\">new</span> PageFilter(<span class=\"number\">1</span>));</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// TODO 处理异常</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// TODO 在这里添加要查询的colum family和qualifier并执行查询和结果解析</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>查询最后一条记录</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 已知变量</span></span><br><span class=\"line\"><span class=\"keyword\">byte</span>[] startRow, stopRow;</span><br><span class=\"line\"><span class=\"comment\">// TODO 在这里实例化startRow和stopRow</span></span><br><span class=\"line\">Scan scan = <span class=\"keyword\">new</span> Scan();</span><br><span class=\"line\"><span class=\"comment\">// 由于设置了反向扫描，stopRow和startRow需要调转位置</span></span><br><span class=\"line\">scan.setStartRow(stopRow);</span><br><span class=\"line\">scan.setStopRow(startRow);</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// 反向扫描</span></span><br><span class=\"line\">\tscan.setReversed(<span class=\"keyword\">true</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// 限定timestamp</span></span><br><span class=\"line\">\tscan.setTimeStamp(<span class=\"number\">0l</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// 使用new PageFilter(num)限定返回结果行数，num为1表示只返回一行记录</span></span><br><span class=\"line\">\tscan.setFilter(<span class=\"keyword\">new</span> PageFilter(<span class=\"number\">1</span>));</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// TODO 处理异常</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// TODO 在这里添加要查询的colum family和qualifier并执行查询和结果解析</span></span><br></pre></td></tr></table></figure>"},{"layout":"post","title":"Maven HOWTO","date":"2015-12-20T08:31:00.000Z","comments":1,"_content":"\nMaven版本：3.3.1\n\n<!--more-->\n\n操作系统：Windows 7\n\nJava版本：1.8\n\n移译自[Maven Getting Started Guide](https://maven.apache.org/guides/getting-started/)。\n\n## What And Why\n\nMaven是一个Java的编译（Build）自动化工具，按我的理解，它可以做到：\n- 创建自动化\n- 包依赖管理自动化\n- 编译和单元测试自动化\n- 配置注入自动化\n- 程序（War或Jar）打包自动化，及远程部署\n\n因此，它是一个可以提升开发效率的工具。\n\n## How\n\n### 配置\n\n#### Java配置\n\n1. 下载[JDK8][2]并安装到你的电脑（本文用的是jdk-8u65-windows-x64.exe）；\n\n2. 配置环境变量，右击“计算机”==>选择“高级系统设置”==>选择“高级”选项卡==>点击“环境变量”按钮：\n    - 新建系统变量`JAVA_HOME`，内容为：`C:\\Program Files\\Java\\jdk1.8.0_65`；\n    - 修改系统变量`PATH`，在末尾加入内容：`;%JAVA_HOME%\\jre\\bin`；如无此系统变量则新建系统变量`PATH`，内容为：`%JAVA_HOME%\\jre\\bin`；\n    - 新建系统变量`CLASSPATH`，内容为：`.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar`；\n\n3. 注销后登入，打开CMD.exe，输入\n    ```\n    echo %JAVA_HOME%\n    java -version\n    ```\n\n    上述两个命令皆有输出则表示安装Java成功。\n\n#### Maven配置\n\n1. 到[Maven下载页][3]下载apache-maven-3.3.1-bin.zip（apache-maven-3.3.3有Bug，其boot文件夹缺少了一个关键Jar包，已向Maven mail-list提出，不知道修复了没有）；\n\n2. 将压缩包解压到一个你喜欢的地方，如`D:\\Softwares\\apache-maven-3.3.1`；\n\n3. 配置环境变量，右击“计算机”==>选择“高级系统设置”==>选择“高级”选项卡==>点击“环境变量”按钮：\n    - 新建系统变量`M2_HOME`，内容为：`D:\\Softwares\\apache-maven-3.3.1`；\n    - 修改系统变量`PATH`，在末尾加入内容：`;%M2_HOME%\\bin`；\n\n4. **重新打开**一个CMD.exe窗口，输入：\n    ```\n    echo %M2_HOME%\n    mvn -v\n    ```\n\n    上述两个命令皆有输出则表示安装Maven成功。\n\n5. 配置开源中国Maven库（非必要）\n    - 第一次运行mvn命令时，需要去官网（国外）的Maven库同步Jar包到本地，据官网说在网络畅通情况下4分钟就同步完毕，后续运行mvn命令就不需要这么长时间了\n    - 如果你觉得时间太长无法忍受，可以配置mvn的中国库，参考[OSC的使用帮助](http://maven.oschina.net/help.html)即可配置。简要概括如下：\n\n```xml\n<! -- 在mirrors添加如下配置即可 -->\n<mirror>\n  <id>nexus-osc</id>\n  <mirrorOf>*</mirrorOf>\n  <name>Nexus osc</name>\n  <url>http://maven.oschina.net/content/groups/public/</url>\n</mirror>\n\n<! -- 在profiles添加如下配置即可 -->\n<profile>\n  <id>jdk-1.4</id>\n  <activation>\n    <jdk>1.4</jdk>\n  </activation>\n  <repositories>\n    <repository>\n      <id>jdk14</id>\n      <name>Repository for JDK 1.4 builds</name>\n      <url>http://www.myhost.com/maven/jdk14</url>\n      <layout>default</layout>\n      <snapshotPolicy>always</snapshotPolicy>\n    </repository>\n  </repositories>\n</profile>\n```\n\n\n### Demo项目\n\n#### 创建Java项目\n\n运行下述命令创建demo项目my-app：\n```bash\nmvn -B archetype:generate \\\n  -DarchetypeGroupId=org.apache.maven.archetypes \\\n  -DgroupId=com.mycompany.app \\\n  -DartifactId=my-app\n```\n\nmy-app的目录结构如下：\n```\nmy-app\n|-- pom.xml\n`-- src\n    |-- main\n    |   `-- java\n    |       `-- com\n    |           `-- mycompany\n    |               `-- app\n    |                   `-- App.java\n    `-- test\n        `-- java\n            `-- com\n                `-- mycompany\n                    `-- app\n                        `-- AppTest.java\n```\n\n其中的pom.xml是Maven的基础配置文件，pom(Project Object Model，项目对象模型)，它的内容及注释如下：\n```xml\n<! -- pom文件的开始标签 -->\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <! -- Maven的pom版本 -->\n  <modelVersion>4.0.0</modelVersion>\n  <! -- 唯一的组织或公司编号，标识此项目所属组 -->\n  <groupId>com.mycompany.app</groupId>\n  <! -- 此项目属于组的哪个项目 -->\n  <artifactId>my-app</artifactId>\n  <! -- 可执行程序打包方式 -->\n  <packaging>jar</packaging>\n  <! -- 项目版本，SNAPSHOT表示开发版 -->\n  <version>1.0-SNAPSHOT</version>\n  <! -- 项目的显示名称，常用于maven生成的文档 -->\n  <name>Maven Quick Start Archetype</name>\n  <! -- 项目的主页，常用于maven生成的文档 -->\n  <url>http://maven.apache.org</url>\n  <! -- 所用的依赖库 -->\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>3.8.1</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n#### 编译\n\n编译项目src/main：`mvn compile`，将更新<project>/target/classes文件夹\n\n#### 测试\n\n编译并运行项目src/test：`mvn test`，将更新<project>/target/test-classes文件夹，并在<project>/target/surefire-reports生成测试报告\n\n编译项目src/test而不运行：`mvn test-compile`\n\n#### 清除\n\n`mvn clean`：删除<project>/target\n\n#### 打包\n\n打包项目到<project>/target：`mvn package`\n\n打包项目到maven本地仓库：`mvn install`\n\n#### 其他\n\n`mvn site`：生成<project>/target/site，即项目主页文档\n\n`mvn eclipse:eclipse`：为项目添加eclipse标识，因此可被eclipse import\n\n`mvn idea:idea`：类似于eclipse\n\n#### 插件\n\n在pom.xml中添加<build>标签，可定制maven的编译过程\n```xml\n<project ...>\n  <build>\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-compiler-plugin</artifactId>\n        <version>2.5.1</version>\n        <configuration>\n          <source>1.5</source>\n          <target>1.5</target>\n        </configuration>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n```\n\n#### 配置注入\n\n文件结构为：\n```\nmy-app\n|-- pom.xml\n`-- src\n    |-- main\n    |   |-- java\n    |   |   `-- com\n    |   |       `-- mycompany\n    |   |           `-- app\n    |   |               `-- App.java\n    |   `-- resources\n    |       `-- META-INF\n    |           `-- application.properties\n    `-- test\n        `-- java\n            `-- com\n                `-- mycompany\n                    `-- app\n                        `-- AppTest.java\n```\n\n想要注入配置到`application.properties`，方法如下\n\n- pom.xml注入\n    - pom.xml配置如下\n    \n    ```xml\n    <build>\n      <resources>\n        <resource>\n          <directory>src/main/resources</directory>\n          <filtering>true</filtering>\n        </resource>\n      </resources>\n    </build>\n    ```\n    - application.properties配置如下\n    \n    ```\n    # application.properties\n    application.name=${pom.name}\n    application.version=${pom.version}\n    ```\n    - 即可使用pom.xml中的name和version属性注入到配置文件，运行`mvn process-resources`后application.properties的内容变为\n    \n    ```\n    # application.properties\n    application.name=Maven Quick Start Archetype\n    application.version=1.0-SNAPSHOT\n    ```\n- 配置文件注入（配置文件必须在classpath内）\n    * pom.xml配置如下，filter.properties的key直接可为src/main/resources下的所有配置文件使用\n    \n    ``` xml\n    <build>\n      <filters>\n        <filter>src/main/filters/filter.properties</filter>\n      </filters>\n      <resources>\n        <resource>\n          <directory>src/main/resources</directory>\n          <filtering>true</filtering>\n        </resource>\n      </resources>\n    </build>\n    ```\n- pom.xml的propertie注入\n    * pom.xml配置如下，my.filter.value可直接为src/main/resources下的所有配置文件使用\n    \n    ```xml\n    <project ...>\n      <properties>\n        <my.filter.value>hello</my.filter.value>\n      </properties>\n    </project>\n    ```\n- 运行时注入\n    * `mvn process-resources \"-Dcommand.line.prop=hello again\"`，command.line.prop可直接为src/main/resources下的所有配置文件使用\n\n#### 依赖\n\n```xml\n<project ...>\n  <dependencies>\n    <dependency>\n      <! -- ~/.m2/repository中查找junit组的junit包的3.8.1版本，如查询不到则到maven仓库下载 -->\n      <! -- 上文mvn package的jar包可在这里使用 -->\n      <groupId>junit</groupId>\n      <! -- junit组的junit项目 -->\n      <artifactId>junit</artifactId>\n      <! -- 版本号 -->\n      <version>3.8.1</version>\n      <! -- test|compile|runtime -->\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n浏览器访问[http://repo.maven.apache.org/maven2](http://repo.maven.apache.org/maven2)可查看maven库的所有可用jar包，以junit为例，查看[http://repo.maven.apache.org/maven2/junit/junit/maven-metadata.xml](http://repo.maven.apache.org/maven2/junit/junit/maven-metadata.xml)可查询junit所有可用版本\n\n使用[http://maven.oschina.net/home.html](http://maven.oschina.net/home.html)可按关键字检索所需jar包\n\n使用`mvn dependency:tree`可查看当前项目的依赖树\n\n#### 远程部署到其他maven库\n\n配置pom.xml如下：\n```xml\n<project ...>\n  <distributionManagement>\n    <repository>\n      <id>mycompany-repository</id>\n      <name>MyCompany Repository</name>\n      <url>scp://repository.mycompany.com/repository/maven2</url>\n    </repository>\n  </distributionManagement>\n</project>\n```\n\n配置Maven的settings.xml如下：\n```xml\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                      http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  ...\n  <servers>\n    <server>\n      <id>mycompany-repository</id>\n      <username>jvanzyl</username>\n      <! -- Default value is ~/.ssh/id_dsa -->\n      <privateKey>/path/to/identity</privateKey> (default is ~/.ssh/id_dsa)\n      <passphrase>my_key_passphrase</passphrase>\n    </server>\n  </servers>\n  ...\n</settings>\n```\n\n#### 文档创建\n\n```bash\nmvn archetype:generate \\\n  -DarchetypeGroupId=org.apache.maven.archetypes \\\n  -DarchetypeArtifactId=maven-archetype-site \\\n  -DgroupId=com.mycompany.app \\\n  -DartifactId=my-app-site\n```\n\n#### 创建web项目\n\n创建web项目：\n```bash\nmvn archetype:generate \\\n    -DarchetypeGroupId=org.apache.maven.archetypes \\\n    -DarchetypeArtifactId=maven-archetype-webapp \\\n    -DgroupId=com.mycompany.app \\\n    -DartifactId=my-webapp\n```\n\nweb项目的pom.xml配置如下：\n```xml\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n \n  <groupId>com.mycompany.app</groupId>\n  <artifactId>my-webapp</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <! -- 打包方式 -->\n  <packaging>war</packaging>\n \n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>3.8.1</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n  <! -- 最终打包成war的名称 -->\n  <build>\n    <finalName>my-webapp</finalName>\n  </build>\n</project>\n```\n\n`mvn clean package`编译并打包为war包`target/my-webapp.war`\n\n#### 多个项目组装为一个项目\n\n两个项目要组装为一个项目，目录结构如下：\n```\n+- pom.xml\n+- my-app\n| +- pom.xml\n| +- src\n|   +- main\n|     +- java\n+- my-webapp\n| +- pom.xml\n| +- src\n|   +- main\n|     +- webapp\n```\n\npom.xml如下：\n```xml\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n \n  <groupId>com.mycompany.app</groupId>\n  <artifactId>app</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <packaging>pom</packaging>\n \n  <modules>\n    <module>my-app</module>\n    <module>my-webapp</module>\n  </modules>\n</project>\n```\n\n配置`my-webapp/pom.xml`使my-webapp引用my-app：\n```xml\n  ...\n  <dependencies>\n    <dependency>\n      <! -- 这将使得my-app在war包之前得到编译和打包 -->\n      <groupId>com.mycompany.app</groupId>\n      <artifactId>my-app</artifactId>\n      <version>1.0-SNAPSHOT</version>\n    </dependency>\n    ...\n  </dependencies>\n```\n\n配置`my-webapp/pom.xml`和`my-app/pom.xml`添加<parent>标签：\n```xml\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <parent>\n    <groupId>com.mycompany.app</groupId>\n    <artifactId>app</artifactId>\n    <version>1.0-SNAPSHOT</version>\n  </parent>\n  ...\n```\n\n`mvn clean install`将编译并打包war包：`my-webapp/target/my-webapp.war`，而my-app项目将作为war包WEB-INF/lib中的一个jar包\n","source":"_posts/2015-12-20-maven-howto.markdown","raw":"---\nlayout: post\ntitle: Maven HOWTO\ndate: '2015-12-20 16:31'\ncomments: true\ncategories: ['工具篇']  \ntags: ['Maven']\n---\n\nMaven版本：3.3.1\n\n<!--more-->\n\n操作系统：Windows 7\n\nJava版本：1.8\n\n移译自[Maven Getting Started Guide](https://maven.apache.org/guides/getting-started/)。\n\n## What And Why\n\nMaven是一个Java的编译（Build）自动化工具，按我的理解，它可以做到：\n- 创建自动化\n- 包依赖管理自动化\n- 编译和单元测试自动化\n- 配置注入自动化\n- 程序（War或Jar）打包自动化，及远程部署\n\n因此，它是一个可以提升开发效率的工具。\n\n## How\n\n### 配置\n\n#### Java配置\n\n1. 下载[JDK8][2]并安装到你的电脑（本文用的是jdk-8u65-windows-x64.exe）；\n\n2. 配置环境变量，右击“计算机”==>选择“高级系统设置”==>选择“高级”选项卡==>点击“环境变量”按钮：\n    - 新建系统变量`JAVA_HOME`，内容为：`C:\\Program Files\\Java\\jdk1.8.0_65`；\n    - 修改系统变量`PATH`，在末尾加入内容：`;%JAVA_HOME%\\jre\\bin`；如无此系统变量则新建系统变量`PATH`，内容为：`%JAVA_HOME%\\jre\\bin`；\n    - 新建系统变量`CLASSPATH`，内容为：`.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar`；\n\n3. 注销后登入，打开CMD.exe，输入\n    ```\n    echo %JAVA_HOME%\n    java -version\n    ```\n\n    上述两个命令皆有输出则表示安装Java成功。\n\n#### Maven配置\n\n1. 到[Maven下载页][3]下载apache-maven-3.3.1-bin.zip（apache-maven-3.3.3有Bug，其boot文件夹缺少了一个关键Jar包，已向Maven mail-list提出，不知道修复了没有）；\n\n2. 将压缩包解压到一个你喜欢的地方，如`D:\\Softwares\\apache-maven-3.3.1`；\n\n3. 配置环境变量，右击“计算机”==>选择“高级系统设置”==>选择“高级”选项卡==>点击“环境变量”按钮：\n    - 新建系统变量`M2_HOME`，内容为：`D:\\Softwares\\apache-maven-3.3.1`；\n    - 修改系统变量`PATH`，在末尾加入内容：`;%M2_HOME%\\bin`；\n\n4. **重新打开**一个CMD.exe窗口，输入：\n    ```\n    echo %M2_HOME%\n    mvn -v\n    ```\n\n    上述两个命令皆有输出则表示安装Maven成功。\n\n5. 配置开源中国Maven库（非必要）\n    - 第一次运行mvn命令时，需要去官网（国外）的Maven库同步Jar包到本地，据官网说在网络畅通情况下4分钟就同步完毕，后续运行mvn命令就不需要这么长时间了\n    - 如果你觉得时间太长无法忍受，可以配置mvn的中国库，参考[OSC的使用帮助](http://maven.oschina.net/help.html)即可配置。简要概括如下：\n\n```xml\n<! -- 在mirrors添加如下配置即可 -->\n<mirror>\n  <id>nexus-osc</id>\n  <mirrorOf>*</mirrorOf>\n  <name>Nexus osc</name>\n  <url>http://maven.oschina.net/content/groups/public/</url>\n</mirror>\n\n<! -- 在profiles添加如下配置即可 -->\n<profile>\n  <id>jdk-1.4</id>\n  <activation>\n    <jdk>1.4</jdk>\n  </activation>\n  <repositories>\n    <repository>\n      <id>jdk14</id>\n      <name>Repository for JDK 1.4 builds</name>\n      <url>http://www.myhost.com/maven/jdk14</url>\n      <layout>default</layout>\n      <snapshotPolicy>always</snapshotPolicy>\n    </repository>\n  </repositories>\n</profile>\n```\n\n\n### Demo项目\n\n#### 创建Java项目\n\n运行下述命令创建demo项目my-app：\n```bash\nmvn -B archetype:generate \\\n  -DarchetypeGroupId=org.apache.maven.archetypes \\\n  -DgroupId=com.mycompany.app \\\n  -DartifactId=my-app\n```\n\nmy-app的目录结构如下：\n```\nmy-app\n|-- pom.xml\n`-- src\n    |-- main\n    |   `-- java\n    |       `-- com\n    |           `-- mycompany\n    |               `-- app\n    |                   `-- App.java\n    `-- test\n        `-- java\n            `-- com\n                `-- mycompany\n                    `-- app\n                        `-- AppTest.java\n```\n\n其中的pom.xml是Maven的基础配置文件，pom(Project Object Model，项目对象模型)，它的内容及注释如下：\n```xml\n<! -- pom文件的开始标签 -->\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <! -- Maven的pom版本 -->\n  <modelVersion>4.0.0</modelVersion>\n  <! -- 唯一的组织或公司编号，标识此项目所属组 -->\n  <groupId>com.mycompany.app</groupId>\n  <! -- 此项目属于组的哪个项目 -->\n  <artifactId>my-app</artifactId>\n  <! -- 可执行程序打包方式 -->\n  <packaging>jar</packaging>\n  <! -- 项目版本，SNAPSHOT表示开发版 -->\n  <version>1.0-SNAPSHOT</version>\n  <! -- 项目的显示名称，常用于maven生成的文档 -->\n  <name>Maven Quick Start Archetype</name>\n  <! -- 项目的主页，常用于maven生成的文档 -->\n  <url>http://maven.apache.org</url>\n  <! -- 所用的依赖库 -->\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>3.8.1</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n#### 编译\n\n编译项目src/main：`mvn compile`，将更新<project>/target/classes文件夹\n\n#### 测试\n\n编译并运行项目src/test：`mvn test`，将更新<project>/target/test-classes文件夹，并在<project>/target/surefire-reports生成测试报告\n\n编译项目src/test而不运行：`mvn test-compile`\n\n#### 清除\n\n`mvn clean`：删除<project>/target\n\n#### 打包\n\n打包项目到<project>/target：`mvn package`\n\n打包项目到maven本地仓库：`mvn install`\n\n#### 其他\n\n`mvn site`：生成<project>/target/site，即项目主页文档\n\n`mvn eclipse:eclipse`：为项目添加eclipse标识，因此可被eclipse import\n\n`mvn idea:idea`：类似于eclipse\n\n#### 插件\n\n在pom.xml中添加<build>标签，可定制maven的编译过程\n```xml\n<project ...>\n  <build>\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-compiler-plugin</artifactId>\n        <version>2.5.1</version>\n        <configuration>\n          <source>1.5</source>\n          <target>1.5</target>\n        </configuration>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n```\n\n#### 配置注入\n\n文件结构为：\n```\nmy-app\n|-- pom.xml\n`-- src\n    |-- main\n    |   |-- java\n    |   |   `-- com\n    |   |       `-- mycompany\n    |   |           `-- app\n    |   |               `-- App.java\n    |   `-- resources\n    |       `-- META-INF\n    |           `-- application.properties\n    `-- test\n        `-- java\n            `-- com\n                `-- mycompany\n                    `-- app\n                        `-- AppTest.java\n```\n\n想要注入配置到`application.properties`，方法如下\n\n- pom.xml注入\n    - pom.xml配置如下\n    \n    ```xml\n    <build>\n      <resources>\n        <resource>\n          <directory>src/main/resources</directory>\n          <filtering>true</filtering>\n        </resource>\n      </resources>\n    </build>\n    ```\n    - application.properties配置如下\n    \n    ```\n    # application.properties\n    application.name=${pom.name}\n    application.version=${pom.version}\n    ```\n    - 即可使用pom.xml中的name和version属性注入到配置文件，运行`mvn process-resources`后application.properties的内容变为\n    \n    ```\n    # application.properties\n    application.name=Maven Quick Start Archetype\n    application.version=1.0-SNAPSHOT\n    ```\n- 配置文件注入（配置文件必须在classpath内）\n    * pom.xml配置如下，filter.properties的key直接可为src/main/resources下的所有配置文件使用\n    \n    ``` xml\n    <build>\n      <filters>\n        <filter>src/main/filters/filter.properties</filter>\n      </filters>\n      <resources>\n        <resource>\n          <directory>src/main/resources</directory>\n          <filtering>true</filtering>\n        </resource>\n      </resources>\n    </build>\n    ```\n- pom.xml的propertie注入\n    * pom.xml配置如下，my.filter.value可直接为src/main/resources下的所有配置文件使用\n    \n    ```xml\n    <project ...>\n      <properties>\n        <my.filter.value>hello</my.filter.value>\n      </properties>\n    </project>\n    ```\n- 运行时注入\n    * `mvn process-resources \"-Dcommand.line.prop=hello again\"`，command.line.prop可直接为src/main/resources下的所有配置文件使用\n\n#### 依赖\n\n```xml\n<project ...>\n  <dependencies>\n    <dependency>\n      <! -- ~/.m2/repository中查找junit组的junit包的3.8.1版本，如查询不到则到maven仓库下载 -->\n      <! -- 上文mvn package的jar包可在这里使用 -->\n      <groupId>junit</groupId>\n      <! -- junit组的junit项目 -->\n      <artifactId>junit</artifactId>\n      <! -- 版本号 -->\n      <version>3.8.1</version>\n      <! -- test|compile|runtime -->\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n浏览器访问[http://repo.maven.apache.org/maven2](http://repo.maven.apache.org/maven2)可查看maven库的所有可用jar包，以junit为例，查看[http://repo.maven.apache.org/maven2/junit/junit/maven-metadata.xml](http://repo.maven.apache.org/maven2/junit/junit/maven-metadata.xml)可查询junit所有可用版本\n\n使用[http://maven.oschina.net/home.html](http://maven.oschina.net/home.html)可按关键字检索所需jar包\n\n使用`mvn dependency:tree`可查看当前项目的依赖树\n\n#### 远程部署到其他maven库\n\n配置pom.xml如下：\n```xml\n<project ...>\n  <distributionManagement>\n    <repository>\n      <id>mycompany-repository</id>\n      <name>MyCompany Repository</name>\n      <url>scp://repository.mycompany.com/repository/maven2</url>\n    </repository>\n  </distributionManagement>\n</project>\n```\n\n配置Maven的settings.xml如下：\n```xml\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                      http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  ...\n  <servers>\n    <server>\n      <id>mycompany-repository</id>\n      <username>jvanzyl</username>\n      <! -- Default value is ~/.ssh/id_dsa -->\n      <privateKey>/path/to/identity</privateKey> (default is ~/.ssh/id_dsa)\n      <passphrase>my_key_passphrase</passphrase>\n    </server>\n  </servers>\n  ...\n</settings>\n```\n\n#### 文档创建\n\n```bash\nmvn archetype:generate \\\n  -DarchetypeGroupId=org.apache.maven.archetypes \\\n  -DarchetypeArtifactId=maven-archetype-site \\\n  -DgroupId=com.mycompany.app \\\n  -DartifactId=my-app-site\n```\n\n#### 创建web项目\n\n创建web项目：\n```bash\nmvn archetype:generate \\\n    -DarchetypeGroupId=org.apache.maven.archetypes \\\n    -DarchetypeArtifactId=maven-archetype-webapp \\\n    -DgroupId=com.mycompany.app \\\n    -DartifactId=my-webapp\n```\n\nweb项目的pom.xml配置如下：\n```xml\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n \n  <groupId>com.mycompany.app</groupId>\n  <artifactId>my-webapp</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <! -- 打包方式 -->\n  <packaging>war</packaging>\n \n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>3.8.1</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n  <! -- 最终打包成war的名称 -->\n  <build>\n    <finalName>my-webapp</finalName>\n  </build>\n</project>\n```\n\n`mvn clean package`编译并打包为war包`target/my-webapp.war`\n\n#### 多个项目组装为一个项目\n\n两个项目要组装为一个项目，目录结构如下：\n```\n+- pom.xml\n+- my-app\n| +- pom.xml\n| +- src\n|   +- main\n|     +- java\n+- my-webapp\n| +- pom.xml\n| +- src\n|   +- main\n|     +- webapp\n```\n\npom.xml如下：\n```xml\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n \n  <groupId>com.mycompany.app</groupId>\n  <artifactId>app</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <packaging>pom</packaging>\n \n  <modules>\n    <module>my-app</module>\n    <module>my-webapp</module>\n  </modules>\n</project>\n```\n\n配置`my-webapp/pom.xml`使my-webapp引用my-app：\n```xml\n  ...\n  <dependencies>\n    <dependency>\n      <! -- 这将使得my-app在war包之前得到编译和打包 -->\n      <groupId>com.mycompany.app</groupId>\n      <artifactId>my-app</artifactId>\n      <version>1.0-SNAPSHOT</version>\n    </dependency>\n    ...\n  </dependencies>\n```\n\n配置`my-webapp/pom.xml`和`my-app/pom.xml`添加<parent>标签：\n```xml\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <parent>\n    <groupId>com.mycompany.app</groupId>\n    <artifactId>app</artifactId>\n    <version>1.0-SNAPSHOT</version>\n  </parent>\n  ...\n```\n\n`mvn clean install`将编译并打包war包：`my-webapp/target/my-webapp.war`，而my-app项目将作为war包WEB-INF/lib中的一个jar包\n","slug":"maven-howto","published":1,"updated":"2022-08-09T15:02:00.590Z","photos":[],"link":"","_id":"cl6mbc11o0004igu8e3alkbq6","content":"<p>Maven版本：3.3.1</p>\n<a id=\"more\"></a>\n<p>操作系统：Windows 7</p>\n<p>Java版本：1.8</p>\n<p>移译自<a href=\"https://maven.apache.org/guides/getting-started/\" target=\"_blank\" rel=\"noopener\">Maven Getting Started Guide</a>。</p>\n<h2 id=\"What-And-Why\"><a href=\"#What-And-Why\" class=\"headerlink\" title=\"What And Why\"></a>What And Why</h2><p>Maven是一个Java的编译（Build）自动化工具，按我的理解，它可以做到：</p>\n<ul>\n<li>创建自动化</li>\n<li>包依赖管理自动化</li>\n<li>编译和单元测试自动化</li>\n<li>配置注入自动化</li>\n<li>程序（War或Jar）打包自动化，及远程部署</li>\n</ul>\n<p>因此，它是一个可以提升开发效率的工具。</p>\n<h2 id=\"How\"><a href=\"#How\" class=\"headerlink\" title=\"How\"></a>How</h2><h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><h4 id=\"Java配置\"><a href=\"#Java配置\" class=\"headerlink\" title=\"Java配置\"></a>Java配置</h4><ol>\n<li><p>下载[JDK8][2]并安装到你的电脑（本文用的是jdk-8u65-windows-x64.exe）；</p>\n</li>\n<li><p>配置环境变量，右击“计算机”==&gt;选择“高级系统设置”==&gt;选择“高级”选项卡==&gt;点击“环境变量”按钮：</p>\n<ul>\n<li>新建系统变量<code>JAVA_HOME</code>，内容为：<code>C:\\Program Files\\Java\\jdk1.8.0_65</code>；</li>\n<li>修改系统变量<code>PATH</code>，在末尾加入内容：<code>;%JAVA_HOME%\\jre\\bin</code>；如无此系统变量则新建系统变量<code>PATH</code>，内容为：<code>%JAVA_HOME%\\jre\\bin</code>；</li>\n<li>新建系统变量<code>CLASSPATH</code>，内容为：<code>.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar</code>；</li>\n</ul>\n</li>\n<li><p>注销后登入，打开CMD.exe，输入</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo %JAVA_HOME%</span><br><span class=\"line\">java -version</span><br></pre></td></tr></table></figure>\n<p> 上述两个命令皆有输出则表示安装Java成功。</p>\n</li>\n</ol>\n<h4 id=\"Maven配置\"><a href=\"#Maven配置\" class=\"headerlink\" title=\"Maven配置\"></a>Maven配置</h4><ol>\n<li><p>到[Maven下载页][3]下载apache-maven-3.3.1-bin.zip（apache-maven-3.3.3有Bug，其boot文件夹缺少了一个关键Jar包，已向Maven mail-list提出，不知道修复了没有）；</p>\n</li>\n<li><p>将压缩包解压到一个你喜欢的地方，如<code>D:\\Softwares\\apache-maven-3.3.1</code>；</p>\n</li>\n<li><p>配置环境变量，右击“计算机”==&gt;选择“高级系统设置”==&gt;选择“高级”选项卡==&gt;点击“环境变量”按钮：</p>\n<ul>\n<li>新建系统变量<code>M2_HOME</code>，内容为：<code>D:\\Softwares\\apache-maven-3.3.1</code>；</li>\n<li>修改系统变量<code>PATH</code>，在末尾加入内容：<code>;%M2_HOME%\\bin</code>；</li>\n</ul>\n</li>\n<li><p><strong>重新打开</strong>一个CMD.exe窗口，输入：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo %M2_HOME%</span><br><span class=\"line\">mvn -v</span><br></pre></td></tr></table></figure>\n<p> 上述两个命令皆有输出则表示安装Maven成功。</p>\n</li>\n<li><p>配置开源中国Maven库（非必要）</p>\n<ul>\n<li>第一次运行mvn命令时，需要去官网（国外）的Maven库同步Jar包到本地，据官网说在网络畅通情况下4分钟就同步完毕，后续运行mvn命令就不需要这么长时间了</li>\n<li>如果你觉得时间太长无法忍受，可以配置mvn的中国库，参考<a href=\"http://maven.oschina.net/help.html\" target=\"_blank\" rel=\"noopener\">OSC的使用帮助</a>即可配置。简要概括如下：</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 在<span class=\"attr\">mirrors</span>添加如下配置即可 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>nexus-osc<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">mirrorOf</span>&gt;</span>*<span class=\"tag\">&lt;/<span class=\"name\">mirrorOf</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>Nexus osc<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://maven.oschina.net/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 在<span class=\"attr\">profiles</span>添加如下配置即可 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>jdk-1.4<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">activation</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">jdk</span>&gt;</span>1.4<span class=\"tag\">&lt;/<span class=\"name\">jdk</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">activation</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>jdk14<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>Repository for JDK 1.4 builds<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://www.myhost.com/maven/jdk14<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">layout</span>&gt;</span>default<span class=\"tag\">&lt;/<span class=\"name\">layout</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">snapshotPolicy</span>&gt;</span>always<span class=\"tag\">&lt;/<span class=\"name\">snapshotPolicy</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Demo项目\"><a href=\"#Demo项目\" class=\"headerlink\" title=\"Demo项目\"></a>Demo项目</h3><h4 id=\"创建Java项目\"><a href=\"#创建Java项目\" class=\"headerlink\" title=\"创建Java项目\"></a>创建Java项目</h4><p>运行下述命令创建demo项目my-app：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn -B archetype:generate \\</span><br><span class=\"line\">  -DarchetypeGroupId=org.apache.maven.archetypes \\</span><br><span class=\"line\">  -DgroupId=com.mycompany.app \\</span><br><span class=\"line\">  -DartifactId=my-app</span><br></pre></td></tr></table></figure></p>\n<p>my-app的目录结构如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my-app</span><br><span class=\"line\">|-- pom.xml</span><br><span class=\"line\">`-- src</span><br><span class=\"line\">    |-- main</span><br><span class=\"line\">    |   `-- java</span><br><span class=\"line\">    |       `-- com</span><br><span class=\"line\">    |           `-- mycompany</span><br><span class=\"line\">    |               `-- app</span><br><span class=\"line\">    |                   `-- App.java</span><br><span class=\"line\">    `-- test</span><br><span class=\"line\">        `-- java</span><br><span class=\"line\">            `-- com</span><br><span class=\"line\">                `-- mycompany</span><br><span class=\"line\">                    `-- app</span><br><span class=\"line\">                        `-- AppTest.java</span><br></pre></td></tr></table></figure></p>\n<p>其中的pom.xml是Maven的基础配置文件，pom(Project Object Model，项目对象模型)，它的内容及注释如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">pom</span>文件的开始标签 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">Maven</span>的<span class=\"attr\">pom</span>版本 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">modelVersion</span>&gt;</span>4.0.0<span class=\"tag\">&lt;/<span class=\"name\">modelVersion</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 唯一的组织或公司编号，标识此项目所属组 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 此项目属于组的哪个项目 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>my-app<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 可执行程序打包方式 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>jar<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 项目版本，<span class=\"attr\">SNAPSHOT</span>表示开发版 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 项目的显示名称，常用于<span class=\"attr\">maven</span>生成的文档 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>Maven Quick Start Archetype<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 项目的主页，常用于<span class=\"attr\">maven</span>生成的文档 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://maven.apache.org<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 所用的依赖库 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h4><p>编译项目src/main：<code>mvn compile</code>，将更新<project>/target/classes文件夹</project></p>\n<h4 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h4><p>编译并运行项目src/test：<code>mvn test</code>，将更新<project>/target/test-classes文件夹，并在<project>/target/surefire-reports生成测试报告</project></project></p>\n<p>编译项目src/test而不运行：<code>mvn test-compile</code></p>\n<h4 id=\"清除\"><a href=\"#清除\" class=\"headerlink\" title=\"清除\"></a>清除</h4><p><code>mvn clean</code>：删除<project>/target</project></p>\n<h4 id=\"打包\"><a href=\"#打包\" class=\"headerlink\" title=\"打包\"></a>打包</h4><p>打包项目到<project>/target：<code>mvn package</code></project></p>\n<p>打包项目到maven本地仓库：<code>mvn install</code></p>\n<h4 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h4><p><code>mvn site</code>：生成<project>/target/site，即项目主页文档</project></p>\n<p><code>mvn eclipse:eclipse</code>：为项目添加eclipse标识，因此可被eclipse import</p>\n<p><code>mvn idea:idea</code>：类似于eclipse</p>\n<h4 id=\"插件\"><a href=\"#插件\" class=\"headerlink\" title=\"插件\"></a>插件</h4><p>在pom.xml中添加<build>标签，可定制maven的编译过程<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">...</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-compiler-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.5.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">source</span>&gt;</span>1.5<span class=\"tag\">&lt;/<span class=\"name\">source</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">target</span>&gt;</span>1.5<span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></build></p>\n<h4 id=\"配置注入\"><a href=\"#配置注入\" class=\"headerlink\" title=\"配置注入\"></a>配置注入</h4><p>文件结构为：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my-app</span><br><span class=\"line\">|-- pom.xml</span><br><span class=\"line\">`-- src</span><br><span class=\"line\">    |-- main</span><br><span class=\"line\">    |   |-- java</span><br><span class=\"line\">    |   |   `-- com</span><br><span class=\"line\">    |   |       `-- mycompany</span><br><span class=\"line\">    |   |           `-- app</span><br><span class=\"line\">    |   |               `-- App.java</span><br><span class=\"line\">    |   `-- resources</span><br><span class=\"line\">    |       `-- META-INF</span><br><span class=\"line\">    |           `-- application.properties</span><br><span class=\"line\">    `-- test</span><br><span class=\"line\">        `-- java</span><br><span class=\"line\">            `-- com</span><br><span class=\"line\">                `-- mycompany</span><br><span class=\"line\">                    `-- app</span><br><span class=\"line\">                        `-- AppTest.java</span><br></pre></td></tr></table></figure></p>\n<p>想要注入配置到<code>application.properties</code>，方法如下</p>\n<ul>\n<li><p>pom.xml注入</p>\n<ul>\n<li><p>pom.xml配置如下</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>src/main/resources<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">filtering</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">filtering</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>application.properties配置如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># application.properties</span><br><span class=\"line\">application.name=$&#123;pom.name&#125;</span><br><span class=\"line\">application.version=$&#123;pom.version&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>即可使用pom.xml中的name和version属性注入到配置文件，运行<code>mvn process-resources</code>后application.properties的内容变为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># application.properties</span><br><span class=\"line\">application.name=Maven Quick Start Archetype</span><br><span class=\"line\">application.version=1.0-SNAPSHOT</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>配置文件注入（配置文件必须在classpath内）</p>\n<ul>\n<li><p>pom.xml配置如下，filter.properties的key直接可为src/main/resources下的所有配置文件使用</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">filters</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">filter</span>&gt;</span>src/main/filters/filter.properties<span class=\"tag\">&lt;/<span class=\"name\">filter</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">filters</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>src/main/resources<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">filtering</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">filtering</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>pom.xml的propertie注入</p>\n<ul>\n<li><p>pom.xml配置如下，my.filter.value可直接为src/main/resources下的所有配置文件使用</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">...</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">my.filter.value</span>&gt;</span>hello<span class=\"tag\">&lt;/<span class=\"name\">my.filter.value</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>运行时注入</p>\n<ul>\n<li><code>mvn process-resources &quot;-Dcommand.line.prop=hello again&quot;</code>，command.line.prop可直接为src/main/resources下的所有配置文件使用</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"依赖\"><a href=\"#依赖\" class=\"headerlink\" title=\"依赖\"></a>依赖</h4><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">...</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> ~/<span class=\"attr\">.m2</span>/<span class=\"attr\">repository</span>中查找<span class=\"attr\">junit</span>组的<span class=\"attr\">junit</span>包的<span class=\"attr\">3.8.1</span>版本，如查询不到则到<span class=\"attr\">maven</span>仓库下载 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 上文<span class=\"attr\">mvn</span> <span class=\"attr\">package</span>的<span class=\"attr\">jar</span>包可在这里使用 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">junit</span>组的<span class=\"attr\">junit</span>项目 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 版本号 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">test</span>|<span class=\"attr\">compile</span>|<span class=\"attr\">runtime</span> <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>浏览器访问<a href=\"http://repo.maven.apache.org/maven2\" target=\"_blank\" rel=\"noopener\">http://repo.maven.apache.org/maven2</a>可查看maven库的所有可用jar包，以junit为例，查看<a href=\"http://repo.maven.apache.org/maven2/junit/junit/maven-metadata.xml\" target=\"_blank\" rel=\"noopener\">http://repo.maven.apache.org/maven2/junit/junit/maven-metadata.xml</a>可查询junit所有可用版本</p>\n<p>使用<a href=\"http://maven.oschina.net/home.html\" target=\"_blank\" rel=\"noopener\">http://maven.oschina.net/home.html</a>可按关键字检索所需jar包</p>\n<p>使用<code>mvn dependency:tree</code>可查看当前项目的依赖树</p>\n<h4 id=\"远程部署到其他maven库\"><a href=\"#远程部署到其他maven库\" class=\"headerlink\" title=\"远程部署到其他maven库\"></a>远程部署到其他maven库</h4><p>配置pom.xml如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">...</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">distributionManagement</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>mycompany-repository<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>MyCompany Repository<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>scp://repository.mycompany.com/repository/maven2<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">distributionManagement</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>配置Maven的settings.xml如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/SETTINGS/1.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/SETTINGS/1.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/settings-1.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>mycompany-repository<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>jvanzyl<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">Default</span> <span class=\"attr\">value</span> <span class=\"attr\">is</span> ~/<span class=\"attr\">.ssh</span>/<span class=\"attr\">id_dsa</span> <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">privateKey</span>&gt;</span>/path/to/identity<span class=\"tag\">&lt;/<span class=\"name\">privateKey</span>&gt;</span> (default is ~/.ssh/id_dsa)</span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">passphrase</span>&gt;</span>my_key_passphrase<span class=\"tag\">&lt;/<span class=\"name\">passphrase</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"文档创建\"><a href=\"#文档创建\" class=\"headerlink\" title=\"文档创建\"></a>文档创建</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn archetype:generate \\</span><br><span class=\"line\">  -DarchetypeGroupId=org.apache.maven.archetypes \\</span><br><span class=\"line\">  -DarchetypeArtifactId=maven-archetype-site \\</span><br><span class=\"line\">  -DgroupId=com.mycompany.app \\</span><br><span class=\"line\">  -DartifactId=my-app-site</span><br></pre></td></tr></table></figure>\n<h4 id=\"创建web项目\"><a href=\"#创建web项目\" class=\"headerlink\" title=\"创建web项目\"></a>创建web项目</h4><p>创建web项目：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn archetype:generate \\</span><br><span class=\"line\">    -DarchetypeGroupId=org.apache.maven.archetypes \\</span><br><span class=\"line\">    -DarchetypeArtifactId=maven-archetype-webapp \\</span><br><span class=\"line\">    -DgroupId=com.mycompany.app \\</span><br><span class=\"line\">    -DartifactId=my-webapp</span><br></pre></td></tr></table></figure></p>\n<p>web项目的pom.xml配置如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">modelVersion</span>&gt;</span>4.0.0<span class=\"tag\">&lt;/<span class=\"name\">modelVersion</span>&gt;</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>my-webapp<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 打包方式 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>war<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 最终打包成<span class=\"attr\">war</span>的名称 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">finalName</span>&gt;</span>my-webapp<span class=\"tag\">&lt;/<span class=\"name\">finalName</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p><code>mvn clean package</code>编译并打包为war包<code>target/my-webapp.war</code></p>\n<h4 id=\"多个项目组装为一个项目\"><a href=\"#多个项目组装为一个项目\" class=\"headerlink\" title=\"多个项目组装为一个项目\"></a>多个项目组装为一个项目</h4><p>两个项目要组装为一个项目，目录结构如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+- pom.xml</span><br><span class=\"line\">+- my-app</span><br><span class=\"line\">| +- pom.xml</span><br><span class=\"line\">| +- src</span><br><span class=\"line\">|   +- main</span><br><span class=\"line\">|     +- java</span><br><span class=\"line\">+- my-webapp</span><br><span class=\"line\">| +- pom.xml</span><br><span class=\"line\">| +- src</span><br><span class=\"line\">|   +- main</span><br><span class=\"line\">|     +- webapp</span><br></pre></td></tr></table></figure></p>\n<p>pom.xml如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">modelVersion</span>&gt;</span>4.0.0<span class=\"tag\">&lt;/<span class=\"name\">modelVersion</span>&gt;</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>app<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>pom<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">modules</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>my-app<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>my-webapp<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">modules</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>配置<code>my-webapp/pom.xml</code>使my-webapp引用my-app：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 这将使得<span class=\"attr\">my-app</span>在<span class=\"attr\">war</span>包之前得到编译和打包 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>my-app<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>配置<code>my-webapp/pom.xml</code>和<code>my-app/pom.xml</code>添加<parent>标签：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">parent</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>app<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">parent</span>&gt;</span></span><br><span class=\"line\">  ...</span><br></pre></td></tr></table></figure></parent></p>\n<p><code>mvn clean install</code>将编译并打包war包：<code>my-webapp/target/my-webapp.war</code>，而my-app项目将作为war包WEB-INF/lib中的一个jar包</p>\n","site":{"data":{}},"excerpt":"<p>Maven版本：3.3.1</p>","more":"<p>操作系统：Windows 7</p>\n<p>Java版本：1.8</p>\n<p>移译自<a href=\"https://maven.apache.org/guides/getting-started/\" target=\"_blank\" rel=\"noopener\">Maven Getting Started Guide</a>。</p>\n<h2 id=\"What-And-Why\"><a href=\"#What-And-Why\" class=\"headerlink\" title=\"What And Why\"></a>What And Why</h2><p>Maven是一个Java的编译（Build）自动化工具，按我的理解，它可以做到：</p>\n<ul>\n<li>创建自动化</li>\n<li>包依赖管理自动化</li>\n<li>编译和单元测试自动化</li>\n<li>配置注入自动化</li>\n<li>程序（War或Jar）打包自动化，及远程部署</li>\n</ul>\n<p>因此，它是一个可以提升开发效率的工具。</p>\n<h2 id=\"How\"><a href=\"#How\" class=\"headerlink\" title=\"How\"></a>How</h2><h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><h4 id=\"Java配置\"><a href=\"#Java配置\" class=\"headerlink\" title=\"Java配置\"></a>Java配置</h4><ol>\n<li><p>下载[JDK8][2]并安装到你的电脑（本文用的是jdk-8u65-windows-x64.exe）；</p>\n</li>\n<li><p>配置环境变量，右击“计算机”==&gt;选择“高级系统设置”==&gt;选择“高级”选项卡==&gt;点击“环境变量”按钮：</p>\n<ul>\n<li>新建系统变量<code>JAVA_HOME</code>，内容为：<code>C:\\Program Files\\Java\\jdk1.8.0_65</code>；</li>\n<li>修改系统变量<code>PATH</code>，在末尾加入内容：<code>;%JAVA_HOME%\\jre\\bin</code>；如无此系统变量则新建系统变量<code>PATH</code>，内容为：<code>%JAVA_HOME%\\jre\\bin</code>；</li>\n<li>新建系统变量<code>CLASSPATH</code>，内容为：<code>.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar</code>；</li>\n</ul>\n</li>\n<li><p>注销后登入，打开CMD.exe，输入</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo %JAVA_HOME%</span><br><span class=\"line\">java -version</span><br></pre></td></tr></table></figure>\n<p> 上述两个命令皆有输出则表示安装Java成功。</p>\n</li>\n</ol>\n<h4 id=\"Maven配置\"><a href=\"#Maven配置\" class=\"headerlink\" title=\"Maven配置\"></a>Maven配置</h4><ol>\n<li><p>到[Maven下载页][3]下载apache-maven-3.3.1-bin.zip（apache-maven-3.3.3有Bug，其boot文件夹缺少了一个关键Jar包，已向Maven mail-list提出，不知道修复了没有）；</p>\n</li>\n<li><p>将压缩包解压到一个你喜欢的地方，如<code>D:\\Softwares\\apache-maven-3.3.1</code>；</p>\n</li>\n<li><p>配置环境变量，右击“计算机”==&gt;选择“高级系统设置”==&gt;选择“高级”选项卡==&gt;点击“环境变量”按钮：</p>\n<ul>\n<li>新建系统变量<code>M2_HOME</code>，内容为：<code>D:\\Softwares\\apache-maven-3.3.1</code>；</li>\n<li>修改系统变量<code>PATH</code>，在末尾加入内容：<code>;%M2_HOME%\\bin</code>；</li>\n</ul>\n</li>\n<li><p><strong>重新打开</strong>一个CMD.exe窗口，输入：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo %M2_HOME%</span><br><span class=\"line\">mvn -v</span><br></pre></td></tr></table></figure>\n<p> 上述两个命令皆有输出则表示安装Maven成功。</p>\n</li>\n<li><p>配置开源中国Maven库（非必要）</p>\n<ul>\n<li>第一次运行mvn命令时，需要去官网（国外）的Maven库同步Jar包到本地，据官网说在网络畅通情况下4分钟就同步完毕，后续运行mvn命令就不需要这么长时间了</li>\n<li>如果你觉得时间太长无法忍受，可以配置mvn的中国库，参考<a href=\"http://maven.oschina.net/help.html\" target=\"_blank\" rel=\"noopener\">OSC的使用帮助</a>即可配置。简要概括如下：</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 在<span class=\"attr\">mirrors</span>添加如下配置即可 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>nexus-osc<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">mirrorOf</span>&gt;</span>*<span class=\"tag\">&lt;/<span class=\"name\">mirrorOf</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>Nexus osc<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://maven.oschina.net/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 在<span class=\"attr\">profiles</span>添加如下配置即可 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>jdk-1.4<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">activation</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">jdk</span>&gt;</span>1.4<span class=\"tag\">&lt;/<span class=\"name\">jdk</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">activation</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>jdk14<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>Repository for JDK 1.4 builds<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://www.myhost.com/maven/jdk14<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">layout</span>&gt;</span>default<span class=\"tag\">&lt;/<span class=\"name\">layout</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">snapshotPolicy</span>&gt;</span>always<span class=\"tag\">&lt;/<span class=\"name\">snapshotPolicy</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Demo项目\"><a href=\"#Demo项目\" class=\"headerlink\" title=\"Demo项目\"></a>Demo项目</h3><h4 id=\"创建Java项目\"><a href=\"#创建Java项目\" class=\"headerlink\" title=\"创建Java项目\"></a>创建Java项目</h4><p>运行下述命令创建demo项目my-app：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn -B archetype:generate \\</span><br><span class=\"line\">  -DarchetypeGroupId=org.apache.maven.archetypes \\</span><br><span class=\"line\">  -DgroupId=com.mycompany.app \\</span><br><span class=\"line\">  -DartifactId=my-app</span><br></pre></td></tr></table></figure></p>\n<p>my-app的目录结构如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my-app</span><br><span class=\"line\">|-- pom.xml</span><br><span class=\"line\">`-- src</span><br><span class=\"line\">    |-- main</span><br><span class=\"line\">    |   `-- java</span><br><span class=\"line\">    |       `-- com</span><br><span class=\"line\">    |           `-- mycompany</span><br><span class=\"line\">    |               `-- app</span><br><span class=\"line\">    |                   `-- App.java</span><br><span class=\"line\">    `-- test</span><br><span class=\"line\">        `-- java</span><br><span class=\"line\">            `-- com</span><br><span class=\"line\">                `-- mycompany</span><br><span class=\"line\">                    `-- app</span><br><span class=\"line\">                        `-- AppTest.java</span><br></pre></td></tr></table></figure></p>\n<p>其中的pom.xml是Maven的基础配置文件，pom(Project Object Model，项目对象模型)，它的内容及注释如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">pom</span>文件的开始标签 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">Maven</span>的<span class=\"attr\">pom</span>版本 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">modelVersion</span>&gt;</span>4.0.0<span class=\"tag\">&lt;/<span class=\"name\">modelVersion</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 唯一的组织或公司编号，标识此项目所属组 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 此项目属于组的哪个项目 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>my-app<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 可执行程序打包方式 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>jar<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 项目版本，<span class=\"attr\">SNAPSHOT</span>表示开发版 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 项目的显示名称，常用于<span class=\"attr\">maven</span>生成的文档 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>Maven Quick Start Archetype<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 项目的主页，常用于<span class=\"attr\">maven</span>生成的文档 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://maven.apache.org<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 所用的依赖库 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h4><p>编译项目src/main：<code>mvn compile</code>，将更新<project>/target/classes文件夹</project></p>\n<h4 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h4><p>编译并运行项目src/test：<code>mvn test</code>，将更新<project>/target/test-classes文件夹，并在<project>/target/surefire-reports生成测试报告</project></project></p>\n<p>编译项目src/test而不运行：<code>mvn test-compile</code></p>\n<h4 id=\"清除\"><a href=\"#清除\" class=\"headerlink\" title=\"清除\"></a>清除</h4><p><code>mvn clean</code>：删除<project>/target</project></p>\n<h4 id=\"打包\"><a href=\"#打包\" class=\"headerlink\" title=\"打包\"></a>打包</h4><p>打包项目到<project>/target：<code>mvn package</code></project></p>\n<p>打包项目到maven本地仓库：<code>mvn install</code></p>\n<h4 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h4><p><code>mvn site</code>：生成<project>/target/site，即项目主页文档</project></p>\n<p><code>mvn eclipse:eclipse</code>：为项目添加eclipse标识，因此可被eclipse import</p>\n<p><code>mvn idea:idea</code>：类似于eclipse</p>\n<h4 id=\"插件\"><a href=\"#插件\" class=\"headerlink\" title=\"插件\"></a>插件</h4><p>在pom.xml中添加<build>标签，可定制maven的编译过程<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">...</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-compiler-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.5.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">source</span>&gt;</span>1.5<span class=\"tag\">&lt;/<span class=\"name\">source</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">target</span>&gt;</span>1.5<span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></build></p>\n<h4 id=\"配置注入\"><a href=\"#配置注入\" class=\"headerlink\" title=\"配置注入\"></a>配置注入</h4><p>文件结构为：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my-app</span><br><span class=\"line\">|-- pom.xml</span><br><span class=\"line\">`-- src</span><br><span class=\"line\">    |-- main</span><br><span class=\"line\">    |   |-- java</span><br><span class=\"line\">    |   |   `-- com</span><br><span class=\"line\">    |   |       `-- mycompany</span><br><span class=\"line\">    |   |           `-- app</span><br><span class=\"line\">    |   |               `-- App.java</span><br><span class=\"line\">    |   `-- resources</span><br><span class=\"line\">    |       `-- META-INF</span><br><span class=\"line\">    |           `-- application.properties</span><br><span class=\"line\">    `-- test</span><br><span class=\"line\">        `-- java</span><br><span class=\"line\">            `-- com</span><br><span class=\"line\">                `-- mycompany</span><br><span class=\"line\">                    `-- app</span><br><span class=\"line\">                        `-- AppTest.java</span><br></pre></td></tr></table></figure></p>\n<p>想要注入配置到<code>application.properties</code>，方法如下</p>\n<ul>\n<li><p>pom.xml注入</p>\n<ul>\n<li><p>pom.xml配置如下</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>src/main/resources<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">filtering</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">filtering</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>application.properties配置如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># application.properties</span><br><span class=\"line\">application.name=$&#123;pom.name&#125;</span><br><span class=\"line\">application.version=$&#123;pom.version&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>即可使用pom.xml中的name和version属性注入到配置文件，运行<code>mvn process-resources</code>后application.properties的内容变为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># application.properties</span><br><span class=\"line\">application.name=Maven Quick Start Archetype</span><br><span class=\"line\">application.version=1.0-SNAPSHOT</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>配置文件注入（配置文件必须在classpath内）</p>\n<ul>\n<li><p>pom.xml配置如下，filter.properties的key直接可为src/main/resources下的所有配置文件使用</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">filters</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">filter</span>&gt;</span>src/main/filters/filter.properties<span class=\"tag\">&lt;/<span class=\"name\">filter</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">filters</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>src/main/resources<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">filtering</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">filtering</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>pom.xml的propertie注入</p>\n<ul>\n<li><p>pom.xml配置如下，my.filter.value可直接为src/main/resources下的所有配置文件使用</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">...</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">my.filter.value</span>&gt;</span>hello<span class=\"tag\">&lt;/<span class=\"name\">my.filter.value</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>运行时注入</p>\n<ul>\n<li><code>mvn process-resources &quot;-Dcommand.line.prop=hello again&quot;</code>，command.line.prop可直接为src/main/resources下的所有配置文件使用</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"依赖\"><a href=\"#依赖\" class=\"headerlink\" title=\"依赖\"></a>依赖</h4><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">...</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> ~/<span class=\"attr\">.m2</span>/<span class=\"attr\">repository</span>中查找<span class=\"attr\">junit</span>组的<span class=\"attr\">junit</span>包的<span class=\"attr\">3.8.1</span>版本，如查询不到则到<span class=\"attr\">maven</span>仓库下载 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 上文<span class=\"attr\">mvn</span> <span class=\"attr\">package</span>的<span class=\"attr\">jar</span>包可在这里使用 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">junit</span>组的<span class=\"attr\">junit</span>项目 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 版本号 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">test</span>|<span class=\"attr\">compile</span>|<span class=\"attr\">runtime</span> <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>浏览器访问<a href=\"http://repo.maven.apache.org/maven2\" target=\"_blank\" rel=\"noopener\">http://repo.maven.apache.org/maven2</a>可查看maven库的所有可用jar包，以junit为例，查看<a href=\"http://repo.maven.apache.org/maven2/junit/junit/maven-metadata.xml\" target=\"_blank\" rel=\"noopener\">http://repo.maven.apache.org/maven2/junit/junit/maven-metadata.xml</a>可查询junit所有可用版本</p>\n<p>使用<a href=\"http://maven.oschina.net/home.html\" target=\"_blank\" rel=\"noopener\">http://maven.oschina.net/home.html</a>可按关键字检索所需jar包</p>\n<p>使用<code>mvn dependency:tree</code>可查看当前项目的依赖树</p>\n<h4 id=\"远程部署到其他maven库\"><a href=\"#远程部署到其他maven库\" class=\"headerlink\" title=\"远程部署到其他maven库\"></a>远程部署到其他maven库</h4><p>配置pom.xml如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">...</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">distributionManagement</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>mycompany-repository<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>MyCompany Repository<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>scp://repository.mycompany.com/repository/maven2<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">distributionManagement</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>配置Maven的settings.xml如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/SETTINGS/1.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/SETTINGS/1.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/settings-1.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>mycompany-repository<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>jvanzyl<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> <span class=\"attr\">Default</span> <span class=\"attr\">value</span> <span class=\"attr\">is</span> ~/<span class=\"attr\">.ssh</span>/<span class=\"attr\">id_dsa</span> <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">privateKey</span>&gt;</span>/path/to/identity<span class=\"tag\">&lt;/<span class=\"name\">privateKey</span>&gt;</span> (default is ~/.ssh/id_dsa)</span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">passphrase</span>&gt;</span>my_key_passphrase<span class=\"tag\">&lt;/<span class=\"name\">passphrase</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"文档创建\"><a href=\"#文档创建\" class=\"headerlink\" title=\"文档创建\"></a>文档创建</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn archetype:generate \\</span><br><span class=\"line\">  -DarchetypeGroupId=org.apache.maven.archetypes \\</span><br><span class=\"line\">  -DarchetypeArtifactId=maven-archetype-site \\</span><br><span class=\"line\">  -DgroupId=com.mycompany.app \\</span><br><span class=\"line\">  -DartifactId=my-app-site</span><br></pre></td></tr></table></figure>\n<h4 id=\"创建web项目\"><a href=\"#创建web项目\" class=\"headerlink\" title=\"创建web项目\"></a>创建web项目</h4><p>创建web项目：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn archetype:generate \\</span><br><span class=\"line\">    -DarchetypeGroupId=org.apache.maven.archetypes \\</span><br><span class=\"line\">    -DarchetypeArtifactId=maven-archetype-webapp \\</span><br><span class=\"line\">    -DgroupId=com.mycompany.app \\</span><br><span class=\"line\">    -DartifactId=my-webapp</span><br></pre></td></tr></table></figure></p>\n<p>web项目的pom.xml配置如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">modelVersion</span>&gt;</span>4.0.0<span class=\"tag\">&lt;/<span class=\"name\">modelVersion</span>&gt;</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>my-webapp<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 打包方式 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>war<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 最终打包成<span class=\"attr\">war</span>的名称 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">finalName</span>&gt;</span>my-webapp<span class=\"tag\">&lt;/<span class=\"name\">finalName</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p><code>mvn clean package</code>编译并打包为war包<code>target/my-webapp.war</code></p>\n<h4 id=\"多个项目组装为一个项目\"><a href=\"#多个项目组装为一个项目\" class=\"headerlink\" title=\"多个项目组装为一个项目\"></a>多个项目组装为一个项目</h4><p>两个项目要组装为一个项目，目录结构如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+- pom.xml</span><br><span class=\"line\">+- my-app</span><br><span class=\"line\">| +- pom.xml</span><br><span class=\"line\">| +- src</span><br><span class=\"line\">|   +- main</span><br><span class=\"line\">|     +- java</span><br><span class=\"line\">+- my-webapp</span><br><span class=\"line\">| +- pom.xml</span><br><span class=\"line\">| +- src</span><br><span class=\"line\">|   +- main</span><br><span class=\"line\">|     +- webapp</span><br></pre></td></tr></table></figure></p>\n<p>pom.xml如下：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">modelVersion</span>&gt;</span>4.0.0<span class=\"tag\">&lt;/<span class=\"name\">modelVersion</span>&gt;</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>app<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>pom<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">modules</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>my-app<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>my-webapp<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">modules</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>配置<code>my-webapp/pom.xml</code>使my-webapp引用my-app：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">!</span> <span class=\"attr\">--</span> 这将使得<span class=\"attr\">my-app</span>在<span class=\"attr\">war</span>包之前得到编译和打包 <span class=\"attr\">--</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>my-app<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>配置<code>my-webapp/pom.xml</code>和<code>my-app/pom.xml</code>添加<parent>标签：<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                      http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">parent</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mycompany.app<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>app<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">parent</span>&gt;</span></span><br><span class=\"line\">  ...</span><br></pre></td></tr></table></figure></parent></p>\n<p><code>mvn clean install</code>将编译并打包war包：<code>my-webapp/target/my-webapp.war</code>，而my-app项目将作为war包WEB-INF/lib中的一个jar包</p>"},{"layout":"post","title":"Spring Boot初探","date":"2016-01-23T07:02:00.000Z","comments":1,"_content":"\n本着实用主义的目的简单介绍Spring Boot。\n\n<!--more-->\n\n## 概要\n\n- 它的出现并不是为了取代传统的Spring Framework，而是提供一种新的Spring开发体验——尽可能消除大量繁琐的XML配置\n- 个人觉得Spring Framework的Java注解式开发已经做得够好了（省去大量的配置工作），并不是非得用Spring Boot不可的\n- 官网的[Guide](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/)已经写得非常好了，我只是从实用主义讲如何快速入门\n\n## 代码与相关理论\n\n### 准备工作\n\n访问[Spring Initializr](https://start.spring.io/)生成以maven构建的demo项目，Dependencies我分别勾选了[Web]和[Security]，在终端下定位到生成的demo项目运行`mvn eclipse:eclipse`生成eclipse标识，接下来就可以使用eclipse进行开发了。\n\n### 代码（自动生成）游园活动\n\n代码结构如下：\n```\ndemo\n + src/test/java\n   + com.example\n     - DemoApplicationTests.java\n + src/main/java\n   + com.example\n     - DemoApplication.java\n + src/main/resources\n   + templates\n   + static\n   - application.properties\n - pom.xml \n```\n\n#### pom.xml\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.example</groupId>\n    <artifactId>demo</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <!-- 不同于传统Spring的地方：兼容将项目打包成war丢到外置Tomcat容器，也可打包成jar使用内置Tomcat运行Spring Web项目，直接运行jar包即可 -->\n    <packaging>jar</packaging>\n\n    <name>demo</name>\n    <description>Demo project for Spring Boot</description>\n\n    <!-- 必须要引入的parent，parent包含了大量基础的spring依赖，因此你不需要在pom.xml配置一堆所需引用的spring jar包 -->\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>1.3.2.RELEASE</version>\n        <relativePath/> <!-- lookup parent from repository -->\n    </parent>\n\n    <properties>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <!-- 以组件的形式在这里添加一条dependency，即官网宣称的开箱即用，简直傻瓜式啊 -->\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-security</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        \n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n    \n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>    \n\n</project>\n```\n可开箱即用的其他dependency如下：\n- [官网](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#using-boot-starter-poms)\n- [非官网](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-starters/README.adoc)\n\n#### DemoApplication.java\n\n```java\npackage com.example;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n/**\n * @SpringBootApplication等价于 @Configuration @EnableAutoConfiguration @ComponentScan\n * @Configuration标注配置类，即以往的XML配置文件被映射成了一个类\n * @EnableAutoConfiguration，表示由Spring Boot启动默认配置，如web项目将默认配置内置tomcat端口号8080\n * @ComponentScan放置在basePackage（例子中是com.example），com.example.*下的所有Java文件将被扫描解释\n */\n@SpringBootApplication\npublic class DemoApplication {\n\n    // 这里的args一般传的是配置类\n    public static void main(String[] args) {\n        SpringApplication.run(DemoApplication.class, args);\n    }\n}\n\n```\n\n#### DemoApplicationTests.java\n\n```java\npackage com.example;\n\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\nimport org.springframework.test.context.web.WebAppConfiguration;\nimport org.springframework.boot.test.SpringApplicationConfiguration;\nimport org.springframework.test.context.junit4.SpringJUnit4ClassRunner;\n\n@RunWith(SpringJUnit4ClassRunner.class) // 指定以spring-junit运行单元测试\n@SpringApplicationConfiguration(classes = DemoApplication.class) // 指定我们的应用类\n@WebAppConfiguration // 表明要测试的是一个web应用\npublic class DemoApplicationTests {\n\n    @Test\n    public void contextLoads() {\n    }\n\n}\n```\n\n#### application.properties\n\nSpring Boot的默认配置文件，假设我在此文件有一个键值`name=jayzee`，那么我在java代码中可以直接使用如下（Spring Boot自动注入）：\n\n```java\n@Value(\"${name}\")\nprivate String name;\n```\n\n我在此文件添加一个键值`server.port=8090`修改内置tomcat的默认端口为8090。\n\n#### templates\n\n[Template engines](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-spring-mvc-template-engines)说到：\n- 此文件夹用于放置动态html如jsp（官网建议尽量少用，因为在内置tomcat下运行将不起作用）等其他模板文件\n\n#### static\n\n[Static Content](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-spring-mvc-static-content)\n- 此文件用于存放静态资源文件如：html、js、css和json等\n- 如果这里存放有index.html，则默认作为项目的home page\n- 前台代码`<link href=\"/css/spring-2a2d595e6ed9a0b24f027f2b63b134d6.css\"/>`直接引用`/static/css/spring-2a2d595e6ed9a0b24f027f2b63b134d6.css`\n\n### 结尾\n\n终端定位到demo项目，运行\n\n```\nmvn package\njava -jar target/demo-0.0.1-SNAPSHOT.jar\n```\n\n访问`http://localhost:8090/`则可看到弹出一个登录窗口（因为我们引入了security组件）。\n\n[Security](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-security)提到，默认账户是`user`，随机密码在启动tomcat时在控制台打印。\n\n其他资源：\n- [spring boot之login+jdbc完整例子](http://www.tianmaying.com/tutorial/spring-mvc-microblog)\n- [此博文demo项目源码](https://github.com/JayzeeZhang/spring-boot-demo)\n","source":"_posts/2016-01-23-sth-about-spring-boot.markdown","raw":"---\nlayout: post\ntitle: Spring Boot初探\ndate: '2016-01-23 15:02'\ncomments: true\ncategories: ['编程实践']  \ntags: ['Spring']\n---\n\n本着实用主义的目的简单介绍Spring Boot。\n\n<!--more-->\n\n## 概要\n\n- 它的出现并不是为了取代传统的Spring Framework，而是提供一种新的Spring开发体验——尽可能消除大量繁琐的XML配置\n- 个人觉得Spring Framework的Java注解式开发已经做得够好了（省去大量的配置工作），并不是非得用Spring Boot不可的\n- 官网的[Guide](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/)已经写得非常好了，我只是从实用主义讲如何快速入门\n\n## 代码与相关理论\n\n### 准备工作\n\n访问[Spring Initializr](https://start.spring.io/)生成以maven构建的demo项目，Dependencies我分别勾选了[Web]和[Security]，在终端下定位到生成的demo项目运行`mvn eclipse:eclipse`生成eclipse标识，接下来就可以使用eclipse进行开发了。\n\n### 代码（自动生成）游园活动\n\n代码结构如下：\n```\ndemo\n + src/test/java\n   + com.example\n     - DemoApplicationTests.java\n + src/main/java\n   + com.example\n     - DemoApplication.java\n + src/main/resources\n   + templates\n   + static\n   - application.properties\n - pom.xml \n```\n\n#### pom.xml\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.example</groupId>\n    <artifactId>demo</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <!-- 不同于传统Spring的地方：兼容将项目打包成war丢到外置Tomcat容器，也可打包成jar使用内置Tomcat运行Spring Web项目，直接运行jar包即可 -->\n    <packaging>jar</packaging>\n\n    <name>demo</name>\n    <description>Demo project for Spring Boot</description>\n\n    <!-- 必须要引入的parent，parent包含了大量基础的spring依赖，因此你不需要在pom.xml配置一堆所需引用的spring jar包 -->\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>1.3.2.RELEASE</version>\n        <relativePath/> <!-- lookup parent from repository -->\n    </parent>\n\n    <properties>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <!-- 以组件的形式在这里添加一条dependency，即官网宣称的开箱即用，简直傻瓜式啊 -->\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-security</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        \n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n    \n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>    \n\n</project>\n```\n可开箱即用的其他dependency如下：\n- [官网](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#using-boot-starter-poms)\n- [非官网](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-starters/README.adoc)\n\n#### DemoApplication.java\n\n```java\npackage com.example;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n/**\n * @SpringBootApplication等价于 @Configuration @EnableAutoConfiguration @ComponentScan\n * @Configuration标注配置类，即以往的XML配置文件被映射成了一个类\n * @EnableAutoConfiguration，表示由Spring Boot启动默认配置，如web项目将默认配置内置tomcat端口号8080\n * @ComponentScan放置在basePackage（例子中是com.example），com.example.*下的所有Java文件将被扫描解释\n */\n@SpringBootApplication\npublic class DemoApplication {\n\n    // 这里的args一般传的是配置类\n    public static void main(String[] args) {\n        SpringApplication.run(DemoApplication.class, args);\n    }\n}\n\n```\n\n#### DemoApplicationTests.java\n\n```java\npackage com.example;\n\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\nimport org.springframework.test.context.web.WebAppConfiguration;\nimport org.springframework.boot.test.SpringApplicationConfiguration;\nimport org.springframework.test.context.junit4.SpringJUnit4ClassRunner;\n\n@RunWith(SpringJUnit4ClassRunner.class) // 指定以spring-junit运行单元测试\n@SpringApplicationConfiguration(classes = DemoApplication.class) // 指定我们的应用类\n@WebAppConfiguration // 表明要测试的是一个web应用\npublic class DemoApplicationTests {\n\n    @Test\n    public void contextLoads() {\n    }\n\n}\n```\n\n#### application.properties\n\nSpring Boot的默认配置文件，假设我在此文件有一个键值`name=jayzee`，那么我在java代码中可以直接使用如下（Spring Boot自动注入）：\n\n```java\n@Value(\"${name}\")\nprivate String name;\n```\n\n我在此文件添加一个键值`server.port=8090`修改内置tomcat的默认端口为8090。\n\n#### templates\n\n[Template engines](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-spring-mvc-template-engines)说到：\n- 此文件夹用于放置动态html如jsp（官网建议尽量少用，因为在内置tomcat下运行将不起作用）等其他模板文件\n\n#### static\n\n[Static Content](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-spring-mvc-static-content)\n- 此文件用于存放静态资源文件如：html、js、css和json等\n- 如果这里存放有index.html，则默认作为项目的home page\n- 前台代码`<link href=\"/css/spring-2a2d595e6ed9a0b24f027f2b63b134d6.css\"/>`直接引用`/static/css/spring-2a2d595e6ed9a0b24f027f2b63b134d6.css`\n\n### 结尾\n\n终端定位到demo项目，运行\n\n```\nmvn package\njava -jar target/demo-0.0.1-SNAPSHOT.jar\n```\n\n访问`http://localhost:8090/`则可看到弹出一个登录窗口（因为我们引入了security组件）。\n\n[Security](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-security)提到，默认账户是`user`，随机密码在启动tomcat时在控制台打印。\n\n其他资源：\n- [spring boot之login+jdbc完整例子](http://www.tianmaying.com/tutorial/spring-mvc-microblog)\n- [此博文demo项目源码](https://github.com/JayzeeZhang/spring-boot-demo)\n","slug":"sth-about-spring-boot","published":1,"updated":"2022-08-09T15:02:00.594Z","photos":[],"link":"","_id":"cl6mbc11r0005igu8izbhzlfo","content":"<p>本着实用主义的目的简单介绍Spring Boot。</p>\n<a id=\"more\"></a>\n<h2 id=\"概要\"><a href=\"#概要\" class=\"headerlink\" title=\"概要\"></a>概要</h2><ul>\n<li>它的出现并不是为了取代传统的Spring Framework，而是提供一种新的Spring开发体验——尽可能消除大量繁琐的XML配置</li>\n<li>个人觉得Spring Framework的Java注解式开发已经做得够好了（省去大量的配置工作），并不是非得用Spring Boot不可的</li>\n<li>官网的<a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/\" target=\"_blank\" rel=\"noopener\">Guide</a>已经写得非常好了，我只是从实用主义讲如何快速入门</li>\n</ul>\n<h2 id=\"代码与相关理论\"><a href=\"#代码与相关理论\" class=\"headerlink\" title=\"代码与相关理论\"></a>代码与相关理论</h2><h3 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h3><p>访问<a href=\"https://start.spring.io/\" target=\"_blank\" rel=\"noopener\">Spring Initializr</a>生成以maven构建的demo项目，Dependencies我分别勾选了[Web]和[Security]，在终端下定位到生成的demo项目运行<code>mvn eclipse:eclipse</code>生成eclipse标识，接下来就可以使用eclipse进行开发了。</p>\n<h3 id=\"代码（自动生成）游园活动\"><a href=\"#代码（自动生成）游园活动\" class=\"headerlink\" title=\"代码（自动生成）游园活动\"></a>代码（自动生成）游园活动</h3><p>代码结构如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">demo</span><br><span class=\"line\"> + src/test/java</span><br><span class=\"line\">   + com.example</span><br><span class=\"line\">     - DemoApplicationTests.java</span><br><span class=\"line\"> + src/main/java</span><br><span class=\"line\">   + com.example</span><br><span class=\"line\">     - DemoApplication.java</span><br><span class=\"line\"> + src/main/resources</span><br><span class=\"line\">   + templates</span><br><span class=\"line\">   + static</span><br><span class=\"line\">   - application.properties</span><br><span class=\"line\"> - pom.xml</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"pom-xml\"><a href=\"#pom-xml\" class=\"headerlink\" title=\"pom.xml\"></a>pom.xml</h4><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span> <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">modelVersion</span>&gt;</span>4.0.0<span class=\"tag\">&lt;/<span class=\"name\">modelVersion</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.example<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>demo<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.0.1-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 不同于传统Spring的地方：兼容将项目打包成war丢到外置Tomcat容器，也可打包成jar使用内置Tomcat运行Spring Web项目，直接运行jar包即可 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>jar<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>demo<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>Demo project for Spring Boot<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 必须要引入的parent，parent包含了大量基础的spring依赖，因此你不需要在pom.xml配置一堆所需引用的spring jar包 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">parent</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-parent<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.3.2.RELEASE<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">relativePath</span>/&gt;</span> <span class=\"comment\">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">parent</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class=\"tag\">&lt;/<span class=\"name\">project.build.sourceEncoding</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">java.version</span>&gt;</span>1.8<span class=\"tag\">&lt;/<span class=\"name\">java.version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 以组件的形式在这里添加一条dependency，即官网宣称的开箱即用，简直傻瓜式啊 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-security<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-web<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-test<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span>    </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>可开箱即用的其他dependency如下：</p>\n<ul>\n<li><a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#using-boot-starter-poms\" target=\"_blank\" rel=\"noopener\">官网</a></li>\n<li><a href=\"https://github.com/spring-projects/spring-boot/blob/master/spring-boot-starters/README.adoc\" target=\"_blank\" rel=\"noopener\">非官网</a></li>\n</ul>\n<h4 id=\"DemoApplication-java\"><a href=\"#DemoApplication-java\" class=\"headerlink\" title=\"DemoApplication.java\"></a>DemoApplication.java</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.example;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.SpringApplication;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@SpringBootApplication</span>等价于 <span class=\"doctag\">@Configuration</span> <span class=\"doctag\">@EnableAutoConfiguration</span> <span class=\"doctag\">@ComponentScan</span></span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Configuration</span>标注配置类，即以往的XML配置文件被映射成了一个类</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@EnableAutoConfiguration</span>，表示由Spring Boot启动默认配置，如web项目将默认配置内置tomcat端口号8080</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@ComponentScan</span>放置在basePackage（例子中是com.example），com.example.*下的所有Java文件将被扫描解释</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@SpringBootApplication</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DemoApplication</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 这里的args一般传的是配置类</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        SpringApplication.run(DemoApplication.class, args);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"DemoApplicationTests-java\"><a href=\"#DemoApplicationTests-java\" class=\"headerlink\" title=\"DemoApplicationTests.java\"></a>DemoApplicationTests.java</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.example;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.Test;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.runner.RunWith;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.test.context.web.WebAppConfiguration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.test.SpringApplicationConfiguration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.test.context.junit4.SpringJUnit4ClassRunner;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@RunWith</span>(SpringJUnit4ClassRunner.class) <span class=\"comment\">// 指定以spring-junit运行单元测试</span></span><br><span class=\"line\"><span class=\"meta\">@SpringApplicationConfiguration</span>(classes = DemoApplication.class) <span class=\"comment\">// 指定我们的应用类</span></span><br><span class=\"line\"><span class=\"meta\">@WebAppConfiguration</span> <span class=\"comment\">// 表明要测试的是一个web应用</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DemoApplicationTests</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">contextLoads</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"application-properties\"><a href=\"#application-properties\" class=\"headerlink\" title=\"application.properties\"></a>application.properties</h4><p>Spring Boot的默认配置文件，假设我在此文件有一个键值<code>name=jayzee</code>，那么我在java代码中可以直接使用如下（Spring Boot自动注入）：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Value</span>(<span class=\"string\">\"$&#123;name&#125;\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">private</span> String name;</span><br></pre></td></tr></table></figure>\n<p>我在此文件添加一个键值<code>server.port=8090</code>修改内置tomcat的默认端口为8090。</p>\n<h4 id=\"templates\"><a href=\"#templates\" class=\"headerlink\" title=\"templates\"></a>templates</h4><p><a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-spring-mvc-template-engines\" target=\"_blank\" rel=\"noopener\">Template engines</a>说到：</p>\n<ul>\n<li>此文件夹用于放置动态html如jsp（官网建议尽量少用，因为在内置tomcat下运行将不起作用）等其他模板文件</li>\n</ul>\n<h4 id=\"static\"><a href=\"#static\" class=\"headerlink\" title=\"static\"></a>static</h4><p><a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-spring-mvc-static-content\" target=\"_blank\" rel=\"noopener\">Static Content</a></p>\n<ul>\n<li>此文件用于存放静态资源文件如：html、js、css和json等</li>\n<li>如果这里存放有index.html，则默认作为项目的home page</li>\n<li>前台代码<code>&lt;link href=&quot;/css/spring-2a2d595e6ed9a0b24f027f2b63b134d6.css&quot;/&gt;</code>直接引用<code>/static/css/spring-2a2d595e6ed9a0b24f027f2b63b134d6.css</code></li>\n</ul>\n<h3 id=\"结尾\"><a href=\"#结尾\" class=\"headerlink\" title=\"结尾\"></a>结尾</h3><p>终端定位到demo项目，运行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn package</span><br><span class=\"line\">java -jar target/demo-0.0.1-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>\n<p>访问<code>http://localhost:8090/</code>则可看到弹出一个登录窗口（因为我们引入了security组件）。</p>\n<p><a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-security\" target=\"_blank\" rel=\"noopener\">Security</a>提到，默认账户是<code>user</code>，随机密码在启动tomcat时在控制台打印。</p>\n<p>其他资源：</p>\n<ul>\n<li><a href=\"http://www.tianmaying.com/tutorial/spring-mvc-microblog\" target=\"_blank\" rel=\"noopener\">spring boot之login+jdbc完整例子</a></li>\n<li><a href=\"https://github.com/JayzeeZhang/spring-boot-demo\" target=\"_blank\" rel=\"noopener\">此博文demo项目源码</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>本着实用主义的目的简单介绍Spring Boot。</p>","more":"<h2 id=\"概要\"><a href=\"#概要\" class=\"headerlink\" title=\"概要\"></a>概要</h2><ul>\n<li>它的出现并不是为了取代传统的Spring Framework，而是提供一种新的Spring开发体验——尽可能消除大量繁琐的XML配置</li>\n<li>个人觉得Spring Framework的Java注解式开发已经做得够好了（省去大量的配置工作），并不是非得用Spring Boot不可的</li>\n<li>官网的<a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/\" target=\"_blank\" rel=\"noopener\">Guide</a>已经写得非常好了，我只是从实用主义讲如何快速入门</li>\n</ul>\n<h2 id=\"代码与相关理论\"><a href=\"#代码与相关理论\" class=\"headerlink\" title=\"代码与相关理论\"></a>代码与相关理论</h2><h3 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h3><p>访问<a href=\"https://start.spring.io/\" target=\"_blank\" rel=\"noopener\">Spring Initializr</a>生成以maven构建的demo项目，Dependencies我分别勾选了[Web]和[Security]，在终端下定位到生成的demo项目运行<code>mvn eclipse:eclipse</code>生成eclipse标识，接下来就可以使用eclipse进行开发了。</p>\n<h3 id=\"代码（自动生成）游园活动\"><a href=\"#代码（自动生成）游园活动\" class=\"headerlink\" title=\"代码（自动生成）游园活动\"></a>代码（自动生成）游园活动</h3><p>代码结构如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">demo</span><br><span class=\"line\"> + src/test/java</span><br><span class=\"line\">   + com.example</span><br><span class=\"line\">     - DemoApplicationTests.java</span><br><span class=\"line\"> + src/main/java</span><br><span class=\"line\">   + com.example</span><br><span class=\"line\">     - DemoApplication.java</span><br><span class=\"line\"> + src/main/resources</span><br><span class=\"line\">   + templates</span><br><span class=\"line\">   + static</span><br><span class=\"line\">   - application.properties</span><br><span class=\"line\"> - pom.xml</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"pom-xml\"><a href=\"#pom-xml\" class=\"headerlink\" title=\"pom.xml\"></a>pom.xml</h4><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span> <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">modelVersion</span>&gt;</span>4.0.0<span class=\"tag\">&lt;/<span class=\"name\">modelVersion</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.example<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>demo<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.0.1-SNAPSHOT<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 不同于传统Spring的地方：兼容将项目打包成war丢到外置Tomcat容器，也可打包成jar使用内置Tomcat运行Spring Web项目，直接运行jar包即可 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>jar<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>demo<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>Demo project for Spring Boot<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 必须要引入的parent，parent包含了大量基础的spring依赖，因此你不需要在pom.xml配置一堆所需引用的spring jar包 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">parent</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-parent<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.3.2.RELEASE<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">relativePath</span>/&gt;</span> <span class=\"comment\">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">parent</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class=\"tag\">&lt;/<span class=\"name\">project.build.sourceEncoding</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">java.version</span>&gt;</span>1.8<span class=\"tag\">&lt;/<span class=\"name\">java.version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- 以组件的形式在这里添加一条dependency，即官网宣称的开箱即用，简直傻瓜式啊 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-security<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-web<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-test<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span>    </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>可开箱即用的其他dependency如下：</p>\n<ul>\n<li><a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#using-boot-starter-poms\" target=\"_blank\" rel=\"noopener\">官网</a></li>\n<li><a href=\"https://github.com/spring-projects/spring-boot/blob/master/spring-boot-starters/README.adoc\" target=\"_blank\" rel=\"noopener\">非官网</a></li>\n</ul>\n<h4 id=\"DemoApplication-java\"><a href=\"#DemoApplication-java\" class=\"headerlink\" title=\"DemoApplication.java\"></a>DemoApplication.java</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.example;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.SpringApplication;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@SpringBootApplication</span>等价于 <span class=\"doctag\">@Configuration</span> <span class=\"doctag\">@EnableAutoConfiguration</span> <span class=\"doctag\">@ComponentScan</span></span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Configuration</span>标注配置类，即以往的XML配置文件被映射成了一个类</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@EnableAutoConfiguration</span>，表示由Spring Boot启动默认配置，如web项目将默认配置内置tomcat端口号8080</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@ComponentScan</span>放置在basePackage（例子中是com.example），com.example.*下的所有Java文件将被扫描解释</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@SpringBootApplication</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DemoApplication</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 这里的args一般传的是配置类</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        SpringApplication.run(DemoApplication.class, args);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"DemoApplicationTests-java\"><a href=\"#DemoApplicationTests-java\" class=\"headerlink\" title=\"DemoApplicationTests.java\"></a>DemoApplicationTests.java</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.example;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.Test;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.runner.RunWith;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.test.context.web.WebAppConfiguration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.test.SpringApplicationConfiguration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.test.context.junit4.SpringJUnit4ClassRunner;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@RunWith</span>(SpringJUnit4ClassRunner.class) <span class=\"comment\">// 指定以spring-junit运行单元测试</span></span><br><span class=\"line\"><span class=\"meta\">@SpringApplicationConfiguration</span>(classes = DemoApplication.class) <span class=\"comment\">// 指定我们的应用类</span></span><br><span class=\"line\"><span class=\"meta\">@WebAppConfiguration</span> <span class=\"comment\">// 表明要测试的是一个web应用</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DemoApplicationTests</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">contextLoads</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"application-properties\"><a href=\"#application-properties\" class=\"headerlink\" title=\"application.properties\"></a>application.properties</h4><p>Spring Boot的默认配置文件，假设我在此文件有一个键值<code>name=jayzee</code>，那么我在java代码中可以直接使用如下（Spring Boot自动注入）：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Value</span>(<span class=\"string\">\"$&#123;name&#125;\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">private</span> String name;</span><br></pre></td></tr></table></figure>\n<p>我在此文件添加一个键值<code>server.port=8090</code>修改内置tomcat的默认端口为8090。</p>\n<h4 id=\"templates\"><a href=\"#templates\" class=\"headerlink\" title=\"templates\"></a>templates</h4><p><a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-spring-mvc-template-engines\" target=\"_blank\" rel=\"noopener\">Template engines</a>说到：</p>\n<ul>\n<li>此文件夹用于放置动态html如jsp（官网建议尽量少用，因为在内置tomcat下运行将不起作用）等其他模板文件</li>\n</ul>\n<h4 id=\"static\"><a href=\"#static\" class=\"headerlink\" title=\"static\"></a>static</h4><p><a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-spring-mvc-static-content\" target=\"_blank\" rel=\"noopener\">Static Content</a></p>\n<ul>\n<li>此文件用于存放静态资源文件如：html、js、css和json等</li>\n<li>如果这里存放有index.html，则默认作为项目的home page</li>\n<li>前台代码<code>&lt;link href=&quot;/css/spring-2a2d595e6ed9a0b24f027f2b63b134d6.css&quot;/&gt;</code>直接引用<code>/static/css/spring-2a2d595e6ed9a0b24f027f2b63b134d6.css</code></li>\n</ul>\n<h3 id=\"结尾\"><a href=\"#结尾\" class=\"headerlink\" title=\"结尾\"></a>结尾</h3><p>终端定位到demo项目，运行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn package</span><br><span class=\"line\">java -jar target/demo-0.0.1-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>\n<p>访问<code>http://localhost:8090/</code>则可看到弹出一个登录窗口（因为我们引入了security组件）。</p>\n<p><a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-security\" target=\"_blank\" rel=\"noopener\">Security</a>提到，默认账户是<code>user</code>，随机密码在启动tomcat时在控制台打印。</p>\n<p>其他资源：</p>\n<ul>\n<li><a href=\"http://www.tianmaying.com/tutorial/spring-mvc-microblog\" target=\"_blank\" rel=\"noopener\">spring boot之login+jdbc完整例子</a></li>\n<li><a href=\"https://github.com/JayzeeZhang/spring-boot-demo\" target=\"_blank\" rel=\"noopener\">此博文demo项目源码</a></li>\n</ul>"},{"layout":"post","title":"《深入理解计算机系统》读书笔记","date":"2015-11-21T07:18:00.000Z","comments":1,"_content":"\n本文为《深入理解计算机系统》的读书笔记。\n\n<!--more-->\n\n## 第1章 计算机系统漫游\n\n### 编译系统的构成及工作过程\n\n------\n\nhello.c（源程序**文本**）↓\n\n　　　　**预处理器(cpp)**↓\n\n　　　　hello.i（被修改的源程序**文本**）↓\n\n　　　　**编译器(ccl)**↓\n\n　　　　hello.s（汇编程序**文本**）↓\n\n　　　　**汇编器(as)**↓\n\n　　　　hello.o（可重定位目标程序**二进制文件**）+printf.o（引用的库文件）↓\n\n　　　　**链接器(ld)**↓\n\nhello(可执行目标程序**二进制文件**)\n\n------\n\n<!--more-->\n\nQ：多个C文件组成的程序是怎么被编译成一个程序的？\t\nA：一个.c文件+此c文件引用的所有.h文件汇编成.o文件，最后所有.o文件再链接成可执行二进制文件\n\nQ：cpp在预处理过程将头文件的内容直接插入到程序文本中，对于多个C文件引用同一个H文件，那不是会导致重复插入？\t\nA：头文件使用如下方式定义可防止宏重复定义或重复引用头文件：\n\n```c++\n#ifndef    __SOMEFILE_H__\n#define  __SOMEFILE_H__\n...... // 一些声明语句\n#endif\n```\n\n1) 预处理三种：宏定义+引用头文件+条件编译\t\n\n2) 在预处理阶段，多C文件引用头一个H文件，CPP预处理器还是会把H文件的内容插入到C文件的，但由于#ifndef的使用，程序在运行阶段并不会出现重复定义相同宏、相同变量或相同函数的情况。\n\n### 系统的硬件组成\n\n1. 总线：传送定长字节块(word)，即字；字的字节数（即字长）是一个基本的系统参数，如4字节（32位），8字节（64位）；\n2. I/O设备：磁盘也是I/O设备，直接存储器存取（DMA）技术可以使数据不经处理器从磁盘直接到达主存；I/O设备通过一个控制器（置于I/O设备本身或主板上的芯片组）或适配器（插在主板插槽上的卡）与I/O总线相连；\n3. 主存：动态随机存取存储器（DRAM），可看成一个极大的线性字节数组；\n4. 处理器：负责解释存储在主存中的指令；核心是一个字长的存储设备（或寄存器），称为程序计数器（PC），任何时刻PC都指向主存中的一条机器语言指令（含有其地址），其次是寄存器文件和算术逻辑单元（ALU）；\n\nQ：通常所说的32位机器和64位机器是由什么决定的？\t\nA：字长，即虚拟地址的字节数或总线传输的最小单元字的字节数。\n\nQ：指令集结构和微体系结构的区别是什么？\t\nA：**TODO**\n\n### 操作系统管理硬件\n\n1. 操作系统：应用程序和硬件间的一层软件，1）防止硬件被失控的应用滥用；2）通过简单且一致的机制来控制复杂而又大相径庭的硬件设备；\n2. 进程：并发指进一个进程的指令和其他进程的指令交错运行，实现这种交错运行叫做上下文切换，由内核代码负责，如保存PC、寄存器文件以及主存的内容；\n3. 线程：多控制流并行（同时执行）；\n4. 虚拟存储器：每个进程看到的是一致的存储器，即虚拟内存空间；地址从小到大依次是：\t\n\t**程序文本(.text)**（程序二进制文件）↓\t\n\n\t**文字常量区(.rodata)**（程序用到的常量字符串）↓\t\n\n\t**已初始化数据(.data)**（已初始化的全局或静态全局变量）↓\t\n\n\t**未初始化数据(.bss)**（未初始化的全局或静态全局变量）↓\t\n\n\t**堆**（malloc伸，free缩，或结束时操作系统释放）↓\t\n\n\t**共享库**（如标准库）↓\t\n\n\t**栈**（函数参数值，局部变量值）↓\t\n\n\t**内核虚拟存储器**\n5. 文件：即字节序列，每个I/O设备都可以视为文件；\n\n总结：文件是对I/O抽象，虚拟存储器是对主存抽象，进程是对运行程序抽象，虚拟机是对操作系统抽象。\n\nQ：举例说明上文提到的虚拟存储器？\t\nA：如下\n```c++\n//main.cpp\nint a = 0;          // 全局初始化区\nchar *p1;           // 全局未初始化区\n                    // built-in type之外的类型都不会默认初始化\nint main()\n{\n  int b;            // 栈区\n  char s[] = \"abc\"; // 栈区\n  char *p2;         // 栈区\n  char *p3 = \"123456\";     // \"123456/0\" 在常量区，p3在栈区\n  static int c =0;         // 全局（静态）初始化区\n \n  p1 = (char *)malloc(10);\n  p2 = (char *)malloc(20); // 分配得来的10和20字节的区域就在堆区\n \n  strcpy(p1, \"123456\");    // \"123456/0\" 放在常量区，编译器可能会将它\n                              // 与p3所指向的\"123456\"优化成一个地方。\n  return 0;\n}\n```\n\n### 并发与并行\n\n1. Inter Core i7有4个核心，每个核心可以执行2个线程（2个控制流，超线程），总共可以并行执行8个线程（多核+超线程）；\n2. 指令级并行：处理器同时执行多条指令；\n3. 单指令、多数据：允许一条指令产生多个可以并行执行的操作，称为单指令、多数据，如浮点数加法；\n\n## 第2章 信息的表示和处理\n\n### 信息存储\n\n1. 虚拟地址空间是展示给进程的，为程序提供一个看上去统一的字节数组，实际实现要配合随机访问存储器（RAM）、磁盘、特殊硬件和操作系统；\n2. 第1章提到的“字”的字节数即虚拟地址空间地址的字节数；\n3. 大端法：human-readable，按从左到右的方式书写，左端是高位；小端法与大端法相反；对于文本不需要考虑大端还是小端法，文本具有更强的平台独立性；\n4. 布尔运算与命题逻辑运算的对应：~对应NOT，&对应AND，|对应OR，^对应异或且`(a^b)^a=b`；\n5. 掩码运算：`x&0xFF`，只保留x的低8位；\n6. 逻辑运算||、&&和!与布尔运算的区别，1）运算不等价，逻辑运算的结果是0或1而布尔运算不然；2）结束条件不同，如果第一个运算就能确定逻辑运算表达式的值运算将终止；\n7. 移位运算：左移右补k个0；逻辑右移左补k个0，算术右移左补k个最高有效位的值；**无符号右移必须是逻辑的，有符号右移默认是算术的根据编译器不同也可能是逻辑的**；Java用`>>`表示算术右移，`>>>`表示逻辑右移；在运算中比加减乘除优先级低；当移动位k大于被移动数位数w时，采用`k mod w`计算位移量；\n\n### 整数表示\n\n1. long、int在不同位级机器上位数不同，需慎用，尽量使用`intN_t`或`uintN_t`，N表示位数；另外在printf的格式化过程中也需要注意这个问题，如不同机器对`%ld`的解释是不同的，另外，`%d`表示有符号整数（取值范围为`-2^(w-1)`到`2^(w-1)-1`），`%u`表示无符号整数（取值范围为`0`到`2^w-1`）；\n2. 补码表示负整数，最高位有效值表示负值；\n3. w位有符号整数x→无符号，位级表示相同：\n\t- 负数→`x+2^w`，\n\t- 非负数→x\n4. w位无符号整数u→有符号，位级表示相同：\n\t- u小于`2^(w-1)`→u，\n\t- u不小于`2^(w-1)`→`u-2^w`\n5. T表示有符号整数x有w位，C语言中，`TMax=2^(w-1)-1`，`TMin=-TMax-1`\n6. 零扩展添加0用于无符号数，符号扩展添加最高位有效值用于有符号数，高位转地位统一使用截断；\n7. 慎用无符号数用于整数运算，有符号负数转为无符号数时将变成一个大数，可能导致不健壮程序代码溢出；\n\nQ：为什么`TMin`要这样表示？\t\nA：**TODO**\n\n### 整数运算\n\n1. 无符号加法：\n\t- 超过`2^w`则减去`2^w`；\n2. 有符号加法（与无符号加法位模式一致，但高位表示符号位）：\n\t- 超过`2^(w-1)`正溢出减去`2^w`（两个正数相加）\n\t- 小于`-2^(w-1)`负溢出加上`2^w`（两个负数相加）\n\t- 否则正常；\n3. 补码非运算：\n\t- x等于`-2^(w-1)`时值不变高位\n\t- 否则等于-x；\n4. 乘法：\n\t- `(x * y) mod 2^w`，对于有符号先按有符号计算后再转为有符号，即位级表示相同；\n5. 乘以常数：\n\t- 化为位移和加减运算；\n6. 除以2的幂：\n\t- 整数除法总是舍入到0，同号是向下取整的，异号是向上取整的；\n\t- “除以2的幂”可使用右移模拟整数除法\n\t\t- 无符号数逻辑右移等价于整数除法\n\t\t- 有符号非负数算术右移等价于整数除法\n\t\t- 有符号负数算术右移不等价于整数除法（如-5除以2的情况），加偏置的思想：y整除x时得k，否则得k+1\n\nQ：证补码非等于其补加1：`-x=~x+1`\t\nA：根据定义分如下两种情况：\n\n- 定义1：x等于-2^(w-1)时值不变，由定义立即得证\n- 定义2：否则等于-x，等效于证明`~x+x+1=0`，`~x+x`的位全为1，立即得证\n\nQ：为什么有符号负数算术右移：`(x+2^k-1) >> k`能正确舍入？\t\nA：**TODO**\n\n### 浮点数\n\n1. 二进制小数表示法的弊端，1）只能精确表示`x * 2^y`形式的数，2）对于大数需要非常多的位表示；\n2. 浮点数定义：`(-1)^s * M * 2^E`\n\t- s为符号sign，由第一位表示；\n\t- M是尾数significand，由末尾的n位小数表示的二进制小数frac（简称f）表示；\n\t- E是阶码exponet，由中间k位的小数exp（简称e）表示，负责对M加权；\n\t- 它在位上的排列是（大端法）：s | exp | frac；\n3. 浮点数分类：\n\t- 非规格化：frac的位全为0，此时`M=f`，`E=1-Bias`，`Bias=2^(k-1) - 1`；\n\t- 规格化：frac的位不全为1，此时`M=1+f`，`E=e-Bias`，`Bias=2^(k-1) - 1`；\n\t- 特殊值：frac的位全为1，当exp全为0表示无穷大，否则表示NaN；\n4. 浮点数偶数舍入\n\t- 将数字向上或向下舍入，使结果最低有效数字位是偶数，如浮点数2.5和1.5的最低有效数字位是个位数的情况下都舍入到2\n\t- 适用于二进制数，二进制0是偶数，1是奇数\n\nQ：浮点数比二进制小数编码优异的地方在哪\t\nA：**TODO**\n\nQ：为什么要这样子编码浮点数\t\nA：**TODO**\n\nQ：试举例将正整数12345做浮点数二进制表示\t\t\nA：使用4个字节32位的单精度浮点数来编码，其中阶码k=8，尾数n=23，十进制12345二进制表示为：0000,0011,0000,0011,1001\n1. 由定义可知最大非规格化数`f*2^(1-Bias)`肯定是小于1的，因此12345肯定是使用规格化数字表示；\n2. 0000,0011,0000,0011,1001 = 二进制的1.**1,0000,0011,1001** * 2^13，由定义得**1,0000,0011,1001**等于f，f求得；而13=E=e-Bias=e-128得e的十进制表示为141即二进制1000,1101\n3. 则其浮点数二进制表示为0, 1000,1101, 000,0000,0001,0000,0011,1001\n","source":"_posts/2015-11-21-computer-systems.markdown","raw":"---\nlayout: post\ntitle: 《深入理解计算机系统》读书笔记\ndate: '2015-11-21 15:18'\ncomments: true\ncategories: ['操作系统'] \ntags: ['操作系统']\n---\n\n本文为《深入理解计算机系统》的读书笔记。\n\n<!--more-->\n\n## 第1章 计算机系统漫游\n\n### 编译系统的构成及工作过程\n\n------\n\nhello.c（源程序**文本**）↓\n\n　　　　**预处理器(cpp)**↓\n\n　　　　hello.i（被修改的源程序**文本**）↓\n\n　　　　**编译器(ccl)**↓\n\n　　　　hello.s（汇编程序**文本**）↓\n\n　　　　**汇编器(as)**↓\n\n　　　　hello.o（可重定位目标程序**二进制文件**）+printf.o（引用的库文件）↓\n\n　　　　**链接器(ld)**↓\n\nhello(可执行目标程序**二进制文件**)\n\n------\n\n<!--more-->\n\nQ：多个C文件组成的程序是怎么被编译成一个程序的？\t\nA：一个.c文件+此c文件引用的所有.h文件汇编成.o文件，最后所有.o文件再链接成可执行二进制文件\n\nQ：cpp在预处理过程将头文件的内容直接插入到程序文本中，对于多个C文件引用同一个H文件，那不是会导致重复插入？\t\nA：头文件使用如下方式定义可防止宏重复定义或重复引用头文件：\n\n```c++\n#ifndef    __SOMEFILE_H__\n#define  __SOMEFILE_H__\n...... // 一些声明语句\n#endif\n```\n\n1) 预处理三种：宏定义+引用头文件+条件编译\t\n\n2) 在预处理阶段，多C文件引用头一个H文件，CPP预处理器还是会把H文件的内容插入到C文件的，但由于#ifndef的使用，程序在运行阶段并不会出现重复定义相同宏、相同变量或相同函数的情况。\n\n### 系统的硬件组成\n\n1. 总线：传送定长字节块(word)，即字；字的字节数（即字长）是一个基本的系统参数，如4字节（32位），8字节（64位）；\n2. I/O设备：磁盘也是I/O设备，直接存储器存取（DMA）技术可以使数据不经处理器从磁盘直接到达主存；I/O设备通过一个控制器（置于I/O设备本身或主板上的芯片组）或适配器（插在主板插槽上的卡）与I/O总线相连；\n3. 主存：动态随机存取存储器（DRAM），可看成一个极大的线性字节数组；\n4. 处理器：负责解释存储在主存中的指令；核心是一个字长的存储设备（或寄存器），称为程序计数器（PC），任何时刻PC都指向主存中的一条机器语言指令（含有其地址），其次是寄存器文件和算术逻辑单元（ALU）；\n\nQ：通常所说的32位机器和64位机器是由什么决定的？\t\nA：字长，即虚拟地址的字节数或总线传输的最小单元字的字节数。\n\nQ：指令集结构和微体系结构的区别是什么？\t\nA：**TODO**\n\n### 操作系统管理硬件\n\n1. 操作系统：应用程序和硬件间的一层软件，1）防止硬件被失控的应用滥用；2）通过简单且一致的机制来控制复杂而又大相径庭的硬件设备；\n2. 进程：并发指进一个进程的指令和其他进程的指令交错运行，实现这种交错运行叫做上下文切换，由内核代码负责，如保存PC、寄存器文件以及主存的内容；\n3. 线程：多控制流并行（同时执行）；\n4. 虚拟存储器：每个进程看到的是一致的存储器，即虚拟内存空间；地址从小到大依次是：\t\n\t**程序文本(.text)**（程序二进制文件）↓\t\n\n\t**文字常量区(.rodata)**（程序用到的常量字符串）↓\t\n\n\t**已初始化数据(.data)**（已初始化的全局或静态全局变量）↓\t\n\n\t**未初始化数据(.bss)**（未初始化的全局或静态全局变量）↓\t\n\n\t**堆**（malloc伸，free缩，或结束时操作系统释放）↓\t\n\n\t**共享库**（如标准库）↓\t\n\n\t**栈**（函数参数值，局部变量值）↓\t\n\n\t**内核虚拟存储器**\n5. 文件：即字节序列，每个I/O设备都可以视为文件；\n\n总结：文件是对I/O抽象，虚拟存储器是对主存抽象，进程是对运行程序抽象，虚拟机是对操作系统抽象。\n\nQ：举例说明上文提到的虚拟存储器？\t\nA：如下\n```c++\n//main.cpp\nint a = 0;          // 全局初始化区\nchar *p1;           // 全局未初始化区\n                    // built-in type之外的类型都不会默认初始化\nint main()\n{\n  int b;            // 栈区\n  char s[] = \"abc\"; // 栈区\n  char *p2;         // 栈区\n  char *p3 = \"123456\";     // \"123456/0\" 在常量区，p3在栈区\n  static int c =0;         // 全局（静态）初始化区\n \n  p1 = (char *)malloc(10);\n  p2 = (char *)malloc(20); // 分配得来的10和20字节的区域就在堆区\n \n  strcpy(p1, \"123456\");    // \"123456/0\" 放在常量区，编译器可能会将它\n                              // 与p3所指向的\"123456\"优化成一个地方。\n  return 0;\n}\n```\n\n### 并发与并行\n\n1. Inter Core i7有4个核心，每个核心可以执行2个线程（2个控制流，超线程），总共可以并行执行8个线程（多核+超线程）；\n2. 指令级并行：处理器同时执行多条指令；\n3. 单指令、多数据：允许一条指令产生多个可以并行执行的操作，称为单指令、多数据，如浮点数加法；\n\n## 第2章 信息的表示和处理\n\n### 信息存储\n\n1. 虚拟地址空间是展示给进程的，为程序提供一个看上去统一的字节数组，实际实现要配合随机访问存储器（RAM）、磁盘、特殊硬件和操作系统；\n2. 第1章提到的“字”的字节数即虚拟地址空间地址的字节数；\n3. 大端法：human-readable，按从左到右的方式书写，左端是高位；小端法与大端法相反；对于文本不需要考虑大端还是小端法，文本具有更强的平台独立性；\n4. 布尔运算与命题逻辑运算的对应：~对应NOT，&对应AND，|对应OR，^对应异或且`(a^b)^a=b`；\n5. 掩码运算：`x&0xFF`，只保留x的低8位；\n6. 逻辑运算||、&&和!与布尔运算的区别，1）运算不等价，逻辑运算的结果是0或1而布尔运算不然；2）结束条件不同，如果第一个运算就能确定逻辑运算表达式的值运算将终止；\n7. 移位运算：左移右补k个0；逻辑右移左补k个0，算术右移左补k个最高有效位的值；**无符号右移必须是逻辑的，有符号右移默认是算术的根据编译器不同也可能是逻辑的**；Java用`>>`表示算术右移，`>>>`表示逻辑右移；在运算中比加减乘除优先级低；当移动位k大于被移动数位数w时，采用`k mod w`计算位移量；\n\n### 整数表示\n\n1. long、int在不同位级机器上位数不同，需慎用，尽量使用`intN_t`或`uintN_t`，N表示位数；另外在printf的格式化过程中也需要注意这个问题，如不同机器对`%ld`的解释是不同的，另外，`%d`表示有符号整数（取值范围为`-2^(w-1)`到`2^(w-1)-1`），`%u`表示无符号整数（取值范围为`0`到`2^w-1`）；\n2. 补码表示负整数，最高位有效值表示负值；\n3. w位有符号整数x→无符号，位级表示相同：\n\t- 负数→`x+2^w`，\n\t- 非负数→x\n4. w位无符号整数u→有符号，位级表示相同：\n\t- u小于`2^(w-1)`→u，\n\t- u不小于`2^(w-1)`→`u-2^w`\n5. T表示有符号整数x有w位，C语言中，`TMax=2^(w-1)-1`，`TMin=-TMax-1`\n6. 零扩展添加0用于无符号数，符号扩展添加最高位有效值用于有符号数，高位转地位统一使用截断；\n7. 慎用无符号数用于整数运算，有符号负数转为无符号数时将变成一个大数，可能导致不健壮程序代码溢出；\n\nQ：为什么`TMin`要这样表示？\t\nA：**TODO**\n\n### 整数运算\n\n1. 无符号加法：\n\t- 超过`2^w`则减去`2^w`；\n2. 有符号加法（与无符号加法位模式一致，但高位表示符号位）：\n\t- 超过`2^(w-1)`正溢出减去`2^w`（两个正数相加）\n\t- 小于`-2^(w-1)`负溢出加上`2^w`（两个负数相加）\n\t- 否则正常；\n3. 补码非运算：\n\t- x等于`-2^(w-1)`时值不变高位\n\t- 否则等于-x；\n4. 乘法：\n\t- `(x * y) mod 2^w`，对于有符号先按有符号计算后再转为有符号，即位级表示相同；\n5. 乘以常数：\n\t- 化为位移和加减运算；\n6. 除以2的幂：\n\t- 整数除法总是舍入到0，同号是向下取整的，异号是向上取整的；\n\t- “除以2的幂”可使用右移模拟整数除法\n\t\t- 无符号数逻辑右移等价于整数除法\n\t\t- 有符号非负数算术右移等价于整数除法\n\t\t- 有符号负数算术右移不等价于整数除法（如-5除以2的情况），加偏置的思想：y整除x时得k，否则得k+1\n\nQ：证补码非等于其补加1：`-x=~x+1`\t\nA：根据定义分如下两种情况：\n\n- 定义1：x等于-2^(w-1)时值不变，由定义立即得证\n- 定义2：否则等于-x，等效于证明`~x+x+1=0`，`~x+x`的位全为1，立即得证\n\nQ：为什么有符号负数算术右移：`(x+2^k-1) >> k`能正确舍入？\t\nA：**TODO**\n\n### 浮点数\n\n1. 二进制小数表示法的弊端，1）只能精确表示`x * 2^y`形式的数，2）对于大数需要非常多的位表示；\n2. 浮点数定义：`(-1)^s * M * 2^E`\n\t- s为符号sign，由第一位表示；\n\t- M是尾数significand，由末尾的n位小数表示的二进制小数frac（简称f）表示；\n\t- E是阶码exponet，由中间k位的小数exp（简称e）表示，负责对M加权；\n\t- 它在位上的排列是（大端法）：s | exp | frac；\n3. 浮点数分类：\n\t- 非规格化：frac的位全为0，此时`M=f`，`E=1-Bias`，`Bias=2^(k-1) - 1`；\n\t- 规格化：frac的位不全为1，此时`M=1+f`，`E=e-Bias`，`Bias=2^(k-1) - 1`；\n\t- 特殊值：frac的位全为1，当exp全为0表示无穷大，否则表示NaN；\n4. 浮点数偶数舍入\n\t- 将数字向上或向下舍入，使结果最低有效数字位是偶数，如浮点数2.5和1.5的最低有效数字位是个位数的情况下都舍入到2\n\t- 适用于二进制数，二进制0是偶数，1是奇数\n\nQ：浮点数比二进制小数编码优异的地方在哪\t\nA：**TODO**\n\nQ：为什么要这样子编码浮点数\t\nA：**TODO**\n\nQ：试举例将正整数12345做浮点数二进制表示\t\t\nA：使用4个字节32位的单精度浮点数来编码，其中阶码k=8，尾数n=23，十进制12345二进制表示为：0000,0011,0000,0011,1001\n1. 由定义可知最大非规格化数`f*2^(1-Bias)`肯定是小于1的，因此12345肯定是使用规格化数字表示；\n2. 0000,0011,0000,0011,1001 = 二进制的1.**1,0000,0011,1001** * 2^13，由定义得**1,0000,0011,1001**等于f，f求得；而13=E=e-Bias=e-128得e的十进制表示为141即二进制1000,1101\n3. 则其浮点数二进制表示为0, 1000,1101, 000,0000,0001,0000,0011,1001\n","slug":"computer-systems","published":1,"updated":"2022-08-09T15:02:00.590Z","photos":[],"link":"","_id":"cl6mbc11v0006igu8jw5xqhr3","content":"<p>本文为《深入理解计算机系统》的读书笔记。</p>\n<a id=\"more\"></a>\n<h2 id=\"第1章-计算机系统漫游\"><a href=\"#第1章-计算机系统漫游\" class=\"headerlink\" title=\"第1章 计算机系统漫游\"></a>第1章 计算机系统漫游</h2><h3 id=\"编译系统的构成及工作过程\"><a href=\"#编译系统的构成及工作过程\" class=\"headerlink\" title=\"编译系统的构成及工作过程\"></a>编译系统的构成及工作过程</h3><hr>\n<p>hello.c（源程序<strong>文本</strong>）↓</p>\n<p>　　　　<strong>预处理器(cpp)</strong>↓</p>\n<p>　　　　hello.i（被修改的源程序<strong>文本</strong>）↓</p>\n<p>　　　　<strong>编译器(ccl)</strong>↓</p>\n<p>　　　　hello.s（汇编程序<strong>文本</strong>）↓</p>\n<p>　　　　<strong>汇编器(as)</strong>↓</p>\n<p>　　　　hello.o（可重定位目标程序<strong>二进制文件</strong>）+printf.o（引用的库文件）↓</p>\n<p>　　　　<strong>链接器(ld)</strong>↓</p>\n<p>hello(可执行目标程序<strong>二进制文件</strong>)</p>\n<hr>\n<!--more-->\n<p>Q：多个C文件组成的程序是怎么被编译成一个程序的？<br>A：一个.c文件+此c文件引用的所有.h文件汇编成.o文件，最后所有.o文件再链接成可执行二进制文件</p>\n<p>Q：cpp在预处理过程将头文件的内容直接插入到程序文本中，对于多个C文件引用同一个H文件，那不是会导致重复插入？<br>A：头文件使用如下方式定义可防止宏重复定义或重复引用头文件：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span>    __SOMEFILE_H__</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span>  __SOMEFILE_H__</span></span><br><span class=\"line\">...... <span class=\"comment\">// 一些声明语句</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br></pre></td></tr></table></figure>\n<p>1) 预处理三种：宏定义+引用头文件+条件编译    </p>\n<p>2) 在预处理阶段，多C文件引用头一个H文件，CPP预处理器还是会把H文件的内容插入到C文件的，但由于#ifndef的使用，程序在运行阶段并不会出现重复定义相同宏、相同变量或相同函数的情况。</p>\n<h3 id=\"系统的硬件组成\"><a href=\"#系统的硬件组成\" class=\"headerlink\" title=\"系统的硬件组成\"></a>系统的硬件组成</h3><ol>\n<li>总线：传送定长字节块(word)，即字；字的字节数（即字长）是一个基本的系统参数，如4字节（32位），8字节（64位）；</li>\n<li>I/O设备：磁盘也是I/O设备，直接存储器存取（DMA）技术可以使数据不经处理器从磁盘直接到达主存；I/O设备通过一个控制器（置于I/O设备本身或主板上的芯片组）或适配器（插在主板插槽上的卡）与I/O总线相连；</li>\n<li>主存：动态随机存取存储器（DRAM），可看成一个极大的线性字节数组；</li>\n<li>处理器：负责解释存储在主存中的指令；核心是一个字长的存储设备（或寄存器），称为程序计数器（PC），任何时刻PC都指向主存中的一条机器语言指令（含有其地址），其次是寄存器文件和算术逻辑单元（ALU）；</li>\n</ol>\n<p>Q：通常所说的32位机器和64位机器是由什么决定的？<br>A：字长，即虚拟地址的字节数或总线传输的最小单元字的字节数。</p>\n<p>Q：指令集结构和微体系结构的区别是什么？<br>A：<strong>TODO</strong></p>\n<h3 id=\"操作系统管理硬件\"><a href=\"#操作系统管理硬件\" class=\"headerlink\" title=\"操作系统管理硬件\"></a>操作系统管理硬件</h3><ol>\n<li>操作系统：应用程序和硬件间的一层软件，1）防止硬件被失控的应用滥用；2）通过简单且一致的机制来控制复杂而又大相径庭的硬件设备；</li>\n<li>进程：并发指进一个进程的指令和其他进程的指令交错运行，实现这种交错运行叫做上下文切换，由内核代码负责，如保存PC、寄存器文件以及主存的内容；</li>\n<li>线程：多控制流并行（同时执行）；</li>\n<li><p>虚拟存储器：每个进程看到的是一致的存储器，即虚拟内存空间；地址从小到大依次是：<br> <strong>程序文本(.text)</strong>（程序二进制文件）↓    </p>\n<p> <strong>文字常量区(.rodata)</strong>（程序用到的常量字符串）↓    </p>\n<p> <strong>已初始化数据(.data)</strong>（已初始化的全局或静态全局变量）↓    </p>\n<p> <strong>未初始化数据(.bss)</strong>（未初始化的全局或静态全局变量）↓    </p>\n<p> <strong>堆</strong>（malloc伸，free缩，或结束时操作系统释放）↓    </p>\n<p> <strong>共享库</strong>（如标准库）↓    </p>\n<p> <strong>栈</strong>（函数参数值，局部变量值）↓    </p>\n<p> <strong>内核虚拟存储器</strong></p>\n</li>\n<li>文件：即字节序列，每个I/O设备都可以视为文件；</li>\n</ol>\n<p>总结：文件是对I/O抽象，虚拟存储器是对主存抽象，进程是对运行程序抽象，虚拟机是对操作系统抽象。</p>\n<p>Q：举例说明上文提到的虚拟存储器？<br>A：如下<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//main.cpp</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;          <span class=\"comment\">// 全局初始化区</span></span><br><span class=\"line\"><span class=\"keyword\">char</span> *p1;           <span class=\"comment\">// 全局未初始化区</span></span><br><span class=\"line\">                    <span class=\"comment\">// built-in type之外的类型都不会默认初始化</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">int</span> b;            <span class=\"comment\">// 栈区</span></span><br><span class=\"line\">  <span class=\"keyword\">char</span> s[] = <span class=\"string\">\"abc\"</span>; <span class=\"comment\">// 栈区</span></span><br><span class=\"line\">  <span class=\"keyword\">char</span> *p2;         <span class=\"comment\">// 栈区</span></span><br><span class=\"line\">  <span class=\"keyword\">char</span> *p3 = <span class=\"string\">\"123456\"</span>;     <span class=\"comment\">// \"123456/0\" 在常量区，p3在栈区</span></span><br><span class=\"line\">  <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> c =<span class=\"number\">0</span>;         <span class=\"comment\">// 全局（静态）初始化区</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  p1 = (<span class=\"keyword\">char</span> *)<span class=\"built_in\">malloc</span>(<span class=\"number\">10</span>);</span><br><span class=\"line\">  p2 = (<span class=\"keyword\">char</span> *)<span class=\"built_in\">malloc</span>(<span class=\"number\">20</span>); <span class=\"comment\">// 分配得来的10和20字节的区域就在堆区</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"built_in\">strcpy</span>(p1, <span class=\"string\">\"123456\"</span>);    <span class=\"comment\">// \"123456/0\" 放在常量区，编译器可能会将它</span></span><br><span class=\"line\">                              <span class=\"comment\">// 与p3所指向的\"123456\"优化成一个地方。</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"并发与并行\"><a href=\"#并发与并行\" class=\"headerlink\" title=\"并发与并行\"></a>并发与并行</h3><ol>\n<li>Inter Core i7有4个核心，每个核心可以执行2个线程（2个控制流，超线程），总共可以并行执行8个线程（多核+超线程）；</li>\n<li>指令级并行：处理器同时执行多条指令；</li>\n<li>单指令、多数据：允许一条指令产生多个可以并行执行的操作，称为单指令、多数据，如浮点数加法；</li>\n</ol>\n<h2 id=\"第2章-信息的表示和处理\"><a href=\"#第2章-信息的表示和处理\" class=\"headerlink\" title=\"第2章 信息的表示和处理\"></a>第2章 信息的表示和处理</h2><h3 id=\"信息存储\"><a href=\"#信息存储\" class=\"headerlink\" title=\"信息存储\"></a>信息存储</h3><ol>\n<li>虚拟地址空间是展示给进程的，为程序提供一个看上去统一的字节数组，实际实现要配合随机访问存储器（RAM）、磁盘、特殊硬件和操作系统；</li>\n<li>第1章提到的“字”的字节数即虚拟地址空间地址的字节数；</li>\n<li>大端法：human-readable，按从左到右的方式书写，左端是高位；小端法与大端法相反；对于文本不需要考虑大端还是小端法，文本具有更强的平台独立性；</li>\n<li>布尔运算与命题逻辑运算的对应：~对应NOT，&amp;对应AND，|对应OR，^对应异或且<code>(a^b)^a=b</code>；</li>\n<li>掩码运算：<code>x&amp;0xFF</code>，只保留x的低8位；</li>\n<li>逻辑运算||、&amp;&amp;和!与布尔运算的区别，1）运算不等价，逻辑运算的结果是0或1而布尔运算不然；2）结束条件不同，如果第一个运算就能确定逻辑运算表达式的值运算将终止；</li>\n<li>移位运算：左移右补k个0；逻辑右移左补k个0，算术右移左补k个最高有效位的值；<strong>无符号右移必须是逻辑的，有符号右移默认是算术的根据编译器不同也可能是逻辑的</strong>；Java用<code>&gt;&gt;</code>表示算术右移，<code>&gt;&gt;&gt;</code>表示逻辑右移；在运算中比加减乘除优先级低；当移动位k大于被移动数位数w时，采用<code>k mod w</code>计算位移量；</li>\n</ol>\n<h3 id=\"整数表示\"><a href=\"#整数表示\" class=\"headerlink\" title=\"整数表示\"></a>整数表示</h3><ol>\n<li>long、int在不同位级机器上位数不同，需慎用，尽量使用<code>intN_t</code>或<code>uintN_t</code>，N表示位数；另外在printf的格式化过程中也需要注意这个问题，如不同机器对<code>%ld</code>的解释是不同的，另外，<code>%d</code>表示有符号整数（取值范围为<code>-2^(w-1)</code>到<code>2^(w-1)-1</code>），<code>%u</code>表示无符号整数（取值范围为<code>0</code>到<code>2^w-1</code>）；</li>\n<li>补码表示负整数，最高位有效值表示负值；</li>\n<li>w位有符号整数x→无符号，位级表示相同：<ul>\n<li>负数→<code>x+2^w</code>，</li>\n<li>非负数→x</li>\n</ul>\n</li>\n<li>w位无符号整数u→有符号，位级表示相同：<ul>\n<li>u小于<code>2^(w-1)</code>→u，</li>\n<li>u不小于<code>2^(w-1)</code>→<code>u-2^w</code></li>\n</ul>\n</li>\n<li>T表示有符号整数x有w位，C语言中，<code>TMax=2^(w-1)-1</code>，<code>TMin=-TMax-1</code></li>\n<li>零扩展添加0用于无符号数，符号扩展添加最高位有效值用于有符号数，高位转地位统一使用截断；</li>\n<li>慎用无符号数用于整数运算，有符号负数转为无符号数时将变成一个大数，可能导致不健壮程序代码溢出；</li>\n</ol>\n<p>Q：为什么<code>TMin</code>要这样表示？<br>A：<strong>TODO</strong></p>\n<h3 id=\"整数运算\"><a href=\"#整数运算\" class=\"headerlink\" title=\"整数运算\"></a>整数运算</h3><ol>\n<li>无符号加法：<ul>\n<li>超过<code>2^w</code>则减去<code>2^w</code>；</li>\n</ul>\n</li>\n<li>有符号加法（与无符号加法位模式一致，但高位表示符号位）：<ul>\n<li>超过<code>2^(w-1)</code>正溢出减去<code>2^w</code>（两个正数相加）</li>\n<li>小于<code>-2^(w-1)</code>负溢出加上<code>2^w</code>（两个负数相加）</li>\n<li>否则正常；</li>\n</ul>\n</li>\n<li>补码非运算：<ul>\n<li>x等于<code>-2^(w-1)</code>时值不变高位</li>\n<li>否则等于-x；</li>\n</ul>\n</li>\n<li>乘法：<ul>\n<li><code>(x * y) mod 2^w</code>，对于有符号先按有符号计算后再转为有符号，即位级表示相同；</li>\n</ul>\n</li>\n<li>乘以常数：<ul>\n<li>化为位移和加减运算；</li>\n</ul>\n</li>\n<li>除以2的幂：<ul>\n<li>整数除法总是舍入到0，同号是向下取整的，异号是向上取整的；</li>\n<li>“除以2的幂”可使用右移模拟整数除法<ul>\n<li>无符号数逻辑右移等价于整数除法</li>\n<li>有符号非负数算术右移等价于整数除法</li>\n<li>有符号负数算术右移不等价于整数除法（如-5除以2的情况），加偏置的思想：y整除x时得k，否则得k+1</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<p>Q：证补码非等于其补加1：<code>-x=~x+1</code><br>A：根据定义分如下两种情况：</p>\n<ul>\n<li>定义1：x等于-2^(w-1)时值不变，由定义立即得证</li>\n<li>定义2：否则等于-x，等效于证明<code>~x+x+1=0</code>，<code>~x+x</code>的位全为1，立即得证</li>\n</ul>\n<p>Q：为什么有符号负数算术右移：<code>(x+2^k-1) &gt;&gt; k</code>能正确舍入？<br>A：<strong>TODO</strong></p>\n<h3 id=\"浮点数\"><a href=\"#浮点数\" class=\"headerlink\" title=\"浮点数\"></a>浮点数</h3><ol>\n<li>二进制小数表示法的弊端，1）只能精确表示<code>x * 2^y</code>形式的数，2）对于大数需要非常多的位表示；</li>\n<li>浮点数定义：<code>(-1)^s * M * 2^E</code><ul>\n<li>s为符号sign，由第一位表示；</li>\n<li>M是尾数significand，由末尾的n位小数表示的二进制小数frac（简称f）表示；</li>\n<li>E是阶码exponet，由中间k位的小数exp（简称e）表示，负责对M加权；</li>\n<li>它在位上的排列是（大端法）：s | exp | frac；</li>\n</ul>\n</li>\n<li>浮点数分类：<ul>\n<li>非规格化：frac的位全为0，此时<code>M=f</code>，<code>E=1-Bias</code>，<code>Bias=2^(k-1) - 1</code>；</li>\n<li>规格化：frac的位不全为1，此时<code>M=1+f</code>，<code>E=e-Bias</code>，<code>Bias=2^(k-1) - 1</code>；</li>\n<li>特殊值：frac的位全为1，当exp全为0表示无穷大，否则表示NaN；</li>\n</ul>\n</li>\n<li>浮点数偶数舍入<ul>\n<li>将数字向上或向下舍入，使结果最低有效数字位是偶数，如浮点数2.5和1.5的最低有效数字位是个位数的情况下都舍入到2</li>\n<li>适用于二进制数，二进制0是偶数，1是奇数</li>\n</ul>\n</li>\n</ol>\n<p>Q：浮点数比二进制小数编码优异的地方在哪<br>A：<strong>TODO</strong></p>\n<p>Q：为什么要这样子编码浮点数<br>A：<strong>TODO</strong></p>\n<p>Q：试举例将正整数12345做浮点数二进制表示<br>A：使用4个字节32位的单精度浮点数来编码，其中阶码k=8，尾数n=23，十进制12345二进制表示为：0000,0011,0000,0011,1001</p>\n<ol>\n<li>由定义可知最大非规格化数<code>f*2^(1-Bias)</code>肯定是小于1的，因此12345肯定是使用规格化数字表示；</li>\n<li>0000,0011,0000,0011,1001 = 二进制的1.<strong>1,0000,0011,1001</strong> * 2^13，由定义得<strong>1,0000,0011,1001</strong>等于f，f求得；而13=E=e-Bias=e-128得e的十进制表示为141即二进制1000,1101</li>\n<li>则其浮点数二进制表示为0, 1000,1101, 000,0000,0001,0000,0011,1001</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>本文为《深入理解计算机系统》的读书笔记。</p>","more":"<h2 id=\"第1章-计算机系统漫游\"><a href=\"#第1章-计算机系统漫游\" class=\"headerlink\" title=\"第1章 计算机系统漫游\"></a>第1章 计算机系统漫游</h2><h3 id=\"编译系统的构成及工作过程\"><a href=\"#编译系统的构成及工作过程\" class=\"headerlink\" title=\"编译系统的构成及工作过程\"></a>编译系统的构成及工作过程</h3><hr>\n<p>hello.c（源程序<strong>文本</strong>）↓</p>\n<p>　　　　<strong>预处理器(cpp)</strong>↓</p>\n<p>　　　　hello.i（被修改的源程序<strong>文本</strong>）↓</p>\n<p>　　　　<strong>编译器(ccl)</strong>↓</p>\n<p>　　　　hello.s（汇编程序<strong>文本</strong>）↓</p>\n<p>　　　　<strong>汇编器(as)</strong>↓</p>\n<p>　　　　hello.o（可重定位目标程序<strong>二进制文件</strong>）+printf.o（引用的库文件）↓</p>\n<p>　　　　<strong>链接器(ld)</strong>↓</p>\n<p>hello(可执行目标程序<strong>二进制文件</strong>)</p>\n<hr>\n<!--more-->\n<p>Q：多个C文件组成的程序是怎么被编译成一个程序的？<br>A：一个.c文件+此c文件引用的所有.h文件汇编成.o文件，最后所有.o文件再链接成可执行二进制文件</p>\n<p>Q：cpp在预处理过程将头文件的内容直接插入到程序文本中，对于多个C文件引用同一个H文件，那不是会导致重复插入？<br>A：头文件使用如下方式定义可防止宏重复定义或重复引用头文件：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span>    __SOMEFILE_H__</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span>  __SOMEFILE_H__</span></span><br><span class=\"line\">...... <span class=\"comment\">// 一些声明语句</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br></pre></td></tr></table></figure>\n<p>1) 预处理三种：宏定义+引用头文件+条件编译    </p>\n<p>2) 在预处理阶段，多C文件引用头一个H文件，CPP预处理器还是会把H文件的内容插入到C文件的，但由于#ifndef的使用，程序在运行阶段并不会出现重复定义相同宏、相同变量或相同函数的情况。</p>\n<h3 id=\"系统的硬件组成\"><a href=\"#系统的硬件组成\" class=\"headerlink\" title=\"系统的硬件组成\"></a>系统的硬件组成</h3><ol>\n<li>总线：传送定长字节块(word)，即字；字的字节数（即字长）是一个基本的系统参数，如4字节（32位），8字节（64位）；</li>\n<li>I/O设备：磁盘也是I/O设备，直接存储器存取（DMA）技术可以使数据不经处理器从磁盘直接到达主存；I/O设备通过一个控制器（置于I/O设备本身或主板上的芯片组）或适配器（插在主板插槽上的卡）与I/O总线相连；</li>\n<li>主存：动态随机存取存储器（DRAM），可看成一个极大的线性字节数组；</li>\n<li>处理器：负责解释存储在主存中的指令；核心是一个字长的存储设备（或寄存器），称为程序计数器（PC），任何时刻PC都指向主存中的一条机器语言指令（含有其地址），其次是寄存器文件和算术逻辑单元（ALU）；</li>\n</ol>\n<p>Q：通常所说的32位机器和64位机器是由什么决定的？<br>A：字长，即虚拟地址的字节数或总线传输的最小单元字的字节数。</p>\n<p>Q：指令集结构和微体系结构的区别是什么？<br>A：<strong>TODO</strong></p>\n<h3 id=\"操作系统管理硬件\"><a href=\"#操作系统管理硬件\" class=\"headerlink\" title=\"操作系统管理硬件\"></a>操作系统管理硬件</h3><ol>\n<li>操作系统：应用程序和硬件间的一层软件，1）防止硬件被失控的应用滥用；2）通过简单且一致的机制来控制复杂而又大相径庭的硬件设备；</li>\n<li>进程：并发指进一个进程的指令和其他进程的指令交错运行，实现这种交错运行叫做上下文切换，由内核代码负责，如保存PC、寄存器文件以及主存的内容；</li>\n<li>线程：多控制流并行（同时执行）；</li>\n<li><p>虚拟存储器：每个进程看到的是一致的存储器，即虚拟内存空间；地址从小到大依次是：<br> <strong>程序文本(.text)</strong>（程序二进制文件）↓    </p>\n<p> <strong>文字常量区(.rodata)</strong>（程序用到的常量字符串）↓    </p>\n<p> <strong>已初始化数据(.data)</strong>（已初始化的全局或静态全局变量）↓    </p>\n<p> <strong>未初始化数据(.bss)</strong>（未初始化的全局或静态全局变量）↓    </p>\n<p> <strong>堆</strong>（malloc伸，free缩，或结束时操作系统释放）↓    </p>\n<p> <strong>共享库</strong>（如标准库）↓    </p>\n<p> <strong>栈</strong>（函数参数值，局部变量值）↓    </p>\n<p> <strong>内核虚拟存储器</strong></p>\n</li>\n<li>文件：即字节序列，每个I/O设备都可以视为文件；</li>\n</ol>\n<p>总结：文件是对I/O抽象，虚拟存储器是对主存抽象，进程是对运行程序抽象，虚拟机是对操作系统抽象。</p>\n<p>Q：举例说明上文提到的虚拟存储器？<br>A：如下<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//main.cpp</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;          <span class=\"comment\">// 全局初始化区</span></span><br><span class=\"line\"><span class=\"keyword\">char</span> *p1;           <span class=\"comment\">// 全局未初始化区</span></span><br><span class=\"line\">                    <span class=\"comment\">// built-in type之外的类型都不会默认初始化</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">int</span> b;            <span class=\"comment\">// 栈区</span></span><br><span class=\"line\">  <span class=\"keyword\">char</span> s[] = <span class=\"string\">\"abc\"</span>; <span class=\"comment\">// 栈区</span></span><br><span class=\"line\">  <span class=\"keyword\">char</span> *p2;         <span class=\"comment\">// 栈区</span></span><br><span class=\"line\">  <span class=\"keyword\">char</span> *p3 = <span class=\"string\">\"123456\"</span>;     <span class=\"comment\">// \"123456/0\" 在常量区，p3在栈区</span></span><br><span class=\"line\">  <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> c =<span class=\"number\">0</span>;         <span class=\"comment\">// 全局（静态）初始化区</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  p1 = (<span class=\"keyword\">char</span> *)<span class=\"built_in\">malloc</span>(<span class=\"number\">10</span>);</span><br><span class=\"line\">  p2 = (<span class=\"keyword\">char</span> *)<span class=\"built_in\">malloc</span>(<span class=\"number\">20</span>); <span class=\"comment\">// 分配得来的10和20字节的区域就在堆区</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  <span class=\"built_in\">strcpy</span>(p1, <span class=\"string\">\"123456\"</span>);    <span class=\"comment\">// \"123456/0\" 放在常量区，编译器可能会将它</span></span><br><span class=\"line\">                              <span class=\"comment\">// 与p3所指向的\"123456\"优化成一个地方。</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"并发与并行\"><a href=\"#并发与并行\" class=\"headerlink\" title=\"并发与并行\"></a>并发与并行</h3><ol>\n<li>Inter Core i7有4个核心，每个核心可以执行2个线程（2个控制流，超线程），总共可以并行执行8个线程（多核+超线程）；</li>\n<li>指令级并行：处理器同时执行多条指令；</li>\n<li>单指令、多数据：允许一条指令产生多个可以并行执行的操作，称为单指令、多数据，如浮点数加法；</li>\n</ol>\n<h2 id=\"第2章-信息的表示和处理\"><a href=\"#第2章-信息的表示和处理\" class=\"headerlink\" title=\"第2章 信息的表示和处理\"></a>第2章 信息的表示和处理</h2><h3 id=\"信息存储\"><a href=\"#信息存储\" class=\"headerlink\" title=\"信息存储\"></a>信息存储</h3><ol>\n<li>虚拟地址空间是展示给进程的，为程序提供一个看上去统一的字节数组，实际实现要配合随机访问存储器（RAM）、磁盘、特殊硬件和操作系统；</li>\n<li>第1章提到的“字”的字节数即虚拟地址空间地址的字节数；</li>\n<li>大端法：human-readable，按从左到右的方式书写，左端是高位；小端法与大端法相反；对于文本不需要考虑大端还是小端法，文本具有更强的平台独立性；</li>\n<li>布尔运算与命题逻辑运算的对应：~对应NOT，&amp;对应AND，|对应OR，^对应异或且<code>(a^b)^a=b</code>；</li>\n<li>掩码运算：<code>x&amp;0xFF</code>，只保留x的低8位；</li>\n<li>逻辑运算||、&amp;&amp;和!与布尔运算的区别，1）运算不等价，逻辑运算的结果是0或1而布尔运算不然；2）结束条件不同，如果第一个运算就能确定逻辑运算表达式的值运算将终止；</li>\n<li>移位运算：左移右补k个0；逻辑右移左补k个0，算术右移左补k个最高有效位的值；<strong>无符号右移必须是逻辑的，有符号右移默认是算术的根据编译器不同也可能是逻辑的</strong>；Java用<code>&gt;&gt;</code>表示算术右移，<code>&gt;&gt;&gt;</code>表示逻辑右移；在运算中比加减乘除优先级低；当移动位k大于被移动数位数w时，采用<code>k mod w</code>计算位移量；</li>\n</ol>\n<h3 id=\"整数表示\"><a href=\"#整数表示\" class=\"headerlink\" title=\"整数表示\"></a>整数表示</h3><ol>\n<li>long、int在不同位级机器上位数不同，需慎用，尽量使用<code>intN_t</code>或<code>uintN_t</code>，N表示位数；另外在printf的格式化过程中也需要注意这个问题，如不同机器对<code>%ld</code>的解释是不同的，另外，<code>%d</code>表示有符号整数（取值范围为<code>-2^(w-1)</code>到<code>2^(w-1)-1</code>），<code>%u</code>表示无符号整数（取值范围为<code>0</code>到<code>2^w-1</code>）；</li>\n<li>补码表示负整数，最高位有效值表示负值；</li>\n<li>w位有符号整数x→无符号，位级表示相同：<ul>\n<li>负数→<code>x+2^w</code>，</li>\n<li>非负数→x</li>\n</ul>\n</li>\n<li>w位无符号整数u→有符号，位级表示相同：<ul>\n<li>u小于<code>2^(w-1)</code>→u，</li>\n<li>u不小于<code>2^(w-1)</code>→<code>u-2^w</code></li>\n</ul>\n</li>\n<li>T表示有符号整数x有w位，C语言中，<code>TMax=2^(w-1)-1</code>，<code>TMin=-TMax-1</code></li>\n<li>零扩展添加0用于无符号数，符号扩展添加最高位有效值用于有符号数，高位转地位统一使用截断；</li>\n<li>慎用无符号数用于整数运算，有符号负数转为无符号数时将变成一个大数，可能导致不健壮程序代码溢出；</li>\n</ol>\n<p>Q：为什么<code>TMin</code>要这样表示？<br>A：<strong>TODO</strong></p>\n<h3 id=\"整数运算\"><a href=\"#整数运算\" class=\"headerlink\" title=\"整数运算\"></a>整数运算</h3><ol>\n<li>无符号加法：<ul>\n<li>超过<code>2^w</code>则减去<code>2^w</code>；</li>\n</ul>\n</li>\n<li>有符号加法（与无符号加法位模式一致，但高位表示符号位）：<ul>\n<li>超过<code>2^(w-1)</code>正溢出减去<code>2^w</code>（两个正数相加）</li>\n<li>小于<code>-2^(w-1)</code>负溢出加上<code>2^w</code>（两个负数相加）</li>\n<li>否则正常；</li>\n</ul>\n</li>\n<li>补码非运算：<ul>\n<li>x等于<code>-2^(w-1)</code>时值不变高位</li>\n<li>否则等于-x；</li>\n</ul>\n</li>\n<li>乘法：<ul>\n<li><code>(x * y) mod 2^w</code>，对于有符号先按有符号计算后再转为有符号，即位级表示相同；</li>\n</ul>\n</li>\n<li>乘以常数：<ul>\n<li>化为位移和加减运算；</li>\n</ul>\n</li>\n<li>除以2的幂：<ul>\n<li>整数除法总是舍入到0，同号是向下取整的，异号是向上取整的；</li>\n<li>“除以2的幂”可使用右移模拟整数除法<ul>\n<li>无符号数逻辑右移等价于整数除法</li>\n<li>有符号非负数算术右移等价于整数除法</li>\n<li>有符号负数算术右移不等价于整数除法（如-5除以2的情况），加偏置的思想：y整除x时得k，否则得k+1</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<p>Q：证补码非等于其补加1：<code>-x=~x+1</code><br>A：根据定义分如下两种情况：</p>\n<ul>\n<li>定义1：x等于-2^(w-1)时值不变，由定义立即得证</li>\n<li>定义2：否则等于-x，等效于证明<code>~x+x+1=0</code>，<code>~x+x</code>的位全为1，立即得证</li>\n</ul>\n<p>Q：为什么有符号负数算术右移：<code>(x+2^k-1) &gt;&gt; k</code>能正确舍入？<br>A：<strong>TODO</strong></p>\n<h3 id=\"浮点数\"><a href=\"#浮点数\" class=\"headerlink\" title=\"浮点数\"></a>浮点数</h3><ol>\n<li>二进制小数表示法的弊端，1）只能精确表示<code>x * 2^y</code>形式的数，2）对于大数需要非常多的位表示；</li>\n<li>浮点数定义：<code>(-1)^s * M * 2^E</code><ul>\n<li>s为符号sign，由第一位表示；</li>\n<li>M是尾数significand，由末尾的n位小数表示的二进制小数frac（简称f）表示；</li>\n<li>E是阶码exponet，由中间k位的小数exp（简称e）表示，负责对M加权；</li>\n<li>它在位上的排列是（大端法）：s | exp | frac；</li>\n</ul>\n</li>\n<li>浮点数分类：<ul>\n<li>非规格化：frac的位全为0，此时<code>M=f</code>，<code>E=1-Bias</code>，<code>Bias=2^(k-1) - 1</code>；</li>\n<li>规格化：frac的位不全为1，此时<code>M=1+f</code>，<code>E=e-Bias</code>，<code>Bias=2^(k-1) - 1</code>；</li>\n<li>特殊值：frac的位全为1，当exp全为0表示无穷大，否则表示NaN；</li>\n</ul>\n</li>\n<li>浮点数偶数舍入<ul>\n<li>将数字向上或向下舍入，使结果最低有效数字位是偶数，如浮点数2.5和1.5的最低有效数字位是个位数的情况下都舍入到2</li>\n<li>适用于二进制数，二进制0是偶数，1是奇数</li>\n</ul>\n</li>\n</ol>\n<p>Q：浮点数比二进制小数编码优异的地方在哪<br>A：<strong>TODO</strong></p>\n<p>Q：为什么要这样子编码浮点数<br>A：<strong>TODO</strong></p>\n<p>Q：试举例将正整数12345做浮点数二进制表示<br>A：使用4个字节32位的单精度浮点数来编码，其中阶码k=8，尾数n=23，十进制12345二进制表示为：0000,0011,0000,0011,1001</p>\n<ol>\n<li>由定义可知最大非规格化数<code>f*2^(1-Bias)</code>肯定是小于1的，因此12345肯定是使用规格化数字表示；</li>\n<li>0000,0011,0000,0011,1001 = 二进制的1.<strong>1,0000,0011,1001</strong> * 2^13，由定义得<strong>1,0000,0011,1001</strong>等于f，f求得；而13=E=e-Bias=e-128得e的十进制表示为141即二进制1000,1101</li>\n<li>则其浮点数二进制表示为0, 1000,1101, 000,0000,0001,0000,0011,1001</li>\n</ol>"},{"layout":"post","title":"读《Advanced Linux Programing》","date":"2016-04-22T11:03:00.000Z","comments":1,"_content":"\n《Advanced Linux Programing》读书笔记。\n\n<!--more-->\n\n## 一些介绍\n\nLinux Kernel\n\n- 硬件交互；\n- 内存管理；\n- 文件管理；\n- 多进程管理；\n- 共享库载入；\n\nGNU Project\n\n- 编辑器；\n- 编译器；\n- Shell（/bin/bash，Bourne-Again SHell）；\n\n注意：\n\n1. Linux Kernel加GNU Project，构成了现在主流的Linux操作系统，所以应该称之为GNU/Linux；\n2. Linux操作系统只是UNIX的一种系统实现，其他类UNIX操作系统有FreeBSD、Solaris等；\n\n## Hello, World（快速了解）\n\n### 从文本到可执行程序\n\n```c\n/** main.c **/\n#include <stdio.h>\n\nvoid sayHello() {\n    printf(\"Hello, World\\n\");\n}\n\nint main() {\n    sayHello();\n    return 0;\n}\n```\n\nShell下运行`gcc -o main main.c`即可得到可执行文件`main`，执行`./main`即可在控制台上看到`Hello, World`的输出。那么，它的原理是什么？从`main.c`到`main`，经历了以下步骤：\n\n- main.c --> main.i --> main.s --> main.o --> main\n- 程序文本 + **预处理器(cpp)** --> 被修改的源程序文本 + **编译器(ccl)** --> 汇编文本 + **汇编器(as)** --> 可重定向目标文件（二进制） + printf.o + **链接器(ld)** --> main（可执行程序）\n\n对应到Shell下，经历了以下命令：\n\n```bash\ngcc -E main.c -o main.i\ngcc -S main.i -o main.s --> main.s\ngcc -c main.s -o main.o --> main.o\ngcc main.o -o main --> main\n\n# 上面4句等价于下面一句，gcc自动进行预处理、编译、汇编和链接\ngcc main.c -o main\n\n```\n\n`-E`进行预处理，将头文件插入C文件同时执行宏替换；`-S`用于生成汇编绘本；`-c`命令用于汇编；`-o`命令用于指定输出文件名称。\n\n### 编写可用g++编译的c程序\n\n```c\n/** main.c **/\n#include <stdio.h>\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\nvoid sayHello();\n#ifdef __cplusplus\n}\n#endif\n\nvoid sayHello() {\n    printf(\"Hello, World\\n\");\n}\n\nint main() {\n    sayHello();\n    return 0;\n}\n```\n\n### 其他常用gcc命令\n\n- `-I`指定存放头文件的路径（相对或绝对路径）；\n- `-D`定义一个宏；\n- `-O`指定优化级别；\n- `-l`指定要链接的库；\n- `-L`指定搜索动态链接库的路径；\n\n```bash\n# 生成可执行文件main\n# 从绝对路径/root/搜索头文件\n# 定义宏DEBUG\n# 定义优化级别为2（0<1<2<3，0表示不优化）\n# 链接数学库m\n# 在/usr/local/lib下查找数学库m的动态链接库\ngcc main.c -o main -I /root/ -D DEBUG=2 -O2 -lm -L/usr/local/lib\n```\n\n### 如何节省编译的工作\n\n1. 写MakeFile；\n2. 使用autoconf、automake和libtool；\n\n简单的makefile举例：\n\n```\nmain.o: main.c\n        gcc -c main.c -o main.o\n\nall: main\n\nmain: main.o\n        gcc main.o -o main\n\nclean:\n        rm main.o main\n```\n\n如何使用这个makefile：\n\n```bash\n# 编译（把all换成main效果一致）\n# 方法1：用-f指定makefile文件\nmake -f makefile all\n# 方法2：不指定makefile文件，默认会在当前文件夹寻找\n# 按顺序寻找文件GNUmakefile-->makefile-->Makefile，找不到则报错\nmake all\n\n# 清除编译结果，以下二选一\nmake clean\nmake -f makefile clean\n```\n\nmakefile的基本组成如下（**command必须以一个tab开始**）：\n\n```\n# target表示目标体，它位于冒号之前\n# dependency_files表示依赖的文件或target，它位于冒号之后\n# command表示达成这个目标所需执行命令\ntarget: dependency_files\n        command\n```\n\nmakefile里面也可定义和调用变量：\n\n```\nCC=gcc\nEXE=main\n\nmain.o: main.c\n        $(CC) -c main.c -o main.o\n\nall: $(EXE)\n\n$(EXE): main.o\n        gcc main.o -o $(EXE)\n\nclean:\n        rm main.o $(EXE)\n```\n\n也可在外部调用时传入变量（会将makefile中已存在的变量覆盖掉），命令如下：\n\n```bash\nmake EXE=mm all\nmake EXE=mm clean\n```\n\n### 使用GDB调试程序简介\n\n使用`gdb 程序名（相对或绝对路径）`进入gdb：\n2. 输入`break main`为main函数设置断点，输入`break main.c:5`为`main.c`的第5行设置断点；\n3. 输入`i b`查看当前断点；\n4. 输入`delete 1`删除第一个断点；\n5. 输入`disable 1`停用第一个断点；\n6. 输入`list main.c:5`可在gdb显示代码；\n6. 输入`r`或`run`运行，这时用户将无法再输入命令，直到运行到断点时，gdb将交回命令行控制权，这时输入`n`或`next`表示运行到下一行，`s`或`step`表示进入当前行调用的函数，输入`return`返回到上一层函数；\n7. gdb交回命令行控制权时，输入`print 参数名`可查看当前作用域内的具体参数值；\n8. 假如程序意外退出，这时输入`where`、`bt`或`backtrace`可以查看错误堆栈；\n\n### 如何查看帮助手册\n\n终端下输入`man 命令名称`（如`man printf`）将看到如下提示：\n\n```\nMan: 寻找所有匹配的手册页 (set MAN_POSIXLY_CORRECT to avoid this)\n * printf (1)\n   printf (3)\n   printf (1p)\n   printf (3p)\nMan: 您需要什么手册页？\nMan: \n```\n\n1. 数字1表示这是一个用户命令（user commands，如**echo**）；\n2. 数字2表示这是一个系统调用（system calls，如**fork**）；\n3. 数字3表示这是一个标准库（stand library，如**printf**）；\n4. 带p后缀的为POSIX标准，释义：POSIX标准定义了操作系统应该为应用程序提供的接口标准，一个POSIX兼容的操作系统编写的程序，应该可以在任何其它的POSIX操作系统（即使是来自另一个厂商）上编译执行；\n\n## 编程实践\n\n### 环境交互\n\n1. 临时文件（用于暂时存放数据），使用下述命令查看具体用途\n    - `man mkstemp`\n    - `man tmpfile`\n1. 环境变量（设置运行环境）\n    - shell下`echo $USER`或`printenv USER`打印环境变量`USER`；\n    - shell下`export USER=jayzee`设置环境变量`USER`为`jayzee`；\n    - shell下`env`查询当前用户所有环境变量；\n    - Linux下调用一个C/C++程序时，该程序继承其调用者的所有环境变量，标准库`stdlib.h`的`getenv`、`setenv`和`unsetenv`用于获取、操纵环境变量；\n1. shell下调用程序结束后，使用`echo $?`获取程序退出代码（0表示正常）；\n1. IO（输入输出流）\n    - 程序中，宏`stdin`表示输入流，对应int值0；宏`stdout`表示标准输出流，对应int值1；宏`stderr`表示错误输出流，对应int值2；\n    - `stdin`只能是buffered的，但其buffered size可以修改；\n    - `stderr`只能是unbuffered，一有错误立即输出；\n    - 当程序直接在shell调用并且直接输出到控制台时，`stdout`是line-buffered的，否则是buffered的，但其buffered size可以修改，`man setvbuf`查看标准库如何设置输入输出流；\n    - 程序写文件也是默认buffered，写完后应使用`fflush(your_file)`立即清空buffer写入到文件；\n    - shell命令`your_program > output_file.txt 2>&1`表示将`your_program`的标准输出写入到文件`output_file.txt`（`>`执行覆盖写，`>>`执行追加写），并且将错误输出流重定向到标准输出流，Linux规定文件名必须在流重定向之前；\n    - shell命令`program 2>&1 | filter`表示将标准输出使用管道过滤，Linux规定重定向必须在过滤器之前；\n1. `man getopt_long`查看`getopt.h`库如何处理程序参数（类似于`ls -l`的`-l`）；\n\n### 好的编程习惯\n\n使用断言assert：\n\n- 所有需确认值为true或非0的需使用`assert(condition)`；\n- 编译时指定`-DNDEBUG`可移除所有assert语句，所以**千万不要把程序的重要逻辑放在assert语句中**；\n\n处理系统调用失败：\n\n- 系统调用如`fork`失败时会返回非零值，这时宏`errno`会被设置，下次系统调用失败时又会覆盖这个宏的值；\n- `man strerror`查看如何使用`string.h`的`strerror`的具体字符串释义，细节如下：\n\n```\nEINTR : blocking function interrupt, like sleep, read, select\nEPERM : Permission denied\nEROFS : PATH is on a read-only file system\nENAMETOOLONG : PATH is too long\nENOENT : PATH does not exit\nENOTDIR : A component of PATH is not a directory\nEACCES : A component of PATH is not accessible\nEFAULT : PATH contains an invalid memory address.  This is probably a bug\nENOMEM : Ran out of kernel memory\n```\n\n申请内存与释放内存：\n\n- 申请内存与释放内存的语句必须成对，即有申请内存则相应的要有释放内存；\n\n### 链接程序（库：快速开发，软件复用）\n\n以下文字部分引用自[C++静态库与动态库 - 吴秦 - 博客园](http://www.cnblogs.com/skynet/p/3372855.html)，向该作者致敬。\n\n下文用到的main.c文件：\n\n```bash\n/** main.c **/\nint add(int x, int y) {\n    return x + y;\n}\n```\n\n#### 静态链接\n\n静态库的特点：\n\n- 静态库对函数库的链接是放在编译时期完成的；\n- 程序在运行时与函数库再无瓜葛，移植方便；\n- 浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件；\n\n静态库的创建：\n\n- 静态库的命名规范为lib[your_library_name].a：lib为前缀，中间是静态库名，扩展名为.a；\n- 首先将代码文件编译成目标文件.o，再通过ar工具将目标文件打包.a静态库文件；\n\n```bash\n# 假定有一个math.c文件，提供加法函数int add(int x, int y)，我们现在将其打包成静态库\ngcc -c math.c -o math.o\nar -crv libmath.a math.o\n```\n\n使用静态库：\n\n- 在编译时指定静态库搜索路径（-L选项）、指定静态库名称（不需要lib前缀和.a后缀，-l选项）；\n\n```bash\n# -l为什么一定要放在末尾？它会去查找库的所有被引用的函数或宏等并插入到最终的可执行程序，放在末尾是为了这种依赖搜索在最后执行\ngcc main.c -o main -Lfilepath_of_your_static_library -lmath\n```\n\n静态库优缺点：\n\n- 优点：编译成可执行文件后与其编译时引用的静态库再无任何瓜葛；\n- 缺点：导致可执行程序体量庞大，同一个操作系统上运行的多个程序引用同一个静态库会导致内存浪费（相同的代码），导致客户的全量更新；\n\n#### 动态链接\n\n动态库的特点：\n\n- 动态库把对一些库函数的链接载入推迟到程序运行的时期；\n- 可以实现进程之间的资源共享（因此动态库也称为共享库）；\n- 将一些程序升级变得简单；\n- 甚至可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）；\n\n动态库的创建：\n\n- 动态库的命名规范为lib[your_library_name].so：lib为前缀，中间是动态库名，扩展名为.so；\n- 首先将代码文件编译成目标文件.o，再通过gcc工具将目标文件打包.so动态库文件；\n    - `-fPIC`创建与地址无关的编译程序（pic，position independent code），是为了能够在多个应用程序间共享；\n    - `-shared`指定生成动态链接库；\n\n```bash\n# 假定有一个math.c文件，提供加法函数int add(int x, int y)，我们现在将其打包成动态库\ngcc -fPIC -c math.c -o math.o\ngcc -shared -o libmath.so math.o\n# 上面两条命令等价于\ngcc -fPIC -shared -o libmath.so math.c\n```\n\n使用动态库：\n\n- 在编译时指定动态库搜索路径（-L选项）、指定动态库名称（不需要lib前缀和.so后缀，-l选项）；\n\n```bash\ngcc main.c -o main -Lfilepath_of_your_static_library -lmath\n```\n\n- 注意，运行上述生成的可执行文件时，操作系统会去一些指定路径查找并载入该动态库，如查找不到将抛出找不到动态库的异常信息，这些指定路径是：\n    - 环境变量LD_LIBRARY_PATH，如`LD_LIBRARY_PATH=/usr/local/lib:/opt/lib`；\n    - /etc/ld.so.cache文件列表，需要额外操作如下：\n        + 编辑/etc/ld.so.conf文件，加入库文件所在目录的路径；\n        + 运行ldconfig ，该命令会重建/etc/ld.so.cache文件；\n    - /lib/，/usr/lib目录；\n- `-L`指定的库搜索路径下即有动态库也有静态库，则动态库具有较高优先级被链接；\n\n动态库优缺点：\n\n- 缺点：增量更新必须考虑向后兼容；\n- 优点：增量更新，避免内存浪费（同一个操作系统上运行的多个程序引用同一个动态库只需要一份共享库示例）；\n\n#### 链接检查辅助命令\n\n`nm`命令：打印出库中的涉及到的所有符号。库既可以是静态的也可以是动态的。nm列出的符号有很多，常见的有三种，\n\n- 一种是在库中被调用，但并没有在库中定义(表明需要其他库支持)，用U表示；\n- 一种是库中定义的函数，用T表示，这是最常见的；\n- 一种是所谓的弱态”符号，它们虽然在库中被定义，但是可能被其他库中的同名符号覆盖，用W表示；\n\n`ldd`命令：查看一个可执行程序依赖的共享库。\n\n## 进程\n\n本章节部分内容引用自[Linux下Fork与Exec使用 - hicjiajia - 博客园](http://www.cnblogs.com/hicjiajia/archive/2011/01/20/1940154.html)和[系统调用跟我学(3)](http://www.ibm.com/developerworks/cn/linux/kernel/syscall/part3/index.html)，向作者致敬。\n\n### 进程查看\n\n`pid`指进程id，`ppid`指父进程id。\n\n1. Linux所有**用户进程**呈树状结构，这棵用户进程树的根节点是init进程（内核启动的第一个用户级进程），init进程的`pid`为1，其ppid为0；\n2. shell下运行`ps -e -o pid,ppid,command`可查看所有用户进程的pid、ppid和command；\n3. `unistd.h`提供`getpid()`和`getppid()`获取进程的ID和父ID；\n\n### 进程创建\n\n#### system函数：执行shell命令\n\nsystem函数用于在C/C++语言中执行shell命令，其API如下：\n\n```bash\n#include <stdlib.h>\nint system(const char *command);\n```\n\n其具体实现是：\n\n1. 先执行系统调用`fork()`创建子进程；\n2. 再执行`execl(\"/bin/sh\", \"sh\". \"-c\", command, (char *) 0);`去调用shell执行command；\n\n#### fork函数，exec族函数\n\n##### fork函数：创建子进程，进程分叉\n\nfork函数API如下：\n\n```bash\n#include <unistd.h>\npid_t fork(void);\n```\n\nfork函数的特点：\n\n- fork调用之后，父进程进入`pid>0`的分支，子进程进入`pid==0`的分支；\n- fork创建的子进程是父进程的一个完整拷贝，**当且仅当fork之后的代码即将开始更新内存，真实的拷贝才会发生**（也就是上述例子并没有发生拷贝），为什么这么设计，我们会在下面讲到；\n- fork创建的子进程拥有一个新的进程pid号，子进程的ppid为调用fork函数的进程id；\n\npid_t是一个整型变量。具体示例如下：\n\n```c\n/* zombie.c */\n#include <sys/types.h>\n#include <unistd.h>\nint main() {\n    pid_t pid;\n    pid=fork();\n    if(pid<0) /* 如果出错 */\n        printf(\"error occurred!\\n\");\n    else if(pid==0) /* 如果是子进程 */\n        exit(0);\n    else /* 如果是父进程 */\n        sleep(60); /* 休眠60秒，这段时间里，父进程什么也干不了 */\n    wait(NULL); /* 收集僵尸进程 */\n}\n```\n\n##### exec函数族：对当前进程进行替换\n\nexec并不是一个具体函数，它是以下六个函数：\n\n```c\n#include <unistd.h>\nint execl(const char *path, const char *arg, ...);\nint execlp(const char *file, const char *arg, ...);\nint execle(const char *path, const char *arg, ..., char *const envp[]);\nint execv(const char *path, char *const argv[]);\nint execvp(const char *file, char *const argv[]);\nint execve(const char *path, char *const argv[], char *const envp[]);\n```\n\n其中`execl`是基函数，其他5个是它的变种（区别在于传参形式不同，带v的表示参数以数组传递，带l的表示参数以陈列的方式传递）。\n\nexec函数族特点：\n\n- 只保留当前进程的pid，其他进程相关的数据段全部废弃；对系统而言，还是同一个进程号，但其实已经是另外一个程序了，即调用exec函数族的进程已“死亡”了；\n- 上面说到，fork的数据拷贝只发生在子进程更新内存时，fork调用后立即执行exec函数族使得我们能够产生一个全新的进程（**这意味着当前进程的所有线程、文件描述符等都被释放**），与fork调用进程再无任何瓜葛；\n\n举一个具体例子如下：\n\n```c\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n\nchar command[256];\nvoid main()\n{\n   int rtn; /*子进程的返回数值*/\n   while(1) {\n       /* 从终端读取要执行的命令 */\n       printf( \">\" );\n       fgets( command, 256, stdin );\n       command[strlen(command)-1] = 0;\n       if ( fork() == 0 ) {/* 子进程执行此命令 */\n          execlp( command, NULL );\n          /* 如果exec函数返回，表明没有正常执行命令，打印错误信息*/\n          perror( command );\n          exit( errno );\n       }\n       else {/* 父进程， 等待子进程结束，并打印子进程的返回值 */\n          wait ( &rtn );\n          printf( \" child process return %d\\n\", rtn );\n       }\n   }\n}\n```\n\n### 信号处理\n\n信号是一种异步的进程通信机制，是软件层面的中断，进程接收到线程必须进行处理，有以下三种处理方式：\n\n- 使用进程对信号的静默处理；\n- 忽略该信号；\n- 使用特定的信号处理函数进行处理；\n\n上述的后两种方式需要使用`signal()`函数进行处理，举例如下：\n\n```c\n// 忽略SIGPIPE信号\nsignal ( SIGPIPE, SIG_IGN );\n// 使用PrepareExit处理SIGINT信号\nsignal ( SIGINT, (__sighandler_t ) PrepareExit );\n```\n\nLinux的信号如下：\n\n```\n信号值 默认处理动作 发出信号的原因\nSIGHUP 1 A 终端挂起或者控制进程终止\nSIGINT 2 A 键盘中断（如break键被按下）\nSIGQUIT 3 C 键盘的退出键被按下\nSIGILL 4 C 非法指令\nSIGABRT 6 C 由abort(3)发出的退出指令\nSIGFPE 8 C 浮点异常\nSIGKILL 9 AEF Kill信号\nSIGSEGV 11 C 无效的内存引用\nSIGPIPE 13 A 管道破裂: 写一个没有读端口的管道\nSIGALRM 14 A 由alarm(2)发出的信号\nSIGTERM 15 A 终止信号\nSIGUSR1 30,10,16 A 用户自定义信号1\nSIGUSR2 31,12,17 A 用户自定义信号2\nSIGCHLD 20,17,18 B 子进程结束信号\nSIGCONT 19,18,25 进程继续（曾被停止的进程）\nSIGSTOP 17,19,23 DEF 终止进程\nSIGTSTP 18,20,24 D 控制终端（tty）上按下停止键\nSIGTTIN 21,21,26 D 后台进程企图从控制终端读\nSIGTTOU 22,22,27 D 后台进程企图从控制终端写\n\n处理动作一项中的字母含义如下：\nA 缺省的动作是终止进程\nB 缺省的动作是忽略此信号，将该信号丢弃，不做处理\nC 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序\nD 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用）\nE 信号不能被捕获\nF 信号不能被忽略\n```\n\n**注意**：\n信号处理函数可被新产生的信号所中断，所以信号处理函数应该做尽可能少的工作；\n\n\n### 进程终止\n\n#### 信号终止\n\n1. `SIGINT`：CRTL+C产生；\n2. `SIGTERM`：shell下`kill pid`产生；\n3. `abort()`：发送一个`SIGABRT`信号给自己；\n4. `SIGKILL`：强制退出信号，shell下`kill -9 pid`产生；\n\n当进程终止时，shell调用`echo $?`可取得该进程的exit code，\n\n- 如果该进程由信号终止，exit code为128加上信号值；\n- 调用`exit(int exit_code)`函数退出，exit_code的范围需在0到128之间；\n\n如何给进程发送指定信号，\n\n- 在shell下使用`kill -s SIGNAL_NAME pid`，可以给进程pid发送SIGNAL_NAME信号；\n- 程序使用`kill(pid, SIGNAL_NAME)`函数；\n\n#### wait\n\nUnix的进程终止时，一些资源（如进程pid、进程exit code、收到的信号、占用CPU时间等）并不会被立即释放（堆栈等内存立即释放），死亡进程的父进程必须调用`wait`函数对进程进行“收尸”，即释放进程的pid和exit code等资源。\n\n`wait`函数的API定义如下：\n\n```c\npid_t wait(int *status);\n```\n\n一些说明：\n\n- `wait`函数是阻塞式的，在子进程未结束时将阻塞；\n- 如果`pid_t`为-1，表明`wait`调用失败，这是因为调用进程没有子进程导致；否则，表明收集子进程“死亡”信息成功，`pid_t`的值为“死亡”进程pid；\n- `status`是一个指针，如果这个指针为空，表明我们不关心进程的“死亡”信息细节，只是发起了回收这个动作；否则，status将包含进程“死亡”的一些信息；\n- 调用`WIFEXITED(status)`，若返回值回0表明进程异常退出（如信号导致退出），这时调用`WTERMSIG(status)`将得到使进程死亡的信号int值；否则表示程序正常退出，这时候调用`WEXITSTATUS(status)`可获取“死亡”进程的exit code（如“死亡”进程调用`exit(7)`退出，则`WEXITSTATUS(status)`的结果为7）；\n\n```c\n/* wait2.c */\n#include <sys/types.h>\n#include <sys/wait.h>\n#include <unistd.h>\n#include <stdio.h>\n#include <stdlib.h>\n\nmain()\n{\n    int status;\n    pid_t pc,pr;\n    pc=fork();\n    if(pc<0)     /* 如果出错 */\n        printf(\"error ocurred!\\n\");\n    else if(pc==0){ /* 子进程 */\n        printf(\"This is child process with pid of %d.\\n\",getpid());\n        exit(3);    /* 子进程返回3 */\n    }\n    else{       /* 父进程 */\n        pr=wait(&status);\n        if(WIFEXITED(status)){  /* 如果WIFEXITED返回非零值 */\n            printf(\"the child process %d exit normally.\\n\",pr);\n            printf(\"the return code is %d.\\n\",WEXITSTATUS(status));\n        }else           /* 如果WIFEXITED返回零，这时pr存储死亡进程pid */\n            printf(\"the child process %d exit abnormally with signal number %d.\\n\",pr,WTERMSIG(status));\n    }\n}\n```\n\n#### 僵尸进程\n\n如果子进程死亡，父进程却没有调用`wait`对其进行“收尸”，子进程就会变成一个僵尸进程，\n\n```\n$ ps -ax\n  PID TTY      STAT   TIME COMMAND\n 1177 pts/0    S      0:00 -bash\n 1577 pts/0    S      0:00 ./zombie\n 1578 pts/0    Z      0:00 [zombie <defunct>]\n 1579 pts/0    R      0:00 ps -ax\n```\n\n若STAT为Z则表明则是一个僵尸进程，关于僵尸进程，\n\n- 在父进程退出时，init进程会自动对其下的所有僵尸子进程进行清理；\n- 子进程意外死亡时，父进程会受到一个SIGCHLD信号，父进程可以注册这个信号的处理函数进行“收尸”；\n- `wait3`和`wait4`函数为异步的，可以周期调用这两个函数执行回收；\n\n## 线程\n\n### 线程创建\n\n**线程创建**：`int pthread_create(pthread_t *thread, const pthread_attr_t *attr,\nvoid *(*start_routine) (void *), void *arg);`\n\n- `pthread_create`的返回值为0表示创建线程成功；\n- `thread`是指向`pthread_t`的指针；\n- `pthread_attr_t`在下一个例子介绍；\n- `start_routine`是一个无形参且无返回值的函数指针；\n- `arg`是上面提到的函数指针所接收的参数；\n\n**线程回收**：`int pthread_join(pthread_t thread, void **retval);`\n\n- `retval`实际上是一个指向整型指针的指针，它存放的是线程调用`exit`或`pthread_exit`的退出值；\n- `When a joinable thread terminates, its memory resources (thread descriptor and stack) are not deallocated until another thread performs pthread_join on it. Therefore, pthread_join must be called  once  for each joinable thread created to avoid memory leaks.`\n- 这是一个阻塞式的方法，当监控到有线程结束时才返回；\n\n**线程退出**：`void pthread_exit(void *retval);`\n\n- `retval`实际是一个整型指针，在退出时标识线程的退出值；\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\nint code = 11;\n\nvoid hello(void *args) {\n    char *str = (char *) args;\n    sleep(5);\n    printf(\"Hello, %s!\\n\", str);\n    pthread_exit(&code);\n}\n\nint main() {\n    pthread_t thread;\n    int status = pthread_create(&thread, NULL, (void *)hello, (void *) \"Jayzee\");\n    printf(\"thread create status : %d\\n\", status);\n    int *exit_code = 0;\n    status = pthread_join(thread, (void *) &exit_code);\n    printf(\"thread join status : %d\\n\", status);\n    printf(\"thread exit code : %d\\n\", *exit_code);\n    return 0;\n}\n```\n\n------\n\n下面的例子在`pthread_create`时用到了`pthread_attr_t`，必须经历下面四个过程\n\n1. 先实例化`pthread_attr_t`；\n2. 再设置`pthread_attr_t`；\n3. 在线程创建时使用该`pthread_attr_t`；\n4. 线程创建完后销毁`pthread_attr_t`；\n\n注意：\n\n1. 创建线程时设置其为detach态，意味着我们不关心它的返回值，只是进行线程相关资源回收；\n2. 也可创建线程时不指定detach态，在线程创建后可使用`int pthread_detach(pthread_t thread);`设置其为detach态；\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\nint code = 11;\n\nvoid hello(void *args) {\n    char *str = (char *) args;\n    sleep(5);\n    printf(\"Hello, %s!\\n\", str);\n    pthread_exit(&code);\n}\n\nint main() {\n    pthread_t thread;\n    pthread_attr_t attr;\n    pthread_attr_init (&attr);\n    pthread_attr_setdetachstate (&attr, PTHREAD_CREATE_DETACHED);\n    int status = pthread_create (&thread, &attr, (void *)hello, (void *) \"Jayzee\");\n    pthread_attr_destroy (&attr);\n    printf(\"thread create status : %d\\n\", status);\n    return 0;\n}\n```\n\n### 线程取消\n\n```\nint pthread_setcancelstate(int state, int *oldstate);\nint pthread_setcanceltype(int type, int *oldtype);\nint pthread_cancel(pthread_t thread);\n```\n\n- `pthread_setcancelstate`在运行时设置线程的状态`state`，并取得其之前的状态`oldstate`；\n- `pthread_setcanceltype`在运行时设置线程的类型`type`，并取得其之前的类型`oldtype`；\n- `pthread_cancel`用于取消线程的执行；\n\n\n注意，\n\n1. type：`PTHREAD_CANCEL_DEFERRED`或`PTHREAD_CANCEL_ASYNCHRONOUS`\n2. state：`PTHREAD_CANCEL_ENABLE`或`PTHREAD_CANCEL_DISABLE`\n3. type和state作用于`pthread_cancel`：\n    - 当state为`PTHREAD_CANCEL_DISABLE`时，设置的type和调用`pthread_cancel`不会对线程造成任何影响；\n    - 否则，当设置的type为`PTHREAD_CANCEL_DEFERRED`时，为非阻塞取消（等待达到取消的条件，如释放锁）；当设置的type为`PTHREAD_CANCEL_ASYNCHRONOUS`时为异步取消（即线程立即被取消，但不同操作系统有可能实现不同，理应处理释放锁）；\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\nint code = 11;\n\nvoid hello(void *args) {\n    pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, &last_state); \n    pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, &last_type);\n    char *str = (char *) args;\n    sleep(5);\n    printf(\"Hello, %s!\\n\", str);\n    pthread_exit(&code);\n}\n\nint main() {\n    pthread_t thread;\n    int status = pthread_create(&thread, NULL, (void *)hello, (void *) \"Jayzee\");\n    printf(\"thread create status : %d\\n\", status);\n    int *exit_code = 0;\n    status = pthread_join(thread, (void *) &exit_code);\n    printf(\"thread join status : %d\\n\", status);\n    printf(\"thread exit code : %d\\n\", *exit_code);\n    pthread_cancel(thread);\n    return 0;\n}\n```\n\n### 线程特定数据\n\n```\nint pthread_key_create(pthread_key_t *key, void (*destructor)(void*));\nint pthread_setspecific(pthread_key_t key, const void *value);\nvoid *pthread_getspecific(pthread_key_t key);\n```\n\n1. 使用`pthread_key_create`创建`key`，`destructor`为线程结束时用于析构的函数指针，一个进程内的多个线程可以共用一个`key`；\n2. `pthread_setspecific`为线程设定key-value，`pthread_getspecific`根据key获得value；\n3. 当线程结束时，若`pthread_getspecific`的内容不为空，且`destructor`不为空，则`pthread_getspecific`的内容将作为`destructor`的参数来执行析构函数；\n\n```c\n#include <malloc.h>\n#include <pthread.h>\n#include <stdio.h>\n\n/* The key used to associate a log file pointer with each thread. */\nstatic pthread_key_t thread_log_key;\n\n/* Write MESSAGE to the log file for the current thread. */\nvoid write_to_thread_log (const char* message) {\n    FILE* thread_log = (FILE*) pthread_getspecific (thread_log_key);\n    fprintf (thread_log, \"%s\\n\", message);\n}\n\n/* Close the log file pointer THREAD_LOG. */\nvoid close_thread_log (void* thread_log) {\n    fclose ((FILE*) thread_log);    \n}\n\nvoid* thread_function (void* args) {\n    char thread_log_filename[20];\n    FILE* thread_log;\n    /* Generate the filename for this thread’s log file. */\n    sprintf (thread_log_filename, \"thread%d.log\", (int) pthread_self ());\n    /* Open the log file. */\n    thread_log = fopen (thread_log_filename, \"w\");\n    /* Store the file pointer in thread-specific data under thread_log_key. */\n    pthread_setspecific (thread_log_key, thread_log);\n    write_to_thread_log (\"Thread starting.\");\n    /* Do work here... */\n    return NULL;\n}\n\nint main () {\n    int i;\n    pthread_t threads[5];\n    /* Create a key to associate thread log file pointers in\n    thread-specific data. Use close_thread_log to clean up the file\n    pointers. */\n    pthread_key_create (&thread_log_key, close_thread_log);\n    /* Create threads to do the work. */\n    for (i = 0; i < 5; ++i)\n        pthread_create (&(threads[i]), NULL, thread_function, NULL);\n    /* Wait for all threads to finish. */\n    for (i = 0; i < 5; ++i)\n        pthread_join (threads[i], NULL);\n    return 0;\n}  \n```\n\n```\nvoid pthread_cleanup_push(void (*routine)(void *), void *arg);\nvoid pthread_cleanup_pop(int execute);\n```\n\n1. `pthread_cleanup_push`在线程运行时为线程压栈清理函数；\n2. `pthread_cleanup_pop`从栈弹出一个清理函数，如果`execute`不为0则执行这个清理函数；\n3. 线程结束时，所有压栈的清理函数会自动被弹出栈进行执行；\n4. 当在线程内使用longjump前，应手动调用`pthread_cleanup_pop`执行清理；\n\n### 线程同步\n\n#### 互斥锁\n\n```\nint pthread_mutex_destroy(pthread_mutex_t *mutex);\nint pthread_mutex_init(pthread_mutex_t *restrict mutex,\n    const pthread_mutexattr_t *restrict attr);\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\n```\n\n1. `pthread_mutex_destroy`销毁互斥锁，`pthread_mutex_init`创建互斥锁；\n2. `pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;`表示定义并默认实例化一个互斥锁；\n\n```\nint pthread_mutex_lock(pthread_mutex_t *mutex);\nint pthread_mutex_trylock(pthread_mutex_t *mutex);\nint pthread_mutex_unlock(pthread_mutex_t *mutex);\n```\n\n1. `pthread_mutex_lock`为阻塞锁，`pthread_mutex_trylock`为非阻塞锁（获取不到锁）则立即返回，`pthread_mutex_unlock`为释放锁；\n\n```c\n#include <pthread.h>\n\nint main() {\n    pthread_mutexattr_t attr;\n    pthread_mutex_t mutex;\n    pthread_mutexattr_init (&attr);\n    // 带错误检查的互斥锁\n    pthread_mutexattr_setkind_np (&attr, PTHREAD_MUTEX_ERRORCHECK_NP);\n    pthread_mutex_init (&mutex, &attr);\n    pthread_mutex_lock(&mutex);\n    /** do some work **/\n    pthread_mutex_unlock(&mutex);\n    pthread_mutexattr_destroy (&attr);\n}\n```\n\n#### 信号量\n\n```\nint sem_init(sem_t *sem, int pshared, unsigned int value);\nint sem_post(sem_t *sem);\nint sem_wait(sem_t *sem);\n```\n\n1. `sem_init`实例化信号量`sem`，`pshared`为0表示进程内共享（非0为进程间共享），`value`为初始容量值（默认容量值为0）；\n2. `sem_wait`将容量值减一，`sem_wait`之后若容量值小于0则线程阻塞；`sem_post`将容量值加一；\n3. 假设容量值为负，一次`sem_post`只能唤醒一个线程；\n4. `sem_wait`和`sem_post`是线程安全的；\n\n```c\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h>\n#include <semaphore.h>\n\nsem_t semaphore;\n\nvoid threadfunc() {\n    int i = 0;\n    for (; i<10; i++) {\n        // 实际上不会这么使用，这里仅是展示\n        sem_wait(&semaphore);\n        printf(\"Hello from da thread!\\n\");\n        sem_post(&semaphore);\n        sleep(1);\n    }\n}\n\nint main(void) {\n    // 实例化\n    sem_init(&semaphore, 0, 1);\n    \n    pthread_t *mythread;    \n    mythread = (pthread_t *)malloc(sizeof(*mythread));\n    \n    // 启动线程\n    printf(\"Starting thread, semaphore is unlocked.\\n\");\n    pthread_create(mythread, NULL, (void*)threadfunc, NULL);\n    pthread_join(mythread, NULL);\n    \n    return 0;\n}\n```\n\n#### 条件值\n\n```\nint pthread_cond_init(pthread_cond_t *restrict cond,\n    const pthread_condattr_t *restrict attr);\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\nint pthread_cond_signal(pthread_cond_t *cond);\nint pthread_cond_wait(pthread_cond_t *restrict cond,\n   pthread_mutex_t *restrict mutex);\n```\n\n1. `pthread_cond_t cond = PTHREAD_COND_INITIALIZER;`等价于`pthread_cond_init(&pthread_cond_t, NULL);`\n2. 当调用`pthread_cond_signal`或`pthread_cond_wait`时，必须获得锁；\n3. 调用`pthread_cond_wait`时，自动释放锁，直到被`pthread_cond_signal`唤醒时，才重新自动获得锁；\n4. `pthread_cond_timedwait`可批量唤醒等待的线程；\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\nint condition = 0;\nint count = 0;\n\nint consume( void )\n{\n    while( 1 )\n    {\n        pthread_mutex_lock( &mutex );\n        while( condition == 0 )\n            pthread_cond_wait( &cond, &mutex );\n        printf( \"Consumed %d\\n\", count );\n        condition = 0;\n        pthread_cond_signal( &cond );        \n        pthread_mutex_unlock( &mutex );\n    }\n\n    return( 0 );\n}\n\nvoid* produce( void * arg )\n{\n    while( 1 )\n    {\n        pthread_mutex_lock( &mutex );\n        while( condition == 1 )\n            pthread_cond_wait( &cond, &mutex );\n        printf( \"Produced %d\\n\", count++ );\n        condition = 1;\n        pthread_cond_signal( &cond );        \n        pthread_mutex_unlock( &mutex );\n    }\n    return( 0 );\n}\n\nint main( void )\n{\n    pthread_create( NULL, NULL, &produce, NULL );\n    return consume();\n}\n```\n\n### 线程实现\n\nLinux的线程实现是系统调用`clone()`，它创建一个与父进程共用资源的子进程。\n\n## 进程间通信\n\n### 共享内存\n\n```\n#include <sys/ipc.h>\n#include <sys/shm.h>\nint shmget(key_t key, size_t size, int shmflg);\nvoid *shmat(int shmid, const void *shmaddr, int shmflg);\nint shmdt(const void *shmaddr);\nint shmctl(int shmid, int cmd, struct shmid_ds *buf);\n```\n\n1. `shmget`申请共享内存；\n2. `shmat`取得已申请的共享内存，共享内存使用者计数器加1；\n3. `shmdt`断开已申请的共享内存，共享内存使用者计数器减1，如果计时器减到0，这块共享内存会被系统标注并删除；\n4. `shmctl`对共享内存的标识信息进行设置；\n\n### 进程信号量\n\n```\n#include <sys/types.h>\n#include <sys/ipc.h>\n#include <sys/sem.h>\nint semget(key_t key, int nsems, int semflg);\nint semctl(int semid, int semnum, int cmd, ...);\nint semop(int semid, struct sembuf *sops, size_t nsops);\n```\n\n1. `semget`用于申请信号量；\n2. `semctl`用于释放或实例化信号量；\n3. `semop`用于执行wait或post；\n\n### 映射到内存\n\n```\n#include <sys/mman.h>\nvoid *mmap(void *addr, size_t length, int prot, int flags,\n    int fd, off_t offset);\n```\n\n`mmap`是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。\n\n### 管道\n\n```\n#include <unistd.h>\nint pipe(int pipefd[2]);\n```\n\n`pipe`的一端写，由内核缓存，直到另一端将其读出。\n\n### Socket\n\n```\n#include <sys/types.h>\n#include <sys/socket.h>\nint socket(int domain, int type, int protocol);\nint close(int fd);\nint connect(int sockfd, const struct sockaddr *addr,\n    socklen_t addrlen);\nint bind(int sockfd, const struct sockaddr *addr,\n    socklen_t addrlen);\nint listen(int sockfd, int backlog);\nint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);\n```\n\n1. `socket`创建一个socket；\n2. `close`关闭一个socket；\n3. `connect`建立两个socket的连接；\n4. `bind`将socket绑定到地址和端口；\n5. `listen`配置socket接受连接的条件；\n6. `accept`接收一个socket连接并为其创建一个socket；\n\n## 设备\n\n### 操作\n\n```\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\nint mknod(const char *pathname, mode_t mode, dev_t dev);\n```\n\n`mknod`用于创建一个设备。\n\n```\n#include <sys/ioctl.h>\nint ioctl(int d, unsigned long request, ...);\n```\n\n`ioctl`用于控制设备，常用于驱动编程。\n\n### 特殊设备\n\n`/dev/null`是一个内容为空的设备，将IO流定向到`/dev/null`意味着丢弃其内容；\n\n`/dev/zero`是一个无限长的文件；\n\n`/dev/random`可用于产生随机数；\n\n`/dev/tty*`是串行终端设备，如串口；\n\n`pty`是伪终端，接受键盘的输入并显示到运行它的终端界面；\n\n`pty`的实现涉及到两个概念：\n\n- `ptmx`：被连接的master主机；\n- `pts`：发起向master主机连接的slave主机`pts`，我们常用的SSH登录就意外着在master主机建立一个`pts`进程；\n\n## 常用/proc简介\n\n`/proc/cpuinfo`查看cpu信息；\n\n`/proc/meminfo`查看内存信息；\n\n`/proc/self`查看自身信息；\n\n`/proc/pid_number`查看pid为pid_number的进程信息；\n\n`/proc/loadavg`查看负载信息；\n\n`/proc/uptime`查看启动时间；\n\n`/proc/interrupts`查看中断情况；\n\n## 常用系统调用\n\n`strace`查看系统调用情况；\n\n`access`检测是否具备读写权限；\n`fcntl`操纵文件描述符；\n\n`fsync`和`fdatasync`将缓冲区的文件改动同步到实际文件；\n\n`getrlimit`取得系统的资源限定情况；\n\n`getrusage`取得系统资源使用情况；\n\n`gettimeofday`取得系统时间；\n\n`mlock`锁住一块内存；\n\n`mprotect`保护一块内存；\n\n## 用户与用户组\n\n### 用户与用户组ID\n\n每个用户名对应到一个用户ID，每个用户ID可从属于多个用户组ID。Shell下输入`id`得到如下输出：\n\n```\n# uid为0表示root用户\nuid=0(root) gid=0(root) groups=0(root),1001(nagcmd)\n```\n\n### 文件与用户（组）的关系\n\n`ls -l APL.txt`后得到如下输出：\n\n```\n-rw-r--r-- 1 Jayzee None   1237 五月 18 12:19 APL.txt\n```\n\n`-rw-r--r--`解释：\n\n- 第一个字符`-`表示这是一个文件，`d`表示这是一个文件夹；\n- 2至4字符`rw-`表示拥有者`Jayzee`的权限，顺序为：读（r）、写（w）、执行（x），可读写但不可执行；\n- 5至7字符`r--`表示所属组`None`的权限；\n- 8至10字符`r--`表示组外其他用户的权限；\n\n`man chmod`查看如何更改文件的权限；\n`man chown`查看如何更改文件的拥有者和所属组；\n\n**特殊**\n\n```\ndrwxrwxrwt   1 root root 26416 5月  18 21:53 tmp\n```\n\n只适用于文件夹：当文件夹的所属组或组外的执行（x）被设置为（t）时，表示当且仅当你是该文件夹内文件的创建者，才可以删除该文件；（正常情况下如果该文件夹内文件的权限是对于组或组外可读写，不需要是文件的创建者也可删除的），这里的`t`称为sticky bits。\n\n### 真实的用户ID和有效的用户ID\n\n定义`euid`为有效用户id（effective），`uid`为真实用户id（real）；\n\n`man 2 getuid`查看如何使用C函数获取uid；\n`man 2 geteuid`查看如何使用C函数获取euid；\n\n为什么要引入euid？\n\n1. 当用户发出对文件的操作时，Linux Kernel根据用户的euid检查用户是否具备权限；\n2. euid可被修改，uid不可被修改；\n3. euid被修改代表着用户的切换，uid不被修改表示最初登入系统的uid不变；\n\n用户登录系统时用户id发生什么变化？\n\n1. Linux的登录进程检查登入者输入的账号密码是否正确；\n2. 若正确，使用`exec`为其创建一个User Shell（pts）；\n3. Linux的登录进程设置这个User Shell的euid和uid为同一个值，即该用户的uid（只有euid为0的User Shell可设置euid和uid）；\n\n设置说明：\n\n1. 当我们设置`euid = uid`时，表示返回到最初登录用户的Shell；\n2. 当我们设置`uid = euid`时，表示Linux的登录进程将euid与uid同步，该登录用户与Linux的登录进程（root）再无联系；\n\n`su`命令的原理：\n\n1. `/bin/su`的拥有者为root，其执行项不是（x）而是（s），当文件拥有者的执行项不是（x）而是（s）时，此文件可被执行，且执行文件时调用`geteuid`函数返回的是该可执行文件拥有者的uid而不是调用者的euid；\n2. Linux利用此技术实现普通用户到root用户时，uid不变，而euid变为0；\n3. 当调用`su`时，调用者原User Shell阻塞，Kernel创建一个新User Shell给调用者使用；\n\n注：组ID也分真实和有效，与用户ID类同，故不展开叙述；\n","source":"_posts/2016-04-22-advanced-linux-programing.markdown","raw":"---\nlayout: post\ntitle: 读《Advanced Linux Programing》\ndate: '2016-04-22 19:03'\ncomments: true\ncategories: ['编程语言']  \ntags: ['Linux', 'C/C++']\n---\n\n《Advanced Linux Programing》读书笔记。\n\n<!--more-->\n\n## 一些介绍\n\nLinux Kernel\n\n- 硬件交互；\n- 内存管理；\n- 文件管理；\n- 多进程管理；\n- 共享库载入；\n\nGNU Project\n\n- 编辑器；\n- 编译器；\n- Shell（/bin/bash，Bourne-Again SHell）；\n\n注意：\n\n1. Linux Kernel加GNU Project，构成了现在主流的Linux操作系统，所以应该称之为GNU/Linux；\n2. Linux操作系统只是UNIX的一种系统实现，其他类UNIX操作系统有FreeBSD、Solaris等；\n\n## Hello, World（快速了解）\n\n### 从文本到可执行程序\n\n```c\n/** main.c **/\n#include <stdio.h>\n\nvoid sayHello() {\n    printf(\"Hello, World\\n\");\n}\n\nint main() {\n    sayHello();\n    return 0;\n}\n```\n\nShell下运行`gcc -o main main.c`即可得到可执行文件`main`，执行`./main`即可在控制台上看到`Hello, World`的输出。那么，它的原理是什么？从`main.c`到`main`，经历了以下步骤：\n\n- main.c --> main.i --> main.s --> main.o --> main\n- 程序文本 + **预处理器(cpp)** --> 被修改的源程序文本 + **编译器(ccl)** --> 汇编文本 + **汇编器(as)** --> 可重定向目标文件（二进制） + printf.o + **链接器(ld)** --> main（可执行程序）\n\n对应到Shell下，经历了以下命令：\n\n```bash\ngcc -E main.c -o main.i\ngcc -S main.i -o main.s --> main.s\ngcc -c main.s -o main.o --> main.o\ngcc main.o -o main --> main\n\n# 上面4句等价于下面一句，gcc自动进行预处理、编译、汇编和链接\ngcc main.c -o main\n\n```\n\n`-E`进行预处理，将头文件插入C文件同时执行宏替换；`-S`用于生成汇编绘本；`-c`命令用于汇编；`-o`命令用于指定输出文件名称。\n\n### 编写可用g++编译的c程序\n\n```c\n/** main.c **/\n#include <stdio.h>\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\nvoid sayHello();\n#ifdef __cplusplus\n}\n#endif\n\nvoid sayHello() {\n    printf(\"Hello, World\\n\");\n}\n\nint main() {\n    sayHello();\n    return 0;\n}\n```\n\n### 其他常用gcc命令\n\n- `-I`指定存放头文件的路径（相对或绝对路径）；\n- `-D`定义一个宏；\n- `-O`指定优化级别；\n- `-l`指定要链接的库；\n- `-L`指定搜索动态链接库的路径；\n\n```bash\n# 生成可执行文件main\n# 从绝对路径/root/搜索头文件\n# 定义宏DEBUG\n# 定义优化级别为2（0<1<2<3，0表示不优化）\n# 链接数学库m\n# 在/usr/local/lib下查找数学库m的动态链接库\ngcc main.c -o main -I /root/ -D DEBUG=2 -O2 -lm -L/usr/local/lib\n```\n\n### 如何节省编译的工作\n\n1. 写MakeFile；\n2. 使用autoconf、automake和libtool；\n\n简单的makefile举例：\n\n```\nmain.o: main.c\n        gcc -c main.c -o main.o\n\nall: main\n\nmain: main.o\n        gcc main.o -o main\n\nclean:\n        rm main.o main\n```\n\n如何使用这个makefile：\n\n```bash\n# 编译（把all换成main效果一致）\n# 方法1：用-f指定makefile文件\nmake -f makefile all\n# 方法2：不指定makefile文件，默认会在当前文件夹寻找\n# 按顺序寻找文件GNUmakefile-->makefile-->Makefile，找不到则报错\nmake all\n\n# 清除编译结果，以下二选一\nmake clean\nmake -f makefile clean\n```\n\nmakefile的基本组成如下（**command必须以一个tab开始**）：\n\n```\n# target表示目标体，它位于冒号之前\n# dependency_files表示依赖的文件或target，它位于冒号之后\n# command表示达成这个目标所需执行命令\ntarget: dependency_files\n        command\n```\n\nmakefile里面也可定义和调用变量：\n\n```\nCC=gcc\nEXE=main\n\nmain.o: main.c\n        $(CC) -c main.c -o main.o\n\nall: $(EXE)\n\n$(EXE): main.o\n        gcc main.o -o $(EXE)\n\nclean:\n        rm main.o $(EXE)\n```\n\n也可在外部调用时传入变量（会将makefile中已存在的变量覆盖掉），命令如下：\n\n```bash\nmake EXE=mm all\nmake EXE=mm clean\n```\n\n### 使用GDB调试程序简介\n\n使用`gdb 程序名（相对或绝对路径）`进入gdb：\n2. 输入`break main`为main函数设置断点，输入`break main.c:5`为`main.c`的第5行设置断点；\n3. 输入`i b`查看当前断点；\n4. 输入`delete 1`删除第一个断点；\n5. 输入`disable 1`停用第一个断点；\n6. 输入`list main.c:5`可在gdb显示代码；\n6. 输入`r`或`run`运行，这时用户将无法再输入命令，直到运行到断点时，gdb将交回命令行控制权，这时输入`n`或`next`表示运行到下一行，`s`或`step`表示进入当前行调用的函数，输入`return`返回到上一层函数；\n7. gdb交回命令行控制权时，输入`print 参数名`可查看当前作用域内的具体参数值；\n8. 假如程序意外退出，这时输入`where`、`bt`或`backtrace`可以查看错误堆栈；\n\n### 如何查看帮助手册\n\n终端下输入`man 命令名称`（如`man printf`）将看到如下提示：\n\n```\nMan: 寻找所有匹配的手册页 (set MAN_POSIXLY_CORRECT to avoid this)\n * printf (1)\n   printf (3)\n   printf (1p)\n   printf (3p)\nMan: 您需要什么手册页？\nMan: \n```\n\n1. 数字1表示这是一个用户命令（user commands，如**echo**）；\n2. 数字2表示这是一个系统调用（system calls，如**fork**）；\n3. 数字3表示这是一个标准库（stand library，如**printf**）；\n4. 带p后缀的为POSIX标准，释义：POSIX标准定义了操作系统应该为应用程序提供的接口标准，一个POSIX兼容的操作系统编写的程序，应该可以在任何其它的POSIX操作系统（即使是来自另一个厂商）上编译执行；\n\n## 编程实践\n\n### 环境交互\n\n1. 临时文件（用于暂时存放数据），使用下述命令查看具体用途\n    - `man mkstemp`\n    - `man tmpfile`\n1. 环境变量（设置运行环境）\n    - shell下`echo $USER`或`printenv USER`打印环境变量`USER`；\n    - shell下`export USER=jayzee`设置环境变量`USER`为`jayzee`；\n    - shell下`env`查询当前用户所有环境变量；\n    - Linux下调用一个C/C++程序时，该程序继承其调用者的所有环境变量，标准库`stdlib.h`的`getenv`、`setenv`和`unsetenv`用于获取、操纵环境变量；\n1. shell下调用程序结束后，使用`echo $?`获取程序退出代码（0表示正常）；\n1. IO（输入输出流）\n    - 程序中，宏`stdin`表示输入流，对应int值0；宏`stdout`表示标准输出流，对应int值1；宏`stderr`表示错误输出流，对应int值2；\n    - `stdin`只能是buffered的，但其buffered size可以修改；\n    - `stderr`只能是unbuffered，一有错误立即输出；\n    - 当程序直接在shell调用并且直接输出到控制台时，`stdout`是line-buffered的，否则是buffered的，但其buffered size可以修改，`man setvbuf`查看标准库如何设置输入输出流；\n    - 程序写文件也是默认buffered，写完后应使用`fflush(your_file)`立即清空buffer写入到文件；\n    - shell命令`your_program > output_file.txt 2>&1`表示将`your_program`的标准输出写入到文件`output_file.txt`（`>`执行覆盖写，`>>`执行追加写），并且将错误输出流重定向到标准输出流，Linux规定文件名必须在流重定向之前；\n    - shell命令`program 2>&1 | filter`表示将标准输出使用管道过滤，Linux规定重定向必须在过滤器之前；\n1. `man getopt_long`查看`getopt.h`库如何处理程序参数（类似于`ls -l`的`-l`）；\n\n### 好的编程习惯\n\n使用断言assert：\n\n- 所有需确认值为true或非0的需使用`assert(condition)`；\n- 编译时指定`-DNDEBUG`可移除所有assert语句，所以**千万不要把程序的重要逻辑放在assert语句中**；\n\n处理系统调用失败：\n\n- 系统调用如`fork`失败时会返回非零值，这时宏`errno`会被设置，下次系统调用失败时又会覆盖这个宏的值；\n- `man strerror`查看如何使用`string.h`的`strerror`的具体字符串释义，细节如下：\n\n```\nEINTR : blocking function interrupt, like sleep, read, select\nEPERM : Permission denied\nEROFS : PATH is on a read-only file system\nENAMETOOLONG : PATH is too long\nENOENT : PATH does not exit\nENOTDIR : A component of PATH is not a directory\nEACCES : A component of PATH is not accessible\nEFAULT : PATH contains an invalid memory address.  This is probably a bug\nENOMEM : Ran out of kernel memory\n```\n\n申请内存与释放内存：\n\n- 申请内存与释放内存的语句必须成对，即有申请内存则相应的要有释放内存；\n\n### 链接程序（库：快速开发，软件复用）\n\n以下文字部分引用自[C++静态库与动态库 - 吴秦 - 博客园](http://www.cnblogs.com/skynet/p/3372855.html)，向该作者致敬。\n\n下文用到的main.c文件：\n\n```bash\n/** main.c **/\nint add(int x, int y) {\n    return x + y;\n}\n```\n\n#### 静态链接\n\n静态库的特点：\n\n- 静态库对函数库的链接是放在编译时期完成的；\n- 程序在运行时与函数库再无瓜葛，移植方便；\n- 浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件；\n\n静态库的创建：\n\n- 静态库的命名规范为lib[your_library_name].a：lib为前缀，中间是静态库名，扩展名为.a；\n- 首先将代码文件编译成目标文件.o，再通过ar工具将目标文件打包.a静态库文件；\n\n```bash\n# 假定有一个math.c文件，提供加法函数int add(int x, int y)，我们现在将其打包成静态库\ngcc -c math.c -o math.o\nar -crv libmath.a math.o\n```\n\n使用静态库：\n\n- 在编译时指定静态库搜索路径（-L选项）、指定静态库名称（不需要lib前缀和.a后缀，-l选项）；\n\n```bash\n# -l为什么一定要放在末尾？它会去查找库的所有被引用的函数或宏等并插入到最终的可执行程序，放在末尾是为了这种依赖搜索在最后执行\ngcc main.c -o main -Lfilepath_of_your_static_library -lmath\n```\n\n静态库优缺点：\n\n- 优点：编译成可执行文件后与其编译时引用的静态库再无任何瓜葛；\n- 缺点：导致可执行程序体量庞大，同一个操作系统上运行的多个程序引用同一个静态库会导致内存浪费（相同的代码），导致客户的全量更新；\n\n#### 动态链接\n\n动态库的特点：\n\n- 动态库把对一些库函数的链接载入推迟到程序运行的时期；\n- 可以实现进程之间的资源共享（因此动态库也称为共享库）；\n- 将一些程序升级变得简单；\n- 甚至可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）；\n\n动态库的创建：\n\n- 动态库的命名规范为lib[your_library_name].so：lib为前缀，中间是动态库名，扩展名为.so；\n- 首先将代码文件编译成目标文件.o，再通过gcc工具将目标文件打包.so动态库文件；\n    - `-fPIC`创建与地址无关的编译程序（pic，position independent code），是为了能够在多个应用程序间共享；\n    - `-shared`指定生成动态链接库；\n\n```bash\n# 假定有一个math.c文件，提供加法函数int add(int x, int y)，我们现在将其打包成动态库\ngcc -fPIC -c math.c -o math.o\ngcc -shared -o libmath.so math.o\n# 上面两条命令等价于\ngcc -fPIC -shared -o libmath.so math.c\n```\n\n使用动态库：\n\n- 在编译时指定动态库搜索路径（-L选项）、指定动态库名称（不需要lib前缀和.so后缀，-l选项）；\n\n```bash\ngcc main.c -o main -Lfilepath_of_your_static_library -lmath\n```\n\n- 注意，运行上述生成的可执行文件时，操作系统会去一些指定路径查找并载入该动态库，如查找不到将抛出找不到动态库的异常信息，这些指定路径是：\n    - 环境变量LD_LIBRARY_PATH，如`LD_LIBRARY_PATH=/usr/local/lib:/opt/lib`；\n    - /etc/ld.so.cache文件列表，需要额外操作如下：\n        + 编辑/etc/ld.so.conf文件，加入库文件所在目录的路径；\n        + 运行ldconfig ，该命令会重建/etc/ld.so.cache文件；\n    - /lib/，/usr/lib目录；\n- `-L`指定的库搜索路径下即有动态库也有静态库，则动态库具有较高优先级被链接；\n\n动态库优缺点：\n\n- 缺点：增量更新必须考虑向后兼容；\n- 优点：增量更新，避免内存浪费（同一个操作系统上运行的多个程序引用同一个动态库只需要一份共享库示例）；\n\n#### 链接检查辅助命令\n\n`nm`命令：打印出库中的涉及到的所有符号。库既可以是静态的也可以是动态的。nm列出的符号有很多，常见的有三种，\n\n- 一种是在库中被调用，但并没有在库中定义(表明需要其他库支持)，用U表示；\n- 一种是库中定义的函数，用T表示，这是最常见的；\n- 一种是所谓的弱态”符号，它们虽然在库中被定义，但是可能被其他库中的同名符号覆盖，用W表示；\n\n`ldd`命令：查看一个可执行程序依赖的共享库。\n\n## 进程\n\n本章节部分内容引用自[Linux下Fork与Exec使用 - hicjiajia - 博客园](http://www.cnblogs.com/hicjiajia/archive/2011/01/20/1940154.html)和[系统调用跟我学(3)](http://www.ibm.com/developerworks/cn/linux/kernel/syscall/part3/index.html)，向作者致敬。\n\n### 进程查看\n\n`pid`指进程id，`ppid`指父进程id。\n\n1. Linux所有**用户进程**呈树状结构，这棵用户进程树的根节点是init进程（内核启动的第一个用户级进程），init进程的`pid`为1，其ppid为0；\n2. shell下运行`ps -e -o pid,ppid,command`可查看所有用户进程的pid、ppid和command；\n3. `unistd.h`提供`getpid()`和`getppid()`获取进程的ID和父ID；\n\n### 进程创建\n\n#### system函数：执行shell命令\n\nsystem函数用于在C/C++语言中执行shell命令，其API如下：\n\n```bash\n#include <stdlib.h>\nint system(const char *command);\n```\n\n其具体实现是：\n\n1. 先执行系统调用`fork()`创建子进程；\n2. 再执行`execl(\"/bin/sh\", \"sh\". \"-c\", command, (char *) 0);`去调用shell执行command；\n\n#### fork函数，exec族函数\n\n##### fork函数：创建子进程，进程分叉\n\nfork函数API如下：\n\n```bash\n#include <unistd.h>\npid_t fork(void);\n```\n\nfork函数的特点：\n\n- fork调用之后，父进程进入`pid>0`的分支，子进程进入`pid==0`的分支；\n- fork创建的子进程是父进程的一个完整拷贝，**当且仅当fork之后的代码即将开始更新内存，真实的拷贝才会发生**（也就是上述例子并没有发生拷贝），为什么这么设计，我们会在下面讲到；\n- fork创建的子进程拥有一个新的进程pid号，子进程的ppid为调用fork函数的进程id；\n\npid_t是一个整型变量。具体示例如下：\n\n```c\n/* zombie.c */\n#include <sys/types.h>\n#include <unistd.h>\nint main() {\n    pid_t pid;\n    pid=fork();\n    if(pid<0) /* 如果出错 */\n        printf(\"error occurred!\\n\");\n    else if(pid==0) /* 如果是子进程 */\n        exit(0);\n    else /* 如果是父进程 */\n        sleep(60); /* 休眠60秒，这段时间里，父进程什么也干不了 */\n    wait(NULL); /* 收集僵尸进程 */\n}\n```\n\n##### exec函数族：对当前进程进行替换\n\nexec并不是一个具体函数，它是以下六个函数：\n\n```c\n#include <unistd.h>\nint execl(const char *path, const char *arg, ...);\nint execlp(const char *file, const char *arg, ...);\nint execle(const char *path, const char *arg, ..., char *const envp[]);\nint execv(const char *path, char *const argv[]);\nint execvp(const char *file, char *const argv[]);\nint execve(const char *path, char *const argv[], char *const envp[]);\n```\n\n其中`execl`是基函数，其他5个是它的变种（区别在于传参形式不同，带v的表示参数以数组传递，带l的表示参数以陈列的方式传递）。\n\nexec函数族特点：\n\n- 只保留当前进程的pid，其他进程相关的数据段全部废弃；对系统而言，还是同一个进程号，但其实已经是另外一个程序了，即调用exec函数族的进程已“死亡”了；\n- 上面说到，fork的数据拷贝只发生在子进程更新内存时，fork调用后立即执行exec函数族使得我们能够产生一个全新的进程（**这意味着当前进程的所有线程、文件描述符等都被释放**），与fork调用进程再无任何瓜葛；\n\n举一个具体例子如下：\n\n```c\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n\nchar command[256];\nvoid main()\n{\n   int rtn; /*子进程的返回数值*/\n   while(1) {\n       /* 从终端读取要执行的命令 */\n       printf( \">\" );\n       fgets( command, 256, stdin );\n       command[strlen(command)-1] = 0;\n       if ( fork() == 0 ) {/* 子进程执行此命令 */\n          execlp( command, NULL );\n          /* 如果exec函数返回，表明没有正常执行命令，打印错误信息*/\n          perror( command );\n          exit( errno );\n       }\n       else {/* 父进程， 等待子进程结束，并打印子进程的返回值 */\n          wait ( &rtn );\n          printf( \" child process return %d\\n\", rtn );\n       }\n   }\n}\n```\n\n### 信号处理\n\n信号是一种异步的进程通信机制，是软件层面的中断，进程接收到线程必须进行处理，有以下三种处理方式：\n\n- 使用进程对信号的静默处理；\n- 忽略该信号；\n- 使用特定的信号处理函数进行处理；\n\n上述的后两种方式需要使用`signal()`函数进行处理，举例如下：\n\n```c\n// 忽略SIGPIPE信号\nsignal ( SIGPIPE, SIG_IGN );\n// 使用PrepareExit处理SIGINT信号\nsignal ( SIGINT, (__sighandler_t ) PrepareExit );\n```\n\nLinux的信号如下：\n\n```\n信号值 默认处理动作 发出信号的原因\nSIGHUP 1 A 终端挂起或者控制进程终止\nSIGINT 2 A 键盘中断（如break键被按下）\nSIGQUIT 3 C 键盘的退出键被按下\nSIGILL 4 C 非法指令\nSIGABRT 6 C 由abort(3)发出的退出指令\nSIGFPE 8 C 浮点异常\nSIGKILL 9 AEF Kill信号\nSIGSEGV 11 C 无效的内存引用\nSIGPIPE 13 A 管道破裂: 写一个没有读端口的管道\nSIGALRM 14 A 由alarm(2)发出的信号\nSIGTERM 15 A 终止信号\nSIGUSR1 30,10,16 A 用户自定义信号1\nSIGUSR2 31,12,17 A 用户自定义信号2\nSIGCHLD 20,17,18 B 子进程结束信号\nSIGCONT 19,18,25 进程继续（曾被停止的进程）\nSIGSTOP 17,19,23 DEF 终止进程\nSIGTSTP 18,20,24 D 控制终端（tty）上按下停止键\nSIGTTIN 21,21,26 D 后台进程企图从控制终端读\nSIGTTOU 22,22,27 D 后台进程企图从控制终端写\n\n处理动作一项中的字母含义如下：\nA 缺省的动作是终止进程\nB 缺省的动作是忽略此信号，将该信号丢弃，不做处理\nC 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序\nD 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用）\nE 信号不能被捕获\nF 信号不能被忽略\n```\n\n**注意**：\n信号处理函数可被新产生的信号所中断，所以信号处理函数应该做尽可能少的工作；\n\n\n### 进程终止\n\n#### 信号终止\n\n1. `SIGINT`：CRTL+C产生；\n2. `SIGTERM`：shell下`kill pid`产生；\n3. `abort()`：发送一个`SIGABRT`信号给自己；\n4. `SIGKILL`：强制退出信号，shell下`kill -9 pid`产生；\n\n当进程终止时，shell调用`echo $?`可取得该进程的exit code，\n\n- 如果该进程由信号终止，exit code为128加上信号值；\n- 调用`exit(int exit_code)`函数退出，exit_code的范围需在0到128之间；\n\n如何给进程发送指定信号，\n\n- 在shell下使用`kill -s SIGNAL_NAME pid`，可以给进程pid发送SIGNAL_NAME信号；\n- 程序使用`kill(pid, SIGNAL_NAME)`函数；\n\n#### wait\n\nUnix的进程终止时，一些资源（如进程pid、进程exit code、收到的信号、占用CPU时间等）并不会被立即释放（堆栈等内存立即释放），死亡进程的父进程必须调用`wait`函数对进程进行“收尸”，即释放进程的pid和exit code等资源。\n\n`wait`函数的API定义如下：\n\n```c\npid_t wait(int *status);\n```\n\n一些说明：\n\n- `wait`函数是阻塞式的，在子进程未结束时将阻塞；\n- 如果`pid_t`为-1，表明`wait`调用失败，这是因为调用进程没有子进程导致；否则，表明收集子进程“死亡”信息成功，`pid_t`的值为“死亡”进程pid；\n- `status`是一个指针，如果这个指针为空，表明我们不关心进程的“死亡”信息细节，只是发起了回收这个动作；否则，status将包含进程“死亡”的一些信息；\n- 调用`WIFEXITED(status)`，若返回值回0表明进程异常退出（如信号导致退出），这时调用`WTERMSIG(status)`将得到使进程死亡的信号int值；否则表示程序正常退出，这时候调用`WEXITSTATUS(status)`可获取“死亡”进程的exit code（如“死亡”进程调用`exit(7)`退出，则`WEXITSTATUS(status)`的结果为7）；\n\n```c\n/* wait2.c */\n#include <sys/types.h>\n#include <sys/wait.h>\n#include <unistd.h>\n#include <stdio.h>\n#include <stdlib.h>\n\nmain()\n{\n    int status;\n    pid_t pc,pr;\n    pc=fork();\n    if(pc<0)     /* 如果出错 */\n        printf(\"error ocurred!\\n\");\n    else if(pc==0){ /* 子进程 */\n        printf(\"This is child process with pid of %d.\\n\",getpid());\n        exit(3);    /* 子进程返回3 */\n    }\n    else{       /* 父进程 */\n        pr=wait(&status);\n        if(WIFEXITED(status)){  /* 如果WIFEXITED返回非零值 */\n            printf(\"the child process %d exit normally.\\n\",pr);\n            printf(\"the return code is %d.\\n\",WEXITSTATUS(status));\n        }else           /* 如果WIFEXITED返回零，这时pr存储死亡进程pid */\n            printf(\"the child process %d exit abnormally with signal number %d.\\n\",pr,WTERMSIG(status));\n    }\n}\n```\n\n#### 僵尸进程\n\n如果子进程死亡，父进程却没有调用`wait`对其进行“收尸”，子进程就会变成一个僵尸进程，\n\n```\n$ ps -ax\n  PID TTY      STAT   TIME COMMAND\n 1177 pts/0    S      0:00 -bash\n 1577 pts/0    S      0:00 ./zombie\n 1578 pts/0    Z      0:00 [zombie <defunct>]\n 1579 pts/0    R      0:00 ps -ax\n```\n\n若STAT为Z则表明则是一个僵尸进程，关于僵尸进程，\n\n- 在父进程退出时，init进程会自动对其下的所有僵尸子进程进行清理；\n- 子进程意外死亡时，父进程会受到一个SIGCHLD信号，父进程可以注册这个信号的处理函数进行“收尸”；\n- `wait3`和`wait4`函数为异步的，可以周期调用这两个函数执行回收；\n\n## 线程\n\n### 线程创建\n\n**线程创建**：`int pthread_create(pthread_t *thread, const pthread_attr_t *attr,\nvoid *(*start_routine) (void *), void *arg);`\n\n- `pthread_create`的返回值为0表示创建线程成功；\n- `thread`是指向`pthread_t`的指针；\n- `pthread_attr_t`在下一个例子介绍；\n- `start_routine`是一个无形参且无返回值的函数指针；\n- `arg`是上面提到的函数指针所接收的参数；\n\n**线程回收**：`int pthread_join(pthread_t thread, void **retval);`\n\n- `retval`实际上是一个指向整型指针的指针，它存放的是线程调用`exit`或`pthread_exit`的退出值；\n- `When a joinable thread terminates, its memory resources (thread descriptor and stack) are not deallocated until another thread performs pthread_join on it. Therefore, pthread_join must be called  once  for each joinable thread created to avoid memory leaks.`\n- 这是一个阻塞式的方法，当监控到有线程结束时才返回；\n\n**线程退出**：`void pthread_exit(void *retval);`\n\n- `retval`实际是一个整型指针，在退出时标识线程的退出值；\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\nint code = 11;\n\nvoid hello(void *args) {\n    char *str = (char *) args;\n    sleep(5);\n    printf(\"Hello, %s!\\n\", str);\n    pthread_exit(&code);\n}\n\nint main() {\n    pthread_t thread;\n    int status = pthread_create(&thread, NULL, (void *)hello, (void *) \"Jayzee\");\n    printf(\"thread create status : %d\\n\", status);\n    int *exit_code = 0;\n    status = pthread_join(thread, (void *) &exit_code);\n    printf(\"thread join status : %d\\n\", status);\n    printf(\"thread exit code : %d\\n\", *exit_code);\n    return 0;\n}\n```\n\n------\n\n下面的例子在`pthread_create`时用到了`pthread_attr_t`，必须经历下面四个过程\n\n1. 先实例化`pthread_attr_t`；\n2. 再设置`pthread_attr_t`；\n3. 在线程创建时使用该`pthread_attr_t`；\n4. 线程创建完后销毁`pthread_attr_t`；\n\n注意：\n\n1. 创建线程时设置其为detach态，意味着我们不关心它的返回值，只是进行线程相关资源回收；\n2. 也可创建线程时不指定detach态，在线程创建后可使用`int pthread_detach(pthread_t thread);`设置其为detach态；\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\nint code = 11;\n\nvoid hello(void *args) {\n    char *str = (char *) args;\n    sleep(5);\n    printf(\"Hello, %s!\\n\", str);\n    pthread_exit(&code);\n}\n\nint main() {\n    pthread_t thread;\n    pthread_attr_t attr;\n    pthread_attr_init (&attr);\n    pthread_attr_setdetachstate (&attr, PTHREAD_CREATE_DETACHED);\n    int status = pthread_create (&thread, &attr, (void *)hello, (void *) \"Jayzee\");\n    pthread_attr_destroy (&attr);\n    printf(\"thread create status : %d\\n\", status);\n    return 0;\n}\n```\n\n### 线程取消\n\n```\nint pthread_setcancelstate(int state, int *oldstate);\nint pthread_setcanceltype(int type, int *oldtype);\nint pthread_cancel(pthread_t thread);\n```\n\n- `pthread_setcancelstate`在运行时设置线程的状态`state`，并取得其之前的状态`oldstate`；\n- `pthread_setcanceltype`在运行时设置线程的类型`type`，并取得其之前的类型`oldtype`；\n- `pthread_cancel`用于取消线程的执行；\n\n\n注意，\n\n1. type：`PTHREAD_CANCEL_DEFERRED`或`PTHREAD_CANCEL_ASYNCHRONOUS`\n2. state：`PTHREAD_CANCEL_ENABLE`或`PTHREAD_CANCEL_DISABLE`\n3. type和state作用于`pthread_cancel`：\n    - 当state为`PTHREAD_CANCEL_DISABLE`时，设置的type和调用`pthread_cancel`不会对线程造成任何影响；\n    - 否则，当设置的type为`PTHREAD_CANCEL_DEFERRED`时，为非阻塞取消（等待达到取消的条件，如释放锁）；当设置的type为`PTHREAD_CANCEL_ASYNCHRONOUS`时为异步取消（即线程立即被取消，但不同操作系统有可能实现不同，理应处理释放锁）；\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\nint code = 11;\n\nvoid hello(void *args) {\n    pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, &last_state); \n    pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, &last_type);\n    char *str = (char *) args;\n    sleep(5);\n    printf(\"Hello, %s!\\n\", str);\n    pthread_exit(&code);\n}\n\nint main() {\n    pthread_t thread;\n    int status = pthread_create(&thread, NULL, (void *)hello, (void *) \"Jayzee\");\n    printf(\"thread create status : %d\\n\", status);\n    int *exit_code = 0;\n    status = pthread_join(thread, (void *) &exit_code);\n    printf(\"thread join status : %d\\n\", status);\n    printf(\"thread exit code : %d\\n\", *exit_code);\n    pthread_cancel(thread);\n    return 0;\n}\n```\n\n### 线程特定数据\n\n```\nint pthread_key_create(pthread_key_t *key, void (*destructor)(void*));\nint pthread_setspecific(pthread_key_t key, const void *value);\nvoid *pthread_getspecific(pthread_key_t key);\n```\n\n1. 使用`pthread_key_create`创建`key`，`destructor`为线程结束时用于析构的函数指针，一个进程内的多个线程可以共用一个`key`；\n2. `pthread_setspecific`为线程设定key-value，`pthread_getspecific`根据key获得value；\n3. 当线程结束时，若`pthread_getspecific`的内容不为空，且`destructor`不为空，则`pthread_getspecific`的内容将作为`destructor`的参数来执行析构函数；\n\n```c\n#include <malloc.h>\n#include <pthread.h>\n#include <stdio.h>\n\n/* The key used to associate a log file pointer with each thread. */\nstatic pthread_key_t thread_log_key;\n\n/* Write MESSAGE to the log file for the current thread. */\nvoid write_to_thread_log (const char* message) {\n    FILE* thread_log = (FILE*) pthread_getspecific (thread_log_key);\n    fprintf (thread_log, \"%s\\n\", message);\n}\n\n/* Close the log file pointer THREAD_LOG. */\nvoid close_thread_log (void* thread_log) {\n    fclose ((FILE*) thread_log);    \n}\n\nvoid* thread_function (void* args) {\n    char thread_log_filename[20];\n    FILE* thread_log;\n    /* Generate the filename for this thread’s log file. */\n    sprintf (thread_log_filename, \"thread%d.log\", (int) pthread_self ());\n    /* Open the log file. */\n    thread_log = fopen (thread_log_filename, \"w\");\n    /* Store the file pointer in thread-specific data under thread_log_key. */\n    pthread_setspecific (thread_log_key, thread_log);\n    write_to_thread_log (\"Thread starting.\");\n    /* Do work here... */\n    return NULL;\n}\n\nint main () {\n    int i;\n    pthread_t threads[5];\n    /* Create a key to associate thread log file pointers in\n    thread-specific data. Use close_thread_log to clean up the file\n    pointers. */\n    pthread_key_create (&thread_log_key, close_thread_log);\n    /* Create threads to do the work. */\n    for (i = 0; i < 5; ++i)\n        pthread_create (&(threads[i]), NULL, thread_function, NULL);\n    /* Wait for all threads to finish. */\n    for (i = 0; i < 5; ++i)\n        pthread_join (threads[i], NULL);\n    return 0;\n}  \n```\n\n```\nvoid pthread_cleanup_push(void (*routine)(void *), void *arg);\nvoid pthread_cleanup_pop(int execute);\n```\n\n1. `pthread_cleanup_push`在线程运行时为线程压栈清理函数；\n2. `pthread_cleanup_pop`从栈弹出一个清理函数，如果`execute`不为0则执行这个清理函数；\n3. 线程结束时，所有压栈的清理函数会自动被弹出栈进行执行；\n4. 当在线程内使用longjump前，应手动调用`pthread_cleanup_pop`执行清理；\n\n### 线程同步\n\n#### 互斥锁\n\n```\nint pthread_mutex_destroy(pthread_mutex_t *mutex);\nint pthread_mutex_init(pthread_mutex_t *restrict mutex,\n    const pthread_mutexattr_t *restrict attr);\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\n```\n\n1. `pthread_mutex_destroy`销毁互斥锁，`pthread_mutex_init`创建互斥锁；\n2. `pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;`表示定义并默认实例化一个互斥锁；\n\n```\nint pthread_mutex_lock(pthread_mutex_t *mutex);\nint pthread_mutex_trylock(pthread_mutex_t *mutex);\nint pthread_mutex_unlock(pthread_mutex_t *mutex);\n```\n\n1. `pthread_mutex_lock`为阻塞锁，`pthread_mutex_trylock`为非阻塞锁（获取不到锁）则立即返回，`pthread_mutex_unlock`为释放锁；\n\n```c\n#include <pthread.h>\n\nint main() {\n    pthread_mutexattr_t attr;\n    pthread_mutex_t mutex;\n    pthread_mutexattr_init (&attr);\n    // 带错误检查的互斥锁\n    pthread_mutexattr_setkind_np (&attr, PTHREAD_MUTEX_ERRORCHECK_NP);\n    pthread_mutex_init (&mutex, &attr);\n    pthread_mutex_lock(&mutex);\n    /** do some work **/\n    pthread_mutex_unlock(&mutex);\n    pthread_mutexattr_destroy (&attr);\n}\n```\n\n#### 信号量\n\n```\nint sem_init(sem_t *sem, int pshared, unsigned int value);\nint sem_post(sem_t *sem);\nint sem_wait(sem_t *sem);\n```\n\n1. `sem_init`实例化信号量`sem`，`pshared`为0表示进程内共享（非0为进程间共享），`value`为初始容量值（默认容量值为0）；\n2. `sem_wait`将容量值减一，`sem_wait`之后若容量值小于0则线程阻塞；`sem_post`将容量值加一；\n3. 假设容量值为负，一次`sem_post`只能唤醒一个线程；\n4. `sem_wait`和`sem_post`是线程安全的；\n\n```c\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h>\n#include <semaphore.h>\n\nsem_t semaphore;\n\nvoid threadfunc() {\n    int i = 0;\n    for (; i<10; i++) {\n        // 实际上不会这么使用，这里仅是展示\n        sem_wait(&semaphore);\n        printf(\"Hello from da thread!\\n\");\n        sem_post(&semaphore);\n        sleep(1);\n    }\n}\n\nint main(void) {\n    // 实例化\n    sem_init(&semaphore, 0, 1);\n    \n    pthread_t *mythread;    \n    mythread = (pthread_t *)malloc(sizeof(*mythread));\n    \n    // 启动线程\n    printf(\"Starting thread, semaphore is unlocked.\\n\");\n    pthread_create(mythread, NULL, (void*)threadfunc, NULL);\n    pthread_join(mythread, NULL);\n    \n    return 0;\n}\n```\n\n#### 条件值\n\n```\nint pthread_cond_init(pthread_cond_t *restrict cond,\n    const pthread_condattr_t *restrict attr);\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\nint pthread_cond_signal(pthread_cond_t *cond);\nint pthread_cond_wait(pthread_cond_t *restrict cond,\n   pthread_mutex_t *restrict mutex);\n```\n\n1. `pthread_cond_t cond = PTHREAD_COND_INITIALIZER;`等价于`pthread_cond_init(&pthread_cond_t, NULL);`\n2. 当调用`pthread_cond_signal`或`pthread_cond_wait`时，必须获得锁；\n3. 调用`pthread_cond_wait`时，自动释放锁，直到被`pthread_cond_signal`唤醒时，才重新自动获得锁；\n4. `pthread_cond_timedwait`可批量唤醒等待的线程；\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\nint condition = 0;\nint count = 0;\n\nint consume( void )\n{\n    while( 1 )\n    {\n        pthread_mutex_lock( &mutex );\n        while( condition == 0 )\n            pthread_cond_wait( &cond, &mutex );\n        printf( \"Consumed %d\\n\", count );\n        condition = 0;\n        pthread_cond_signal( &cond );        \n        pthread_mutex_unlock( &mutex );\n    }\n\n    return( 0 );\n}\n\nvoid* produce( void * arg )\n{\n    while( 1 )\n    {\n        pthread_mutex_lock( &mutex );\n        while( condition == 1 )\n            pthread_cond_wait( &cond, &mutex );\n        printf( \"Produced %d\\n\", count++ );\n        condition = 1;\n        pthread_cond_signal( &cond );        \n        pthread_mutex_unlock( &mutex );\n    }\n    return( 0 );\n}\n\nint main( void )\n{\n    pthread_create( NULL, NULL, &produce, NULL );\n    return consume();\n}\n```\n\n### 线程实现\n\nLinux的线程实现是系统调用`clone()`，它创建一个与父进程共用资源的子进程。\n\n## 进程间通信\n\n### 共享内存\n\n```\n#include <sys/ipc.h>\n#include <sys/shm.h>\nint shmget(key_t key, size_t size, int shmflg);\nvoid *shmat(int shmid, const void *shmaddr, int shmflg);\nint shmdt(const void *shmaddr);\nint shmctl(int shmid, int cmd, struct shmid_ds *buf);\n```\n\n1. `shmget`申请共享内存；\n2. `shmat`取得已申请的共享内存，共享内存使用者计数器加1；\n3. `shmdt`断开已申请的共享内存，共享内存使用者计数器减1，如果计时器减到0，这块共享内存会被系统标注并删除；\n4. `shmctl`对共享内存的标识信息进行设置；\n\n### 进程信号量\n\n```\n#include <sys/types.h>\n#include <sys/ipc.h>\n#include <sys/sem.h>\nint semget(key_t key, int nsems, int semflg);\nint semctl(int semid, int semnum, int cmd, ...);\nint semop(int semid, struct sembuf *sops, size_t nsops);\n```\n\n1. `semget`用于申请信号量；\n2. `semctl`用于释放或实例化信号量；\n3. `semop`用于执行wait或post；\n\n### 映射到内存\n\n```\n#include <sys/mman.h>\nvoid *mmap(void *addr, size_t length, int prot, int flags,\n    int fd, off_t offset);\n```\n\n`mmap`是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。\n\n### 管道\n\n```\n#include <unistd.h>\nint pipe(int pipefd[2]);\n```\n\n`pipe`的一端写，由内核缓存，直到另一端将其读出。\n\n### Socket\n\n```\n#include <sys/types.h>\n#include <sys/socket.h>\nint socket(int domain, int type, int protocol);\nint close(int fd);\nint connect(int sockfd, const struct sockaddr *addr,\n    socklen_t addrlen);\nint bind(int sockfd, const struct sockaddr *addr,\n    socklen_t addrlen);\nint listen(int sockfd, int backlog);\nint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);\n```\n\n1. `socket`创建一个socket；\n2. `close`关闭一个socket；\n3. `connect`建立两个socket的连接；\n4. `bind`将socket绑定到地址和端口；\n5. `listen`配置socket接受连接的条件；\n6. `accept`接收一个socket连接并为其创建一个socket；\n\n## 设备\n\n### 操作\n\n```\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\nint mknod(const char *pathname, mode_t mode, dev_t dev);\n```\n\n`mknod`用于创建一个设备。\n\n```\n#include <sys/ioctl.h>\nint ioctl(int d, unsigned long request, ...);\n```\n\n`ioctl`用于控制设备，常用于驱动编程。\n\n### 特殊设备\n\n`/dev/null`是一个内容为空的设备，将IO流定向到`/dev/null`意味着丢弃其内容；\n\n`/dev/zero`是一个无限长的文件；\n\n`/dev/random`可用于产生随机数；\n\n`/dev/tty*`是串行终端设备，如串口；\n\n`pty`是伪终端，接受键盘的输入并显示到运行它的终端界面；\n\n`pty`的实现涉及到两个概念：\n\n- `ptmx`：被连接的master主机；\n- `pts`：发起向master主机连接的slave主机`pts`，我们常用的SSH登录就意外着在master主机建立一个`pts`进程；\n\n## 常用/proc简介\n\n`/proc/cpuinfo`查看cpu信息；\n\n`/proc/meminfo`查看内存信息；\n\n`/proc/self`查看自身信息；\n\n`/proc/pid_number`查看pid为pid_number的进程信息；\n\n`/proc/loadavg`查看负载信息；\n\n`/proc/uptime`查看启动时间；\n\n`/proc/interrupts`查看中断情况；\n\n## 常用系统调用\n\n`strace`查看系统调用情况；\n\n`access`检测是否具备读写权限；\n`fcntl`操纵文件描述符；\n\n`fsync`和`fdatasync`将缓冲区的文件改动同步到实际文件；\n\n`getrlimit`取得系统的资源限定情况；\n\n`getrusage`取得系统资源使用情况；\n\n`gettimeofday`取得系统时间；\n\n`mlock`锁住一块内存；\n\n`mprotect`保护一块内存；\n\n## 用户与用户组\n\n### 用户与用户组ID\n\n每个用户名对应到一个用户ID，每个用户ID可从属于多个用户组ID。Shell下输入`id`得到如下输出：\n\n```\n# uid为0表示root用户\nuid=0(root) gid=0(root) groups=0(root),1001(nagcmd)\n```\n\n### 文件与用户（组）的关系\n\n`ls -l APL.txt`后得到如下输出：\n\n```\n-rw-r--r-- 1 Jayzee None   1237 五月 18 12:19 APL.txt\n```\n\n`-rw-r--r--`解释：\n\n- 第一个字符`-`表示这是一个文件，`d`表示这是一个文件夹；\n- 2至4字符`rw-`表示拥有者`Jayzee`的权限，顺序为：读（r）、写（w）、执行（x），可读写但不可执行；\n- 5至7字符`r--`表示所属组`None`的权限；\n- 8至10字符`r--`表示组外其他用户的权限；\n\n`man chmod`查看如何更改文件的权限；\n`man chown`查看如何更改文件的拥有者和所属组；\n\n**特殊**\n\n```\ndrwxrwxrwt   1 root root 26416 5月  18 21:53 tmp\n```\n\n只适用于文件夹：当文件夹的所属组或组外的执行（x）被设置为（t）时，表示当且仅当你是该文件夹内文件的创建者，才可以删除该文件；（正常情况下如果该文件夹内文件的权限是对于组或组外可读写，不需要是文件的创建者也可删除的），这里的`t`称为sticky bits。\n\n### 真实的用户ID和有效的用户ID\n\n定义`euid`为有效用户id（effective），`uid`为真实用户id（real）；\n\n`man 2 getuid`查看如何使用C函数获取uid；\n`man 2 geteuid`查看如何使用C函数获取euid；\n\n为什么要引入euid？\n\n1. 当用户发出对文件的操作时，Linux Kernel根据用户的euid检查用户是否具备权限；\n2. euid可被修改，uid不可被修改；\n3. euid被修改代表着用户的切换，uid不被修改表示最初登入系统的uid不变；\n\n用户登录系统时用户id发生什么变化？\n\n1. Linux的登录进程检查登入者输入的账号密码是否正确；\n2. 若正确，使用`exec`为其创建一个User Shell（pts）；\n3. Linux的登录进程设置这个User Shell的euid和uid为同一个值，即该用户的uid（只有euid为0的User Shell可设置euid和uid）；\n\n设置说明：\n\n1. 当我们设置`euid = uid`时，表示返回到最初登录用户的Shell；\n2. 当我们设置`uid = euid`时，表示Linux的登录进程将euid与uid同步，该登录用户与Linux的登录进程（root）再无联系；\n\n`su`命令的原理：\n\n1. `/bin/su`的拥有者为root，其执行项不是（x）而是（s），当文件拥有者的执行项不是（x）而是（s）时，此文件可被执行，且执行文件时调用`geteuid`函数返回的是该可执行文件拥有者的uid而不是调用者的euid；\n2. Linux利用此技术实现普通用户到root用户时，uid不变，而euid变为0；\n3. 当调用`su`时，调用者原User Shell阻塞，Kernel创建一个新User Shell给调用者使用；\n\n注：组ID也分真实和有效，与用户ID类同，故不展开叙述；\n","slug":"advanced-linux-programing","published":1,"updated":"2022-08-09T15:02:00.595Z","photos":[],"link":"","_id":"cl6mbc123000aigu8cxeefykl","content":"<p>《Advanced Linux Programing》读书笔记。</p>\n<a id=\"more\"></a>\n<h2 id=\"一些介绍\"><a href=\"#一些介绍\" class=\"headerlink\" title=\"一些介绍\"></a>一些介绍</h2><p>Linux Kernel</p>\n<ul>\n<li>硬件交互；</li>\n<li>内存管理；</li>\n<li>文件管理；</li>\n<li>多进程管理；</li>\n<li>共享库载入；</li>\n</ul>\n<p>GNU Project</p>\n<ul>\n<li>编辑器；</li>\n<li>编译器；</li>\n<li>Shell（/bin/bash，Bourne-Again SHell）；</li>\n</ul>\n<p>注意：</p>\n<ol>\n<li>Linux Kernel加GNU Project，构成了现在主流的Linux操作系统，所以应该称之为GNU/Linux；</li>\n<li>Linux操作系统只是UNIX的一种系统实现，其他类UNIX操作系统有FreeBSD、Solaris等；</li>\n</ol>\n<h2 id=\"Hello-World（快速了解）\"><a href=\"#Hello-World（快速了解）\" class=\"headerlink\" title=\"Hello, World（快速了解）\"></a>Hello, World（快速了解）</h2><h3 id=\"从文本到可执行程序\"><a href=\"#从文本到可执行程序\" class=\"headerlink\" title=\"从文本到可执行程序\"></a>从文本到可执行程序</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/** main.c **/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">sayHello</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, World\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    sayHello();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Shell下运行<code>gcc -o main main.c</code>即可得到可执行文件<code>main</code>，执行<code>./main</code>即可在控制台上看到<code>Hello, World</code>的输出。那么，它的原理是什么？从<code>main.c</code>到<code>main</code>，经历了以下步骤：</p>\n<ul>\n<li>main.c –&gt; main.i –&gt; main.s –&gt; main.o –&gt; main</li>\n<li>程序文本 + <strong>预处理器(cpp)</strong> –&gt; 被修改的源程序文本 + <strong>编译器(ccl)</strong> –&gt; 汇编文本 + <strong>汇编器(as)</strong> –&gt; 可重定向目标文件（二进制） + printf.o + <strong>链接器(ld)</strong> –&gt; main（可执行程序）</li>\n</ul>\n<p>对应到Shell下，经历了以下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -E main.c -o main.i</span><br><span class=\"line\">gcc -S main.i -o main.s --&gt; main.s</span><br><span class=\"line\">gcc -c main.s -o main.o --&gt; main.o</span><br><span class=\"line\">gcc main.o -o main --&gt; main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 上面4句等价于下面一句，gcc自动进行预处理、编译、汇编和链接</span></span><br><span class=\"line\">gcc main.c -o main</span><br></pre></td></tr></table></figure>\n<p><code>-E</code>进行预处理，将头文件插入C文件同时执行宏替换；<code>-S</code>用于生成汇编绘本；<code>-c</code>命令用于汇编；<code>-o</code>命令用于指定输出文件名称。</p>\n<h3 id=\"编写可用g-编译的c程序\"><a href=\"#编写可用g-编译的c程序\" class=\"headerlink\" title=\"编写可用g++编译的c程序\"></a>编写可用g++编译的c程序</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/** main.c **/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> __cplusplus</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"string\">\"C\"</span> &#123;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">sayHello</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> __cplusplus</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">sayHello</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, World\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    sayHello();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"其他常用gcc命令\"><a href=\"#其他常用gcc命令\" class=\"headerlink\" title=\"其他常用gcc命令\"></a>其他常用gcc命令</h3><ul>\n<li><code>-I</code>指定存放头文件的路径（相对或绝对路径）；</li>\n<li><code>-D</code>定义一个宏；</li>\n<li><code>-O</code>指定优化级别；</li>\n<li><code>-l</code>指定要链接的库；</li>\n<li><code>-L</code>指定搜索动态链接库的路径；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 生成可执行文件main</span></span><br><span class=\"line\"><span class=\"comment\"># 从绝对路径/root/搜索头文件</span></span><br><span class=\"line\"><span class=\"comment\"># 定义宏DEBUG</span></span><br><span class=\"line\"><span class=\"comment\"># 定义优化级别为2（0&lt;1&lt;2&lt;3，0表示不优化）</span></span><br><span class=\"line\"><span class=\"comment\"># 链接数学库m</span></span><br><span class=\"line\"><span class=\"comment\"># 在/usr/local/lib下查找数学库m的动态链接库</span></span><br><span class=\"line\">gcc main.c -o main -I /root/ -D DEBUG=2 -O2 -lm -L/usr/<span class=\"built_in\">local</span>/lib</span><br></pre></td></tr></table></figure>\n<h3 id=\"如何节省编译的工作\"><a href=\"#如何节省编译的工作\" class=\"headerlink\" title=\"如何节省编译的工作\"></a>如何节省编译的工作</h3><ol>\n<li>写MakeFile；</li>\n<li>使用autoconf、automake和libtool；</li>\n</ol>\n<p>简单的makefile举例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main.o: main.c</span><br><span class=\"line\">        gcc -c main.c -o main.o</span><br><span class=\"line\"></span><br><span class=\"line\">all: main</span><br><span class=\"line\"></span><br><span class=\"line\">main: main.o</span><br><span class=\"line\">        gcc main.o -o main</span><br><span class=\"line\"></span><br><span class=\"line\">clean:</span><br><span class=\"line\">        rm main.o main</span><br></pre></td></tr></table></figure>\n<p>如何使用这个makefile：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 编译（把all换成main效果一致）</span></span><br><span class=\"line\"><span class=\"comment\"># 方法1：用-f指定makefile文件</span></span><br><span class=\"line\">make -f makefile all</span><br><span class=\"line\"><span class=\"comment\"># 方法2：不指定makefile文件，默认会在当前文件夹寻找</span></span><br><span class=\"line\"><span class=\"comment\"># 按顺序寻找文件GNUmakefile--&gt;makefile--&gt;Makefile，找不到则报错</span></span><br><span class=\"line\">make all</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 清除编译结果，以下二选一</span></span><br><span class=\"line\">make clean</span><br><span class=\"line\">make -f makefile clean</span><br></pre></td></tr></table></figure>\n<p>makefile的基本组成如下（<strong>command必须以一个tab开始</strong>）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># target表示目标体，它位于冒号之前</span><br><span class=\"line\"># dependency_files表示依赖的文件或target，它位于冒号之后</span><br><span class=\"line\"># command表示达成这个目标所需执行命令</span><br><span class=\"line\">target: dependency_files</span><br><span class=\"line\">        command</span><br></pre></td></tr></table></figure>\n<p>makefile里面也可定义和调用变量：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CC=gcc</span><br><span class=\"line\">EXE=main</span><br><span class=\"line\"></span><br><span class=\"line\">main.o: main.c</span><br><span class=\"line\">        $(CC) -c main.c -o main.o</span><br><span class=\"line\"></span><br><span class=\"line\">all: $(EXE)</span><br><span class=\"line\"></span><br><span class=\"line\">$(EXE): main.o</span><br><span class=\"line\">        gcc main.o -o $(EXE)</span><br><span class=\"line\"></span><br><span class=\"line\">clean:</span><br><span class=\"line\">        rm main.o $(EXE)</span><br></pre></td></tr></table></figure>\n<p>也可在外部调用时传入变量（会将makefile中已存在的变量覆盖掉），命令如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make EXE=mm all</span><br><span class=\"line\">make EXE=mm clean</span><br></pre></td></tr></table></figure>\n<h3 id=\"使用GDB调试程序简介\"><a href=\"#使用GDB调试程序简介\" class=\"headerlink\" title=\"使用GDB调试程序简介\"></a>使用GDB调试程序简介</h3><p>使用<code>gdb 程序名（相对或绝对路径）</code>进入gdb：</p>\n<ol start=\"2\">\n<li>输入<code>break main</code>为main函数设置断点，输入<code>break main.c:5</code>为<code>main.c</code>的第5行设置断点；</li>\n<li>输入<code>i b</code>查看当前断点；</li>\n<li>输入<code>delete 1</code>删除第一个断点；</li>\n<li>输入<code>disable 1</code>停用第一个断点；</li>\n<li>输入<code>list main.c:5</code>可在gdb显示代码；</li>\n<li>输入<code>r</code>或<code>run</code>运行，这时用户将无法再输入命令，直到运行到断点时，gdb将交回命令行控制权，这时输入<code>n</code>或<code>next</code>表示运行到下一行，<code>s</code>或<code>step</code>表示进入当前行调用的函数，输入<code>return</code>返回到上一层函数；</li>\n<li>gdb交回命令行控制权时，输入<code>print 参数名</code>可查看当前作用域内的具体参数值；</li>\n<li>假如程序意外退出，这时输入<code>where</code>、<code>bt</code>或<code>backtrace</code>可以查看错误堆栈；</li>\n</ol>\n<h3 id=\"如何查看帮助手册\"><a href=\"#如何查看帮助手册\" class=\"headerlink\" title=\"如何查看帮助手册\"></a>如何查看帮助手册</h3><p>终端下输入<code>man 命令名称</code>（如<code>man printf</code>）将看到如下提示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Man: 寻找所有匹配的手册页 (set MAN_POSIXLY_CORRECT to avoid this)</span><br><span class=\"line\"> * printf (1)</span><br><span class=\"line\">   printf (3)</span><br><span class=\"line\">   printf (1p)</span><br><span class=\"line\">   printf (3p)</span><br><span class=\"line\">Man: 您需要什么手册页？</span><br><span class=\"line\">Man:</span><br></pre></td></tr></table></figure>\n<ol>\n<li>数字1表示这是一个用户命令（user commands，如<strong>echo</strong>）；</li>\n<li>数字2表示这是一个系统调用（system calls，如<strong>fork</strong>）；</li>\n<li>数字3表示这是一个标准库（stand library，如<strong>printf</strong>）；</li>\n<li>带p后缀的为POSIX标准，释义：POSIX标准定义了操作系统应该为应用程序提供的接口标准，一个POSIX兼容的操作系统编写的程序，应该可以在任何其它的POSIX操作系统（即使是来自另一个厂商）上编译执行；</li>\n</ol>\n<h2 id=\"编程实践\"><a href=\"#编程实践\" class=\"headerlink\" title=\"编程实践\"></a>编程实践</h2><h3 id=\"环境交互\"><a href=\"#环境交互\" class=\"headerlink\" title=\"环境交互\"></a>环境交互</h3><ol>\n<li>临时文件（用于暂时存放数据），使用下述命令查看具体用途<ul>\n<li><code>man mkstemp</code></li>\n<li><code>man tmpfile</code></li>\n</ul>\n</li>\n<li>环境变量（设置运行环境）<ul>\n<li>shell下<code>echo $USER</code>或<code>printenv USER</code>打印环境变量<code>USER</code>；</li>\n<li>shell下<code>export USER=jayzee</code>设置环境变量<code>USER</code>为<code>jayzee</code>；</li>\n<li>shell下<code>env</code>查询当前用户所有环境变量；</li>\n<li>Linux下调用一个C/C++程序时，该程序继承其调用者的所有环境变量，标准库<code>stdlib.h</code>的<code>getenv</code>、<code>setenv</code>和<code>unsetenv</code>用于获取、操纵环境变量；</li>\n</ul>\n</li>\n<li>shell下调用程序结束后，使用<code>echo $?</code>获取程序退出代码（0表示正常）；</li>\n<li>IO（输入输出流）<ul>\n<li>程序中，宏<code>stdin</code>表示输入流，对应int值0；宏<code>stdout</code>表示标准输出流，对应int值1；宏<code>stderr</code>表示错误输出流，对应int值2；</li>\n<li><code>stdin</code>只能是buffered的，但其buffered size可以修改；</li>\n<li><code>stderr</code>只能是unbuffered，一有错误立即输出；</li>\n<li>当程序直接在shell调用并且直接输出到控制台时，<code>stdout</code>是line-buffered的，否则是buffered的，但其buffered size可以修改，<code>man setvbuf</code>查看标准库如何设置输入输出流；</li>\n<li>程序写文件也是默认buffered，写完后应使用<code>fflush(your_file)</code>立即清空buffer写入到文件；</li>\n<li>shell命令<code>your_program &gt; output_file.txt 2&gt;&amp;1</code>表示将<code>your_program</code>的标准输出写入到文件<code>output_file.txt</code>（<code>&gt;</code>执行覆盖写，<code>&gt;&gt;</code>执行追加写），并且将错误输出流重定向到标准输出流，Linux规定文件名必须在流重定向之前；</li>\n<li>shell命令<code>program 2&gt;&amp;1 | filter</code>表示将标准输出使用管道过滤，Linux规定重定向必须在过滤器之前；</li>\n</ul>\n</li>\n<li><code>man getopt_long</code>查看<code>getopt.h</code>库如何处理程序参数（类似于<code>ls -l</code>的<code>-l</code>）；</li>\n</ol>\n<h3 id=\"好的编程习惯\"><a href=\"#好的编程习惯\" class=\"headerlink\" title=\"好的编程习惯\"></a>好的编程习惯</h3><p>使用断言assert：</p>\n<ul>\n<li>所有需确认值为true或非0的需使用<code>assert(condition)</code>；</li>\n<li>编译时指定<code>-DNDEBUG</code>可移除所有assert语句，所以<strong>千万不要把程序的重要逻辑放在assert语句中</strong>；</li>\n</ul>\n<p>处理系统调用失败：</p>\n<ul>\n<li>系统调用如<code>fork</code>失败时会返回非零值，这时宏<code>errno</code>会被设置，下次系统调用失败时又会覆盖这个宏的值；</li>\n<li><code>man strerror</code>查看如何使用<code>string.h</code>的<code>strerror</code>的具体字符串释义，细节如下：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EINTR : blocking function interrupt, like sleep, read, select</span><br><span class=\"line\">EPERM : Permission denied</span><br><span class=\"line\">EROFS : PATH is on a read-only file system</span><br><span class=\"line\">ENAMETOOLONG : PATH is too long</span><br><span class=\"line\">ENOENT : PATH does not exit</span><br><span class=\"line\">ENOTDIR : A component of PATH is not a directory</span><br><span class=\"line\">EACCES : A component of PATH is not accessible</span><br><span class=\"line\">EFAULT : PATH contains an invalid memory address.  This is probably a bug</span><br><span class=\"line\">ENOMEM : Ran out of kernel memory</span><br></pre></td></tr></table></figure>\n<p>申请内存与释放内存：</p>\n<ul>\n<li>申请内存与释放内存的语句必须成对，即有申请内存则相应的要有释放内存；</li>\n</ul>\n<h3 id=\"链接程序（库：快速开发，软件复用）\"><a href=\"#链接程序（库：快速开发，软件复用）\" class=\"headerlink\" title=\"链接程序（库：快速开发，软件复用）\"></a>链接程序（库：快速开发，软件复用）</h3><p>以下文字部分引用自<a href=\"http://www.cnblogs.com/skynet/p/3372855.html\" target=\"_blank\" rel=\"noopener\">C++静态库与动态库 - 吴秦 - 博客园</a>，向该作者致敬。</p>\n<p>下文用到的main.c文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/** main.c **/</span><br><span class=\"line\">int add(int x, int y) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">return</span> x + y;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"静态链接\"><a href=\"#静态链接\" class=\"headerlink\" title=\"静态链接\"></a>静态链接</h4><p>静态库的特点：</p>\n<ul>\n<li>静态库对函数库的链接是放在编译时期完成的；</li>\n<li>程序在运行时与函数库再无瓜葛，移植方便；</li>\n<li>浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件；</li>\n</ul>\n<p>静态库的创建：</p>\n<ul>\n<li>静态库的命名规范为lib[your_library_name].a：lib为前缀，中间是静态库名，扩展名为.a；</li>\n<li>首先将代码文件编译成目标文件.o，再通过ar工具将目标文件打包.a静态库文件；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 假定有一个math.c文件，提供加法函数int add(int x, int y)，我们现在将其打包成静态库</span></span><br><span class=\"line\">gcc -c math.c -o math.o</span><br><span class=\"line\">ar -crv libmath.a math.o</span><br></pre></td></tr></table></figure>\n<p>使用静态库：</p>\n<ul>\n<li>在编译时指定静态库搜索路径（-L选项）、指定静态库名称（不需要lib前缀和.a后缀，-l选项）；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -l为什么一定要放在末尾？它会去查找库的所有被引用的函数或宏等并插入到最终的可执行程序，放在末尾是为了这种依赖搜索在最后执行</span></span><br><span class=\"line\">gcc main.c -o main -Lfilepath_of_your_static_library -lmath</span><br></pre></td></tr></table></figure>\n<p>静态库优缺点：</p>\n<ul>\n<li>优点：编译成可执行文件后与其编译时引用的静态库再无任何瓜葛；</li>\n<li>缺点：导致可执行程序体量庞大，同一个操作系统上运行的多个程序引用同一个静态库会导致内存浪费（相同的代码），导致客户的全量更新；</li>\n</ul>\n<h4 id=\"动态链接\"><a href=\"#动态链接\" class=\"headerlink\" title=\"动态链接\"></a>动态链接</h4><p>动态库的特点：</p>\n<ul>\n<li>动态库把对一些库函数的链接载入推迟到程序运行的时期；</li>\n<li>可以实现进程之间的资源共享（因此动态库也称为共享库）；</li>\n<li>将一些程序升级变得简单；</li>\n<li>甚至可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）；</li>\n</ul>\n<p>动态库的创建：</p>\n<ul>\n<li>动态库的命名规范为lib[your_library_name].so：lib为前缀，中间是动态库名，扩展名为.so；</li>\n<li>首先将代码文件编译成目标文件.o，再通过gcc工具将目标文件打包.so动态库文件；<ul>\n<li><code>-fPIC</code>创建与地址无关的编译程序（pic，position independent code），是为了能够在多个应用程序间共享；</li>\n<li><code>-shared</code>指定生成动态链接库；</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 假定有一个math.c文件，提供加法函数int add(int x, int y)，我们现在将其打包成动态库</span></span><br><span class=\"line\">gcc -fPIC -c math.c -o math.o</span><br><span class=\"line\">gcc -shared -o libmath.so math.o</span><br><span class=\"line\"><span class=\"comment\"># 上面两条命令等价于</span></span><br><span class=\"line\">gcc -fPIC -shared -o libmath.so math.c</span><br></pre></td></tr></table></figure>\n<p>使用动态库：</p>\n<ul>\n<li>在编译时指定动态库搜索路径（-L选项）、指定动态库名称（不需要lib前缀和.so后缀，-l选项）；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc main.c -o main -Lfilepath_of_your_static_library -lmath</span><br></pre></td></tr></table></figure>\n<ul>\n<li>注意，运行上述生成的可执行文件时，操作系统会去一些指定路径查找并载入该动态库，如查找不到将抛出找不到动态库的异常信息，这些指定路径是：<ul>\n<li>环境变量LD_LIBRARY_PATH，如<code>LD_LIBRARY_PATH=/usr/local/lib:/opt/lib</code>；</li>\n<li>/etc/ld.so.cache文件列表，需要额外操作如下：<ul>\n<li>编辑/etc/ld.so.conf文件，加入库文件所在目录的路径；</li>\n<li>运行ldconfig ，该命令会重建/etc/ld.so.cache文件；</li>\n</ul>\n</li>\n<li>/lib/，/usr/lib目录；</li>\n</ul>\n</li>\n<li><code>-L</code>指定的库搜索路径下即有动态库也有静态库，则动态库具有较高优先级被链接；</li>\n</ul>\n<p>动态库优缺点：</p>\n<ul>\n<li>缺点：增量更新必须考虑向后兼容；</li>\n<li>优点：增量更新，避免内存浪费（同一个操作系统上运行的多个程序引用同一个动态库只需要一份共享库示例）；</li>\n</ul>\n<h4 id=\"链接检查辅助命令\"><a href=\"#链接检查辅助命令\" class=\"headerlink\" title=\"链接检查辅助命令\"></a>链接检查辅助命令</h4><p><code>nm</code>命令：打印出库中的涉及到的所有符号。库既可以是静态的也可以是动态的。nm列出的符号有很多，常见的有三种，</p>\n<ul>\n<li>一种是在库中被调用，但并没有在库中定义(表明需要其他库支持)，用U表示；</li>\n<li>一种是库中定义的函数，用T表示，这是最常见的；</li>\n<li>一种是所谓的弱态”符号，它们虽然在库中被定义，但是可能被其他库中的同名符号覆盖，用W表示；</li>\n</ul>\n<p><code>ldd</code>命令：查看一个可执行程序依赖的共享库。</p>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><p>本章节部分内容引用自<a href=\"http://www.cnblogs.com/hicjiajia/archive/2011/01/20/1940154.html\" target=\"_blank\" rel=\"noopener\">Linux下Fork与Exec使用 - hicjiajia - 博客园</a>和<a href=\"http://www.ibm.com/developerworks/cn/linux/kernel/syscall/part3/index.html\" target=\"_blank\" rel=\"noopener\">系统调用跟我学(3)</a>，向作者致敬。</p>\n<h3 id=\"进程查看\"><a href=\"#进程查看\" class=\"headerlink\" title=\"进程查看\"></a>进程查看</h3><p><code>pid</code>指进程id，<code>ppid</code>指父进程id。</p>\n<ol>\n<li>Linux所有<strong>用户进程</strong>呈树状结构，这棵用户进程树的根节点是init进程（内核启动的第一个用户级进程），init进程的<code>pid</code>为1，其ppid为0；</li>\n<li>shell下运行<code>ps -e -o pid,ppid,command</code>可查看所有用户进程的pid、ppid和command；</li>\n<li><code>unistd.h</code>提供<code>getpid()</code>和<code>getppid()</code>获取进程的ID和父ID；</li>\n</ol>\n<h3 id=\"进程创建\"><a href=\"#进程创建\" class=\"headerlink\" title=\"进程创建\"></a>进程创建</h3><h4 id=\"system函数：执行shell命令\"><a href=\"#system函数：执行shell命令\" class=\"headerlink\" title=\"system函数：执行shell命令\"></a>system函数：执行shell命令</h4><p>system函数用于在C/C++语言中执行shell命令，其API如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#include &lt;stdlib.h&gt;</span></span><br><span class=\"line\">int system(const char *<span class=\"built_in\">command</span>);</span><br></pre></td></tr></table></figure>\n<p>其具体实现是：</p>\n<ol>\n<li>先执行系统调用<code>fork()</code>创建子进程；</li>\n<li>再执行<code>execl(&quot;/bin/sh&quot;, &quot;sh&quot;. &quot;-c&quot;, command, (char *) 0);</code>去调用shell执行command；</li>\n</ol>\n<h4 id=\"fork函数，exec族函数\"><a href=\"#fork函数，exec族函数\" class=\"headerlink\" title=\"fork函数，exec族函数\"></a>fork函数，exec族函数</h4><h5 id=\"fork函数：创建子进程，进程分叉\"><a href=\"#fork函数：创建子进程，进程分叉\" class=\"headerlink\" title=\"fork函数：创建子进程，进程分叉\"></a>fork函数：创建子进程，进程分叉</h5><p>fork函数API如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#include &lt;unistd.h&gt;</span></span><br><span class=\"line\">pid_t fork(void);</span><br></pre></td></tr></table></figure>\n<p>fork函数的特点：</p>\n<ul>\n<li>fork调用之后，父进程进入<code>pid&gt;0</code>的分支，子进程进入<code>pid==0</code>的分支；</li>\n<li>fork创建的子进程是父进程的一个完整拷贝，<strong>当且仅当fork之后的代码即将开始更新内存，真实的拷贝才会发生</strong>（也就是上述例子并没有发生拷贝），为什么这么设计，我们会在下面讲到；</li>\n<li>fork创建的子进程拥有一个新的进程pid号，子进程的ppid为调用fork函数的进程id；</li>\n</ul>\n<p>pid_t是一个整型变量。具体示例如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* zombie.c */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/types.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pid_t</span> pid;</span><br><span class=\"line\">    pid=fork();</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(pid&lt;<span class=\"number\">0</span>) <span class=\"comment\">/* 如果出错 */</span></span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"error occurred!\\n\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(pid==<span class=\"number\">0</span>) <span class=\"comment\">/* 如果是子进程 */</span></span><br><span class=\"line\">        <span class=\"built_in\">exit</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"comment\">/* 如果是父进程 */</span></span><br><span class=\"line\">        sleep(<span class=\"number\">60</span>); <span class=\"comment\">/* 休眠60秒，这段时间里，父进程什么也干不了 */</span></span><br><span class=\"line\">    wait(<span class=\"literal\">NULL</span>); <span class=\"comment\">/* 收集僵尸进程 */</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"exec函数族：对当前进程进行替换\"><a href=\"#exec函数族：对当前进程进行替换\" class=\"headerlink\" title=\"exec函数族：对当前进程进行替换\"></a>exec函数族：对当前进程进行替换</h5><p>exec并不是一个具体函数，它是以下六个函数：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execl</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *path, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *arg, ...)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execlp</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *file, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *arg, ...)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execle</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *path, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *arg, ..., <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> envp[])</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execv</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *path, <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv[])</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execvp</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *file, <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv[])</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execve</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *path, <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv[], <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> envp[])</span></span>;</span><br></pre></td></tr></table></figure>\n<p>其中<code>execl</code>是基函数，其他5个是它的变种（区别在于传参形式不同，带v的表示参数以数组传递，带l的表示参数以陈列的方式传递）。</p>\n<p>exec函数族特点：</p>\n<ul>\n<li>只保留当前进程的pid，其他进程相关的数据段全部废弃；对系统而言，还是同一个进程号，但其实已经是另外一个程序了，即调用exec函数族的进程已“死亡”了；</li>\n<li>上面说到，fork的数据拷贝只发生在子进程更新内存时，fork调用后立即执行exec函数族使得我们能够产生一个全新的进程（<strong>这意味着当前进程的所有线程、文件描述符等都被释放</strong>），与fork调用进程再无任何瓜葛；</li>\n</ul>\n<p>举一个具体例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;errno.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">char</span> command[<span class=\"number\">256</span>];</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">   <span class=\"keyword\">int</span> rtn; <span class=\"comment\">/*子进程的返回数值*/</span></span><br><span class=\"line\">   <span class=\"keyword\">while</span>(<span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">       <span class=\"comment\">/* 从终端读取要执行的命令 */</span></span><br><span class=\"line\">       <span class=\"built_in\">printf</span>( <span class=\"string\">\"&gt;\"</span> );</span><br><span class=\"line\">       fgets( command, <span class=\"number\">256</span>, <span class=\"built_in\">stdin</span> );</span><br><span class=\"line\">       command[<span class=\"built_in\">strlen</span>(command)<span class=\"number\">-1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> ( fork() == <span class=\"number\">0</span> ) &#123;<span class=\"comment\">/* 子进程执行此命令 */</span></span><br><span class=\"line\">          execlp( command, <span class=\"literal\">NULL</span> );</span><br><span class=\"line\">          <span class=\"comment\">/* 如果exec函数返回，表明没有正常执行命令，打印错误信息*/</span></span><br><span class=\"line\">          perror( command );</span><br><span class=\"line\">          <span class=\"built_in\">exit</span>( errno );</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">else</span> &#123;<span class=\"comment\">/* 父进程， 等待子进程结束，并打印子进程的返回值 */</span></span><br><span class=\"line\">          wait ( &amp;rtn );</span><br><span class=\"line\">          <span class=\"built_in\">printf</span>( <span class=\"string\">\" child process return %d\\n\"</span>, rtn );</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"信号处理\"><a href=\"#信号处理\" class=\"headerlink\" title=\"信号处理\"></a>信号处理</h3><p>信号是一种异步的进程通信机制，是软件层面的中断，进程接收到线程必须进行处理，有以下三种处理方式：</p>\n<ul>\n<li>使用进程对信号的静默处理；</li>\n<li>忽略该信号；</li>\n<li>使用特定的信号处理函数进行处理；</li>\n</ul>\n<p>上述的后两种方式需要使用<code>signal()</code>函数进行处理，举例如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 忽略SIGPIPE信号</span></span><br><span class=\"line\">signal ( SIGPIPE, SIG_IGN );</span><br><span class=\"line\"><span class=\"comment\">// 使用PrepareExit处理SIGINT信号</span></span><br><span class=\"line\">signal ( SIGINT, (<span class=\"keyword\">__sighandler_t</span> ) PrepareExit );</span><br></pre></td></tr></table></figure>\n<p>Linux的信号如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">信号值 默认处理动作 发出信号的原因</span><br><span class=\"line\">SIGHUP 1 A 终端挂起或者控制进程终止</span><br><span class=\"line\">SIGINT 2 A 键盘中断（如break键被按下）</span><br><span class=\"line\">SIGQUIT 3 C 键盘的退出键被按下</span><br><span class=\"line\">SIGILL 4 C 非法指令</span><br><span class=\"line\">SIGABRT 6 C 由abort(3)发出的退出指令</span><br><span class=\"line\">SIGFPE 8 C 浮点异常</span><br><span class=\"line\">SIGKILL 9 AEF Kill信号</span><br><span class=\"line\">SIGSEGV 11 C 无效的内存引用</span><br><span class=\"line\">SIGPIPE 13 A 管道破裂: 写一个没有读端口的管道</span><br><span class=\"line\">SIGALRM 14 A 由alarm(2)发出的信号</span><br><span class=\"line\">SIGTERM 15 A 终止信号</span><br><span class=\"line\">SIGUSR1 30,10,16 A 用户自定义信号1</span><br><span class=\"line\">SIGUSR2 31,12,17 A 用户自定义信号2</span><br><span class=\"line\">SIGCHLD 20,17,18 B 子进程结束信号</span><br><span class=\"line\">SIGCONT 19,18,25 进程继续（曾被停止的进程）</span><br><span class=\"line\">SIGSTOP 17,19,23 DEF 终止进程</span><br><span class=\"line\">SIGTSTP 18,20,24 D 控制终端（tty）上按下停止键</span><br><span class=\"line\">SIGTTIN 21,21,26 D 后台进程企图从控制终端读</span><br><span class=\"line\">SIGTTOU 22,22,27 D 后台进程企图从控制终端写</span><br><span class=\"line\"></span><br><span class=\"line\">处理动作一项中的字母含义如下：</span><br><span class=\"line\">A 缺省的动作是终止进程</span><br><span class=\"line\">B 缺省的动作是忽略此信号，将该信号丢弃，不做处理</span><br><span class=\"line\">C 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序</span><br><span class=\"line\">D 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用）</span><br><span class=\"line\">E 信号不能被捕获</span><br><span class=\"line\">F 信号不能被忽略</span><br></pre></td></tr></table></figure>\n<p><strong>注意</strong>：<br>信号处理函数可被新产生的信号所中断，所以信号处理函数应该做尽可能少的工作；</p>\n<h3 id=\"进程终止\"><a href=\"#进程终止\" class=\"headerlink\" title=\"进程终止\"></a>进程终止</h3><h4 id=\"信号终止\"><a href=\"#信号终止\" class=\"headerlink\" title=\"信号终止\"></a>信号终止</h4><ol>\n<li><code>SIGINT</code>：CRTL+C产生；</li>\n<li><code>SIGTERM</code>：shell下<code>kill pid</code>产生；</li>\n<li><code>abort()</code>：发送一个<code>SIGABRT</code>信号给自己；</li>\n<li><code>SIGKILL</code>：强制退出信号，shell下<code>kill -9 pid</code>产生；</li>\n</ol>\n<p>当进程终止时，shell调用<code>echo $?</code>可取得该进程的exit code，</p>\n<ul>\n<li>如果该进程由信号终止，exit code为128加上信号值；</li>\n<li>调用<code>exit(int exit_code)</code>函数退出，exit_code的范围需在0到128之间；</li>\n</ul>\n<p>如何给进程发送指定信号，</p>\n<ul>\n<li>在shell下使用<code>kill -s SIGNAL_NAME pid</code>，可以给进程pid发送SIGNAL_NAME信号；</li>\n<li>程序使用<code>kill(pid, SIGNAL_NAME)</code>函数；</li>\n</ul>\n<h4 id=\"wait\"><a href=\"#wait\" class=\"headerlink\" title=\"wait\"></a>wait</h4><p>Unix的进程终止时，一些资源（如进程pid、进程exit code、收到的信号、占用CPU时间等）并不会被立即释放（堆栈等内存立即释放），死亡进程的父进程必须调用<code>wait</code>函数对进程进行“收尸”，即释放进程的pid和exit code等资源。</p>\n<p><code>wait</code>函数的API定义如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">pid_t</span> wait(<span class=\"keyword\">int</span> *status);</span><br></pre></td></tr></table></figure>\n<p>一些说明：</p>\n<ul>\n<li><code>wait</code>函数是阻塞式的，在子进程未结束时将阻塞；</li>\n<li>如果<code>pid_t</code>为-1，表明<code>wait</code>调用失败，这是因为调用进程没有子进程导致；否则，表明收集子进程“死亡”信息成功，<code>pid_t</code>的值为“死亡”进程pid；</li>\n<li><code>status</code>是一个指针，如果这个指针为空，表明我们不关心进程的“死亡”信息细节，只是发起了回收这个动作；否则，status将包含进程“死亡”的一些信息；</li>\n<li>调用<code>WIFEXITED(status)</code>，若返回值回0表明进程异常退出（如信号导致退出），这时调用<code>WTERMSIG(status)</code>将得到使进程死亡的信号int值；否则表示程序正常退出，这时候调用<code>WEXITSTATUS(status)</code>可获取“死亡”进程的exit code（如“死亡”进程调用<code>exit(7)</code>退出，则<code>WEXITSTATUS(status)</code>的结果为7）；</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* wait2.c */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/types.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/wait.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> status;</span><br><span class=\"line\">    <span class=\"keyword\">pid_t</span> pc,pr;</span><br><span class=\"line\">    pc=fork();</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(pc&lt;<span class=\"number\">0</span>)     <span class=\"comment\">/* 如果出错 */</span></span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"error ocurred!\\n\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(pc==<span class=\"number\">0</span>)&#123; <span class=\"comment\">/* 子进程 */</span></span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"This is child process with pid of %d.\\n\"</span>,getpid());</span><br><span class=\"line\">        <span class=\"built_in\">exit</span>(<span class=\"number\">3</span>);    <span class=\"comment\">/* 子进程返回3 */</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>&#123;       <span class=\"comment\">/* 父进程 */</span></span><br><span class=\"line\">        pr=wait(&amp;status);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(WIFEXITED(status))&#123;  <span class=\"comment\">/* 如果WIFEXITED返回非零值 */</span></span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"the child process %d exit normally.\\n\"</span>,pr);</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"the return code is %d.\\n\"</span>,WEXITSTATUS(status));</span><br><span class=\"line\">        &#125;<span class=\"keyword\">else</span>           <span class=\"comment\">/* 如果WIFEXITED返回零，这时pr存储死亡进程pid */</span></span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"the child process %d exit abnormally with signal number %d.\\n\"</span>,pr,WTERMSIG(status));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"僵尸进程\"><a href=\"#僵尸进程\" class=\"headerlink\" title=\"僵尸进程\"></a>僵尸进程</h4><p>如果子进程死亡，父进程却没有调用<code>wait</code>对其进行“收尸”，子进程就会变成一个僵尸进程，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ps -ax</span><br><span class=\"line\">  PID TTY      STAT   TIME COMMAND</span><br><span class=\"line\"> 1177 pts/0    S      0:00 -bash</span><br><span class=\"line\"> 1577 pts/0    S      0:00 ./zombie</span><br><span class=\"line\"> 1578 pts/0    Z      0:00 [zombie &lt;defunct&gt;]</span><br><span class=\"line\"> 1579 pts/0    R      0:00 ps -ax</span><br></pre></td></tr></table></figure>\n<p>若STAT为Z则表明则是一个僵尸进程，关于僵尸进程，</p>\n<ul>\n<li>在父进程退出时，init进程会自动对其下的所有僵尸子进程进行清理；</li>\n<li>子进程意外死亡时，父进程会受到一个SIGCHLD信号，父进程可以注册这个信号的处理函数进行“收尸”；</li>\n<li><code>wait3</code>和<code>wait4</code>函数为异步的，可以周期调用这两个函数执行回收；</li>\n</ul>\n<h2 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h2><h3 id=\"线程创建\"><a href=\"#线程创建\" class=\"headerlink\" title=\"线程创建\"></a>线程创建</h3><p><strong>线程创建</strong>：<code>int pthread_create(pthread_t *thread, const pthread_attr_t *attr,\nvoid *(*start_routine) (void *), void *arg);</code></p>\n<ul>\n<li><code>pthread_create</code>的返回值为0表示创建线程成功；</li>\n<li><code>thread</code>是指向<code>pthread_t</code>的指针；</li>\n<li><code>pthread_attr_t</code>在下一个例子介绍；</li>\n<li><code>start_routine</code>是一个无形参且无返回值的函数指针；</li>\n<li><code>arg</code>是上面提到的函数指针所接收的参数；</li>\n</ul>\n<p><strong>线程回收</strong>：<code>int pthread_join(pthread_t thread, void **retval);</code></p>\n<ul>\n<li><code>retval</code>实际上是一个指向整型指针的指针，它存放的是线程调用<code>exit</code>或<code>pthread_exit</code>的退出值；</li>\n<li><code>When a joinable thread terminates, its memory resources (thread descriptor and stack) are not deallocated until another thread performs pthread_join on it. Therefore, pthread_join must be called  once  for each joinable thread created to avoid memory leaks.</code></li>\n<li>这是一个阻塞式的方法，当监控到有线程结束时才返回；</li>\n</ul>\n<p><strong>线程退出</strong>：<code>void pthread_exit(void *retval);</code></p>\n<ul>\n<li><code>retval</code>实际是一个整型指针，在退出时标识线程的退出值；</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> code = <span class=\"number\">11</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">hello</span><span class=\"params\">(<span class=\"keyword\">void</span> *args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *str = (<span class=\"keyword\">char</span> *) args;</span><br><span class=\"line\">    sleep(<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, %s!\\n\"</span>, str);</span><br><span class=\"line\">    pthread_exit(&amp;code);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> thread;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> status = pthread_create(&amp;thread, <span class=\"literal\">NULL</span>, (<span class=\"keyword\">void</span> *)hello, (<span class=\"keyword\">void</span> *) <span class=\"string\">\"Jayzee\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread create status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *exit_code = <span class=\"number\">0</span>;</span><br><span class=\"line\">    status = pthread_join(thread, (<span class=\"keyword\">void</span> *) &amp;exit_code);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread join status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread exit code : %d\\n\"</span>, *exit_code);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<hr>\n<p>下面的例子在<code>pthread_create</code>时用到了<code>pthread_attr_t</code>，必须经历下面四个过程</p>\n<ol>\n<li>先实例化<code>pthread_attr_t</code>；</li>\n<li>再设置<code>pthread_attr_t</code>；</li>\n<li>在线程创建时使用该<code>pthread_attr_t</code>；</li>\n<li>线程创建完后销毁<code>pthread_attr_t</code>；</li>\n</ol>\n<p>注意：</p>\n<ol>\n<li>创建线程时设置其为detach态，意味着我们不关心它的返回值，只是进行线程相关资源回收；</li>\n<li>也可创建线程时不指定detach态，在线程创建后可使用<code>int pthread_detach(pthread_t thread);</code>设置其为detach态；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> code = <span class=\"number\">11</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">hello</span><span class=\"params\">(<span class=\"keyword\">void</span> *args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *str = (<span class=\"keyword\">char</span> *) args;</span><br><span class=\"line\">    sleep(<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, %s!\\n\"</span>, str);</span><br><span class=\"line\">    pthread_exit(&amp;code);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> thread;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_attr_t</span> attr;</span><br><span class=\"line\">    pthread_attr_init (&amp;attr);</span><br><span class=\"line\">    pthread_attr_setdetachstate (&amp;attr, PTHREAD_CREATE_DETACHED);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> status = pthread_create (&amp;thread, &amp;attr, (<span class=\"keyword\">void</span> *)hello, (<span class=\"keyword\">void</span> *) <span class=\"string\">\"Jayzee\"</span>);</span><br><span class=\"line\">    pthread_attr_destroy (&amp;attr);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread create status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"线程取消\"><a href=\"#线程取消\" class=\"headerlink\" title=\"线程取消\"></a>线程取消</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_setcancelstate(int state, int *oldstate);</span><br><span class=\"line\">int pthread_setcanceltype(int type, int *oldtype);</span><br><span class=\"line\">int pthread_cancel(pthread_t thread);</span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>pthread_setcancelstate</code>在运行时设置线程的状态<code>state</code>，并取得其之前的状态<code>oldstate</code>；</li>\n<li><code>pthread_setcanceltype</code>在运行时设置线程的类型<code>type</code>，并取得其之前的类型<code>oldtype</code>；</li>\n<li><code>pthread_cancel</code>用于取消线程的执行；</li>\n</ul>\n<p>注意，</p>\n<ol>\n<li>type：<code>PTHREAD_CANCEL_DEFERRED</code>或<code>PTHREAD_CANCEL_ASYNCHRONOUS</code></li>\n<li>state：<code>PTHREAD_CANCEL_ENABLE</code>或<code>PTHREAD_CANCEL_DISABLE</code></li>\n<li>type和state作用于<code>pthread_cancel</code>：<ul>\n<li>当state为<code>PTHREAD_CANCEL_DISABLE</code>时，设置的type和调用<code>pthread_cancel</code>不会对线程造成任何影响；</li>\n<li>否则，当设置的type为<code>PTHREAD_CANCEL_DEFERRED</code>时，为非阻塞取消（等待达到取消的条件，如释放锁）；当设置的type为<code>PTHREAD_CANCEL_ASYNCHRONOUS</code>时为异步取消（即线程立即被取消，但不同操作系统有可能实现不同，理应处理释放锁）；</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> code = <span class=\"number\">11</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">hello</span><span class=\"params\">(<span class=\"keyword\">void</span> *args)</span> </span>&#123;</span><br><span class=\"line\">    pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, &amp;last_state); </span><br><span class=\"line\">    pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, &amp;last_type);</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *str = (<span class=\"keyword\">char</span> *) args;</span><br><span class=\"line\">    sleep(<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, %s!\\n\"</span>, str);</span><br><span class=\"line\">    pthread_exit(&amp;code);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> thread;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> status = pthread_create(&amp;thread, <span class=\"literal\">NULL</span>, (<span class=\"keyword\">void</span> *)hello, (<span class=\"keyword\">void</span> *) <span class=\"string\">\"Jayzee\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread create status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *exit_code = <span class=\"number\">0</span>;</span><br><span class=\"line\">    status = pthread_join(thread, (<span class=\"keyword\">void</span> *) &amp;exit_code);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread join status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread exit code : %d\\n\"</span>, *exit_code);</span><br><span class=\"line\">    pthread_cancel(thread);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"线程特定数据\"><a href=\"#线程特定数据\" class=\"headerlink\" title=\"线程特定数据\"></a>线程特定数据</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_key_create(pthread_key_t *key, void (*destructor)(void*));</span><br><span class=\"line\">int pthread_setspecific(pthread_key_t key, const void *value);</span><br><span class=\"line\">void *pthread_getspecific(pthread_key_t key);</span><br></pre></td></tr></table></figure>\n<ol>\n<li>使用<code>pthread_key_create</code>创建<code>key</code>，<code>destructor</code>为线程结束时用于析构的函数指针，一个进程内的多个线程可以共用一个<code>key</code>；</li>\n<li><code>pthread_setspecific</code>为线程设定key-value，<code>pthread_getspecific</code>根据key获得value；</li>\n<li>当线程结束时，若<code>pthread_getspecific</code>的内容不为空，且<code>destructor</code>不为空，则<code>pthread_getspecific</code>的内容将作为<code>destructor</code>的参数来执行析构函数；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;malloc.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* The key used to associate a log file pointer with each thread. */</span></span><br><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">pthread_key_t</span> thread_log_key;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Write MESSAGE to the log file for the current thread. */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">write_to_thread_log</span> <span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* message)</span> </span>&#123;</span><br><span class=\"line\">    FILE* thread_log = (FILE*) pthread_getspecific (thread_log_key);</span><br><span class=\"line\">    <span class=\"built_in\">fprintf</span> (thread_log, <span class=\"string\">\"%s\\n\"</span>, message);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Close the log file pointer THREAD_LOG. */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">close_thread_log</span> <span class=\"params\">(<span class=\"keyword\">void</span>* thread_log)</span> </span>&#123;</span><br><span class=\"line\">    fclose ((FILE*) thread_log);    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">thread_function</span> <span class=\"params\">(<span class=\"keyword\">void</span>* args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> thread_log_filename[<span class=\"number\">20</span>];</span><br><span class=\"line\">    FILE* thread_log;</span><br><span class=\"line\">    <span class=\"comment\">/* Generate the filename for this thread’s log file. */</span></span><br><span class=\"line\">    <span class=\"built_in\">sprintf</span> (thread_log_filename, <span class=\"string\">\"thread%d.log\"</span>, (<span class=\"keyword\">int</span>) pthread_self ());</span><br><span class=\"line\">    <span class=\"comment\">/* Open the log file. */</span></span><br><span class=\"line\">    thread_log = fopen (thread_log_filename, <span class=\"string\">\"w\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">/* Store the file pointer in thread-specific data under thread_log_key. */</span></span><br><span class=\"line\">    pthread_setspecific (thread_log_key, thread_log);</span><br><span class=\"line\">    write_to_thread_log (<span class=\"string\">\"Thread starting.\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">/* Do work here... */</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> threads[<span class=\"number\">5</span>];</span><br><span class=\"line\">    <span class=\"comment\">/* Create a key to associate thread log file pointers in</span></span><br><span class=\"line\"><span class=\"comment\">    thread-specific data. Use close_thread_log to clean up the file</span></span><br><span class=\"line\"><span class=\"comment\">    pointers. */</span></span><br><span class=\"line\">    pthread_key_create (&amp;thread_log_key, close_thread_log);</span><br><span class=\"line\">    <span class=\"comment\">/* Create threads to do the work. */</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; ++i)</span><br><span class=\"line\">        pthread_create (&amp;(threads[i]), <span class=\"literal\">NULL</span>, thread_function, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"comment\">/* Wait for all threads to finish. */</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; ++i)</span><br><span class=\"line\">        pthread_join (threads[i], <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void pthread_cleanup_push(void (*routine)(void *), void *arg);</span><br><span class=\"line\">void pthread_cleanup_pop(int execute);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>pthread_cleanup_push</code>在线程运行时为线程压栈清理函数；</li>\n<li><code>pthread_cleanup_pop</code>从栈弹出一个清理函数，如果<code>execute</code>不为0则执行这个清理函数；</li>\n<li>线程结束时，所有压栈的清理函数会自动被弹出栈进行执行；</li>\n<li>当在线程内使用longjump前，应手动调用<code>pthread_cleanup_pop</code>执行清理；</li>\n</ol>\n<h3 id=\"线程同步\"><a href=\"#线程同步\" class=\"headerlink\" title=\"线程同步\"></a>线程同步</h3><h4 id=\"互斥锁\"><a href=\"#互斥锁\" class=\"headerlink\" title=\"互斥锁\"></a>互斥锁</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_mutex_destroy(pthread_mutex_t *mutex);</span><br><span class=\"line\">int pthread_mutex_init(pthread_mutex_t *restrict mutex,</span><br><span class=\"line\">    const pthread_mutexattr_t *restrict attr);</span><br><span class=\"line\">pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>pthread_mutex_destroy</code>销毁互斥锁，<code>pthread_mutex_init</code>创建互斥锁；</li>\n<li><code>pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;</code>表示定义并默认实例化一个互斥锁；</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_mutex_lock(pthread_mutex_t *mutex);</span><br><span class=\"line\">int pthread_mutex_trylock(pthread_mutex_t *mutex);</span><br><span class=\"line\">int pthread_mutex_unlock(pthread_mutex_t *mutex);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>pthread_mutex_lock</code>为阻塞锁，<code>pthread_mutex_trylock</code>为非阻塞锁（获取不到锁）则立即返回，<code>pthread_mutex_unlock</code>为释放锁；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_mutexattr_t</span> attr;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_mutex_t</span> mutex;</span><br><span class=\"line\">    pthread_mutexattr_init (&amp;attr);</span><br><span class=\"line\">    <span class=\"comment\">// 带错误检查的互斥锁</span></span><br><span class=\"line\">    pthread_mutexattr_setkind_np (&amp;attr, PTHREAD_MUTEX_ERRORCHECK_NP);</span><br><span class=\"line\">    pthread_mutex_init (&amp;mutex, &amp;attr);</span><br><span class=\"line\">    pthread_mutex_lock(&amp;mutex);</span><br><span class=\"line\">    <span class=\"comment\">/** do some work **/</span></span><br><span class=\"line\">    pthread_mutex_unlock(&amp;mutex);</span><br><span class=\"line\">    pthread_mutexattr_destroy (&amp;attr);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int sem_init(sem_t *sem, int pshared, unsigned int value);</span><br><span class=\"line\">int sem_post(sem_t *sem);</span><br><span class=\"line\">int sem_wait(sem_t *sem);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>sem_init</code>实例化信号量<code>sem</code>，<code>pshared</code>为0表示进程内共享（非0为进程间共享），<code>value</code>为初始容量值（默认容量值为0）；</li>\n<li><code>sem_wait</code>将容量值减一，<code>sem_wait</code>之后若容量值小于0则线程阻塞；<code>sem_post</code>将容量值加一；</li>\n<li>假设容量值为负，一次<code>sem_post</code>只能唤醒一个线程；</li>\n<li><code>sem_wait</code>和<code>sem_post</code>是线程安全的；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;semaphore.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">sem_t</span> semaphore;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">threadfunc</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (; i&lt;<span class=\"number\">10</span>; i++) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 实际上不会这么使用，这里仅是展示</span></span><br><span class=\"line\">        sem_wait(&amp;semaphore);</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello from da thread!\\n\"</span>);</span><br><span class=\"line\">        sem_post(&amp;semaphore);</span><br><span class=\"line\">        sleep(<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 实例化</span></span><br><span class=\"line\">    sem_init(&amp;semaphore, <span class=\"number\">0</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> *mythread;    </span><br><span class=\"line\">    mythread = (<span class=\"keyword\">pthread_t</span> *)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(*mythread));</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 启动线程</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Starting thread, semaphore is unlocked.\\n\"</span>);</span><br><span class=\"line\">    pthread_create(mythread, <span class=\"literal\">NULL</span>, (<span class=\"keyword\">void</span>*)threadfunc, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    pthread_join(mythread, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"条件值\"><a href=\"#条件值\" class=\"headerlink\" title=\"条件值\"></a>条件值</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_cond_init(pthread_cond_t *restrict cond,</span><br><span class=\"line\">    const pthread_condattr_t *restrict attr);</span><br><span class=\"line\">pthread_cond_t cond = PTHREAD_COND_INITIALIZER;</span><br><span class=\"line\">int pthread_cond_signal(pthread_cond_t *cond);</span><br><span class=\"line\">int pthread_cond_wait(pthread_cond_t *restrict cond,</span><br><span class=\"line\">   pthread_mutex_t *restrict mutex);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>pthread_cond_t cond = PTHREAD_COND_INITIALIZER;</code>等价于<code>pthread_cond_init(&amp;pthread_cond_t, NULL);</code></li>\n<li>当调用<code>pthread_cond_signal</code>或<code>pthread_cond_wait</code>时，必须获得锁；</li>\n<li>调用<code>pthread_cond_wait</code>时，自动释放锁，直到被<code>pthread_cond_signal</code>唤醒时，才重新自动获得锁；</li>\n<li><code>pthread_cond_timedwait</code>可批量唤醒等待的线程；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">pthread_mutex_t</span> mutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class=\"line\"><span class=\"keyword\">pthread_cond_t</span> cond = PTHREAD_COND_INITIALIZER;</span><br><span class=\"line\"><span class=\"keyword\">int</span> condition = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">consume</span><span class=\"params\">( <span class=\"keyword\">void</span> )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>( <span class=\"number\">1</span> )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        pthread_mutex_lock( &amp;mutex );</span><br><span class=\"line\">        <span class=\"keyword\">while</span>( condition == <span class=\"number\">0</span> )</span><br><span class=\"line\">            pthread_cond_wait( &amp;cond, &amp;mutex );</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>( <span class=\"string\">\"Consumed %d\\n\"</span>, count );</span><br><span class=\"line\">        condition = <span class=\"number\">0</span>;</span><br><span class=\"line\">        pthread_cond_signal( &amp;cond );        </span><br><span class=\"line\">        pthread_mutex_unlock( &amp;mutex );</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span>( <span class=\"number\">0</span> );</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">produce</span><span class=\"params\">( <span class=\"keyword\">void</span> * arg )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>( <span class=\"number\">1</span> )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        pthread_mutex_lock( &amp;mutex );</span><br><span class=\"line\">        <span class=\"keyword\">while</span>( condition == <span class=\"number\">1</span> )</span><br><span class=\"line\">            pthread_cond_wait( &amp;cond, &amp;mutex );</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>( <span class=\"string\">\"Produced %d\\n\"</span>, count++ );</span><br><span class=\"line\">        condition = <span class=\"number\">1</span>;</span><br><span class=\"line\">        pthread_cond_signal( &amp;cond );        </span><br><span class=\"line\">        pthread_mutex_unlock( &amp;mutex );</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span>( <span class=\"number\">0</span> );</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">void</span> )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    pthread_create( <span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>, &amp;produce, <span class=\"literal\">NULL</span> );</span><br><span class=\"line\">    <span class=\"keyword\">return</span> consume();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"线程实现\"><a href=\"#线程实现\" class=\"headerlink\" title=\"线程实现\"></a>线程实现</h3><p>Linux的线程实现是系统调用<code>clone()</code>，它创建一个与父进程共用资源的子进程。</p>\n<h2 id=\"进程间通信\"><a href=\"#进程间通信\" class=\"headerlink\" title=\"进程间通信\"></a>进程间通信</h2><h3 id=\"共享内存\"><a href=\"#共享内存\" class=\"headerlink\" title=\"共享内存\"></a>共享内存</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/ipc.h&gt;</span><br><span class=\"line\">#include &lt;sys/shm.h&gt;</span><br><span class=\"line\">int shmget(key_t key, size_t size, int shmflg);</span><br><span class=\"line\">void *shmat(int shmid, const void *shmaddr, int shmflg);</span><br><span class=\"line\">int shmdt(const void *shmaddr);</span><br><span class=\"line\">int shmctl(int shmid, int cmd, struct shmid_ds *buf);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>shmget</code>申请共享内存；</li>\n<li><code>shmat</code>取得已申请的共享内存，共享内存使用者计数器加1；</li>\n<li><code>shmdt</code>断开已申请的共享内存，共享内存使用者计数器减1，如果计时器减到0，这块共享内存会被系统标注并删除；</li>\n<li><code>shmctl</code>对共享内存的标识信息进行设置；</li>\n</ol>\n<h3 id=\"进程信号量\"><a href=\"#进程信号量\" class=\"headerlink\" title=\"进程信号量\"></a>进程信号量</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/ipc.h&gt;</span><br><span class=\"line\">#include &lt;sys/sem.h&gt;</span><br><span class=\"line\">int semget(key_t key, int nsems, int semflg);</span><br><span class=\"line\">int semctl(int semid, int semnum, int cmd, ...);</span><br><span class=\"line\">int semop(int semid, struct sembuf *sops, size_t nsops);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>semget</code>用于申请信号量；</li>\n<li><code>semctl</code>用于释放或实例化信号量；</li>\n<li><code>semop</code>用于执行wait或post；</li>\n</ol>\n<h3 id=\"映射到内存\"><a href=\"#映射到内存\" class=\"headerlink\" title=\"映射到内存\"></a>映射到内存</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/mman.h&gt;</span><br><span class=\"line\">void *mmap(void *addr, size_t length, int prot, int flags,</span><br><span class=\"line\">    int fd, off_t offset);</span><br></pre></td></tr></table></figure>\n<p><code>mmap</code>是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。</p>\n<h3 id=\"管道\"><a href=\"#管道\" class=\"headerlink\" title=\"管道\"></a>管道</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;unistd.h&gt;</span><br><span class=\"line\">int pipe(int pipefd[2]);</span><br></pre></td></tr></table></figure>\n<p><code>pipe</code>的一端写，由内核缓存，直到另一端将其读出。</p>\n<h3 id=\"Socket\"><a href=\"#Socket\" class=\"headerlink\" title=\"Socket\"></a>Socket</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/socket.h&gt;</span><br><span class=\"line\">int socket(int domain, int type, int protocol);</span><br><span class=\"line\">int close(int fd);</span><br><span class=\"line\">int connect(int sockfd, const struct sockaddr *addr,</span><br><span class=\"line\">    socklen_t addrlen);</span><br><span class=\"line\">int bind(int sockfd, const struct sockaddr *addr,</span><br><span class=\"line\">    socklen_t addrlen);</span><br><span class=\"line\">int listen(int sockfd, int backlog);</span><br><span class=\"line\">int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>socket</code>创建一个socket；</li>\n<li><code>close</code>关闭一个socket；</li>\n<li><code>connect</code>建立两个socket的连接；</li>\n<li><code>bind</code>将socket绑定到地址和端口；</li>\n<li><code>listen</code>配置socket接受连接的条件；</li>\n<li><code>accept</code>接收一个socket连接并为其创建一个socket；</li>\n</ol>\n<h2 id=\"设备\"><a href=\"#设备\" class=\"headerlink\" title=\"设备\"></a>设备</h2><h3 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/stat.h&gt;</span><br><span class=\"line\">#include &lt;fcntl.h&gt;</span><br><span class=\"line\">#include &lt;unistd.h&gt;</span><br><span class=\"line\">int mknod(const char *pathname, mode_t mode, dev_t dev);</span><br></pre></td></tr></table></figure>\n<p><code>mknod</code>用于创建一个设备。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/ioctl.h&gt;</span><br><span class=\"line\">int ioctl(int d, unsigned long request, ...);</span><br></pre></td></tr></table></figure>\n<p><code>ioctl</code>用于控制设备，常用于驱动编程。</p>\n<h3 id=\"特殊设备\"><a href=\"#特殊设备\" class=\"headerlink\" title=\"特殊设备\"></a>特殊设备</h3><p><code>/dev/null</code>是一个内容为空的设备，将IO流定向到<code>/dev/null</code>意味着丢弃其内容；</p>\n<p><code>/dev/zero</code>是一个无限长的文件；</p>\n<p><code>/dev/random</code>可用于产生随机数；</p>\n<p><code>/dev/tty*</code>是串行终端设备，如串口；</p>\n<p><code>pty</code>是伪终端，接受键盘的输入并显示到运行它的终端界面；</p>\n<p><code>pty</code>的实现涉及到两个概念：</p>\n<ul>\n<li><code>ptmx</code>：被连接的master主机；</li>\n<li><code>pts</code>：发起向master主机连接的slave主机<code>pts</code>，我们常用的SSH登录就意外着在master主机建立一个<code>pts</code>进程；</li>\n</ul>\n<h2 id=\"常用-proc简介\"><a href=\"#常用-proc简介\" class=\"headerlink\" title=\"常用/proc简介\"></a>常用/proc简介</h2><p><code>/proc/cpuinfo</code>查看cpu信息；</p>\n<p><code>/proc/meminfo</code>查看内存信息；</p>\n<p><code>/proc/self</code>查看自身信息；</p>\n<p><code>/proc/pid_number</code>查看pid为pid_number的进程信息；</p>\n<p><code>/proc/loadavg</code>查看负载信息；</p>\n<p><code>/proc/uptime</code>查看启动时间；</p>\n<p><code>/proc/interrupts</code>查看中断情况；</p>\n<h2 id=\"常用系统调用\"><a href=\"#常用系统调用\" class=\"headerlink\" title=\"常用系统调用\"></a>常用系统调用</h2><p><code>strace</code>查看系统调用情况；</p>\n<p><code>access</code>检测是否具备读写权限；<br><code>fcntl</code>操纵文件描述符；</p>\n<p><code>fsync</code>和<code>fdatasync</code>将缓冲区的文件改动同步到实际文件；</p>\n<p><code>getrlimit</code>取得系统的资源限定情况；</p>\n<p><code>getrusage</code>取得系统资源使用情况；</p>\n<p><code>gettimeofday</code>取得系统时间；</p>\n<p><code>mlock</code>锁住一块内存；</p>\n<p><code>mprotect</code>保护一块内存；</p>\n<h2 id=\"用户与用户组\"><a href=\"#用户与用户组\" class=\"headerlink\" title=\"用户与用户组\"></a>用户与用户组</h2><h3 id=\"用户与用户组ID\"><a href=\"#用户与用户组ID\" class=\"headerlink\" title=\"用户与用户组ID\"></a>用户与用户组ID</h3><p>每个用户名对应到一个用户ID，每个用户ID可从属于多个用户组ID。Shell下输入<code>id</code>得到如下输出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># uid为0表示root用户</span><br><span class=\"line\">uid=0(root) gid=0(root) groups=0(root),1001(nagcmd)</span><br></pre></td></tr></table></figure>\n<h3 id=\"文件与用户（组）的关系\"><a href=\"#文件与用户（组）的关系\" class=\"headerlink\" title=\"文件与用户（组）的关系\"></a>文件与用户（组）的关系</h3><p><code>ls -l APL.txt</code>后得到如下输出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rw-r--r-- 1 Jayzee None   1237 五月 18 12:19 APL.txt</span><br></pre></td></tr></table></figure>\n<p><code>-rw-r--r--</code>解释：</p>\n<ul>\n<li>第一个字符<code>-</code>表示这是一个文件，<code>d</code>表示这是一个文件夹；</li>\n<li>2至4字符<code>rw-</code>表示拥有者<code>Jayzee</code>的权限，顺序为：读（r）、写（w）、执行（x），可读写但不可执行；</li>\n<li>5至7字符<code>r--</code>表示所属组<code>None</code>的权限；</li>\n<li>8至10字符<code>r--</code>表示组外其他用户的权限；</li>\n</ul>\n<p><code>man chmod</code>查看如何更改文件的权限；<br><code>man chown</code>查看如何更改文件的拥有者和所属组；</p>\n<p><strong>特殊</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">drwxrwxrwt   1 root root 26416 5月  18 21:53 tmp</span><br></pre></td></tr></table></figure>\n<p>只适用于文件夹：当文件夹的所属组或组外的执行（x）被设置为（t）时，表示当且仅当你是该文件夹内文件的创建者，才可以删除该文件；（正常情况下如果该文件夹内文件的权限是对于组或组外可读写，不需要是文件的创建者也可删除的），这里的<code>t</code>称为sticky bits。</p>\n<h3 id=\"真实的用户ID和有效的用户ID\"><a href=\"#真实的用户ID和有效的用户ID\" class=\"headerlink\" title=\"真实的用户ID和有效的用户ID\"></a>真实的用户ID和有效的用户ID</h3><p>定义<code>euid</code>为有效用户id（effective），<code>uid</code>为真实用户id（real）；</p>\n<p><code>man 2 getuid</code>查看如何使用C函数获取uid；<br><code>man 2 geteuid</code>查看如何使用C函数获取euid；</p>\n<p>为什么要引入euid？</p>\n<ol>\n<li>当用户发出对文件的操作时，Linux Kernel根据用户的euid检查用户是否具备权限；</li>\n<li>euid可被修改，uid不可被修改；</li>\n<li>euid被修改代表着用户的切换，uid不被修改表示最初登入系统的uid不变；</li>\n</ol>\n<p>用户登录系统时用户id发生什么变化？</p>\n<ol>\n<li>Linux的登录进程检查登入者输入的账号密码是否正确；</li>\n<li>若正确，使用<code>exec</code>为其创建一个User Shell（pts）；</li>\n<li>Linux的登录进程设置这个User Shell的euid和uid为同一个值，即该用户的uid（只有euid为0的User Shell可设置euid和uid）；</li>\n</ol>\n<p>设置说明：</p>\n<ol>\n<li>当我们设置<code>euid = uid</code>时，表示返回到最初登录用户的Shell；</li>\n<li>当我们设置<code>uid = euid</code>时，表示Linux的登录进程将euid与uid同步，该登录用户与Linux的登录进程（root）再无联系；</li>\n</ol>\n<p><code>su</code>命令的原理：</p>\n<ol>\n<li><code>/bin/su</code>的拥有者为root，其执行项不是（x）而是（s），当文件拥有者的执行项不是（x）而是（s）时，此文件可被执行，且执行文件时调用<code>geteuid</code>函数返回的是该可执行文件拥有者的uid而不是调用者的euid；</li>\n<li>Linux利用此技术实现普通用户到root用户时，uid不变，而euid变为0；</li>\n<li>当调用<code>su</code>时，调用者原User Shell阻塞，Kernel创建一个新User Shell给调用者使用；</li>\n</ol>\n<p>注：组ID也分真实和有效，与用户ID类同，故不展开叙述；</p>\n","site":{"data":{}},"excerpt":"<p>《Advanced Linux Programing》读书笔记。</p>","more":"<h2 id=\"一些介绍\"><a href=\"#一些介绍\" class=\"headerlink\" title=\"一些介绍\"></a>一些介绍</h2><p>Linux Kernel</p>\n<ul>\n<li>硬件交互；</li>\n<li>内存管理；</li>\n<li>文件管理；</li>\n<li>多进程管理；</li>\n<li>共享库载入；</li>\n</ul>\n<p>GNU Project</p>\n<ul>\n<li>编辑器；</li>\n<li>编译器；</li>\n<li>Shell（/bin/bash，Bourne-Again SHell）；</li>\n</ul>\n<p>注意：</p>\n<ol>\n<li>Linux Kernel加GNU Project，构成了现在主流的Linux操作系统，所以应该称之为GNU/Linux；</li>\n<li>Linux操作系统只是UNIX的一种系统实现，其他类UNIX操作系统有FreeBSD、Solaris等；</li>\n</ol>\n<h2 id=\"Hello-World（快速了解）\"><a href=\"#Hello-World（快速了解）\" class=\"headerlink\" title=\"Hello, World（快速了解）\"></a>Hello, World（快速了解）</h2><h3 id=\"从文本到可执行程序\"><a href=\"#从文本到可执行程序\" class=\"headerlink\" title=\"从文本到可执行程序\"></a>从文本到可执行程序</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/** main.c **/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">sayHello</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, World\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    sayHello();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Shell下运行<code>gcc -o main main.c</code>即可得到可执行文件<code>main</code>，执行<code>./main</code>即可在控制台上看到<code>Hello, World</code>的输出。那么，它的原理是什么？从<code>main.c</code>到<code>main</code>，经历了以下步骤：</p>\n<ul>\n<li>main.c –&gt; main.i –&gt; main.s –&gt; main.o –&gt; main</li>\n<li>程序文本 + <strong>预处理器(cpp)</strong> –&gt; 被修改的源程序文本 + <strong>编译器(ccl)</strong> –&gt; 汇编文本 + <strong>汇编器(as)</strong> –&gt; 可重定向目标文件（二进制） + printf.o + <strong>链接器(ld)</strong> –&gt; main（可执行程序）</li>\n</ul>\n<p>对应到Shell下，经历了以下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -E main.c -o main.i</span><br><span class=\"line\">gcc -S main.i -o main.s --&gt; main.s</span><br><span class=\"line\">gcc -c main.s -o main.o --&gt; main.o</span><br><span class=\"line\">gcc main.o -o main --&gt; main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 上面4句等价于下面一句，gcc自动进行预处理、编译、汇编和链接</span></span><br><span class=\"line\">gcc main.c -o main</span><br></pre></td></tr></table></figure>\n<p><code>-E</code>进行预处理，将头文件插入C文件同时执行宏替换；<code>-S</code>用于生成汇编绘本；<code>-c</code>命令用于汇编；<code>-o</code>命令用于指定输出文件名称。</p>\n<h3 id=\"编写可用g-编译的c程序\"><a href=\"#编写可用g-编译的c程序\" class=\"headerlink\" title=\"编写可用g++编译的c程序\"></a>编写可用g++编译的c程序</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/** main.c **/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> __cplusplus</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"string\">\"C\"</span> &#123;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">sayHello</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> __cplusplus</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">sayHello</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, World\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    sayHello();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"其他常用gcc命令\"><a href=\"#其他常用gcc命令\" class=\"headerlink\" title=\"其他常用gcc命令\"></a>其他常用gcc命令</h3><ul>\n<li><code>-I</code>指定存放头文件的路径（相对或绝对路径）；</li>\n<li><code>-D</code>定义一个宏；</li>\n<li><code>-O</code>指定优化级别；</li>\n<li><code>-l</code>指定要链接的库；</li>\n<li><code>-L</code>指定搜索动态链接库的路径；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 生成可执行文件main</span></span><br><span class=\"line\"><span class=\"comment\"># 从绝对路径/root/搜索头文件</span></span><br><span class=\"line\"><span class=\"comment\"># 定义宏DEBUG</span></span><br><span class=\"line\"><span class=\"comment\"># 定义优化级别为2（0&lt;1&lt;2&lt;3，0表示不优化）</span></span><br><span class=\"line\"><span class=\"comment\"># 链接数学库m</span></span><br><span class=\"line\"><span class=\"comment\"># 在/usr/local/lib下查找数学库m的动态链接库</span></span><br><span class=\"line\">gcc main.c -o main -I /root/ -D DEBUG=2 -O2 -lm -L/usr/<span class=\"built_in\">local</span>/lib</span><br></pre></td></tr></table></figure>\n<h3 id=\"如何节省编译的工作\"><a href=\"#如何节省编译的工作\" class=\"headerlink\" title=\"如何节省编译的工作\"></a>如何节省编译的工作</h3><ol>\n<li>写MakeFile；</li>\n<li>使用autoconf、automake和libtool；</li>\n</ol>\n<p>简单的makefile举例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main.o: main.c</span><br><span class=\"line\">        gcc -c main.c -o main.o</span><br><span class=\"line\"></span><br><span class=\"line\">all: main</span><br><span class=\"line\"></span><br><span class=\"line\">main: main.o</span><br><span class=\"line\">        gcc main.o -o main</span><br><span class=\"line\"></span><br><span class=\"line\">clean:</span><br><span class=\"line\">        rm main.o main</span><br></pre></td></tr></table></figure>\n<p>如何使用这个makefile：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 编译（把all换成main效果一致）</span></span><br><span class=\"line\"><span class=\"comment\"># 方法1：用-f指定makefile文件</span></span><br><span class=\"line\">make -f makefile all</span><br><span class=\"line\"><span class=\"comment\"># 方法2：不指定makefile文件，默认会在当前文件夹寻找</span></span><br><span class=\"line\"><span class=\"comment\"># 按顺序寻找文件GNUmakefile--&gt;makefile--&gt;Makefile，找不到则报错</span></span><br><span class=\"line\">make all</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 清除编译结果，以下二选一</span></span><br><span class=\"line\">make clean</span><br><span class=\"line\">make -f makefile clean</span><br></pre></td></tr></table></figure>\n<p>makefile的基本组成如下（<strong>command必须以一个tab开始</strong>）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># target表示目标体，它位于冒号之前</span><br><span class=\"line\"># dependency_files表示依赖的文件或target，它位于冒号之后</span><br><span class=\"line\"># command表示达成这个目标所需执行命令</span><br><span class=\"line\">target: dependency_files</span><br><span class=\"line\">        command</span><br></pre></td></tr></table></figure>\n<p>makefile里面也可定义和调用变量：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CC=gcc</span><br><span class=\"line\">EXE=main</span><br><span class=\"line\"></span><br><span class=\"line\">main.o: main.c</span><br><span class=\"line\">        $(CC) -c main.c -o main.o</span><br><span class=\"line\"></span><br><span class=\"line\">all: $(EXE)</span><br><span class=\"line\"></span><br><span class=\"line\">$(EXE): main.o</span><br><span class=\"line\">        gcc main.o -o $(EXE)</span><br><span class=\"line\"></span><br><span class=\"line\">clean:</span><br><span class=\"line\">        rm main.o $(EXE)</span><br></pre></td></tr></table></figure>\n<p>也可在外部调用时传入变量（会将makefile中已存在的变量覆盖掉），命令如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make EXE=mm all</span><br><span class=\"line\">make EXE=mm clean</span><br></pre></td></tr></table></figure>\n<h3 id=\"使用GDB调试程序简介\"><a href=\"#使用GDB调试程序简介\" class=\"headerlink\" title=\"使用GDB调试程序简介\"></a>使用GDB调试程序简介</h3><p>使用<code>gdb 程序名（相对或绝对路径）</code>进入gdb：</p>\n<ol start=\"2\">\n<li>输入<code>break main</code>为main函数设置断点，输入<code>break main.c:5</code>为<code>main.c</code>的第5行设置断点；</li>\n<li>输入<code>i b</code>查看当前断点；</li>\n<li>输入<code>delete 1</code>删除第一个断点；</li>\n<li>输入<code>disable 1</code>停用第一个断点；</li>\n<li>输入<code>list main.c:5</code>可在gdb显示代码；</li>\n<li>输入<code>r</code>或<code>run</code>运行，这时用户将无法再输入命令，直到运行到断点时，gdb将交回命令行控制权，这时输入<code>n</code>或<code>next</code>表示运行到下一行，<code>s</code>或<code>step</code>表示进入当前行调用的函数，输入<code>return</code>返回到上一层函数；</li>\n<li>gdb交回命令行控制权时，输入<code>print 参数名</code>可查看当前作用域内的具体参数值；</li>\n<li>假如程序意外退出，这时输入<code>where</code>、<code>bt</code>或<code>backtrace</code>可以查看错误堆栈；</li>\n</ol>\n<h3 id=\"如何查看帮助手册\"><a href=\"#如何查看帮助手册\" class=\"headerlink\" title=\"如何查看帮助手册\"></a>如何查看帮助手册</h3><p>终端下输入<code>man 命令名称</code>（如<code>man printf</code>）将看到如下提示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Man: 寻找所有匹配的手册页 (set MAN_POSIXLY_CORRECT to avoid this)</span><br><span class=\"line\"> * printf (1)</span><br><span class=\"line\">   printf (3)</span><br><span class=\"line\">   printf (1p)</span><br><span class=\"line\">   printf (3p)</span><br><span class=\"line\">Man: 您需要什么手册页？</span><br><span class=\"line\">Man:</span><br></pre></td></tr></table></figure>\n<ol>\n<li>数字1表示这是一个用户命令（user commands，如<strong>echo</strong>）；</li>\n<li>数字2表示这是一个系统调用（system calls，如<strong>fork</strong>）；</li>\n<li>数字3表示这是一个标准库（stand library，如<strong>printf</strong>）；</li>\n<li>带p后缀的为POSIX标准，释义：POSIX标准定义了操作系统应该为应用程序提供的接口标准，一个POSIX兼容的操作系统编写的程序，应该可以在任何其它的POSIX操作系统（即使是来自另一个厂商）上编译执行；</li>\n</ol>\n<h2 id=\"编程实践\"><a href=\"#编程实践\" class=\"headerlink\" title=\"编程实践\"></a>编程实践</h2><h3 id=\"环境交互\"><a href=\"#环境交互\" class=\"headerlink\" title=\"环境交互\"></a>环境交互</h3><ol>\n<li>临时文件（用于暂时存放数据），使用下述命令查看具体用途<ul>\n<li><code>man mkstemp</code></li>\n<li><code>man tmpfile</code></li>\n</ul>\n</li>\n<li>环境变量（设置运行环境）<ul>\n<li>shell下<code>echo $USER</code>或<code>printenv USER</code>打印环境变量<code>USER</code>；</li>\n<li>shell下<code>export USER=jayzee</code>设置环境变量<code>USER</code>为<code>jayzee</code>；</li>\n<li>shell下<code>env</code>查询当前用户所有环境变量；</li>\n<li>Linux下调用一个C/C++程序时，该程序继承其调用者的所有环境变量，标准库<code>stdlib.h</code>的<code>getenv</code>、<code>setenv</code>和<code>unsetenv</code>用于获取、操纵环境变量；</li>\n</ul>\n</li>\n<li>shell下调用程序结束后，使用<code>echo $?</code>获取程序退出代码（0表示正常）；</li>\n<li>IO（输入输出流）<ul>\n<li>程序中，宏<code>stdin</code>表示输入流，对应int值0；宏<code>stdout</code>表示标准输出流，对应int值1；宏<code>stderr</code>表示错误输出流，对应int值2；</li>\n<li><code>stdin</code>只能是buffered的，但其buffered size可以修改；</li>\n<li><code>stderr</code>只能是unbuffered，一有错误立即输出；</li>\n<li>当程序直接在shell调用并且直接输出到控制台时，<code>stdout</code>是line-buffered的，否则是buffered的，但其buffered size可以修改，<code>man setvbuf</code>查看标准库如何设置输入输出流；</li>\n<li>程序写文件也是默认buffered，写完后应使用<code>fflush(your_file)</code>立即清空buffer写入到文件；</li>\n<li>shell命令<code>your_program &gt; output_file.txt 2&gt;&amp;1</code>表示将<code>your_program</code>的标准输出写入到文件<code>output_file.txt</code>（<code>&gt;</code>执行覆盖写，<code>&gt;&gt;</code>执行追加写），并且将错误输出流重定向到标准输出流，Linux规定文件名必须在流重定向之前；</li>\n<li>shell命令<code>program 2&gt;&amp;1 | filter</code>表示将标准输出使用管道过滤，Linux规定重定向必须在过滤器之前；</li>\n</ul>\n</li>\n<li><code>man getopt_long</code>查看<code>getopt.h</code>库如何处理程序参数（类似于<code>ls -l</code>的<code>-l</code>）；</li>\n</ol>\n<h3 id=\"好的编程习惯\"><a href=\"#好的编程习惯\" class=\"headerlink\" title=\"好的编程习惯\"></a>好的编程习惯</h3><p>使用断言assert：</p>\n<ul>\n<li>所有需确认值为true或非0的需使用<code>assert(condition)</code>；</li>\n<li>编译时指定<code>-DNDEBUG</code>可移除所有assert语句，所以<strong>千万不要把程序的重要逻辑放在assert语句中</strong>；</li>\n</ul>\n<p>处理系统调用失败：</p>\n<ul>\n<li>系统调用如<code>fork</code>失败时会返回非零值，这时宏<code>errno</code>会被设置，下次系统调用失败时又会覆盖这个宏的值；</li>\n<li><code>man strerror</code>查看如何使用<code>string.h</code>的<code>strerror</code>的具体字符串释义，细节如下：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EINTR : blocking function interrupt, like sleep, read, select</span><br><span class=\"line\">EPERM : Permission denied</span><br><span class=\"line\">EROFS : PATH is on a read-only file system</span><br><span class=\"line\">ENAMETOOLONG : PATH is too long</span><br><span class=\"line\">ENOENT : PATH does not exit</span><br><span class=\"line\">ENOTDIR : A component of PATH is not a directory</span><br><span class=\"line\">EACCES : A component of PATH is not accessible</span><br><span class=\"line\">EFAULT : PATH contains an invalid memory address.  This is probably a bug</span><br><span class=\"line\">ENOMEM : Ran out of kernel memory</span><br></pre></td></tr></table></figure>\n<p>申请内存与释放内存：</p>\n<ul>\n<li>申请内存与释放内存的语句必须成对，即有申请内存则相应的要有释放内存；</li>\n</ul>\n<h3 id=\"链接程序（库：快速开发，软件复用）\"><a href=\"#链接程序（库：快速开发，软件复用）\" class=\"headerlink\" title=\"链接程序（库：快速开发，软件复用）\"></a>链接程序（库：快速开发，软件复用）</h3><p>以下文字部分引用自<a href=\"http://www.cnblogs.com/skynet/p/3372855.html\" target=\"_blank\" rel=\"noopener\">C++静态库与动态库 - 吴秦 - 博客园</a>，向该作者致敬。</p>\n<p>下文用到的main.c文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/** main.c **/</span><br><span class=\"line\">int add(int x, int y) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">return</span> x + y;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"静态链接\"><a href=\"#静态链接\" class=\"headerlink\" title=\"静态链接\"></a>静态链接</h4><p>静态库的特点：</p>\n<ul>\n<li>静态库对函数库的链接是放在编译时期完成的；</li>\n<li>程序在运行时与函数库再无瓜葛，移植方便；</li>\n<li>浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件；</li>\n</ul>\n<p>静态库的创建：</p>\n<ul>\n<li>静态库的命名规范为lib[your_library_name].a：lib为前缀，中间是静态库名，扩展名为.a；</li>\n<li>首先将代码文件编译成目标文件.o，再通过ar工具将目标文件打包.a静态库文件；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 假定有一个math.c文件，提供加法函数int add(int x, int y)，我们现在将其打包成静态库</span></span><br><span class=\"line\">gcc -c math.c -o math.o</span><br><span class=\"line\">ar -crv libmath.a math.o</span><br></pre></td></tr></table></figure>\n<p>使用静态库：</p>\n<ul>\n<li>在编译时指定静态库搜索路径（-L选项）、指定静态库名称（不需要lib前缀和.a后缀，-l选项）；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -l为什么一定要放在末尾？它会去查找库的所有被引用的函数或宏等并插入到最终的可执行程序，放在末尾是为了这种依赖搜索在最后执行</span></span><br><span class=\"line\">gcc main.c -o main -Lfilepath_of_your_static_library -lmath</span><br></pre></td></tr></table></figure>\n<p>静态库优缺点：</p>\n<ul>\n<li>优点：编译成可执行文件后与其编译时引用的静态库再无任何瓜葛；</li>\n<li>缺点：导致可执行程序体量庞大，同一个操作系统上运行的多个程序引用同一个静态库会导致内存浪费（相同的代码），导致客户的全量更新；</li>\n</ul>\n<h4 id=\"动态链接\"><a href=\"#动态链接\" class=\"headerlink\" title=\"动态链接\"></a>动态链接</h4><p>动态库的特点：</p>\n<ul>\n<li>动态库把对一些库函数的链接载入推迟到程序运行的时期；</li>\n<li>可以实现进程之间的资源共享（因此动态库也称为共享库）；</li>\n<li>将一些程序升级变得简单；</li>\n<li>甚至可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）；</li>\n</ul>\n<p>动态库的创建：</p>\n<ul>\n<li>动态库的命名规范为lib[your_library_name].so：lib为前缀，中间是动态库名，扩展名为.so；</li>\n<li>首先将代码文件编译成目标文件.o，再通过gcc工具将目标文件打包.so动态库文件；<ul>\n<li><code>-fPIC</code>创建与地址无关的编译程序（pic，position independent code），是为了能够在多个应用程序间共享；</li>\n<li><code>-shared</code>指定生成动态链接库；</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 假定有一个math.c文件，提供加法函数int add(int x, int y)，我们现在将其打包成动态库</span></span><br><span class=\"line\">gcc -fPIC -c math.c -o math.o</span><br><span class=\"line\">gcc -shared -o libmath.so math.o</span><br><span class=\"line\"><span class=\"comment\"># 上面两条命令等价于</span></span><br><span class=\"line\">gcc -fPIC -shared -o libmath.so math.c</span><br></pre></td></tr></table></figure>\n<p>使用动态库：</p>\n<ul>\n<li>在编译时指定动态库搜索路径（-L选项）、指定动态库名称（不需要lib前缀和.so后缀，-l选项）；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc main.c -o main -Lfilepath_of_your_static_library -lmath</span><br></pre></td></tr></table></figure>\n<ul>\n<li>注意，运行上述生成的可执行文件时，操作系统会去一些指定路径查找并载入该动态库，如查找不到将抛出找不到动态库的异常信息，这些指定路径是：<ul>\n<li>环境变量LD_LIBRARY_PATH，如<code>LD_LIBRARY_PATH=/usr/local/lib:/opt/lib</code>；</li>\n<li>/etc/ld.so.cache文件列表，需要额外操作如下：<ul>\n<li>编辑/etc/ld.so.conf文件，加入库文件所在目录的路径；</li>\n<li>运行ldconfig ，该命令会重建/etc/ld.so.cache文件；</li>\n</ul>\n</li>\n<li>/lib/，/usr/lib目录；</li>\n</ul>\n</li>\n<li><code>-L</code>指定的库搜索路径下即有动态库也有静态库，则动态库具有较高优先级被链接；</li>\n</ul>\n<p>动态库优缺点：</p>\n<ul>\n<li>缺点：增量更新必须考虑向后兼容；</li>\n<li>优点：增量更新，避免内存浪费（同一个操作系统上运行的多个程序引用同一个动态库只需要一份共享库示例）；</li>\n</ul>\n<h4 id=\"链接检查辅助命令\"><a href=\"#链接检查辅助命令\" class=\"headerlink\" title=\"链接检查辅助命令\"></a>链接检查辅助命令</h4><p><code>nm</code>命令：打印出库中的涉及到的所有符号。库既可以是静态的也可以是动态的。nm列出的符号有很多，常见的有三种，</p>\n<ul>\n<li>一种是在库中被调用，但并没有在库中定义(表明需要其他库支持)，用U表示；</li>\n<li>一种是库中定义的函数，用T表示，这是最常见的；</li>\n<li>一种是所谓的弱态”符号，它们虽然在库中被定义，但是可能被其他库中的同名符号覆盖，用W表示；</li>\n</ul>\n<p><code>ldd</code>命令：查看一个可执行程序依赖的共享库。</p>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><p>本章节部分内容引用自<a href=\"http://www.cnblogs.com/hicjiajia/archive/2011/01/20/1940154.html\" target=\"_blank\" rel=\"noopener\">Linux下Fork与Exec使用 - hicjiajia - 博客园</a>和<a href=\"http://www.ibm.com/developerworks/cn/linux/kernel/syscall/part3/index.html\" target=\"_blank\" rel=\"noopener\">系统调用跟我学(3)</a>，向作者致敬。</p>\n<h3 id=\"进程查看\"><a href=\"#进程查看\" class=\"headerlink\" title=\"进程查看\"></a>进程查看</h3><p><code>pid</code>指进程id，<code>ppid</code>指父进程id。</p>\n<ol>\n<li>Linux所有<strong>用户进程</strong>呈树状结构，这棵用户进程树的根节点是init进程（内核启动的第一个用户级进程），init进程的<code>pid</code>为1，其ppid为0；</li>\n<li>shell下运行<code>ps -e -o pid,ppid,command</code>可查看所有用户进程的pid、ppid和command；</li>\n<li><code>unistd.h</code>提供<code>getpid()</code>和<code>getppid()</code>获取进程的ID和父ID；</li>\n</ol>\n<h3 id=\"进程创建\"><a href=\"#进程创建\" class=\"headerlink\" title=\"进程创建\"></a>进程创建</h3><h4 id=\"system函数：执行shell命令\"><a href=\"#system函数：执行shell命令\" class=\"headerlink\" title=\"system函数：执行shell命令\"></a>system函数：执行shell命令</h4><p>system函数用于在C/C++语言中执行shell命令，其API如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#include &lt;stdlib.h&gt;</span></span><br><span class=\"line\">int system(const char *<span class=\"built_in\">command</span>);</span><br></pre></td></tr></table></figure>\n<p>其具体实现是：</p>\n<ol>\n<li>先执行系统调用<code>fork()</code>创建子进程；</li>\n<li>再执行<code>execl(&quot;/bin/sh&quot;, &quot;sh&quot;. &quot;-c&quot;, command, (char *) 0);</code>去调用shell执行command；</li>\n</ol>\n<h4 id=\"fork函数，exec族函数\"><a href=\"#fork函数，exec族函数\" class=\"headerlink\" title=\"fork函数，exec族函数\"></a>fork函数，exec族函数</h4><h5 id=\"fork函数：创建子进程，进程分叉\"><a href=\"#fork函数：创建子进程，进程分叉\" class=\"headerlink\" title=\"fork函数：创建子进程，进程分叉\"></a>fork函数：创建子进程，进程分叉</h5><p>fork函数API如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#include &lt;unistd.h&gt;</span></span><br><span class=\"line\">pid_t fork(void);</span><br></pre></td></tr></table></figure>\n<p>fork函数的特点：</p>\n<ul>\n<li>fork调用之后，父进程进入<code>pid&gt;0</code>的分支，子进程进入<code>pid==0</code>的分支；</li>\n<li>fork创建的子进程是父进程的一个完整拷贝，<strong>当且仅当fork之后的代码即将开始更新内存，真实的拷贝才会发生</strong>（也就是上述例子并没有发生拷贝），为什么这么设计，我们会在下面讲到；</li>\n<li>fork创建的子进程拥有一个新的进程pid号，子进程的ppid为调用fork函数的进程id；</li>\n</ul>\n<p>pid_t是一个整型变量。具体示例如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* zombie.c */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/types.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pid_t</span> pid;</span><br><span class=\"line\">    pid=fork();</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(pid&lt;<span class=\"number\">0</span>) <span class=\"comment\">/* 如果出错 */</span></span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"error occurred!\\n\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(pid==<span class=\"number\">0</span>) <span class=\"comment\">/* 如果是子进程 */</span></span><br><span class=\"line\">        <span class=\"built_in\">exit</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"comment\">/* 如果是父进程 */</span></span><br><span class=\"line\">        sleep(<span class=\"number\">60</span>); <span class=\"comment\">/* 休眠60秒，这段时间里，父进程什么也干不了 */</span></span><br><span class=\"line\">    wait(<span class=\"literal\">NULL</span>); <span class=\"comment\">/* 收集僵尸进程 */</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"exec函数族：对当前进程进行替换\"><a href=\"#exec函数族：对当前进程进行替换\" class=\"headerlink\" title=\"exec函数族：对当前进程进行替换\"></a>exec函数族：对当前进程进行替换</h5><p>exec并不是一个具体函数，它是以下六个函数：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execl</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *path, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *arg, ...)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execlp</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *file, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *arg, ...)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execle</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *path, <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *arg, ..., <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> envp[])</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execv</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *path, <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv[])</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execvp</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *file, <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv[])</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">execve</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *path, <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv[], <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> envp[])</span></span>;</span><br></pre></td></tr></table></figure>\n<p>其中<code>execl</code>是基函数，其他5个是它的变种（区别在于传参形式不同，带v的表示参数以数组传递，带l的表示参数以陈列的方式传递）。</p>\n<p>exec函数族特点：</p>\n<ul>\n<li>只保留当前进程的pid，其他进程相关的数据段全部废弃；对系统而言，还是同一个进程号，但其实已经是另外一个程序了，即调用exec函数族的进程已“死亡”了；</li>\n<li>上面说到，fork的数据拷贝只发生在子进程更新内存时，fork调用后立即执行exec函数族使得我们能够产生一个全新的进程（<strong>这意味着当前进程的所有线程、文件描述符等都被释放</strong>），与fork调用进程再无任何瓜葛；</li>\n</ul>\n<p>举一个具体例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;errno.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">char</span> command[<span class=\"number\">256</span>];</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">   <span class=\"keyword\">int</span> rtn; <span class=\"comment\">/*子进程的返回数值*/</span></span><br><span class=\"line\">   <span class=\"keyword\">while</span>(<span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">       <span class=\"comment\">/* 从终端读取要执行的命令 */</span></span><br><span class=\"line\">       <span class=\"built_in\">printf</span>( <span class=\"string\">\"&gt;\"</span> );</span><br><span class=\"line\">       fgets( command, <span class=\"number\">256</span>, <span class=\"built_in\">stdin</span> );</span><br><span class=\"line\">       command[<span class=\"built_in\">strlen</span>(command)<span class=\"number\">-1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> ( fork() == <span class=\"number\">0</span> ) &#123;<span class=\"comment\">/* 子进程执行此命令 */</span></span><br><span class=\"line\">          execlp( command, <span class=\"literal\">NULL</span> );</span><br><span class=\"line\">          <span class=\"comment\">/* 如果exec函数返回，表明没有正常执行命令，打印错误信息*/</span></span><br><span class=\"line\">          perror( command );</span><br><span class=\"line\">          <span class=\"built_in\">exit</span>( errno );</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">else</span> &#123;<span class=\"comment\">/* 父进程， 等待子进程结束，并打印子进程的返回值 */</span></span><br><span class=\"line\">          wait ( &amp;rtn );</span><br><span class=\"line\">          <span class=\"built_in\">printf</span>( <span class=\"string\">\" child process return %d\\n\"</span>, rtn );</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"信号处理\"><a href=\"#信号处理\" class=\"headerlink\" title=\"信号处理\"></a>信号处理</h3><p>信号是一种异步的进程通信机制，是软件层面的中断，进程接收到线程必须进行处理，有以下三种处理方式：</p>\n<ul>\n<li>使用进程对信号的静默处理；</li>\n<li>忽略该信号；</li>\n<li>使用特定的信号处理函数进行处理；</li>\n</ul>\n<p>上述的后两种方式需要使用<code>signal()</code>函数进行处理，举例如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 忽略SIGPIPE信号</span></span><br><span class=\"line\">signal ( SIGPIPE, SIG_IGN );</span><br><span class=\"line\"><span class=\"comment\">// 使用PrepareExit处理SIGINT信号</span></span><br><span class=\"line\">signal ( SIGINT, (<span class=\"keyword\">__sighandler_t</span> ) PrepareExit );</span><br></pre></td></tr></table></figure>\n<p>Linux的信号如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">信号值 默认处理动作 发出信号的原因</span><br><span class=\"line\">SIGHUP 1 A 终端挂起或者控制进程终止</span><br><span class=\"line\">SIGINT 2 A 键盘中断（如break键被按下）</span><br><span class=\"line\">SIGQUIT 3 C 键盘的退出键被按下</span><br><span class=\"line\">SIGILL 4 C 非法指令</span><br><span class=\"line\">SIGABRT 6 C 由abort(3)发出的退出指令</span><br><span class=\"line\">SIGFPE 8 C 浮点异常</span><br><span class=\"line\">SIGKILL 9 AEF Kill信号</span><br><span class=\"line\">SIGSEGV 11 C 无效的内存引用</span><br><span class=\"line\">SIGPIPE 13 A 管道破裂: 写一个没有读端口的管道</span><br><span class=\"line\">SIGALRM 14 A 由alarm(2)发出的信号</span><br><span class=\"line\">SIGTERM 15 A 终止信号</span><br><span class=\"line\">SIGUSR1 30,10,16 A 用户自定义信号1</span><br><span class=\"line\">SIGUSR2 31,12,17 A 用户自定义信号2</span><br><span class=\"line\">SIGCHLD 20,17,18 B 子进程结束信号</span><br><span class=\"line\">SIGCONT 19,18,25 进程继续（曾被停止的进程）</span><br><span class=\"line\">SIGSTOP 17,19,23 DEF 终止进程</span><br><span class=\"line\">SIGTSTP 18,20,24 D 控制终端（tty）上按下停止键</span><br><span class=\"line\">SIGTTIN 21,21,26 D 后台进程企图从控制终端读</span><br><span class=\"line\">SIGTTOU 22,22,27 D 后台进程企图从控制终端写</span><br><span class=\"line\"></span><br><span class=\"line\">处理动作一项中的字母含义如下：</span><br><span class=\"line\">A 缺省的动作是终止进程</span><br><span class=\"line\">B 缺省的动作是忽略此信号，将该信号丢弃，不做处理</span><br><span class=\"line\">C 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序</span><br><span class=\"line\">D 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用）</span><br><span class=\"line\">E 信号不能被捕获</span><br><span class=\"line\">F 信号不能被忽略</span><br></pre></td></tr></table></figure>\n<p><strong>注意</strong>：<br>信号处理函数可被新产生的信号所中断，所以信号处理函数应该做尽可能少的工作；</p>\n<h3 id=\"进程终止\"><a href=\"#进程终止\" class=\"headerlink\" title=\"进程终止\"></a>进程终止</h3><h4 id=\"信号终止\"><a href=\"#信号终止\" class=\"headerlink\" title=\"信号终止\"></a>信号终止</h4><ol>\n<li><code>SIGINT</code>：CRTL+C产生；</li>\n<li><code>SIGTERM</code>：shell下<code>kill pid</code>产生；</li>\n<li><code>abort()</code>：发送一个<code>SIGABRT</code>信号给自己；</li>\n<li><code>SIGKILL</code>：强制退出信号，shell下<code>kill -9 pid</code>产生；</li>\n</ol>\n<p>当进程终止时，shell调用<code>echo $?</code>可取得该进程的exit code，</p>\n<ul>\n<li>如果该进程由信号终止，exit code为128加上信号值；</li>\n<li>调用<code>exit(int exit_code)</code>函数退出，exit_code的范围需在0到128之间；</li>\n</ul>\n<p>如何给进程发送指定信号，</p>\n<ul>\n<li>在shell下使用<code>kill -s SIGNAL_NAME pid</code>，可以给进程pid发送SIGNAL_NAME信号；</li>\n<li>程序使用<code>kill(pid, SIGNAL_NAME)</code>函数；</li>\n</ul>\n<h4 id=\"wait\"><a href=\"#wait\" class=\"headerlink\" title=\"wait\"></a>wait</h4><p>Unix的进程终止时，一些资源（如进程pid、进程exit code、收到的信号、占用CPU时间等）并不会被立即释放（堆栈等内存立即释放），死亡进程的父进程必须调用<code>wait</code>函数对进程进行“收尸”，即释放进程的pid和exit code等资源。</p>\n<p><code>wait</code>函数的API定义如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">pid_t</span> wait(<span class=\"keyword\">int</span> *status);</span><br></pre></td></tr></table></figure>\n<p>一些说明：</p>\n<ul>\n<li><code>wait</code>函数是阻塞式的，在子进程未结束时将阻塞；</li>\n<li>如果<code>pid_t</code>为-1，表明<code>wait</code>调用失败，这是因为调用进程没有子进程导致；否则，表明收集子进程“死亡”信息成功，<code>pid_t</code>的值为“死亡”进程pid；</li>\n<li><code>status</code>是一个指针，如果这个指针为空，表明我们不关心进程的“死亡”信息细节，只是发起了回收这个动作；否则，status将包含进程“死亡”的一些信息；</li>\n<li>调用<code>WIFEXITED(status)</code>，若返回值回0表明进程异常退出（如信号导致退出），这时调用<code>WTERMSIG(status)</code>将得到使进程死亡的信号int值；否则表示程序正常退出，这时候调用<code>WEXITSTATUS(status)</code>可获取“死亡”进程的exit code（如“死亡”进程调用<code>exit(7)</code>退出，则<code>WEXITSTATUS(status)</code>的结果为7）；</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* wait2.c */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/types.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/wait.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> status;</span><br><span class=\"line\">    <span class=\"keyword\">pid_t</span> pc,pr;</span><br><span class=\"line\">    pc=fork();</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(pc&lt;<span class=\"number\">0</span>)     <span class=\"comment\">/* 如果出错 */</span></span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"error ocurred!\\n\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(pc==<span class=\"number\">0</span>)&#123; <span class=\"comment\">/* 子进程 */</span></span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"This is child process with pid of %d.\\n\"</span>,getpid());</span><br><span class=\"line\">        <span class=\"built_in\">exit</span>(<span class=\"number\">3</span>);    <span class=\"comment\">/* 子进程返回3 */</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>&#123;       <span class=\"comment\">/* 父进程 */</span></span><br><span class=\"line\">        pr=wait(&amp;status);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(WIFEXITED(status))&#123;  <span class=\"comment\">/* 如果WIFEXITED返回非零值 */</span></span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"the child process %d exit normally.\\n\"</span>,pr);</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"the return code is %d.\\n\"</span>,WEXITSTATUS(status));</span><br><span class=\"line\">        &#125;<span class=\"keyword\">else</span>           <span class=\"comment\">/* 如果WIFEXITED返回零，这时pr存储死亡进程pid */</span></span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"the child process %d exit abnormally with signal number %d.\\n\"</span>,pr,WTERMSIG(status));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"僵尸进程\"><a href=\"#僵尸进程\" class=\"headerlink\" title=\"僵尸进程\"></a>僵尸进程</h4><p>如果子进程死亡，父进程却没有调用<code>wait</code>对其进行“收尸”，子进程就会变成一个僵尸进程，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ps -ax</span><br><span class=\"line\">  PID TTY      STAT   TIME COMMAND</span><br><span class=\"line\"> 1177 pts/0    S      0:00 -bash</span><br><span class=\"line\"> 1577 pts/0    S      0:00 ./zombie</span><br><span class=\"line\"> 1578 pts/0    Z      0:00 [zombie &lt;defunct&gt;]</span><br><span class=\"line\"> 1579 pts/0    R      0:00 ps -ax</span><br></pre></td></tr></table></figure>\n<p>若STAT为Z则表明则是一个僵尸进程，关于僵尸进程，</p>\n<ul>\n<li>在父进程退出时，init进程会自动对其下的所有僵尸子进程进行清理；</li>\n<li>子进程意外死亡时，父进程会受到一个SIGCHLD信号，父进程可以注册这个信号的处理函数进行“收尸”；</li>\n<li><code>wait3</code>和<code>wait4</code>函数为异步的，可以周期调用这两个函数执行回收；</li>\n</ul>\n<h2 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h2><h3 id=\"线程创建\"><a href=\"#线程创建\" class=\"headerlink\" title=\"线程创建\"></a>线程创建</h3><p><strong>线程创建</strong>：<code>int pthread_create(pthread_t *thread, const pthread_attr_t *attr,\nvoid *(*start_routine) (void *), void *arg);</code></p>\n<ul>\n<li><code>pthread_create</code>的返回值为0表示创建线程成功；</li>\n<li><code>thread</code>是指向<code>pthread_t</code>的指针；</li>\n<li><code>pthread_attr_t</code>在下一个例子介绍；</li>\n<li><code>start_routine</code>是一个无形参且无返回值的函数指针；</li>\n<li><code>arg</code>是上面提到的函数指针所接收的参数；</li>\n</ul>\n<p><strong>线程回收</strong>：<code>int pthread_join(pthread_t thread, void **retval);</code></p>\n<ul>\n<li><code>retval</code>实际上是一个指向整型指针的指针，它存放的是线程调用<code>exit</code>或<code>pthread_exit</code>的退出值；</li>\n<li><code>When a joinable thread terminates, its memory resources (thread descriptor and stack) are not deallocated until another thread performs pthread_join on it. Therefore, pthread_join must be called  once  for each joinable thread created to avoid memory leaks.</code></li>\n<li>这是一个阻塞式的方法，当监控到有线程结束时才返回；</li>\n</ul>\n<p><strong>线程退出</strong>：<code>void pthread_exit(void *retval);</code></p>\n<ul>\n<li><code>retval</code>实际是一个整型指针，在退出时标识线程的退出值；</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> code = <span class=\"number\">11</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">hello</span><span class=\"params\">(<span class=\"keyword\">void</span> *args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *str = (<span class=\"keyword\">char</span> *) args;</span><br><span class=\"line\">    sleep(<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, %s!\\n\"</span>, str);</span><br><span class=\"line\">    pthread_exit(&amp;code);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> thread;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> status = pthread_create(&amp;thread, <span class=\"literal\">NULL</span>, (<span class=\"keyword\">void</span> *)hello, (<span class=\"keyword\">void</span> *) <span class=\"string\">\"Jayzee\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread create status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *exit_code = <span class=\"number\">0</span>;</span><br><span class=\"line\">    status = pthread_join(thread, (<span class=\"keyword\">void</span> *) &amp;exit_code);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread join status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread exit code : %d\\n\"</span>, *exit_code);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<hr>\n<p>下面的例子在<code>pthread_create</code>时用到了<code>pthread_attr_t</code>，必须经历下面四个过程</p>\n<ol>\n<li>先实例化<code>pthread_attr_t</code>；</li>\n<li>再设置<code>pthread_attr_t</code>；</li>\n<li>在线程创建时使用该<code>pthread_attr_t</code>；</li>\n<li>线程创建完后销毁<code>pthread_attr_t</code>；</li>\n</ol>\n<p>注意：</p>\n<ol>\n<li>创建线程时设置其为detach态，意味着我们不关心它的返回值，只是进行线程相关资源回收；</li>\n<li>也可创建线程时不指定detach态，在线程创建后可使用<code>int pthread_detach(pthread_t thread);</code>设置其为detach态；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> code = <span class=\"number\">11</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">hello</span><span class=\"params\">(<span class=\"keyword\">void</span> *args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *str = (<span class=\"keyword\">char</span> *) args;</span><br><span class=\"line\">    sleep(<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, %s!\\n\"</span>, str);</span><br><span class=\"line\">    pthread_exit(&amp;code);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> thread;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_attr_t</span> attr;</span><br><span class=\"line\">    pthread_attr_init (&amp;attr);</span><br><span class=\"line\">    pthread_attr_setdetachstate (&amp;attr, PTHREAD_CREATE_DETACHED);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> status = pthread_create (&amp;thread, &amp;attr, (<span class=\"keyword\">void</span> *)hello, (<span class=\"keyword\">void</span> *) <span class=\"string\">\"Jayzee\"</span>);</span><br><span class=\"line\">    pthread_attr_destroy (&amp;attr);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread create status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"线程取消\"><a href=\"#线程取消\" class=\"headerlink\" title=\"线程取消\"></a>线程取消</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_setcancelstate(int state, int *oldstate);</span><br><span class=\"line\">int pthread_setcanceltype(int type, int *oldtype);</span><br><span class=\"line\">int pthread_cancel(pthread_t thread);</span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>pthread_setcancelstate</code>在运行时设置线程的状态<code>state</code>，并取得其之前的状态<code>oldstate</code>；</li>\n<li><code>pthread_setcanceltype</code>在运行时设置线程的类型<code>type</code>，并取得其之前的类型<code>oldtype</code>；</li>\n<li><code>pthread_cancel</code>用于取消线程的执行；</li>\n</ul>\n<p>注意，</p>\n<ol>\n<li>type：<code>PTHREAD_CANCEL_DEFERRED</code>或<code>PTHREAD_CANCEL_ASYNCHRONOUS</code></li>\n<li>state：<code>PTHREAD_CANCEL_ENABLE</code>或<code>PTHREAD_CANCEL_DISABLE</code></li>\n<li>type和state作用于<code>pthread_cancel</code>：<ul>\n<li>当state为<code>PTHREAD_CANCEL_DISABLE</code>时，设置的type和调用<code>pthread_cancel</code>不会对线程造成任何影响；</li>\n<li>否则，当设置的type为<code>PTHREAD_CANCEL_DEFERRED</code>时，为非阻塞取消（等待达到取消的条件，如释放锁）；当设置的type为<code>PTHREAD_CANCEL_ASYNCHRONOUS</code>时为异步取消（即线程立即被取消，但不同操作系统有可能实现不同，理应处理释放锁）；</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> code = <span class=\"number\">11</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">hello</span><span class=\"params\">(<span class=\"keyword\">void</span> *args)</span> </span>&#123;</span><br><span class=\"line\">    pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, &amp;last_state); </span><br><span class=\"line\">    pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, &amp;last_type);</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *str = (<span class=\"keyword\">char</span> *) args;</span><br><span class=\"line\">    sleep(<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, %s!\\n\"</span>, str);</span><br><span class=\"line\">    pthread_exit(&amp;code);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> thread;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> status = pthread_create(&amp;thread, <span class=\"literal\">NULL</span>, (<span class=\"keyword\">void</span> *)hello, (<span class=\"keyword\">void</span> *) <span class=\"string\">\"Jayzee\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread create status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *exit_code = <span class=\"number\">0</span>;</span><br><span class=\"line\">    status = pthread_join(thread, (<span class=\"keyword\">void</span> *) &amp;exit_code);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread join status : %d\\n\"</span>, status);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"thread exit code : %d\\n\"</span>, *exit_code);</span><br><span class=\"line\">    pthread_cancel(thread);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"线程特定数据\"><a href=\"#线程特定数据\" class=\"headerlink\" title=\"线程特定数据\"></a>线程特定数据</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_key_create(pthread_key_t *key, void (*destructor)(void*));</span><br><span class=\"line\">int pthread_setspecific(pthread_key_t key, const void *value);</span><br><span class=\"line\">void *pthread_getspecific(pthread_key_t key);</span><br></pre></td></tr></table></figure>\n<ol>\n<li>使用<code>pthread_key_create</code>创建<code>key</code>，<code>destructor</code>为线程结束时用于析构的函数指针，一个进程内的多个线程可以共用一个<code>key</code>；</li>\n<li><code>pthread_setspecific</code>为线程设定key-value，<code>pthread_getspecific</code>根据key获得value；</li>\n<li>当线程结束时，若<code>pthread_getspecific</code>的内容不为空，且<code>destructor</code>不为空，则<code>pthread_getspecific</code>的内容将作为<code>destructor</code>的参数来执行析构函数；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;malloc.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* The key used to associate a log file pointer with each thread. */</span></span><br><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">pthread_key_t</span> thread_log_key;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Write MESSAGE to the log file for the current thread. */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">write_to_thread_log</span> <span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* message)</span> </span>&#123;</span><br><span class=\"line\">    FILE* thread_log = (FILE*) pthread_getspecific (thread_log_key);</span><br><span class=\"line\">    <span class=\"built_in\">fprintf</span> (thread_log, <span class=\"string\">\"%s\\n\"</span>, message);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Close the log file pointer THREAD_LOG. */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">close_thread_log</span> <span class=\"params\">(<span class=\"keyword\">void</span>* thread_log)</span> </span>&#123;</span><br><span class=\"line\">    fclose ((FILE*) thread_log);    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">thread_function</span> <span class=\"params\">(<span class=\"keyword\">void</span>* args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> thread_log_filename[<span class=\"number\">20</span>];</span><br><span class=\"line\">    FILE* thread_log;</span><br><span class=\"line\">    <span class=\"comment\">/* Generate the filename for this thread’s log file. */</span></span><br><span class=\"line\">    <span class=\"built_in\">sprintf</span> (thread_log_filename, <span class=\"string\">\"thread%d.log\"</span>, (<span class=\"keyword\">int</span>) pthread_self ());</span><br><span class=\"line\">    <span class=\"comment\">/* Open the log file. */</span></span><br><span class=\"line\">    thread_log = fopen (thread_log_filename, <span class=\"string\">\"w\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">/* Store the file pointer in thread-specific data under thread_log_key. */</span></span><br><span class=\"line\">    pthread_setspecific (thread_log_key, thread_log);</span><br><span class=\"line\">    write_to_thread_log (<span class=\"string\">\"Thread starting.\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">/* Do work here... */</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> threads[<span class=\"number\">5</span>];</span><br><span class=\"line\">    <span class=\"comment\">/* Create a key to associate thread log file pointers in</span></span><br><span class=\"line\"><span class=\"comment\">    thread-specific data. Use close_thread_log to clean up the file</span></span><br><span class=\"line\"><span class=\"comment\">    pointers. */</span></span><br><span class=\"line\">    pthread_key_create (&amp;thread_log_key, close_thread_log);</span><br><span class=\"line\">    <span class=\"comment\">/* Create threads to do the work. */</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; ++i)</span><br><span class=\"line\">        pthread_create (&amp;(threads[i]), <span class=\"literal\">NULL</span>, thread_function, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"comment\">/* Wait for all threads to finish. */</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; ++i)</span><br><span class=\"line\">        pthread_join (threads[i], <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void pthread_cleanup_push(void (*routine)(void *), void *arg);</span><br><span class=\"line\">void pthread_cleanup_pop(int execute);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>pthread_cleanup_push</code>在线程运行时为线程压栈清理函数；</li>\n<li><code>pthread_cleanup_pop</code>从栈弹出一个清理函数，如果<code>execute</code>不为0则执行这个清理函数；</li>\n<li>线程结束时，所有压栈的清理函数会自动被弹出栈进行执行；</li>\n<li>当在线程内使用longjump前，应手动调用<code>pthread_cleanup_pop</code>执行清理；</li>\n</ol>\n<h3 id=\"线程同步\"><a href=\"#线程同步\" class=\"headerlink\" title=\"线程同步\"></a>线程同步</h3><h4 id=\"互斥锁\"><a href=\"#互斥锁\" class=\"headerlink\" title=\"互斥锁\"></a>互斥锁</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_mutex_destroy(pthread_mutex_t *mutex);</span><br><span class=\"line\">int pthread_mutex_init(pthread_mutex_t *restrict mutex,</span><br><span class=\"line\">    const pthread_mutexattr_t *restrict attr);</span><br><span class=\"line\">pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>pthread_mutex_destroy</code>销毁互斥锁，<code>pthread_mutex_init</code>创建互斥锁；</li>\n<li><code>pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;</code>表示定义并默认实例化一个互斥锁；</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_mutex_lock(pthread_mutex_t *mutex);</span><br><span class=\"line\">int pthread_mutex_trylock(pthread_mutex_t *mutex);</span><br><span class=\"line\">int pthread_mutex_unlock(pthread_mutex_t *mutex);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>pthread_mutex_lock</code>为阻塞锁，<code>pthread_mutex_trylock</code>为非阻塞锁（获取不到锁）则立即返回，<code>pthread_mutex_unlock</code>为释放锁；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_mutexattr_t</span> attr;</span><br><span class=\"line\">    <span class=\"keyword\">pthread_mutex_t</span> mutex;</span><br><span class=\"line\">    pthread_mutexattr_init (&amp;attr);</span><br><span class=\"line\">    <span class=\"comment\">// 带错误检查的互斥锁</span></span><br><span class=\"line\">    pthread_mutexattr_setkind_np (&amp;attr, PTHREAD_MUTEX_ERRORCHECK_NP);</span><br><span class=\"line\">    pthread_mutex_init (&amp;mutex, &amp;attr);</span><br><span class=\"line\">    pthread_mutex_lock(&amp;mutex);</span><br><span class=\"line\">    <span class=\"comment\">/** do some work **/</span></span><br><span class=\"line\">    pthread_mutex_unlock(&amp;mutex);</span><br><span class=\"line\">    pthread_mutexattr_destroy (&amp;attr);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int sem_init(sem_t *sem, int pshared, unsigned int value);</span><br><span class=\"line\">int sem_post(sem_t *sem);</span><br><span class=\"line\">int sem_wait(sem_t *sem);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>sem_init</code>实例化信号量<code>sem</code>，<code>pshared</code>为0表示进程内共享（非0为进程间共享），<code>value</code>为初始容量值（默认容量值为0）；</li>\n<li><code>sem_wait</code>将容量值减一，<code>sem_wait</code>之后若容量值小于0则线程阻塞；<code>sem_post</code>将容量值加一；</li>\n<li>假设容量值为负，一次<code>sem_post</code>只能唤醒一个线程；</li>\n<li><code>sem_wait</code>和<code>sem_post</code>是线程安全的；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;semaphore.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">sem_t</span> semaphore;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">threadfunc</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (; i&lt;<span class=\"number\">10</span>; i++) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 实际上不会这么使用，这里仅是展示</span></span><br><span class=\"line\">        sem_wait(&amp;semaphore);</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello from da thread!\\n\"</span>);</span><br><span class=\"line\">        sem_post(&amp;semaphore);</span><br><span class=\"line\">        sleep(<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 实例化</span></span><br><span class=\"line\">    sem_init(&amp;semaphore, <span class=\"number\">0</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">pthread_t</span> *mythread;    </span><br><span class=\"line\">    mythread = (<span class=\"keyword\">pthread_t</span> *)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(*mythread));</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 启动线程</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Starting thread, semaphore is unlocked.\\n\"</span>);</span><br><span class=\"line\">    pthread_create(mythread, <span class=\"literal\">NULL</span>, (<span class=\"keyword\">void</span>*)threadfunc, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    pthread_join(mythread, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"条件值\"><a href=\"#条件值\" class=\"headerlink\" title=\"条件值\"></a>条件值</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int pthread_cond_init(pthread_cond_t *restrict cond,</span><br><span class=\"line\">    const pthread_condattr_t *restrict attr);</span><br><span class=\"line\">pthread_cond_t cond = PTHREAD_COND_INITIALIZER;</span><br><span class=\"line\">int pthread_cond_signal(pthread_cond_t *cond);</span><br><span class=\"line\">int pthread_cond_wait(pthread_cond_t *restrict cond,</span><br><span class=\"line\">   pthread_mutex_t *restrict mutex);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>pthread_cond_t cond = PTHREAD_COND_INITIALIZER;</code>等价于<code>pthread_cond_init(&amp;pthread_cond_t, NULL);</code></li>\n<li>当调用<code>pthread_cond_signal</code>或<code>pthread_cond_wait</code>时，必须获得锁；</li>\n<li>调用<code>pthread_cond_wait</code>时，自动释放锁，直到被<code>pthread_cond_signal</code>唤醒时，才重新自动获得锁；</li>\n<li><code>pthread_cond_timedwait</code>可批量唤醒等待的线程；</li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pthread.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">pthread_mutex_t</span> mutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class=\"line\"><span class=\"keyword\">pthread_cond_t</span> cond = PTHREAD_COND_INITIALIZER;</span><br><span class=\"line\"><span class=\"keyword\">int</span> condition = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">consume</span><span class=\"params\">( <span class=\"keyword\">void</span> )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>( <span class=\"number\">1</span> )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        pthread_mutex_lock( &amp;mutex );</span><br><span class=\"line\">        <span class=\"keyword\">while</span>( condition == <span class=\"number\">0</span> )</span><br><span class=\"line\">            pthread_cond_wait( &amp;cond, &amp;mutex );</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>( <span class=\"string\">\"Consumed %d\\n\"</span>, count );</span><br><span class=\"line\">        condition = <span class=\"number\">0</span>;</span><br><span class=\"line\">        pthread_cond_signal( &amp;cond );        </span><br><span class=\"line\">        pthread_mutex_unlock( &amp;mutex );</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span>( <span class=\"number\">0</span> );</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">produce</span><span class=\"params\">( <span class=\"keyword\">void</span> * arg )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>( <span class=\"number\">1</span> )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        pthread_mutex_lock( &amp;mutex );</span><br><span class=\"line\">        <span class=\"keyword\">while</span>( condition == <span class=\"number\">1</span> )</span><br><span class=\"line\">            pthread_cond_wait( &amp;cond, &amp;mutex );</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>( <span class=\"string\">\"Produced %d\\n\"</span>, count++ );</span><br><span class=\"line\">        condition = <span class=\"number\">1</span>;</span><br><span class=\"line\">        pthread_cond_signal( &amp;cond );        </span><br><span class=\"line\">        pthread_mutex_unlock( &amp;mutex );</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span>( <span class=\"number\">0</span> );</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">void</span> )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    pthread_create( <span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>, &amp;produce, <span class=\"literal\">NULL</span> );</span><br><span class=\"line\">    <span class=\"keyword\">return</span> consume();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"线程实现\"><a href=\"#线程实现\" class=\"headerlink\" title=\"线程实现\"></a>线程实现</h3><p>Linux的线程实现是系统调用<code>clone()</code>，它创建一个与父进程共用资源的子进程。</p>\n<h2 id=\"进程间通信\"><a href=\"#进程间通信\" class=\"headerlink\" title=\"进程间通信\"></a>进程间通信</h2><h3 id=\"共享内存\"><a href=\"#共享内存\" class=\"headerlink\" title=\"共享内存\"></a>共享内存</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/ipc.h&gt;</span><br><span class=\"line\">#include &lt;sys/shm.h&gt;</span><br><span class=\"line\">int shmget(key_t key, size_t size, int shmflg);</span><br><span class=\"line\">void *shmat(int shmid, const void *shmaddr, int shmflg);</span><br><span class=\"line\">int shmdt(const void *shmaddr);</span><br><span class=\"line\">int shmctl(int shmid, int cmd, struct shmid_ds *buf);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>shmget</code>申请共享内存；</li>\n<li><code>shmat</code>取得已申请的共享内存，共享内存使用者计数器加1；</li>\n<li><code>shmdt</code>断开已申请的共享内存，共享内存使用者计数器减1，如果计时器减到0，这块共享内存会被系统标注并删除；</li>\n<li><code>shmctl</code>对共享内存的标识信息进行设置；</li>\n</ol>\n<h3 id=\"进程信号量\"><a href=\"#进程信号量\" class=\"headerlink\" title=\"进程信号量\"></a>进程信号量</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/ipc.h&gt;</span><br><span class=\"line\">#include &lt;sys/sem.h&gt;</span><br><span class=\"line\">int semget(key_t key, int nsems, int semflg);</span><br><span class=\"line\">int semctl(int semid, int semnum, int cmd, ...);</span><br><span class=\"line\">int semop(int semid, struct sembuf *sops, size_t nsops);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>semget</code>用于申请信号量；</li>\n<li><code>semctl</code>用于释放或实例化信号量；</li>\n<li><code>semop</code>用于执行wait或post；</li>\n</ol>\n<h3 id=\"映射到内存\"><a href=\"#映射到内存\" class=\"headerlink\" title=\"映射到内存\"></a>映射到内存</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/mman.h&gt;</span><br><span class=\"line\">void *mmap(void *addr, size_t length, int prot, int flags,</span><br><span class=\"line\">    int fd, off_t offset);</span><br></pre></td></tr></table></figure>\n<p><code>mmap</code>是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。</p>\n<h3 id=\"管道\"><a href=\"#管道\" class=\"headerlink\" title=\"管道\"></a>管道</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;unistd.h&gt;</span><br><span class=\"line\">int pipe(int pipefd[2]);</span><br></pre></td></tr></table></figure>\n<p><code>pipe</code>的一端写，由内核缓存，直到另一端将其读出。</p>\n<h3 id=\"Socket\"><a href=\"#Socket\" class=\"headerlink\" title=\"Socket\"></a>Socket</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/socket.h&gt;</span><br><span class=\"line\">int socket(int domain, int type, int protocol);</span><br><span class=\"line\">int close(int fd);</span><br><span class=\"line\">int connect(int sockfd, const struct sockaddr *addr,</span><br><span class=\"line\">    socklen_t addrlen);</span><br><span class=\"line\">int bind(int sockfd, const struct sockaddr *addr,</span><br><span class=\"line\">    socklen_t addrlen);</span><br><span class=\"line\">int listen(int sockfd, int backlog);</span><br><span class=\"line\">int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>socket</code>创建一个socket；</li>\n<li><code>close</code>关闭一个socket；</li>\n<li><code>connect</code>建立两个socket的连接；</li>\n<li><code>bind</code>将socket绑定到地址和端口；</li>\n<li><code>listen</code>配置socket接受连接的条件；</li>\n<li><code>accept</code>接收一个socket连接并为其创建一个socket；</li>\n</ol>\n<h2 id=\"设备\"><a href=\"#设备\" class=\"headerlink\" title=\"设备\"></a>设备</h2><h3 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/stat.h&gt;</span><br><span class=\"line\">#include &lt;fcntl.h&gt;</span><br><span class=\"line\">#include &lt;unistd.h&gt;</span><br><span class=\"line\">int mknod(const char *pathname, mode_t mode, dev_t dev);</span><br></pre></td></tr></table></figure>\n<p><code>mknod</code>用于创建一个设备。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/ioctl.h&gt;</span><br><span class=\"line\">int ioctl(int d, unsigned long request, ...);</span><br></pre></td></tr></table></figure>\n<p><code>ioctl</code>用于控制设备，常用于驱动编程。</p>\n<h3 id=\"特殊设备\"><a href=\"#特殊设备\" class=\"headerlink\" title=\"特殊设备\"></a>特殊设备</h3><p><code>/dev/null</code>是一个内容为空的设备，将IO流定向到<code>/dev/null</code>意味着丢弃其内容；</p>\n<p><code>/dev/zero</code>是一个无限长的文件；</p>\n<p><code>/dev/random</code>可用于产生随机数；</p>\n<p><code>/dev/tty*</code>是串行终端设备，如串口；</p>\n<p><code>pty</code>是伪终端，接受键盘的输入并显示到运行它的终端界面；</p>\n<p><code>pty</code>的实现涉及到两个概念：</p>\n<ul>\n<li><code>ptmx</code>：被连接的master主机；</li>\n<li><code>pts</code>：发起向master主机连接的slave主机<code>pts</code>，我们常用的SSH登录就意外着在master主机建立一个<code>pts</code>进程；</li>\n</ul>\n<h2 id=\"常用-proc简介\"><a href=\"#常用-proc简介\" class=\"headerlink\" title=\"常用/proc简介\"></a>常用/proc简介</h2><p><code>/proc/cpuinfo</code>查看cpu信息；</p>\n<p><code>/proc/meminfo</code>查看内存信息；</p>\n<p><code>/proc/self</code>查看自身信息；</p>\n<p><code>/proc/pid_number</code>查看pid为pid_number的进程信息；</p>\n<p><code>/proc/loadavg</code>查看负载信息；</p>\n<p><code>/proc/uptime</code>查看启动时间；</p>\n<p><code>/proc/interrupts</code>查看中断情况；</p>\n<h2 id=\"常用系统调用\"><a href=\"#常用系统调用\" class=\"headerlink\" title=\"常用系统调用\"></a>常用系统调用</h2><p><code>strace</code>查看系统调用情况；</p>\n<p><code>access</code>检测是否具备读写权限；<br><code>fcntl</code>操纵文件描述符；</p>\n<p><code>fsync</code>和<code>fdatasync</code>将缓冲区的文件改动同步到实际文件；</p>\n<p><code>getrlimit</code>取得系统的资源限定情况；</p>\n<p><code>getrusage</code>取得系统资源使用情况；</p>\n<p><code>gettimeofday</code>取得系统时间；</p>\n<p><code>mlock</code>锁住一块内存；</p>\n<p><code>mprotect</code>保护一块内存；</p>\n<h2 id=\"用户与用户组\"><a href=\"#用户与用户组\" class=\"headerlink\" title=\"用户与用户组\"></a>用户与用户组</h2><h3 id=\"用户与用户组ID\"><a href=\"#用户与用户组ID\" class=\"headerlink\" title=\"用户与用户组ID\"></a>用户与用户组ID</h3><p>每个用户名对应到一个用户ID，每个用户ID可从属于多个用户组ID。Shell下输入<code>id</code>得到如下输出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># uid为0表示root用户</span><br><span class=\"line\">uid=0(root) gid=0(root) groups=0(root),1001(nagcmd)</span><br></pre></td></tr></table></figure>\n<h3 id=\"文件与用户（组）的关系\"><a href=\"#文件与用户（组）的关系\" class=\"headerlink\" title=\"文件与用户（组）的关系\"></a>文件与用户（组）的关系</h3><p><code>ls -l APL.txt</code>后得到如下输出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rw-r--r-- 1 Jayzee None   1237 五月 18 12:19 APL.txt</span><br></pre></td></tr></table></figure>\n<p><code>-rw-r--r--</code>解释：</p>\n<ul>\n<li>第一个字符<code>-</code>表示这是一个文件，<code>d</code>表示这是一个文件夹；</li>\n<li>2至4字符<code>rw-</code>表示拥有者<code>Jayzee</code>的权限，顺序为：读（r）、写（w）、执行（x），可读写但不可执行；</li>\n<li>5至7字符<code>r--</code>表示所属组<code>None</code>的权限；</li>\n<li>8至10字符<code>r--</code>表示组外其他用户的权限；</li>\n</ul>\n<p><code>man chmod</code>查看如何更改文件的权限；<br><code>man chown</code>查看如何更改文件的拥有者和所属组；</p>\n<p><strong>特殊</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">drwxrwxrwt   1 root root 26416 5月  18 21:53 tmp</span><br></pre></td></tr></table></figure>\n<p>只适用于文件夹：当文件夹的所属组或组外的执行（x）被设置为（t）时，表示当且仅当你是该文件夹内文件的创建者，才可以删除该文件；（正常情况下如果该文件夹内文件的权限是对于组或组外可读写，不需要是文件的创建者也可删除的），这里的<code>t</code>称为sticky bits。</p>\n<h3 id=\"真实的用户ID和有效的用户ID\"><a href=\"#真实的用户ID和有效的用户ID\" class=\"headerlink\" title=\"真实的用户ID和有效的用户ID\"></a>真实的用户ID和有效的用户ID</h3><p>定义<code>euid</code>为有效用户id（effective），<code>uid</code>为真实用户id（real）；</p>\n<p><code>man 2 getuid</code>查看如何使用C函数获取uid；<br><code>man 2 geteuid</code>查看如何使用C函数获取euid；</p>\n<p>为什么要引入euid？</p>\n<ol>\n<li>当用户发出对文件的操作时，Linux Kernel根据用户的euid检查用户是否具备权限；</li>\n<li>euid可被修改，uid不可被修改；</li>\n<li>euid被修改代表着用户的切换，uid不被修改表示最初登入系统的uid不变；</li>\n</ol>\n<p>用户登录系统时用户id发生什么变化？</p>\n<ol>\n<li>Linux的登录进程检查登入者输入的账号密码是否正确；</li>\n<li>若正确，使用<code>exec</code>为其创建一个User Shell（pts）；</li>\n<li>Linux的登录进程设置这个User Shell的euid和uid为同一个值，即该用户的uid（只有euid为0的User Shell可设置euid和uid）；</li>\n</ol>\n<p>设置说明：</p>\n<ol>\n<li>当我们设置<code>euid = uid</code>时，表示返回到最初登录用户的Shell；</li>\n<li>当我们设置<code>uid = euid</code>时，表示Linux的登录进程将euid与uid同步，该登录用户与Linux的登录进程（root）再无联系；</li>\n</ol>\n<p><code>su</code>命令的原理：</p>\n<ol>\n<li><code>/bin/su</code>的拥有者为root，其执行项不是（x）而是（s），当文件拥有者的执行项不是（x）而是（s）时，此文件可被执行，且执行文件时调用<code>geteuid</code>函数返回的是该可执行文件拥有者的uid而不是调用者的euid；</li>\n<li>Linux利用此技术实现普通用户到root用户时，uid不变，而euid变为0；</li>\n<li>当调用<code>su</code>时，调用者原User Shell阻塞，Kernel创建一个新User Shell给调用者使用；</li>\n</ol>\n<p>注：组ID也分真实和有效，与用户ID类同，故不展开叙述；</p>"},{"layout":"post","title":"LVM动态扩容","date":"2016-05-09T09:25:00.000Z","comments":1,"_content":"\n我选用LVM的目的是，\n\n<!--more-->\n\n1. 可以将多个物理盘组装成一个逻辑盘（你只需读写一个盘）；\n2. 可实现动态扩容；\n\n## 初始安装时的配置\n\n笔者已有的两个空闲物理分区为：\n1. /dev/xvde1 250G\n2. /dev/xvde2 250G\n\n创建vg、pv和lv：\n\n```bash\n## 将物理分区设置为pv\npvcreate /dev/xvde2\n## 创建vg，同时将pv添加进vg\nvgcreate gx /dev/xvde2\n## 创建lv，并指定其容量大小\nlvcreate -n lv1 -l 100%FREE gx\n## 格式化lv为ext4\nmkfs.ext4 /dev/gx/lv1\n```\n\n如何使用lv呢？编辑`/etc/fstab`，加入：\n\n```\n/dev/gx/lv1      /media/disk    ext4    defaults,noatime,nodiratime 0       0\n```\n\n重启操作系统后，你将看到lv被挂载到`/media/disk`，它的大小为250G左右。那么，如何实现动态扩容呢？\n\n```bash\n## 将物理分区设置为pv\npvcreate /dev/xvde1\n## 扩容vg\nvgextend gx /dev/xvde1\n## 扩容lv\nlvextend -l +100%FREE /dev/gx/lv1\n## 通知文件系统更新\nresize2fs /dev/gx/lv1\n```\n\n执行完上述命令后，`/media/disk`将变为500G左右。\n\n## 重装系统后的配置\n\n由于lvm的所有信息都是写在pv的metadata，重装系统后依然有效，重装后执行，\n\n```bash\n## 扫描pv\npvscan\n## 扫描lv\nlvscan\n## 扫描vg\nvgscan\n## 通知操作系统激活vg\nvgchange -a y\n```\n\n编辑`/etc/fstab`，加入：\n\n```\n/dev/gx/lv1      /media/disk    ext4    defaults,noatime,nodiratime 0       0\n```\n","source":"_posts/2016-05-09-lvm-that-i-used.markdown","raw":"---\nlayout: post\ntitle: LVM动态扩容\ndate: '2016-05-09 17:25'\ncomments: true\ncategories: ['工具篇']  \ntags: ['LVM']\n---\n\n我选用LVM的目的是，\n\n<!--more-->\n\n1. 可以将多个物理盘组装成一个逻辑盘（你只需读写一个盘）；\n2. 可实现动态扩容；\n\n## 初始安装时的配置\n\n笔者已有的两个空闲物理分区为：\n1. /dev/xvde1 250G\n2. /dev/xvde2 250G\n\n创建vg、pv和lv：\n\n```bash\n## 将物理分区设置为pv\npvcreate /dev/xvde2\n## 创建vg，同时将pv添加进vg\nvgcreate gx /dev/xvde2\n## 创建lv，并指定其容量大小\nlvcreate -n lv1 -l 100%FREE gx\n## 格式化lv为ext4\nmkfs.ext4 /dev/gx/lv1\n```\n\n如何使用lv呢？编辑`/etc/fstab`，加入：\n\n```\n/dev/gx/lv1      /media/disk    ext4    defaults,noatime,nodiratime 0       0\n```\n\n重启操作系统后，你将看到lv被挂载到`/media/disk`，它的大小为250G左右。那么，如何实现动态扩容呢？\n\n```bash\n## 将物理分区设置为pv\npvcreate /dev/xvde1\n## 扩容vg\nvgextend gx /dev/xvde1\n## 扩容lv\nlvextend -l +100%FREE /dev/gx/lv1\n## 通知文件系统更新\nresize2fs /dev/gx/lv1\n```\n\n执行完上述命令后，`/media/disk`将变为500G左右。\n\n## 重装系统后的配置\n\n由于lvm的所有信息都是写在pv的metadata，重装系统后依然有效，重装后执行，\n\n```bash\n## 扫描pv\npvscan\n## 扫描lv\nlvscan\n## 扫描vg\nvgscan\n## 通知操作系统激活vg\nvgchange -a y\n```\n\n编辑`/etc/fstab`，加入：\n\n```\n/dev/gx/lv1      /media/disk    ext4    defaults,noatime,nodiratime 0       0\n```\n","slug":"lvm-that-i-used","published":1,"updated":"2022-08-09T15:02:00.602Z","photos":[],"link":"","_id":"cl6mbc127000bigu8zmto99ta","content":"<p>我选用LVM的目的是，</p>\n<a id=\"more\"></a>\n<ol>\n<li>可以将多个物理盘组装成一个逻辑盘（你只需读写一个盘）；</li>\n<li>可实现动态扩容；</li>\n</ol>\n<h2 id=\"初始安装时的配置\"><a href=\"#初始安装时的配置\" class=\"headerlink\" title=\"初始安装时的配置\"></a>初始安装时的配置</h2><p>笔者已有的两个空闲物理分区为：</p>\n<ol>\n<li>/dev/xvde1 250G</li>\n<li>/dev/xvde2 250G</li>\n</ol>\n<p>创建vg、pv和lv：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 将物理分区设置为pv</span></span><br><span class=\"line\">pvcreate /dev/xvde2</span><br><span class=\"line\"><span class=\"comment\">## 创建vg，同时将pv添加进vg</span></span><br><span class=\"line\">vgcreate gx /dev/xvde2</span><br><span class=\"line\"><span class=\"comment\">## 创建lv，并指定其容量大小</span></span><br><span class=\"line\">lvcreate -n lv1 -l 100%FREE gx</span><br><span class=\"line\"><span class=\"comment\">## 格式化lv为ext4</span></span><br><span class=\"line\">mkfs.ext4 /dev/gx/lv1</span><br></pre></td></tr></table></figure>\n<p>如何使用lv呢？编辑<code>/etc/fstab</code>，加入：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/dev/gx/lv1      /media/disk    ext4    defaults,noatime,nodiratime 0       0</span><br></pre></td></tr></table></figure>\n<p>重启操作系统后，你将看到lv被挂载到<code>/media/disk</code>，它的大小为250G左右。那么，如何实现动态扩容呢？</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 将物理分区设置为pv</span></span><br><span class=\"line\">pvcreate /dev/xvde1</span><br><span class=\"line\"><span class=\"comment\">## 扩容vg</span></span><br><span class=\"line\">vgextend gx /dev/xvde1</span><br><span class=\"line\"><span class=\"comment\">## 扩容lv</span></span><br><span class=\"line\">lvextend -l +100%FREE /dev/gx/lv1</span><br><span class=\"line\"><span class=\"comment\">## 通知文件系统更新</span></span><br><span class=\"line\">resize2fs /dev/gx/lv1</span><br></pre></td></tr></table></figure>\n<p>执行完上述命令后，<code>/media/disk</code>将变为500G左右。</p>\n<h2 id=\"重装系统后的配置\"><a href=\"#重装系统后的配置\" class=\"headerlink\" title=\"重装系统后的配置\"></a>重装系统后的配置</h2><p>由于lvm的所有信息都是写在pv的metadata，重装系统后依然有效，重装后执行，</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 扫描pv</span></span><br><span class=\"line\">pvscan</span><br><span class=\"line\"><span class=\"comment\">## 扫描lv</span></span><br><span class=\"line\">lvscan</span><br><span class=\"line\"><span class=\"comment\">## 扫描vg</span></span><br><span class=\"line\">vgscan</span><br><span class=\"line\"><span class=\"comment\">## 通知操作系统激活vg</span></span><br><span class=\"line\">vgchange -a y</span><br></pre></td></tr></table></figure>\n<p>编辑<code>/etc/fstab</code>，加入：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/dev/gx/lv1      /media/disk    ext4    defaults,noatime,nodiratime 0       0</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>我选用LVM的目的是，</p>","more":"<ol>\n<li>可以将多个物理盘组装成一个逻辑盘（你只需读写一个盘）；</li>\n<li>可实现动态扩容；</li>\n</ol>\n<h2 id=\"初始安装时的配置\"><a href=\"#初始安装时的配置\" class=\"headerlink\" title=\"初始安装时的配置\"></a>初始安装时的配置</h2><p>笔者已有的两个空闲物理分区为：</p>\n<ol>\n<li>/dev/xvde1 250G</li>\n<li>/dev/xvde2 250G</li>\n</ol>\n<p>创建vg、pv和lv：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 将物理分区设置为pv</span></span><br><span class=\"line\">pvcreate /dev/xvde2</span><br><span class=\"line\"><span class=\"comment\">## 创建vg，同时将pv添加进vg</span></span><br><span class=\"line\">vgcreate gx /dev/xvde2</span><br><span class=\"line\"><span class=\"comment\">## 创建lv，并指定其容量大小</span></span><br><span class=\"line\">lvcreate -n lv1 -l 100%FREE gx</span><br><span class=\"line\"><span class=\"comment\">## 格式化lv为ext4</span></span><br><span class=\"line\">mkfs.ext4 /dev/gx/lv1</span><br></pre></td></tr></table></figure>\n<p>如何使用lv呢？编辑<code>/etc/fstab</code>，加入：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/dev/gx/lv1      /media/disk    ext4    defaults,noatime,nodiratime 0       0</span><br></pre></td></tr></table></figure>\n<p>重启操作系统后，你将看到lv被挂载到<code>/media/disk</code>，它的大小为250G左右。那么，如何实现动态扩容呢？</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 将物理分区设置为pv</span></span><br><span class=\"line\">pvcreate /dev/xvde1</span><br><span class=\"line\"><span class=\"comment\">## 扩容vg</span></span><br><span class=\"line\">vgextend gx /dev/xvde1</span><br><span class=\"line\"><span class=\"comment\">## 扩容lv</span></span><br><span class=\"line\">lvextend -l +100%FREE /dev/gx/lv1</span><br><span class=\"line\"><span class=\"comment\">## 通知文件系统更新</span></span><br><span class=\"line\">resize2fs /dev/gx/lv1</span><br></pre></td></tr></table></figure>\n<p>执行完上述命令后，<code>/media/disk</code>将变为500G左右。</p>\n<h2 id=\"重装系统后的配置\"><a href=\"#重装系统后的配置\" class=\"headerlink\" title=\"重装系统后的配置\"></a>重装系统后的配置</h2><p>由于lvm的所有信息都是写在pv的metadata，重装系统后依然有效，重装后执行，</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 扫描pv</span></span><br><span class=\"line\">pvscan</span><br><span class=\"line\"><span class=\"comment\">## 扫描lv</span></span><br><span class=\"line\">lvscan</span><br><span class=\"line\"><span class=\"comment\">## 扫描vg</span></span><br><span class=\"line\">vgscan</span><br><span class=\"line\"><span class=\"comment\">## 通知操作系统激活vg</span></span><br><span class=\"line\">vgchange -a y</span><br></pre></td></tr></table></figure>\n<p>编辑<code>/etc/fstab</code>，加入：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/dev/gx/lv1      /media/disk    ext4    defaults,noatime,nodiratime 0       0</span><br></pre></td></tr></table></figure>"},{"layout":"post","title":"SVN嵌套权限管理","date":"2016-05-05T05:48:00.000Z","comments":1,"_content":"\n公司有一个ExtJS+Java的云平台项目，该项目模块化得较好，一个包就是一个模块。\n\n<!--more-->\n\n该项目需要多人协作，同时又要让协作者不能获取到全部模块（防止代码泄露）。以往我的做法是分子项目然后使用BeyondCompare作合并，但这样太费时费力了，后来发现SVN能完美达成我的需求。\n\n介绍我的SVN的authz（Linux环境）配置如下：\n\n```\n[groups]\nadmin = jayzee,luzhiquan,hwq\nuser = yifei,shenkai,linjie,cjm\n# gx-desk\n[myproject:/gx-desk]\n@admin = rw\n@user = r\n## gx-desk src\n[myproject:/gx-desk/src]\n@user = rw\n[myproject:/gx-desk/src/main/resources]\n@user = r\n[myproject:/gx-desk/src/main/resources/com]\n@user = rw\n## gx-desk WebContent\n[myproject:/gx-desk/WebContent]\n@user = rw\n[myproject:/gx-desk/WebContent/.sencha]\n@user = r\n[myproject:/gx-desk/WebContent/Chart]\n@user = r\n[myproject:/gx-desk/WebContent/app/App.js]\n@user = r\n[myproject:/gx-desk/WebContent/app/view/infomanage]\n@user =\nlinjie = rw\n```\n\n1. SVN的权限具有继承关系，上例中，`/gx-desk`为项目的根，它设置admin用户可读写，而普通用户可读不可写；\n2. `/gx-desk/src`继承了上一级的权限，其下方的`@user = rw`表示我们将`/gx-desk/src`的权限重写为可读写；\n3. 其他的以此类推，基于此我们就可以实现嵌套的内存管理啦！\n\n注：\n`@user = `表示不可读和不可写；\n","source":"_posts/2016-05-05-svn-that-i-used.markdown","raw":"---\nlayout: post\ntitle: SVN嵌套权限管理\ndate: '2016-05-05 13:48'\ncomments: true\ncategories: ['工具篇']  \ntags: ['SVN']\n---\n\n公司有一个ExtJS+Java的云平台项目，该项目模块化得较好，一个包就是一个模块。\n\n<!--more-->\n\n该项目需要多人协作，同时又要让协作者不能获取到全部模块（防止代码泄露）。以往我的做法是分子项目然后使用BeyondCompare作合并，但这样太费时费力了，后来发现SVN能完美达成我的需求。\n\n介绍我的SVN的authz（Linux环境）配置如下：\n\n```\n[groups]\nadmin = jayzee,luzhiquan,hwq\nuser = yifei,shenkai,linjie,cjm\n# gx-desk\n[myproject:/gx-desk]\n@admin = rw\n@user = r\n## gx-desk src\n[myproject:/gx-desk/src]\n@user = rw\n[myproject:/gx-desk/src/main/resources]\n@user = r\n[myproject:/gx-desk/src/main/resources/com]\n@user = rw\n## gx-desk WebContent\n[myproject:/gx-desk/WebContent]\n@user = rw\n[myproject:/gx-desk/WebContent/.sencha]\n@user = r\n[myproject:/gx-desk/WebContent/Chart]\n@user = r\n[myproject:/gx-desk/WebContent/app/App.js]\n@user = r\n[myproject:/gx-desk/WebContent/app/view/infomanage]\n@user =\nlinjie = rw\n```\n\n1. SVN的权限具有继承关系，上例中，`/gx-desk`为项目的根，它设置admin用户可读写，而普通用户可读不可写；\n2. `/gx-desk/src`继承了上一级的权限，其下方的`@user = rw`表示我们将`/gx-desk/src`的权限重写为可读写；\n3. 其他的以此类推，基于此我们就可以实现嵌套的内存管理啦！\n\n注：\n`@user = `表示不可读和不可写；\n","slug":"svn-that-i-used","published":1,"updated":"2022-08-09T15:02:00.598Z","photos":[],"link":"","_id":"cl6mbc12b000figu8ckry5wjn","content":"<p>公司有一个ExtJS+Java的云平台项目，该项目模块化得较好，一个包就是一个模块。</p>\n<a id=\"more\"></a>\n<p>该项目需要多人协作，同时又要让协作者不能获取到全部模块（防止代码泄露）。以往我的做法是分子项目然后使用BeyondCompare作合并，但这样太费时费力了，后来发现SVN能完美达成我的需求。</p>\n<p>介绍我的SVN的authz（Linux环境）配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[groups]</span><br><span class=\"line\">admin = jayzee,luzhiquan,hwq</span><br><span class=\"line\">user = yifei,shenkai,linjie,cjm</span><br><span class=\"line\"># gx-desk</span><br><span class=\"line\">[myproject:/gx-desk]</span><br><span class=\"line\">@admin = rw</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">## gx-desk src</span><br><span class=\"line\">[myproject:/gx-desk/src]</span><br><span class=\"line\">@user = rw</span><br><span class=\"line\">[myproject:/gx-desk/src/main/resources]</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">[myproject:/gx-desk/src/main/resources/com]</span><br><span class=\"line\">@user = rw</span><br><span class=\"line\">## gx-desk WebContent</span><br><span class=\"line\">[myproject:/gx-desk/WebContent]</span><br><span class=\"line\">@user = rw</span><br><span class=\"line\">[myproject:/gx-desk/WebContent/.sencha]</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">[myproject:/gx-desk/WebContent/Chart]</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">[myproject:/gx-desk/WebContent/app/App.js]</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">[myproject:/gx-desk/WebContent/app/view/infomanage]</span><br><span class=\"line\">@user =</span><br><span class=\"line\">linjie = rw</span><br></pre></td></tr></table></figure>\n<ol>\n<li>SVN的权限具有继承关系，上例中，<code>/gx-desk</code>为项目的根，它设置admin用户可读写，而普通用户可读不可写；</li>\n<li><code>/gx-desk/src</code>继承了上一级的权限，其下方的<code>@user = rw</code>表示我们将<code>/gx-desk/src</code>的权限重写为可读写；</li>\n<li>其他的以此类推，基于此我们就可以实现嵌套的内存管理啦！</li>\n</ol>\n<p>注：<br><code>@user =</code>表示不可读和不可写；</p>\n","site":{"data":{}},"excerpt":"<p>公司有一个ExtJS+Java的云平台项目，该项目模块化得较好，一个包就是一个模块。</p>","more":"<p>该项目需要多人协作，同时又要让协作者不能获取到全部模块（防止代码泄露）。以往我的做法是分子项目然后使用BeyondCompare作合并，但这样太费时费力了，后来发现SVN能完美达成我的需求。</p>\n<p>介绍我的SVN的authz（Linux环境）配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[groups]</span><br><span class=\"line\">admin = jayzee,luzhiquan,hwq</span><br><span class=\"line\">user = yifei,shenkai,linjie,cjm</span><br><span class=\"line\"># gx-desk</span><br><span class=\"line\">[myproject:/gx-desk]</span><br><span class=\"line\">@admin = rw</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">## gx-desk src</span><br><span class=\"line\">[myproject:/gx-desk/src]</span><br><span class=\"line\">@user = rw</span><br><span class=\"line\">[myproject:/gx-desk/src/main/resources]</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">[myproject:/gx-desk/src/main/resources/com]</span><br><span class=\"line\">@user = rw</span><br><span class=\"line\">## gx-desk WebContent</span><br><span class=\"line\">[myproject:/gx-desk/WebContent]</span><br><span class=\"line\">@user = rw</span><br><span class=\"line\">[myproject:/gx-desk/WebContent/.sencha]</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">[myproject:/gx-desk/WebContent/Chart]</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">[myproject:/gx-desk/WebContent/app/App.js]</span><br><span class=\"line\">@user = r</span><br><span class=\"line\">[myproject:/gx-desk/WebContent/app/view/infomanage]</span><br><span class=\"line\">@user =</span><br><span class=\"line\">linjie = rw</span><br></pre></td></tr></table></figure>\n<ol>\n<li>SVN的权限具有继承关系，上例中，<code>/gx-desk</code>为项目的根，它设置admin用户可读写，而普通用户可读不可写；</li>\n<li><code>/gx-desk/src</code>继承了上一级的权限，其下方的<code>@user = rw</code>表示我们将<code>/gx-desk/src</code>的权限重写为可读写；</li>\n<li>其他的以此类推，基于此我们就可以实现嵌套的内存管理啦！</li>\n</ol>\n<p>注：<br><code>@user =</code>表示不可读和不可写；</p>"},{"layout":"post","title":"多对一autossh隧道管理","date":"2016-06-22T13:05:00.000Z","comments":1,"_content":"\n笔者的云端主机开放了两个端口，一个为SSH端口（假定为62638），一个为应用程序TCP端口（假定为62639，长连接），现有多个客户端连接到应用程序TCP端口进行数据通信，但假如我想通过云主机远程到某一个客户进行调试，该如何实现呢？\n\n<!--more-->\n\n这里就需要用到autossh了，简要介绍其思路：客户安装配置autossh，主动去连接云端主机建立autossh隧道，**此隧道在云端主机有一个对端端口**，云端主机直接ssh此端口就会到达隧道的另一端——客户端。\n\n具体实现过程如下，注意：\n1. 下文的bbblack是客户端用于登入云端主机的普通账户；\n2. 125.94.212.178为云端主机公网IP；\n\n## 客户端配置autossh\n\n1. 编辑/etc/ssh/ssh_config，修改`StrictHostKeyChecking ask`为`StrictHostKeyChecking no`并去除其前面的注释；\n2. 执行ssh-keygen得id_rsa.pub，将id_rsa.pub上传到云主机的/home/bbblack/.ssh/customer_name_authorized_keys（**customer_name_authorized_keys为客户名称开头，加_上authorized_keys为后缀**）；\n3. 安装autossh；\n4. crontab配置每5分钟执行一次以下脚本（autossh.sh），\n\n```bash\n#!/bin/sh\n# 隧道在云主机的对端是1235端口，在客户端是22端口（ssh的默认端口）\ntokeep=1235:localhost:22\n# 检测此连接是否存在，否则建立autossh连接\nif $(/bin/ps ax|grep $tokeep|grep -v \"grep\" > /dev/null)\nthen\n    echo \"ok\" > /dev/null\nelse\n    # autossh本身会去检测并维持隧道的长连接\n    /usr/bin/autossh -M 1234 -NR 1235:localhost:22 bbblack@125.94.212.178 -p62638 > /root/autossh.log 2>&1 &\nfi\nexit 0\n```\n\n## 云端配置autossh\n\n1. 编辑/etc/ssh/ssh_config，修改`StrictHostKeyChecking ask`为`StrictHostKeyChecking no`并去除其前面的注释；\n2. 编辑/etc/ssh/sshd_config，修改`AuthorizedKeysFile`配置项为`AuthorizedKeysFile      .ssh/authorized_keys`，若上文的customer_name_authorized_keys与.ssh/authorized_keys内容相同，则客户端无需输入密码通过authorized_keys就能连接上云端；\n\n### 在只有一个客户的情况下\n\n将上文的customer_name重命名为authorized_keys，过一会客户端就会连接上云端，使用`lsof -i:1235`可查看连接建立情况，使用`ssh -p1235 user_name@localhost`可登录到客户端（**user_name为客户端的linux user name**）；\n\n### 在有多个客户的情况下\n\n最简单的一种方案是：使每条隧道的云端主机对端端口唯一，也就是每个客户的隧道互相独立，但如果客户太多，会将云端的端口耗尽。笔者想要的效果是所有客户共用一个云端对端端口，即一次只有一条隧道，一次只能远程登录到一个客户。那么问题来了？如何实现？\n\n使用下述脚本（autossh-helper.sh）即可解决上述问题，\n\n```bash\n#!/bin/sh\n\nfilepath=$1\nport1=1235\n\n[ $# -eq 0 ] && { echo \"Usage: $0 authorized_keys_filepath\"; exit 999; }\n\nif [ -f \"$filepath\" ] ; then\n    # kill 1235\n    pid=$(lsof -i:$port1 -t)\n    echo $pid|while read line\n    do\n        if [ \"\" != \"$line\" ] ; then\n            $(kill $line)\n        fi\n    done\n\n    # clear known_hosts\n    echo > /home/bbblack/.ssh/known_hosts\n\n    # authorized_keys changed\n    cp $filepath /home/bbblack/.ssh/authorized_keys\n    echo \"done ...\"\nelse\n    echo \"$filepath not exists ...\"\nfi\n\nexit 0\n```\n\n**FIXME** \n但是，以非root用户bbblack使用上述脚本有个问题，它需要定位出绑定在1235的pid号是多少，而1235是由sshd进程以bbblack用户在隧道建立时绑定的，这时候不管使用`lsof`还是`netstat`都无法在bbblack用户下定位出绑定在1235的pid号是多少（原因未知）。所以需要配置lsof为setuid程序（有何安全隐患？），root用户运行`chmod u+s /usr/bin/lsof`即可。\n\n接着，以bbblack账户（无需root用户）运行`./autossh-helper.sh customer_name_authorized_keys`（customer_name_authorized_keys为上文提到的文件）即可实现客户切换，其原理无非是一次只有一个客户独占ssh的authorized_keys，其他没有独占的客户由于不满足ssh登入的条件因而无法建立隧道。\n\n但是问题到这里还没有结束，云端的主机由于安全的需要一般都会配置denyhosts，denyhosts会不断检查ssh日志的失败记录，把那些连续失败多次的IP记为黑名单（ssh不可用），于是会出现这样一个现象，即使你运行了上述的autossh-helper.sh切换客户，依然还是没有客户建立隧道，这就是因为该客户所在公网IP被加入黑名单的原因。\n\n有什么解决办法呢？这时候我们的应用程序TCP端口（假定为62639，长连接）派上了用场。这里我们假设，该客户所在公网IP虽然被加入黑名单，但应用程序TCP端口（假定为62639，长连接）依然正常，因为云端和客户端需要源源不断的交互数据，此端口为长连接。若不满足此假设，则以下解决方案无效。\n\n解决方法就是，在执行autossh-helper.sh前，将与云端应用程序正常通信的客户端公网IP从黑名单解除即可。即在执行autossh-helper.sh前，必须先以**root用户**（因为denyhosts需要以root用户执行，这是个遗憾）执行脚本如下（public-ip-helper.sh）：\n\n```bash\n#!/bin/sh\n\nif [ `whoami` = \"root\" ]; then\n    echo \"\" > /dev/null\nelse\n    echo \"please login as root !\"\n    exit 1\nfi\n\ntokill=/usr/bin/denyhosts\n/bin/ps ax|grep $tokill|grep -v \"grep\"|awk '{print $1}'|while read line\ndo\n    kill $line\ndone\n\nnetstat -npt|grep 62639|cut -d \":\" -f2|cut -d \":\" -f1|while read str\ndo\nHOST=${str##* }\necho $HOST >> /usr/share/denyhosts/allowed-hosts\necho '\n/etc/hosts.deny\n/usr/share/denyhosts/data/hosts\n/usr/share/denyhosts/data/hosts-restricted\n/usr/share/denyhosts/data/hosts-root\n/usr/share/denyhosts/data/hosts-valid\n/usr/share/denyhosts/data/users-hosts\n' | grep -v \"^$\" | xargs sed -i \"/${HOST}/d\"\ndone\n\n/etc/init.d/denyhosts start\n```\n","source":"_posts/2016-06-22-autossh-helper.markdown","raw":"---\nlayout: post\ntitle: 多对一autossh隧道管理\ndate: '2016-06-22 21:05'\ncomments: true\ncategories: ['工具篇']  \ntags: ['Linux', 'Network']\n---\n\n笔者的云端主机开放了两个端口，一个为SSH端口（假定为62638），一个为应用程序TCP端口（假定为62639，长连接），现有多个客户端连接到应用程序TCP端口进行数据通信，但假如我想通过云主机远程到某一个客户进行调试，该如何实现呢？\n\n<!--more-->\n\n这里就需要用到autossh了，简要介绍其思路：客户安装配置autossh，主动去连接云端主机建立autossh隧道，**此隧道在云端主机有一个对端端口**，云端主机直接ssh此端口就会到达隧道的另一端——客户端。\n\n具体实现过程如下，注意：\n1. 下文的bbblack是客户端用于登入云端主机的普通账户；\n2. 125.94.212.178为云端主机公网IP；\n\n## 客户端配置autossh\n\n1. 编辑/etc/ssh/ssh_config，修改`StrictHostKeyChecking ask`为`StrictHostKeyChecking no`并去除其前面的注释；\n2. 执行ssh-keygen得id_rsa.pub，将id_rsa.pub上传到云主机的/home/bbblack/.ssh/customer_name_authorized_keys（**customer_name_authorized_keys为客户名称开头，加_上authorized_keys为后缀**）；\n3. 安装autossh；\n4. crontab配置每5分钟执行一次以下脚本（autossh.sh），\n\n```bash\n#!/bin/sh\n# 隧道在云主机的对端是1235端口，在客户端是22端口（ssh的默认端口）\ntokeep=1235:localhost:22\n# 检测此连接是否存在，否则建立autossh连接\nif $(/bin/ps ax|grep $tokeep|grep -v \"grep\" > /dev/null)\nthen\n    echo \"ok\" > /dev/null\nelse\n    # autossh本身会去检测并维持隧道的长连接\n    /usr/bin/autossh -M 1234 -NR 1235:localhost:22 bbblack@125.94.212.178 -p62638 > /root/autossh.log 2>&1 &\nfi\nexit 0\n```\n\n## 云端配置autossh\n\n1. 编辑/etc/ssh/ssh_config，修改`StrictHostKeyChecking ask`为`StrictHostKeyChecking no`并去除其前面的注释；\n2. 编辑/etc/ssh/sshd_config，修改`AuthorizedKeysFile`配置项为`AuthorizedKeysFile      .ssh/authorized_keys`，若上文的customer_name_authorized_keys与.ssh/authorized_keys内容相同，则客户端无需输入密码通过authorized_keys就能连接上云端；\n\n### 在只有一个客户的情况下\n\n将上文的customer_name重命名为authorized_keys，过一会客户端就会连接上云端，使用`lsof -i:1235`可查看连接建立情况，使用`ssh -p1235 user_name@localhost`可登录到客户端（**user_name为客户端的linux user name**）；\n\n### 在有多个客户的情况下\n\n最简单的一种方案是：使每条隧道的云端主机对端端口唯一，也就是每个客户的隧道互相独立，但如果客户太多，会将云端的端口耗尽。笔者想要的效果是所有客户共用一个云端对端端口，即一次只有一条隧道，一次只能远程登录到一个客户。那么问题来了？如何实现？\n\n使用下述脚本（autossh-helper.sh）即可解决上述问题，\n\n```bash\n#!/bin/sh\n\nfilepath=$1\nport1=1235\n\n[ $# -eq 0 ] && { echo \"Usage: $0 authorized_keys_filepath\"; exit 999; }\n\nif [ -f \"$filepath\" ] ; then\n    # kill 1235\n    pid=$(lsof -i:$port1 -t)\n    echo $pid|while read line\n    do\n        if [ \"\" != \"$line\" ] ; then\n            $(kill $line)\n        fi\n    done\n\n    # clear known_hosts\n    echo > /home/bbblack/.ssh/known_hosts\n\n    # authorized_keys changed\n    cp $filepath /home/bbblack/.ssh/authorized_keys\n    echo \"done ...\"\nelse\n    echo \"$filepath not exists ...\"\nfi\n\nexit 0\n```\n\n**FIXME** \n但是，以非root用户bbblack使用上述脚本有个问题，它需要定位出绑定在1235的pid号是多少，而1235是由sshd进程以bbblack用户在隧道建立时绑定的，这时候不管使用`lsof`还是`netstat`都无法在bbblack用户下定位出绑定在1235的pid号是多少（原因未知）。所以需要配置lsof为setuid程序（有何安全隐患？），root用户运行`chmod u+s /usr/bin/lsof`即可。\n\n接着，以bbblack账户（无需root用户）运行`./autossh-helper.sh customer_name_authorized_keys`（customer_name_authorized_keys为上文提到的文件）即可实现客户切换，其原理无非是一次只有一个客户独占ssh的authorized_keys，其他没有独占的客户由于不满足ssh登入的条件因而无法建立隧道。\n\n但是问题到这里还没有结束，云端的主机由于安全的需要一般都会配置denyhosts，denyhosts会不断检查ssh日志的失败记录，把那些连续失败多次的IP记为黑名单（ssh不可用），于是会出现这样一个现象，即使你运行了上述的autossh-helper.sh切换客户，依然还是没有客户建立隧道，这就是因为该客户所在公网IP被加入黑名单的原因。\n\n有什么解决办法呢？这时候我们的应用程序TCP端口（假定为62639，长连接）派上了用场。这里我们假设，该客户所在公网IP虽然被加入黑名单，但应用程序TCP端口（假定为62639，长连接）依然正常，因为云端和客户端需要源源不断的交互数据，此端口为长连接。若不满足此假设，则以下解决方案无效。\n\n解决方法就是，在执行autossh-helper.sh前，将与云端应用程序正常通信的客户端公网IP从黑名单解除即可。即在执行autossh-helper.sh前，必须先以**root用户**（因为denyhosts需要以root用户执行，这是个遗憾）执行脚本如下（public-ip-helper.sh）：\n\n```bash\n#!/bin/sh\n\nif [ `whoami` = \"root\" ]; then\n    echo \"\" > /dev/null\nelse\n    echo \"please login as root !\"\n    exit 1\nfi\n\ntokill=/usr/bin/denyhosts\n/bin/ps ax|grep $tokill|grep -v \"grep\"|awk '{print $1}'|while read line\ndo\n    kill $line\ndone\n\nnetstat -npt|grep 62639|cut -d \":\" -f2|cut -d \":\" -f1|while read str\ndo\nHOST=${str##* }\necho $HOST >> /usr/share/denyhosts/allowed-hosts\necho '\n/etc/hosts.deny\n/usr/share/denyhosts/data/hosts\n/usr/share/denyhosts/data/hosts-restricted\n/usr/share/denyhosts/data/hosts-root\n/usr/share/denyhosts/data/hosts-valid\n/usr/share/denyhosts/data/users-hosts\n' | grep -v \"^$\" | xargs sed -i \"/${HOST}/d\"\ndone\n\n/etc/init.d/denyhosts start\n```\n","slug":"autossh-helper","published":1,"updated":"2022-08-09T15:02:00.606Z","photos":[],"link":"","_id":"cl6mbc12f000gigu8qecu1wzt","content":"<p>笔者的云端主机开放了两个端口，一个为SSH端口（假定为62638），一个为应用程序TCP端口（假定为62639，长连接），现有多个客户端连接到应用程序TCP端口进行数据通信，但假如我想通过云主机远程到某一个客户进行调试，该如何实现呢？</p>\n<a id=\"more\"></a>\n<p>这里就需要用到autossh了，简要介绍其思路：客户安装配置autossh，主动去连接云端主机建立autossh隧道，<strong>此隧道在云端主机有一个对端端口</strong>，云端主机直接ssh此端口就会到达隧道的另一端——客户端。</p>\n<p>具体实现过程如下，注意：</p>\n<ol>\n<li>下文的bbblack是客户端用于登入云端主机的普通账户；</li>\n<li>125.94.212.178为云端主机公网IP；</li>\n</ol>\n<h2 id=\"客户端配置autossh\"><a href=\"#客户端配置autossh\" class=\"headerlink\" title=\"客户端配置autossh\"></a>客户端配置autossh</h2><ol>\n<li>编辑/etc/ssh/ssh_config，修改<code>StrictHostKeyChecking ask</code>为<code>StrictHostKeyChecking no</code>并去除其前面的注释；</li>\n<li>执行ssh-keygen得id_rsa.pub，将id_rsa.pub上传到云主机的/home/bbblack/.ssh/customer_name_authorized_keys（<strong>customer_name_authorized_keys为客户名称开头，加_上authorized_keys为后缀</strong>）；</li>\n<li>安装autossh；</li>\n<li>crontab配置每5分钟执行一次以下脚本（autossh.sh），</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"><span class=\"comment\"># 隧道在云主机的对端是1235端口，在客户端是22端口（ssh的默认端口）</span></span><br><span class=\"line\">tokeep=1235:localhost:22</span><br><span class=\"line\"><span class=\"comment\"># 检测此连接是否存在，否则建立autossh连接</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> $(/bin/ps ax|grep <span class=\"variable\">$tokeep</span>|grep -v <span class=\"string\">\"grep\"</span> &gt; /dev/null)</span><br><span class=\"line\"><span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"ok\"</span> &gt; /dev/null</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"comment\"># autossh本身会去检测并维持隧道的长连接</span></span><br><span class=\"line\">    /usr/bin/autossh -M 1234 -NR 1235:localhost:22 bbblack@125.94.212.178 -p62638 &gt; /root/autossh.log 2&gt;&amp;1 &amp;</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"built_in\">exit</span> 0</span><br></pre></td></tr></table></figure>\n<h2 id=\"云端配置autossh\"><a href=\"#云端配置autossh\" class=\"headerlink\" title=\"云端配置autossh\"></a>云端配置autossh</h2><ol>\n<li>编辑/etc/ssh/ssh_config，修改<code>StrictHostKeyChecking ask</code>为<code>StrictHostKeyChecking no</code>并去除其前面的注释；</li>\n<li>编辑/etc/ssh/sshd_config，修改<code>AuthorizedKeysFile</code>配置项为<code>AuthorizedKeysFile      .ssh/authorized_keys</code>，若上文的customer_name_authorized_keys与.ssh/authorized_keys内容相同，则客户端无需输入密码通过authorized_keys就能连接上云端；</li>\n</ol>\n<h3 id=\"在只有一个客户的情况下\"><a href=\"#在只有一个客户的情况下\" class=\"headerlink\" title=\"在只有一个客户的情况下\"></a>在只有一个客户的情况下</h3><p>将上文的customer_name重命名为authorized_keys，过一会客户端就会连接上云端，使用<code>lsof -i:1235</code>可查看连接建立情况，使用<code>ssh -p1235 user_name@localhost</code>可登录到客户端（<strong>user_name为客户端的linux user name</strong>）；</p>\n<h3 id=\"在有多个客户的情况下\"><a href=\"#在有多个客户的情况下\" class=\"headerlink\" title=\"在有多个客户的情况下\"></a>在有多个客户的情况下</h3><p>最简单的一种方案是：使每条隧道的云端主机对端端口唯一，也就是每个客户的隧道互相独立，但如果客户太多，会将云端的端口耗尽。笔者想要的效果是所有客户共用一个云端对端端口，即一次只有一条隧道，一次只能远程登录到一个客户。那么问题来了？如何实现？</p>\n<p>使用下述脚本（autossh-helper.sh）即可解决上述问题，</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\">filepath=<span class=\"variable\">$1</span></span><br><span class=\"line\">port1=1235</span><br><span class=\"line\"></span><br><span class=\"line\">[ <span class=\"variable\">$#</span> -eq 0 ] &amp;&amp; &#123; <span class=\"built_in\">echo</span> <span class=\"string\">\"Usage: <span class=\"variable\">$0</span> authorized_keys_filepath\"</span>; <span class=\"built_in\">exit</span> 999; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ -f <span class=\"string\">\"<span class=\"variable\">$filepath</span>\"</span> ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"comment\"># kill 1235</span></span><br><span class=\"line\">    pid=$(lsof -i:<span class=\"variable\">$port1</span> -t)</span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"variable\">$pid</span>|<span class=\"keyword\">while</span> <span class=\"built_in\">read</span> line</span><br><span class=\"line\">    <span class=\"keyword\">do</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> [ <span class=\"string\">\"\"</span> != <span class=\"string\">\"<span class=\"variable\">$line</span>\"</span> ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">            $(<span class=\"built_in\">kill</span> <span class=\"variable\">$line</span>)</span><br><span class=\"line\">        <span class=\"keyword\">fi</span></span><br><span class=\"line\">    <span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># clear known_hosts</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> &gt; /home/bbblack/.ssh/known_hosts</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># authorized_keys changed</span></span><br><span class=\"line\">    cp <span class=\"variable\">$filepath</span> /home/bbblack/.ssh/authorized_keys</span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"done ...\"</span></span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"<span class=\"variable\">$filepath</span> not exists ...\"</span></span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">exit</span> 0</span><br></pre></td></tr></table></figure>\n<p><strong>FIXME</strong><br>但是，以非root用户bbblack使用上述脚本有个问题，它需要定位出绑定在1235的pid号是多少，而1235是由sshd进程以bbblack用户在隧道建立时绑定的，这时候不管使用<code>lsof</code>还是<code>netstat</code>都无法在bbblack用户下定位出绑定在1235的pid号是多少（原因未知）。所以需要配置lsof为setuid程序（有何安全隐患？），root用户运行<code>chmod u+s /usr/bin/lsof</code>即可。</p>\n<p>接着，以bbblack账户（无需root用户）运行<code>./autossh-helper.sh customer_name_authorized_keys</code>（customer_name_authorized_keys为上文提到的文件）即可实现客户切换，其原理无非是一次只有一个客户独占ssh的authorized_keys，其他没有独占的客户由于不满足ssh登入的条件因而无法建立隧道。</p>\n<p>但是问题到这里还没有结束，云端的主机由于安全的需要一般都会配置denyhosts，denyhosts会不断检查ssh日志的失败记录，把那些连续失败多次的IP记为黑名单（ssh不可用），于是会出现这样一个现象，即使你运行了上述的autossh-helper.sh切换客户，依然还是没有客户建立隧道，这就是因为该客户所在公网IP被加入黑名单的原因。</p>\n<p>有什么解决办法呢？这时候我们的应用程序TCP端口（假定为62639，长连接）派上了用场。这里我们假设，该客户所在公网IP虽然被加入黑名单，但应用程序TCP端口（假定为62639，长连接）依然正常，因为云端和客户端需要源源不断的交互数据，此端口为长连接。若不满足此假设，则以下解决方案无效。</p>\n<p>解决方法就是，在执行autossh-helper.sh前，将与云端应用程序正常通信的客户端公网IP从黑名单解除即可。即在执行autossh-helper.sh前，必须先以<strong>root用户</strong>（因为denyhosts需要以root用户执行，这是个遗憾）执行脚本如下（public-ip-helper.sh）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ `whoami` = <span class=\"string\">\"root\"</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"\"</span> &gt; /dev/null</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"please login as root !\"</span></span><br><span class=\"line\">    <span class=\"built_in\">exit</span> 1</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\">tokill=/usr/bin/denyhosts</span><br><span class=\"line\">/bin/ps ax|grep <span class=\"variable\">$tokill</span>|grep -v <span class=\"string\">\"grep\"</span>|awk <span class=\"string\">'&#123;print $1&#125;'</span>|<span class=\"keyword\">while</span> <span class=\"built_in\">read</span> line</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">    <span class=\"built_in\">kill</span> <span class=\"variable\">$line</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\">netstat -npt|grep 62639|cut -d <span class=\"string\">\":\"</span> -f2|cut -d <span class=\"string\">\":\"</span> -f1|<span class=\"keyword\">while</span> <span class=\"built_in\">read</span> str</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">HOST=<span class=\"variable\">$&#123;str##* &#125;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$HOST</span> &gt;&gt; /usr/share/denyhosts/allowed-hosts</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'</span></span><br><span class=\"line\"><span class=\"string\">/etc/hosts.deny</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/hosts</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/hosts-restricted</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/hosts-root</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/hosts-valid</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/users-hosts</span></span><br><span class=\"line\"><span class=\"string\">'</span> | grep -v <span class=\"string\">\"^$\"</span> | xargs sed -i <span class=\"string\">\"/<span class=\"variable\">$&#123;HOST&#125;</span>/d\"</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\">/etc/init.d/denyhosts start</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>笔者的云端主机开放了两个端口，一个为SSH端口（假定为62638），一个为应用程序TCP端口（假定为62639，长连接），现有多个客户端连接到应用程序TCP端口进行数据通信，但假如我想通过云主机远程到某一个客户进行调试，该如何实现呢？</p>","more":"<p>这里就需要用到autossh了，简要介绍其思路：客户安装配置autossh，主动去连接云端主机建立autossh隧道，<strong>此隧道在云端主机有一个对端端口</strong>，云端主机直接ssh此端口就会到达隧道的另一端——客户端。</p>\n<p>具体实现过程如下，注意：</p>\n<ol>\n<li>下文的bbblack是客户端用于登入云端主机的普通账户；</li>\n<li>125.94.212.178为云端主机公网IP；</li>\n</ol>\n<h2 id=\"客户端配置autossh\"><a href=\"#客户端配置autossh\" class=\"headerlink\" title=\"客户端配置autossh\"></a>客户端配置autossh</h2><ol>\n<li>编辑/etc/ssh/ssh_config，修改<code>StrictHostKeyChecking ask</code>为<code>StrictHostKeyChecking no</code>并去除其前面的注释；</li>\n<li>执行ssh-keygen得id_rsa.pub，将id_rsa.pub上传到云主机的/home/bbblack/.ssh/customer_name_authorized_keys（<strong>customer_name_authorized_keys为客户名称开头，加_上authorized_keys为后缀</strong>）；</li>\n<li>安装autossh；</li>\n<li>crontab配置每5分钟执行一次以下脚本（autossh.sh），</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"><span class=\"comment\"># 隧道在云主机的对端是1235端口，在客户端是22端口（ssh的默认端口）</span></span><br><span class=\"line\">tokeep=1235:localhost:22</span><br><span class=\"line\"><span class=\"comment\"># 检测此连接是否存在，否则建立autossh连接</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> $(/bin/ps ax|grep <span class=\"variable\">$tokeep</span>|grep -v <span class=\"string\">\"grep\"</span> &gt; /dev/null)</span><br><span class=\"line\"><span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"ok\"</span> &gt; /dev/null</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"comment\"># autossh本身会去检测并维持隧道的长连接</span></span><br><span class=\"line\">    /usr/bin/autossh -M 1234 -NR 1235:localhost:22 bbblack@125.94.212.178 -p62638 &gt; /root/autossh.log 2&gt;&amp;1 &amp;</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"built_in\">exit</span> 0</span><br></pre></td></tr></table></figure>\n<h2 id=\"云端配置autossh\"><a href=\"#云端配置autossh\" class=\"headerlink\" title=\"云端配置autossh\"></a>云端配置autossh</h2><ol>\n<li>编辑/etc/ssh/ssh_config，修改<code>StrictHostKeyChecking ask</code>为<code>StrictHostKeyChecking no</code>并去除其前面的注释；</li>\n<li>编辑/etc/ssh/sshd_config，修改<code>AuthorizedKeysFile</code>配置项为<code>AuthorizedKeysFile      .ssh/authorized_keys</code>，若上文的customer_name_authorized_keys与.ssh/authorized_keys内容相同，则客户端无需输入密码通过authorized_keys就能连接上云端；</li>\n</ol>\n<h3 id=\"在只有一个客户的情况下\"><a href=\"#在只有一个客户的情况下\" class=\"headerlink\" title=\"在只有一个客户的情况下\"></a>在只有一个客户的情况下</h3><p>将上文的customer_name重命名为authorized_keys，过一会客户端就会连接上云端，使用<code>lsof -i:1235</code>可查看连接建立情况，使用<code>ssh -p1235 user_name@localhost</code>可登录到客户端（<strong>user_name为客户端的linux user name</strong>）；</p>\n<h3 id=\"在有多个客户的情况下\"><a href=\"#在有多个客户的情况下\" class=\"headerlink\" title=\"在有多个客户的情况下\"></a>在有多个客户的情况下</h3><p>最简单的一种方案是：使每条隧道的云端主机对端端口唯一，也就是每个客户的隧道互相独立，但如果客户太多，会将云端的端口耗尽。笔者想要的效果是所有客户共用一个云端对端端口，即一次只有一条隧道，一次只能远程登录到一个客户。那么问题来了？如何实现？</p>\n<p>使用下述脚本（autossh-helper.sh）即可解决上述问题，</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\">filepath=<span class=\"variable\">$1</span></span><br><span class=\"line\">port1=1235</span><br><span class=\"line\"></span><br><span class=\"line\">[ <span class=\"variable\">$#</span> -eq 0 ] &amp;&amp; &#123; <span class=\"built_in\">echo</span> <span class=\"string\">\"Usage: <span class=\"variable\">$0</span> authorized_keys_filepath\"</span>; <span class=\"built_in\">exit</span> 999; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ -f <span class=\"string\">\"<span class=\"variable\">$filepath</span>\"</span> ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"comment\"># kill 1235</span></span><br><span class=\"line\">    pid=$(lsof -i:<span class=\"variable\">$port1</span> -t)</span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"variable\">$pid</span>|<span class=\"keyword\">while</span> <span class=\"built_in\">read</span> line</span><br><span class=\"line\">    <span class=\"keyword\">do</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> [ <span class=\"string\">\"\"</span> != <span class=\"string\">\"<span class=\"variable\">$line</span>\"</span> ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">            $(<span class=\"built_in\">kill</span> <span class=\"variable\">$line</span>)</span><br><span class=\"line\">        <span class=\"keyword\">fi</span></span><br><span class=\"line\">    <span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># clear known_hosts</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> &gt; /home/bbblack/.ssh/known_hosts</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># authorized_keys changed</span></span><br><span class=\"line\">    cp <span class=\"variable\">$filepath</span> /home/bbblack/.ssh/authorized_keys</span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"done ...\"</span></span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"<span class=\"variable\">$filepath</span> not exists ...\"</span></span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">exit</span> 0</span><br></pre></td></tr></table></figure>\n<p><strong>FIXME</strong><br>但是，以非root用户bbblack使用上述脚本有个问题，它需要定位出绑定在1235的pid号是多少，而1235是由sshd进程以bbblack用户在隧道建立时绑定的，这时候不管使用<code>lsof</code>还是<code>netstat</code>都无法在bbblack用户下定位出绑定在1235的pid号是多少（原因未知）。所以需要配置lsof为setuid程序（有何安全隐患？），root用户运行<code>chmod u+s /usr/bin/lsof</code>即可。</p>\n<p>接着，以bbblack账户（无需root用户）运行<code>./autossh-helper.sh customer_name_authorized_keys</code>（customer_name_authorized_keys为上文提到的文件）即可实现客户切换，其原理无非是一次只有一个客户独占ssh的authorized_keys，其他没有独占的客户由于不满足ssh登入的条件因而无法建立隧道。</p>\n<p>但是问题到这里还没有结束，云端的主机由于安全的需要一般都会配置denyhosts，denyhosts会不断检查ssh日志的失败记录，把那些连续失败多次的IP记为黑名单（ssh不可用），于是会出现这样一个现象，即使你运行了上述的autossh-helper.sh切换客户，依然还是没有客户建立隧道，这就是因为该客户所在公网IP被加入黑名单的原因。</p>\n<p>有什么解决办法呢？这时候我们的应用程序TCP端口（假定为62639，长连接）派上了用场。这里我们假设，该客户所在公网IP虽然被加入黑名单，但应用程序TCP端口（假定为62639，长连接）依然正常，因为云端和客户端需要源源不断的交互数据，此端口为长连接。若不满足此假设，则以下解决方案无效。</p>\n<p>解决方法就是，在执行autossh-helper.sh前，将与云端应用程序正常通信的客户端公网IP从黑名单解除即可。即在执行autossh-helper.sh前，必须先以<strong>root用户</strong>（因为denyhosts需要以root用户执行，这是个遗憾）执行脚本如下（public-ip-helper.sh）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ `whoami` = <span class=\"string\">\"root\"</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"\"</span> &gt; /dev/null</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"please login as root !\"</span></span><br><span class=\"line\">    <span class=\"built_in\">exit</span> 1</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\">tokill=/usr/bin/denyhosts</span><br><span class=\"line\">/bin/ps ax|grep <span class=\"variable\">$tokill</span>|grep -v <span class=\"string\">\"grep\"</span>|awk <span class=\"string\">'&#123;print $1&#125;'</span>|<span class=\"keyword\">while</span> <span class=\"built_in\">read</span> line</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">    <span class=\"built_in\">kill</span> <span class=\"variable\">$line</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\">netstat -npt|grep 62639|cut -d <span class=\"string\">\":\"</span> -f2|cut -d <span class=\"string\">\":\"</span> -f1|<span class=\"keyword\">while</span> <span class=\"built_in\">read</span> str</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">HOST=<span class=\"variable\">$&#123;str##* &#125;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$HOST</span> &gt;&gt; /usr/share/denyhosts/allowed-hosts</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'</span></span><br><span class=\"line\"><span class=\"string\">/etc/hosts.deny</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/hosts</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/hosts-restricted</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/hosts-root</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/hosts-valid</span></span><br><span class=\"line\"><span class=\"string\">/usr/share/denyhosts/data/users-hosts</span></span><br><span class=\"line\"><span class=\"string\">'</span> | grep -v <span class=\"string\">\"^$\"</span> | xargs sed -i <span class=\"string\">\"/<span class=\"variable\">$&#123;HOST&#125;</span>/d\"</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\">/etc/init.d/denyhosts start</span><br></pre></td></tr></table></figure>"},{"layout":"post","title":"记录一次华为云主机被入侵","date":"2016-05-09T04:34:00.000Z","comments":1,"_content":"\n华为工作人员打电话给我，说扫描到我的6379端口呈开放状态，6379端口开放到公网有被攻击的风险。于是，我登录华为云主机，打算检查下我的iptables。可是，使用ssh竟然登录不上……\n\n<!--more-->\n\n好在华为云主机还提供了web登录的方式，于是我以root用户登录到了华为云主机。登录后，我立即发现不对，我的非root用户怎么全都不见了？于是做了如下检查：\n\n1. 检查iptables，**立即发现异常**，我上一次调试时清除了全部防火墙规则，立马恢复防火墙设置；\n2. 检查/etc/passwd，，**立即发现异常**，发现除了root用户以外的非root用户全部被删除了，我的云主机被入侵了；\n2. 检查所有/var/logs/*.log（按更新时间检查），没有发现任何异常；\n3. 检查root用户的command history，没有发现任何异常；\n4. 检查root用户的.bash_history，没有发现任何异常；\n5. 使用`last -f wtmp`检查登录历史，没发现任何异常；\n6. 检查crontab，没有发现任何异常；\n7. 检查是否有异常进程（进程UID为0），没有发现任何异常；\n8. 检查ssh的authorized_keys，**立即发现异常**，里面竟然有入侵者机器的ssh公钥；\n\n可是，为何我的机器会被入侵而且在/var/log下没有任何痕迹呢？对方如何入侵的呢？当时并没有对redis产生怀疑。于是请教了下专业做运维的同学，他了解了我的一些情况后，告诉我可能是redis的原因。我一查redis，发现原先的key-value全丢失了，我的redis被作为攻击中介，注入了几条lua语言为value的key。为了安全请见，我决定还是备份数据，重装操作系统。\n\n总结，\n1. 必须严格设置iptables，粗心差点酿成大祸；\n2. 关注乌云发布的网络漏洞；\n","source":"_posts/2016-05-09-after-my-machine-was-attacked.markdown","raw":"---\nlayout: post\ntitle: 记录一次华为云主机被入侵\ndate: '2016-05-09 12:34'\ncomments: true\ncategories: ['网络安全']  \ntags: ['信息安全']\n---\n\n华为工作人员打电话给我，说扫描到我的6379端口呈开放状态，6379端口开放到公网有被攻击的风险。于是，我登录华为云主机，打算检查下我的iptables。可是，使用ssh竟然登录不上……\n\n<!--more-->\n\n好在华为云主机还提供了web登录的方式，于是我以root用户登录到了华为云主机。登录后，我立即发现不对，我的非root用户怎么全都不见了？于是做了如下检查：\n\n1. 检查iptables，**立即发现异常**，我上一次调试时清除了全部防火墙规则，立马恢复防火墙设置；\n2. 检查/etc/passwd，，**立即发现异常**，发现除了root用户以外的非root用户全部被删除了，我的云主机被入侵了；\n2. 检查所有/var/logs/*.log（按更新时间检查），没有发现任何异常；\n3. 检查root用户的command history，没有发现任何异常；\n4. 检查root用户的.bash_history，没有发现任何异常；\n5. 使用`last -f wtmp`检查登录历史，没发现任何异常；\n6. 检查crontab，没有发现任何异常；\n7. 检查是否有异常进程（进程UID为0），没有发现任何异常；\n8. 检查ssh的authorized_keys，**立即发现异常**，里面竟然有入侵者机器的ssh公钥；\n\n可是，为何我的机器会被入侵而且在/var/log下没有任何痕迹呢？对方如何入侵的呢？当时并没有对redis产生怀疑。于是请教了下专业做运维的同学，他了解了我的一些情况后，告诉我可能是redis的原因。我一查redis，发现原先的key-value全丢失了，我的redis被作为攻击中介，注入了几条lua语言为value的key。为了安全请见，我决定还是备份数据，重装操作系统。\n\n总结，\n1. 必须严格设置iptables，粗心差点酿成大祸；\n2. 关注乌云发布的网络漏洞；\n","slug":"after-my-machine-was-attacked","published":1,"updated":"2022-08-09T15:02:00.600Z","photos":[],"link":"","_id":"cl6mbc12l000kigu809vtoo9r","content":"<p>华为工作人员打电话给我，说扫描到我的6379端口呈开放状态，6379端口开放到公网有被攻击的风险。于是，我登录华为云主机，打算检查下我的iptables。可是，使用ssh竟然登录不上……</p>\n<a id=\"more\"></a>\n<p>好在华为云主机还提供了web登录的方式，于是我以root用户登录到了华为云主机。登录后，我立即发现不对，我的非root用户怎么全都不见了？于是做了如下检查：</p>\n<ol>\n<li>检查iptables，<strong>立即发现异常</strong>，我上一次调试时清除了全部防火墙规则，立马恢复防火墙设置；</li>\n<li>检查/etc/passwd，，<strong>立即发现异常</strong>，发现除了root用户以外的非root用户全部被删除了，我的云主机被入侵了；</li>\n<li>检查所有/var/logs/*.log（按更新时间检查），没有发现任何异常；</li>\n<li>检查root用户的command history，没有发现任何异常；</li>\n<li>检查root用户的.bash_history，没有发现任何异常；</li>\n<li>使用<code>last -f wtmp</code>检查登录历史，没发现任何异常；</li>\n<li>检查crontab，没有发现任何异常；</li>\n<li>检查是否有异常进程（进程UID为0），没有发现任何异常；</li>\n<li>检查ssh的authorized_keys，<strong>立即发现异常</strong>，里面竟然有入侵者机器的ssh公钥；</li>\n</ol>\n<p>可是，为何我的机器会被入侵而且在/var/log下没有任何痕迹呢？对方如何入侵的呢？当时并没有对redis产生怀疑。于是请教了下专业做运维的同学，他了解了我的一些情况后，告诉我可能是redis的原因。我一查redis，发现原先的key-value全丢失了，我的redis被作为攻击中介，注入了几条lua语言为value的key。为了安全请见，我决定还是备份数据，重装操作系统。</p>\n<p>总结，</p>\n<ol>\n<li>必须严格设置iptables，粗心差点酿成大祸；</li>\n<li>关注乌云发布的网络漏洞；</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>华为工作人员打电话给我，说扫描到我的6379端口呈开放状态，6379端口开放到公网有被攻击的风险。于是，我登录华为云主机，打算检查下我的iptables。可是，使用ssh竟然登录不上……</p>","more":"<p>好在华为云主机还提供了web登录的方式，于是我以root用户登录到了华为云主机。登录后，我立即发现不对，我的非root用户怎么全都不见了？于是做了如下检查：</p>\n<ol>\n<li>检查iptables，<strong>立即发现异常</strong>，我上一次调试时清除了全部防火墙规则，立马恢复防火墙设置；</li>\n<li>检查/etc/passwd，，<strong>立即发现异常</strong>，发现除了root用户以外的非root用户全部被删除了，我的云主机被入侵了；</li>\n<li>检查所有/var/logs/*.log（按更新时间检查），没有发现任何异常；</li>\n<li>检查root用户的command history，没有发现任何异常；</li>\n<li>检查root用户的.bash_history，没有发现任何异常；</li>\n<li>使用<code>last -f wtmp</code>检查登录历史，没发现任何异常；</li>\n<li>检查crontab，没有发现任何异常；</li>\n<li>检查是否有异常进程（进程UID为0），没有发现任何异常；</li>\n<li>检查ssh的authorized_keys，<strong>立即发现异常</strong>，里面竟然有入侵者机器的ssh公钥；</li>\n</ol>\n<p>可是，为何我的机器会被入侵而且在/var/log下没有任何痕迹呢？对方如何入侵的呢？当时并没有对redis产生怀疑。于是请教了下专业做运维的同学，他了解了我的一些情况后，告诉我可能是redis的原因。我一查redis，发现原先的key-value全丢失了，我的redis被作为攻击中介，注入了几条lua语言为value的key。为了安全请见，我决定还是备份数据，重装操作系统。</p>\n<p>总结，</p>\n<ol>\n<li>必须严格设置iptables，粗心差点酿成大祸；</li>\n<li>关注乌云发布的网络漏洞；</li>\n</ol>"},{"layout":"post","title":"HBase增量备份数据","date":"2016-05-11T13:19:00.000Z","comments":1,"_content":"\nHBase如何增量备份数据呢？\n\n<!--more-->\n\n## 传统的Export不支持自定义rowkey增量数据导出\n\n导出语法：\n\n```\nhbase org.apache.hadoop.hbase.mapreduce.Export your_hbase_table_name your_hdfs_file_path\n```\n\n下面简单介绍如何实现自定义rowkey增量导出HBase数据。\n\n<!--more-->\n\n## 运行环境\n\n笔者的hadoop+hbase环境如下：\n\n$ `hadoop version`\n\n```\nHadoop 2.6.0-cdh5.4.3\nSubversion http://github.com/cloudera/hadoop -r 4cd9f51a3f1ef748d45b8d77d0f211ad44296d4b\nCompiled by jenkins on 2015-06-25T02:34Z\nCompiled with protoc 2.5.0\nFrom source with checksum 4acea6ac185376e0b48b33695e88e7a7\nThis command was run using /opt/cloudera/parcels/CDH-5.4.3-1.cdh5.4.3.p0.6/jars/hadoop-common-2.6.0-cdh5.4.3.jar\n```\n\n$ `hbase version`\n\n```\nJava HotSpot(TM) 64-Bit Server VM warning: Using incremental CMS is deprecated and will likely be removed in a future release\n16/06/04 13:13:30 INFO util.VersionInfo: HBase 1.0.0-cdh5.4.3\n16/06/04 13:13:30 INFO util.VersionInfo: Source code repository file:///data/jenkins/workspace/generic-package-ubuntu64-12-04/CDH5.4.3-Packaging-HBase-2015-06-24_19-16-53/hbase-1.0.0+cdh5.4.3+159-1.cdh5.4.3.p0.9~precise revision=Unknown\n16/06/04 13:13:30 INFO util.VersionInfo: Compiled by jenkins on Wed Jun 24 19:32:40 PDT 2015\n16/06/04 13:13:30 INFO util.VersionInfo: From source with checksum d5809febb1e487265280a25f5c74202e\n```\n\n## 如何定制自己的Export实现自定义rowkey增量数据导出\n\n首先，你需要找到源码org.apache.hadoop.hbase.mapreduce.Export.java，修改它为你想要的，并将其上传到具备hadoop+hbase环境的机器上；\n\n紧接着，运行如下语句：\n\n```bash\n# 编译并打包\nexport HADOOP_CLASSPATH=$(hbase classpath)\nhadoop com.sun.tools.javac.Main Export.java\njar cf Export.jar Export.class\n# 准备好hdfs路径\nsu\nsu hdfs -c 'hdfs dfs -mkdir /backup'\nsu hdfs -c 'hdfs dfs -mkdir /backup/20160512'\nsu hdfs -c 'hdfs dfs -ls  /'\n# 使用jar包\n## 兼容传统Export\nhadoop jar Export.jar Export group_hour /backup/20160512/group_hour\n## 实现了自定义rowkey解析\nhadoop jar Export.jar Export -D hbase.mapreduce.scan.row.start=1,9,2016-05-01 -D hbase.mapreduce.scan.row.stop=1,9,2015-05-02 group_hour /backup/20160512/group_hour_rowkey\n```\n\n上述命令执行成功后，就可执行`hdfs dfs -get your_hdfs_filepath your_filesystem_filepath`取得你的导出数据啦！\n\n笔者修改后的Export.java如下：\n\n```java\n/**\n *\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport java.io.IOException;\nimport java.text.DateFormat;\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\n\nimport com.sun.security.auth.module.UnixSystem;\n\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nimport org.apache.hadoop.hbase.classification.InterfaceAudience;\nimport org.apache.hadoop.hbase.classification.InterfaceStability;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.client.Result;\nimport org.apache.hadoop.hbase.client.Scan;\nimport org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;\nimport org.apache.hadoop.hbase.filter.Filter;\nimport org.apache.hadoop.hbase.filter.IncompatibleFilterException;\nimport org.apache.hadoop.hbase.filter.PrefixFilter;\nimport org.apache.hadoop.hbase.filter.RegexStringComparator;\nimport org.apache.hadoop.hbase.filter.RowFilter;\nimport org.apache.hadoop.hbase.io.ImmutableBytesWritable;\nimport org.apache.hadoop.hbase.mapreduce.IdentityTableMapper;\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat;\nimport org.apache.hadoop.hbase.util.Bytes;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\n/**\n * Export an HBase table. Writes content to sequence files up in HDFS. Use\n * {@link Import} to read it back in again.\n */\n@InterfaceAudience.Public\n@InterfaceStability.Stable\npublic class Export {\n    private static final Log LOG = LogFactory.getLog(Export.class);\n    final static String NAME = \"export\";\n    final static String RAW_SCAN = \"hbase.mapreduce.include.deleted.rows\";\n    final static String EXPORT_BATCHING = \"hbase.export.scanner.batch\";\n    final static DateFormat format = new SimpleDateFormat(\"yyyy-MM-dd\");\n\n    /**\n     * Sets up the actual job.\n     *\n     * @param conf\n     *            The current configuration.\n     * @param args\n     *            The command line parameters.\n     * @return The newly created job.\n     * @throws IOException\n     *             When setting up the job fails.\n     */\n    public static Job createSubmittableJob(Configuration conf, String[] args)\n            throws IOException {\n        String tableName = args[0];\n        Path outputDir = new Path(args[1]);\n        Job job = new Job(conf, NAME + \"_\" + tableName);\n        job.setJobName(NAME + \"_\" + tableName);\n        job.setJarByClass(Export.class);\n        job.setUser(\"hdfs\");\n        // Set optional scan parameters\n        Scan s = getConfiguredScanForJob(conf, args);\n        IdentityTableMapper.initJob(tableName, s, IdentityTableMapper.class,\n                job);\n        // No reducers. Just write straight to output files.\n        job.setNumReduceTasks(0);\n        job.setOutputFormatClass(SequenceFileOutputFormat.class);\n        job.setOutputKeyClass(ImmutableBytesWritable.class);\n        job.setOutputValueClass(Result.class);\n        FileOutputFormat.setOutputPath(job, outputDir); // job conf doesn't\n                                                        // contain the conf so\n                                                        // doesn't have a\n                                                        // default fs.\n        return job;\n    }\n\n    private static Scan getConfiguredScanForJob(Configuration conf,\n            String[] args) throws IOException {\n        Scan s = new Scan();\n        // Optional arguments.\n        // Set Scan Versions\n        int versions = args.length > 2 ? Integer.parseInt(args[2]) : 1;\n        s.setMaxVersions(versions);\n        // Set Scan Range\n        long startTime = args.length > 3 ? Long.parseLong(args[3]) : 0L;\n        long endTime = args.length > 4 ? Long.parseLong(args[4])\n                : Long.MAX_VALUE;\n        s.setTimeRange(startTime, endTime);\n        // Set cache blocks\n        s.setCacheBlocks(false);\n        // set Start and Stop row\n        if (conf.get(TableInputFormat.SCAN_ROW_START) != null) {\n            String rowStart[] = conf.get(TableInputFormat.SCAN_ROW_START).split(\",\");\n            Short companyID = Short.valueOf(rowStart[0]);\n            Short deviceID = Short.valueOf(rowStart[1]);\n            Long insertTime = 0l;\n            try {\n                insertTime = format.parse(rowStart[2]).getTime();\n            } catch (ParseException e) {\n                // ignore\n            }\n            s.setStartRow(Bytes.add(Bytes.toBytes(companyID),\n                    Bytes.toBytes(deviceID), Bytes.toBytes(insertTime)));\n        }\n        if (conf.get(TableInputFormat.SCAN_ROW_STOP) != null) {\n            String rowStop[] = conf.get(TableInputFormat.SCAN_ROW_STOP).split(\",\");\n            Short companyID = Short.valueOf(rowStop[0]);\n            Short deviceID = Short.valueOf(rowStop[1]);\n            Long insertTime = 0l;\n            try {\n                insertTime = format.parse(rowStop[2]).getTime();\n            } catch (ParseException e) {\n                // ignore\n            }\n            s.setStopRow(Bytes.add(Bytes.toBytes(companyID),\n                    Bytes.toBytes(deviceID), Bytes.toBytes(insertTime)));\n        }\n        // Set Scan Column Family\n        boolean raw = Boolean.parseBoolean(conf.get(RAW_SCAN));\n        if (raw) {\n            s.setRaw(raw);\n        }\n\n        if (conf.get(TableInputFormat.SCAN_COLUMN_FAMILY) != null) {\n            s.addFamily(Bytes.toBytes(conf\n                    .get(TableInputFormat.SCAN_COLUMN_FAMILY)));\n        }\n        // Set RowFilter or Prefix Filter if applicable.\n        Filter exportFilter = getExportFilter(args);\n        if (exportFilter != null) {\n            LOG.info(\"Setting Scan Filter for Export.\");\n            s.setFilter(exportFilter);\n        }\n\n        int batching = conf.getInt(EXPORT_BATCHING, -1);\n        if (batching != -1) {\n            try {\n                s.setBatch(batching);\n            } catch (IncompatibleFilterException e) {\n                LOG.error(\"Batching could not be set\", e);\n            }\n        }\n        StringBuffer sb = new StringBuffer(\"versions=\" + versions + \", starttime=\" + startTime\n                + \", endtime=\" + endTime + \", keepDeletedCells=\" + raw);\n        if (conf.get(TableInputFormat.SCAN_ROW_START) != null) {\n            sb.append(\", startRow=\" + conf.get(TableInputFormat.SCAN_ROW_START));\n            sb.append(\", stopRow=\" + conf.get(TableInputFormat.SCAN_ROW_STOP));\n        }\n        LOG.info(sb.toString());\n        return s;\n    }\n\n    private static Filter getExportFilter(String[] args) {\n        Filter exportFilter = null;\n        String filterCriteria = (args.length > 5) ? args[5] : null;\n        if (filterCriteria == null)\n            return null;\n        if (filterCriteria.startsWith(\"^\")) {\n            String regexPattern = filterCriteria.substring(1,\n                    filterCriteria.length());\n            exportFilter = new RowFilter(CompareOp.EQUAL,\n                    new RegexStringComparator(regexPattern));\n        } else {\n            exportFilter = new PrefixFilter(Bytes.toBytes(filterCriteria));\n        }\n        return exportFilter;\n    }\n\n    /*\n     * @param errorMsg Error message. Can be null.\n     */\n    private static void usage(final String errorMsg) {\n        if (errorMsg != null && errorMsg.length() > 0) {\n            System.err.println(\"ERROR: \" + errorMsg);\n        }\n        System.err\n                .println(\"Usage: Export [-D <property=value>]* <tablename> <outputdir> [<versions> \"\n                        + \"[<starttime> [<endtime>]] [^[regex pattern] or [Prefix] to filter]]\\n\");\n        System.err\n                .println(\"  Note: -D properties will be applied to the conf used. \");\n        System.err.println(\"  For example: \");\n        System.err\n                .println(\"   -D mapreduce.output.fileoutputformat.compress=true\");\n        System.err\n                .println(\"   -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec\");\n        System.err\n                .println(\"   -D mapreduce.output.fileoutputformat.compress.type=BLOCK\");\n        System.err\n                .println(\"  Additionally, the following SCAN properties can be specified\");\n        System.err.println(\"  to control/limit what is exported..\");\n        System.err.println(\"   -D \" + TableInputFormat.SCAN_COLUMN_FAMILY\n                + \"=<familyName>\");\n        System.err.println(\"   -D \" + RAW_SCAN + \"=true\");\n        System.err.println(\"   -D \" + TableInputFormat.SCAN_ROW_START\n                + \"=<CompanyID(Short),DeviceID(Short),yyyy-MM-dd(String)>\");\n        System.err.println(\"   -D \" + TableInputFormat.SCAN_ROW_STOP\n                + \"=<CompanyID(Short),DeviceID(Short),yyyy-MM-dd(String)>\");\n        System.err\n                .println(\"For performance consider the following properties:\\n\"\n                        + \"   -Dhbase.client.scanner.caching=100\\n\"\n                        + \"   -Dmapreduce.map.speculative=false\\n\"\n                        + \"   -Dmapreduce.reduce.speculative=false\");\n        System.err\n                .println(\"For tables with very wide rows consider setting the batch size as below:\\n\"\n                        + \"   -D\" + EXPORT_BATCHING + \"=10\");\n    }\n\n    /**\n     * Main entry point.\n     *\n     * @param args\n     *            The command line parameters.\n     * @throws Exception\n     *             When running the job fails.\n     */\n    public static void main(String[] args) throws Exception {\n        System.setProperty(\"HADOOP_USER_NAME\", \"hdfs\");\n        UnixSystem us = new UnixSystem();\n        System.out.println(\"Unix Username : \" + us.getUsername());\n        // -----------------------------------------------------\n        Configuration conf = HBaseConfiguration.create();\n        String[] otherArgs = new GenericOptionsParser(conf, args)\n                .getRemainingArgs();\n        if (otherArgs.length < 2) {\n            usage(\"Wrong number of arguments: \" + otherArgs.length);\n            System.exit(-1);\n        }\n        // Check StartRow And StopRow\n        String rowStart = conf.get(TableInputFormat.SCAN_ROW_START);\n        String rowStop = conf.get(TableInputFormat.SCAN_ROW_STOP);\n        if(rowStart == null && rowStop == null) {\n            // do nothing\n        } else {\n            if(rowStart != null && rowStop != null) {\n                // check rowStart\n                String strToCheck[] = rowStart.split(\",\");\n                try {\n                    Short.valueOf(strToCheck[0]);\n                    Short.valueOf(strToCheck[1]);\n                } catch (Exception e) {\n                    usage(\"String parsed to Short error ! Wrong argument of \" + TableInputFormat.SCAN_ROW_START + \" : \" + rowStart);\n                    System.exit(-1);\n                }\n                try {\n                    format.parse(strToCheck[2]);\n                } catch (Exception e) {\n                    usage(\"yyyy-MM-dd String parsed to Date error ! Wrong argument of \" + TableInputFormat.SCAN_ROW_START + \" : \" + rowStart);\n                    System.exit(-1);\n                }\n                // check rowStop\n                strToCheck = rowStop.split(\",\");\n                try {\n                    Short.valueOf(strToCheck[0]);\n                    Short.valueOf(strToCheck[1]);\n                } catch (Exception e) {\n                    usage(\"String parsed to Short error ! Wrong argument of \" + TableInputFormat.SCAN_ROW_STOP + \" : \" + rowStop);\n                    System.exit(-1);\n                }\n                try {\n                    format.parse(strToCheck[2]);\n                } catch (Exception e) {\n                    usage(\"yyyy-MM-dd String parsed to Date error ! Wrong argument of \" + TableInputFormat.SCAN_ROW_STOP + \" : \" + rowStop);\n                    System.exit(-1);\n                }\n            } else {\n                usage(TableInputFormat.SCAN_ROW_START + \" and \" + TableInputFormat.SCAN_ROW_STOP + \" must both not be null.\");\n                System.exit(-1);\n            }\n        }\n        Job job = createSubmittableJob(conf, otherArgs);\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n","source":"_posts/2016-05-11-hbase-incremental-backup.markdown","raw":"---\nlayout: post\ntitle: HBase增量备份数据\ndate: '2016-05-11 21:19'\ncomments: true\ncategories: ['编程实践']  \ntags: ['HBase', 'Hadoop']\n---\n\nHBase如何增量备份数据呢？\n\n<!--more-->\n\n## 传统的Export不支持自定义rowkey增量数据导出\n\n导出语法：\n\n```\nhbase org.apache.hadoop.hbase.mapreduce.Export your_hbase_table_name your_hdfs_file_path\n```\n\n下面简单介绍如何实现自定义rowkey增量导出HBase数据。\n\n<!--more-->\n\n## 运行环境\n\n笔者的hadoop+hbase环境如下：\n\n$ `hadoop version`\n\n```\nHadoop 2.6.0-cdh5.4.3\nSubversion http://github.com/cloudera/hadoop -r 4cd9f51a3f1ef748d45b8d77d0f211ad44296d4b\nCompiled by jenkins on 2015-06-25T02:34Z\nCompiled with protoc 2.5.0\nFrom source with checksum 4acea6ac185376e0b48b33695e88e7a7\nThis command was run using /opt/cloudera/parcels/CDH-5.4.3-1.cdh5.4.3.p0.6/jars/hadoop-common-2.6.0-cdh5.4.3.jar\n```\n\n$ `hbase version`\n\n```\nJava HotSpot(TM) 64-Bit Server VM warning: Using incremental CMS is deprecated and will likely be removed in a future release\n16/06/04 13:13:30 INFO util.VersionInfo: HBase 1.0.0-cdh5.4.3\n16/06/04 13:13:30 INFO util.VersionInfo: Source code repository file:///data/jenkins/workspace/generic-package-ubuntu64-12-04/CDH5.4.3-Packaging-HBase-2015-06-24_19-16-53/hbase-1.0.0+cdh5.4.3+159-1.cdh5.4.3.p0.9~precise revision=Unknown\n16/06/04 13:13:30 INFO util.VersionInfo: Compiled by jenkins on Wed Jun 24 19:32:40 PDT 2015\n16/06/04 13:13:30 INFO util.VersionInfo: From source with checksum d5809febb1e487265280a25f5c74202e\n```\n\n## 如何定制自己的Export实现自定义rowkey增量数据导出\n\n首先，你需要找到源码org.apache.hadoop.hbase.mapreduce.Export.java，修改它为你想要的，并将其上传到具备hadoop+hbase环境的机器上；\n\n紧接着，运行如下语句：\n\n```bash\n# 编译并打包\nexport HADOOP_CLASSPATH=$(hbase classpath)\nhadoop com.sun.tools.javac.Main Export.java\njar cf Export.jar Export.class\n# 准备好hdfs路径\nsu\nsu hdfs -c 'hdfs dfs -mkdir /backup'\nsu hdfs -c 'hdfs dfs -mkdir /backup/20160512'\nsu hdfs -c 'hdfs dfs -ls  /'\n# 使用jar包\n## 兼容传统Export\nhadoop jar Export.jar Export group_hour /backup/20160512/group_hour\n## 实现了自定义rowkey解析\nhadoop jar Export.jar Export -D hbase.mapreduce.scan.row.start=1,9,2016-05-01 -D hbase.mapreduce.scan.row.stop=1,9,2015-05-02 group_hour /backup/20160512/group_hour_rowkey\n```\n\n上述命令执行成功后，就可执行`hdfs dfs -get your_hdfs_filepath your_filesystem_filepath`取得你的导出数据啦！\n\n笔者修改后的Export.java如下：\n\n```java\n/**\n *\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport java.io.IOException;\nimport java.text.DateFormat;\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\n\nimport com.sun.security.auth.module.UnixSystem;\n\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nimport org.apache.hadoop.hbase.classification.InterfaceAudience;\nimport org.apache.hadoop.hbase.classification.InterfaceStability;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.client.Result;\nimport org.apache.hadoop.hbase.client.Scan;\nimport org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;\nimport org.apache.hadoop.hbase.filter.Filter;\nimport org.apache.hadoop.hbase.filter.IncompatibleFilterException;\nimport org.apache.hadoop.hbase.filter.PrefixFilter;\nimport org.apache.hadoop.hbase.filter.RegexStringComparator;\nimport org.apache.hadoop.hbase.filter.RowFilter;\nimport org.apache.hadoop.hbase.io.ImmutableBytesWritable;\nimport org.apache.hadoop.hbase.mapreduce.IdentityTableMapper;\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat;\nimport org.apache.hadoop.hbase.util.Bytes;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\n/**\n * Export an HBase table. Writes content to sequence files up in HDFS. Use\n * {@link Import} to read it back in again.\n */\n@InterfaceAudience.Public\n@InterfaceStability.Stable\npublic class Export {\n    private static final Log LOG = LogFactory.getLog(Export.class);\n    final static String NAME = \"export\";\n    final static String RAW_SCAN = \"hbase.mapreduce.include.deleted.rows\";\n    final static String EXPORT_BATCHING = \"hbase.export.scanner.batch\";\n    final static DateFormat format = new SimpleDateFormat(\"yyyy-MM-dd\");\n\n    /**\n     * Sets up the actual job.\n     *\n     * @param conf\n     *            The current configuration.\n     * @param args\n     *            The command line parameters.\n     * @return The newly created job.\n     * @throws IOException\n     *             When setting up the job fails.\n     */\n    public static Job createSubmittableJob(Configuration conf, String[] args)\n            throws IOException {\n        String tableName = args[0];\n        Path outputDir = new Path(args[1]);\n        Job job = new Job(conf, NAME + \"_\" + tableName);\n        job.setJobName(NAME + \"_\" + tableName);\n        job.setJarByClass(Export.class);\n        job.setUser(\"hdfs\");\n        // Set optional scan parameters\n        Scan s = getConfiguredScanForJob(conf, args);\n        IdentityTableMapper.initJob(tableName, s, IdentityTableMapper.class,\n                job);\n        // No reducers. Just write straight to output files.\n        job.setNumReduceTasks(0);\n        job.setOutputFormatClass(SequenceFileOutputFormat.class);\n        job.setOutputKeyClass(ImmutableBytesWritable.class);\n        job.setOutputValueClass(Result.class);\n        FileOutputFormat.setOutputPath(job, outputDir); // job conf doesn't\n                                                        // contain the conf so\n                                                        // doesn't have a\n                                                        // default fs.\n        return job;\n    }\n\n    private static Scan getConfiguredScanForJob(Configuration conf,\n            String[] args) throws IOException {\n        Scan s = new Scan();\n        // Optional arguments.\n        // Set Scan Versions\n        int versions = args.length > 2 ? Integer.parseInt(args[2]) : 1;\n        s.setMaxVersions(versions);\n        // Set Scan Range\n        long startTime = args.length > 3 ? Long.parseLong(args[3]) : 0L;\n        long endTime = args.length > 4 ? Long.parseLong(args[4])\n                : Long.MAX_VALUE;\n        s.setTimeRange(startTime, endTime);\n        // Set cache blocks\n        s.setCacheBlocks(false);\n        // set Start and Stop row\n        if (conf.get(TableInputFormat.SCAN_ROW_START) != null) {\n            String rowStart[] = conf.get(TableInputFormat.SCAN_ROW_START).split(\",\");\n            Short companyID = Short.valueOf(rowStart[0]);\n            Short deviceID = Short.valueOf(rowStart[1]);\n            Long insertTime = 0l;\n            try {\n                insertTime = format.parse(rowStart[2]).getTime();\n            } catch (ParseException e) {\n                // ignore\n            }\n            s.setStartRow(Bytes.add(Bytes.toBytes(companyID),\n                    Bytes.toBytes(deviceID), Bytes.toBytes(insertTime)));\n        }\n        if (conf.get(TableInputFormat.SCAN_ROW_STOP) != null) {\n            String rowStop[] = conf.get(TableInputFormat.SCAN_ROW_STOP).split(\",\");\n            Short companyID = Short.valueOf(rowStop[0]);\n            Short deviceID = Short.valueOf(rowStop[1]);\n            Long insertTime = 0l;\n            try {\n                insertTime = format.parse(rowStop[2]).getTime();\n            } catch (ParseException e) {\n                // ignore\n            }\n            s.setStopRow(Bytes.add(Bytes.toBytes(companyID),\n                    Bytes.toBytes(deviceID), Bytes.toBytes(insertTime)));\n        }\n        // Set Scan Column Family\n        boolean raw = Boolean.parseBoolean(conf.get(RAW_SCAN));\n        if (raw) {\n            s.setRaw(raw);\n        }\n\n        if (conf.get(TableInputFormat.SCAN_COLUMN_FAMILY) != null) {\n            s.addFamily(Bytes.toBytes(conf\n                    .get(TableInputFormat.SCAN_COLUMN_FAMILY)));\n        }\n        // Set RowFilter or Prefix Filter if applicable.\n        Filter exportFilter = getExportFilter(args);\n        if (exportFilter != null) {\n            LOG.info(\"Setting Scan Filter for Export.\");\n            s.setFilter(exportFilter);\n        }\n\n        int batching = conf.getInt(EXPORT_BATCHING, -1);\n        if (batching != -1) {\n            try {\n                s.setBatch(batching);\n            } catch (IncompatibleFilterException e) {\n                LOG.error(\"Batching could not be set\", e);\n            }\n        }\n        StringBuffer sb = new StringBuffer(\"versions=\" + versions + \", starttime=\" + startTime\n                + \", endtime=\" + endTime + \", keepDeletedCells=\" + raw);\n        if (conf.get(TableInputFormat.SCAN_ROW_START) != null) {\n            sb.append(\", startRow=\" + conf.get(TableInputFormat.SCAN_ROW_START));\n            sb.append(\", stopRow=\" + conf.get(TableInputFormat.SCAN_ROW_STOP));\n        }\n        LOG.info(sb.toString());\n        return s;\n    }\n\n    private static Filter getExportFilter(String[] args) {\n        Filter exportFilter = null;\n        String filterCriteria = (args.length > 5) ? args[5] : null;\n        if (filterCriteria == null)\n            return null;\n        if (filterCriteria.startsWith(\"^\")) {\n            String regexPattern = filterCriteria.substring(1,\n                    filterCriteria.length());\n            exportFilter = new RowFilter(CompareOp.EQUAL,\n                    new RegexStringComparator(regexPattern));\n        } else {\n            exportFilter = new PrefixFilter(Bytes.toBytes(filterCriteria));\n        }\n        return exportFilter;\n    }\n\n    /*\n     * @param errorMsg Error message. Can be null.\n     */\n    private static void usage(final String errorMsg) {\n        if (errorMsg != null && errorMsg.length() > 0) {\n            System.err.println(\"ERROR: \" + errorMsg);\n        }\n        System.err\n                .println(\"Usage: Export [-D <property=value>]* <tablename> <outputdir> [<versions> \"\n                        + \"[<starttime> [<endtime>]] [^[regex pattern] or [Prefix] to filter]]\\n\");\n        System.err\n                .println(\"  Note: -D properties will be applied to the conf used. \");\n        System.err.println(\"  For example: \");\n        System.err\n                .println(\"   -D mapreduce.output.fileoutputformat.compress=true\");\n        System.err\n                .println(\"   -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec\");\n        System.err\n                .println(\"   -D mapreduce.output.fileoutputformat.compress.type=BLOCK\");\n        System.err\n                .println(\"  Additionally, the following SCAN properties can be specified\");\n        System.err.println(\"  to control/limit what is exported..\");\n        System.err.println(\"   -D \" + TableInputFormat.SCAN_COLUMN_FAMILY\n                + \"=<familyName>\");\n        System.err.println(\"   -D \" + RAW_SCAN + \"=true\");\n        System.err.println(\"   -D \" + TableInputFormat.SCAN_ROW_START\n                + \"=<CompanyID(Short),DeviceID(Short),yyyy-MM-dd(String)>\");\n        System.err.println(\"   -D \" + TableInputFormat.SCAN_ROW_STOP\n                + \"=<CompanyID(Short),DeviceID(Short),yyyy-MM-dd(String)>\");\n        System.err\n                .println(\"For performance consider the following properties:\\n\"\n                        + \"   -Dhbase.client.scanner.caching=100\\n\"\n                        + \"   -Dmapreduce.map.speculative=false\\n\"\n                        + \"   -Dmapreduce.reduce.speculative=false\");\n        System.err\n                .println(\"For tables with very wide rows consider setting the batch size as below:\\n\"\n                        + \"   -D\" + EXPORT_BATCHING + \"=10\");\n    }\n\n    /**\n     * Main entry point.\n     *\n     * @param args\n     *            The command line parameters.\n     * @throws Exception\n     *             When running the job fails.\n     */\n    public static void main(String[] args) throws Exception {\n        System.setProperty(\"HADOOP_USER_NAME\", \"hdfs\");\n        UnixSystem us = new UnixSystem();\n        System.out.println(\"Unix Username : \" + us.getUsername());\n        // -----------------------------------------------------\n        Configuration conf = HBaseConfiguration.create();\n        String[] otherArgs = new GenericOptionsParser(conf, args)\n                .getRemainingArgs();\n        if (otherArgs.length < 2) {\n            usage(\"Wrong number of arguments: \" + otherArgs.length);\n            System.exit(-1);\n        }\n        // Check StartRow And StopRow\n        String rowStart = conf.get(TableInputFormat.SCAN_ROW_START);\n        String rowStop = conf.get(TableInputFormat.SCAN_ROW_STOP);\n        if(rowStart == null && rowStop == null) {\n            // do nothing\n        } else {\n            if(rowStart != null && rowStop != null) {\n                // check rowStart\n                String strToCheck[] = rowStart.split(\",\");\n                try {\n                    Short.valueOf(strToCheck[0]);\n                    Short.valueOf(strToCheck[1]);\n                } catch (Exception e) {\n                    usage(\"String parsed to Short error ! Wrong argument of \" + TableInputFormat.SCAN_ROW_START + \" : \" + rowStart);\n                    System.exit(-1);\n                }\n                try {\n                    format.parse(strToCheck[2]);\n                } catch (Exception e) {\n                    usage(\"yyyy-MM-dd String parsed to Date error ! Wrong argument of \" + TableInputFormat.SCAN_ROW_START + \" : \" + rowStart);\n                    System.exit(-1);\n                }\n                // check rowStop\n                strToCheck = rowStop.split(\",\");\n                try {\n                    Short.valueOf(strToCheck[0]);\n                    Short.valueOf(strToCheck[1]);\n                } catch (Exception e) {\n                    usage(\"String parsed to Short error ! Wrong argument of \" + TableInputFormat.SCAN_ROW_STOP + \" : \" + rowStop);\n                    System.exit(-1);\n                }\n                try {\n                    format.parse(strToCheck[2]);\n                } catch (Exception e) {\n                    usage(\"yyyy-MM-dd String parsed to Date error ! Wrong argument of \" + TableInputFormat.SCAN_ROW_STOP + \" : \" + rowStop);\n                    System.exit(-1);\n                }\n            } else {\n                usage(TableInputFormat.SCAN_ROW_START + \" and \" + TableInputFormat.SCAN_ROW_STOP + \" must both not be null.\");\n                System.exit(-1);\n            }\n        }\n        Job job = createSubmittableJob(conf, otherArgs);\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n","slug":"hbase-incremental-backup","published":1,"updated":"2022-08-09T15:02:00.604Z","photos":[],"link":"","_id":"cl6mbc12q000nigu8aa2cniom","content":"<p>HBase如何增量备份数据呢？</p>\n<a id=\"more\"></a>\n<h2 id=\"传统的Export不支持自定义rowkey增量数据导出\"><a href=\"#传统的Export不支持自定义rowkey增量数据导出\" class=\"headerlink\" title=\"传统的Export不支持自定义rowkey增量数据导出\"></a>传统的Export不支持自定义rowkey增量数据导出</h2><p>导出语法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hbase org.apache.hadoop.hbase.mapreduce.Export your_hbase_table_name your_hdfs_file_path</span><br></pre></td></tr></table></figure>\n<p>下面简单介绍如何实现自定义rowkey增量导出HBase数据。</p>\n<!--more-->\n<h2 id=\"运行环境\"><a href=\"#运行环境\" class=\"headerlink\" title=\"运行环境\"></a>运行环境</h2><p>笔者的hadoop+hbase环境如下：</p>\n<p>$ <code>hadoop version</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Hadoop 2.6.0-cdh5.4.3</span><br><span class=\"line\">Subversion http://github.com/cloudera/hadoop -r 4cd9f51a3f1ef748d45b8d77d0f211ad44296d4b</span><br><span class=\"line\">Compiled by jenkins on 2015-06-25T02:34Z</span><br><span class=\"line\">Compiled with protoc 2.5.0</span><br><span class=\"line\">From source with checksum 4acea6ac185376e0b48b33695e88e7a7</span><br><span class=\"line\">This command was run using /opt/cloudera/parcels/CDH-5.4.3-1.cdh5.4.3.p0.6/jars/hadoop-common-2.6.0-cdh5.4.3.jar</span><br></pre></td></tr></table></figure>\n<p>$ <code>hbase version</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Java HotSpot(TM) 64-Bit Server VM warning: Using incremental CMS is deprecated and will likely be removed in a future release</span><br><span class=\"line\">16/06/04 13:13:30 INFO util.VersionInfo: HBase 1.0.0-cdh5.4.3</span><br><span class=\"line\">16/06/04 13:13:30 INFO util.VersionInfo: Source code repository file:///data/jenkins/workspace/generic-package-ubuntu64-12-04/CDH5.4.3-Packaging-HBase-2015-06-24_19-16-53/hbase-1.0.0+cdh5.4.3+159-1.cdh5.4.3.p0.9~precise revision=Unknown</span><br><span class=\"line\">16/06/04 13:13:30 INFO util.VersionInfo: Compiled by jenkins on Wed Jun 24 19:32:40 PDT 2015</span><br><span class=\"line\">16/06/04 13:13:30 INFO util.VersionInfo: From source with checksum d5809febb1e487265280a25f5c74202e</span><br></pre></td></tr></table></figure>\n<h2 id=\"如何定制自己的Export实现自定义rowkey增量数据导出\"><a href=\"#如何定制自己的Export实现自定义rowkey增量数据导出\" class=\"headerlink\" title=\"如何定制自己的Export实现自定义rowkey增量数据导出\"></a>如何定制自己的Export实现自定义rowkey增量数据导出</h2><p>首先，你需要找到源码org.apache.hadoop.hbase.mapreduce.Export.java，修改它为你想要的，并将其上传到具备hadoop+hbase环境的机器上；</p>\n<p>紧接着，运行如下语句：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 编译并打包</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_CLASSPATH=$(hbase classpath)</span><br><span class=\"line\">hadoop com.sun.tools.javac.Main Export.java</span><br><span class=\"line\">jar cf Export.jar Export.class</span><br><span class=\"line\"><span class=\"comment\"># 准备好hdfs路径</span></span><br><span class=\"line\">su</span><br><span class=\"line\">su hdfs -c <span class=\"string\">'hdfs dfs -mkdir /backup'</span></span><br><span class=\"line\">su hdfs -c <span class=\"string\">'hdfs dfs -mkdir /backup/20160512'</span></span><br><span class=\"line\">su hdfs -c <span class=\"string\">'hdfs dfs -ls  /'</span></span><br><span class=\"line\"><span class=\"comment\"># 使用jar包</span></span><br><span class=\"line\"><span class=\"comment\">## 兼容传统Export</span></span><br><span class=\"line\">hadoop jar Export.jar Export group_hour /backup/20160512/group_hour</span><br><span class=\"line\"><span class=\"comment\">## 实现了自定义rowkey解析</span></span><br><span class=\"line\">hadoop jar Export.jar Export -D hbase.mapreduce.scan.row.start=1,9,2016-05-01 -D hbase.mapreduce.scan.row.stop=1,9,2015-05-02 group_hour /backup/20160512/group_hour_rowkey</span><br></pre></td></tr></table></figure>\n<p>上述命令执行成功后，就可执行<code>hdfs dfs -get your_hdfs_filepath your_filesystem_filepath</code>取得你的导出数据啦！</p>\n<p>笔者修改后的Export.java如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class=\"line\"><span class=\"comment\"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class=\"line\"><span class=\"comment\"> * distributed with this work for additional information</span></span><br><span class=\"line\"><span class=\"comment\"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class=\"line\"><span class=\"comment\"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class=\"line\"><span class=\"comment\"> * \"License\"); you may not use this file except in compliance</span></span><br><span class=\"line\"><span class=\"comment\"> * with the License.  You may obtain a copy of the License at</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> *     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class=\"line\"><span class=\"comment\"> * distributed under the License is distributed on an \"AS IS\" BASIS,</span></span><br><span class=\"line\"><span class=\"comment\"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class=\"line\"><span class=\"comment\"> * See the License for the specific language governing permissions and</span></span><br><span class=\"line\"><span class=\"comment\"> * limitations under the License.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.text.DateFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.text.ParseException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.text.SimpleDateFormat;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.sun.security.auth.<span class=\"keyword\">module</span>.UnixSystem;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.commons.logging.Log;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.commons.logging.LogFactory;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.classification.InterfaceAudience;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.classification.InterfaceStability;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.client.Result;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.client.Scan;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.Filter;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.IncompatibleFilterException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.PrefixFilter;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.RegexStringComparator;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.RowFilter;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.mapreduce.IdentityTableMapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.mapreduce.TableInputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Export an HBase table. Writes content to sequence files up in HDFS. Use</span></span><br><span class=\"line\"><span class=\"comment\"> * &#123;<span class=\"doctag\">@link</span> Import&#125; to read it back in again.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@InterfaceAudience</span>.Public</span><br><span class=\"line\"><span class=\"meta\">@InterfaceStability</span>.Stable</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Export</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Log LOG = LogFactory.getLog(Export.class);</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String NAME = <span class=\"string\">\"export\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String RAW_SCAN = <span class=\"string\">\"hbase.mapreduce.include.deleted.rows\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String EXPORT_BATCHING = <span class=\"string\">\"hbase.export.scanner.batch\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> DateFormat format = <span class=\"keyword\">new</span> SimpleDateFormat(<span class=\"string\">\"yyyy-MM-dd\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Sets up the actual job.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> conf</span></span><br><span class=\"line\"><span class=\"comment\">     *            The current configuration.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> args</span></span><br><span class=\"line\"><span class=\"comment\">     *            The command line parameters.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> The newly created job.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     *             When setting up the job fails.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Job <span class=\"title\">createSubmittableJob</span><span class=\"params\">(Configuration conf, String[] args)</span></span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">        String tableName = args[<span class=\"number\">0</span>];</span><br><span class=\"line\">        Path outputDir = <span class=\"keyword\">new</span> Path(args[<span class=\"number\">1</span>]);</span><br><span class=\"line\">        Job job = <span class=\"keyword\">new</span> Job(conf, NAME + <span class=\"string\">\"_\"</span> + tableName);</span><br><span class=\"line\">        job.setJobName(NAME + <span class=\"string\">\"_\"</span> + tableName);</span><br><span class=\"line\">        job.setJarByClass(Export.class);</span><br><span class=\"line\">        job.setUser(<span class=\"string\">\"hdfs\"</span>);</span><br><span class=\"line\">        <span class=\"comment\">// Set optional scan parameters</span></span><br><span class=\"line\">        Scan s = getConfiguredScanForJob(conf, args);</span><br><span class=\"line\">        IdentityTableMapper.initJob(tableName, s, IdentityTableMapper.class,</span><br><span class=\"line\">                job);</span><br><span class=\"line\">        <span class=\"comment\">// No reducers. Just write straight to output files.</span></span><br><span class=\"line\">        job.setNumReduceTasks(<span class=\"number\">0</span>);</span><br><span class=\"line\">        job.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class=\"line\">        job.setOutputKeyClass(ImmutableBytesWritable.class);</span><br><span class=\"line\">        job.setOutputValueClass(Result.class);</span><br><span class=\"line\">        FileOutputFormat.setOutputPath(job, outputDir); <span class=\"comment\">// job conf doesn't</span></span><br><span class=\"line\">                                                        <span class=\"comment\">// contain the conf so</span></span><br><span class=\"line\">                                                        <span class=\"comment\">// doesn't have a</span></span><br><span class=\"line\">                                                        <span class=\"comment\">// default fs.</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> job;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Scan <span class=\"title\">getConfiguredScanForJob</span><span class=\"params\">(Configuration conf,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">            String[] args)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">        Scan s = <span class=\"keyword\">new</span> Scan();</span><br><span class=\"line\">        <span class=\"comment\">// Optional arguments.</span></span><br><span class=\"line\">        <span class=\"comment\">// Set Scan Versions</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> versions = args.length &gt; <span class=\"number\">2</span> ? Integer.parseInt(args[<span class=\"number\">2</span>]) : <span class=\"number\">1</span>;</span><br><span class=\"line\">        s.setMaxVersions(versions);</span><br><span class=\"line\">        <span class=\"comment\">// Set Scan Range</span></span><br><span class=\"line\">        <span class=\"keyword\">long</span> startTime = args.length &gt; <span class=\"number\">3</span> ? Long.parseLong(args[<span class=\"number\">3</span>]) : <span class=\"number\">0L</span>;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> endTime = args.length &gt; <span class=\"number\">4</span> ? Long.parseLong(args[<span class=\"number\">4</span>])</span><br><span class=\"line\">                : Long.MAX_VALUE;</span><br><span class=\"line\">        s.setTimeRange(startTime, endTime);</span><br><span class=\"line\">        <span class=\"comment\">// Set cache blocks</span></span><br><span class=\"line\">        s.setCacheBlocks(<span class=\"keyword\">false</span>);</span><br><span class=\"line\">        <span class=\"comment\">// set Start and Stop row</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (conf.get(TableInputFormat.SCAN_ROW_START) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            String rowStart[] = conf.get(TableInputFormat.SCAN_ROW_START).split(<span class=\"string\">\",\"</span>);</span><br><span class=\"line\">            Short companyID = Short.valueOf(rowStart[<span class=\"number\">0</span>]);</span><br><span class=\"line\">            Short deviceID = Short.valueOf(rowStart[<span class=\"number\">1</span>]);</span><br><span class=\"line\">            Long insertTime = <span class=\"number\">0l</span>;</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                insertTime = format.parse(rowStart[<span class=\"number\">2</span>]).getTime();</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (ParseException e) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// ignore</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            s.setStartRow(Bytes.add(Bytes.toBytes(companyID),</span><br><span class=\"line\">                    Bytes.toBytes(deviceID), Bytes.toBytes(insertTime)));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (conf.get(TableInputFormat.SCAN_ROW_STOP) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            String rowStop[] = conf.get(TableInputFormat.SCAN_ROW_STOP).split(<span class=\"string\">\",\"</span>);</span><br><span class=\"line\">            Short companyID = Short.valueOf(rowStop[<span class=\"number\">0</span>]);</span><br><span class=\"line\">            Short deviceID = Short.valueOf(rowStop[<span class=\"number\">1</span>]);</span><br><span class=\"line\">            Long insertTime = <span class=\"number\">0l</span>;</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                insertTime = format.parse(rowStop[<span class=\"number\">2</span>]).getTime();</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (ParseException e) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// ignore</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            s.setStopRow(Bytes.add(Bytes.toBytes(companyID),</span><br><span class=\"line\">                    Bytes.toBytes(deviceID), Bytes.toBytes(insertTime)));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Set Scan Column Family</span></span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> raw = Boolean.parseBoolean(conf.get(RAW_SCAN));</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (raw) &#123;</span><br><span class=\"line\">            s.setRaw(raw);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (conf.get(TableInputFormat.SCAN_COLUMN_FAMILY) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            s.addFamily(Bytes.toBytes(conf</span><br><span class=\"line\">                    .get(TableInputFormat.SCAN_COLUMN_FAMILY)));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Set RowFilter or Prefix Filter if applicable.</span></span><br><span class=\"line\">        Filter exportFilter = getExportFilter(args);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (exportFilter != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            LOG.info(<span class=\"string\">\"Setting Scan Filter for Export.\"</span>);</span><br><span class=\"line\">            s.setFilter(exportFilter);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">int</span> batching = conf.getInt(EXPORT_BATCHING, -<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (batching != -<span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                s.setBatch(batching);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (IncompatibleFilterException e) &#123;</span><br><span class=\"line\">                LOG.error(<span class=\"string\">\"Batching could not be set\"</span>, e);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        StringBuffer sb = <span class=\"keyword\">new</span> StringBuffer(<span class=\"string\">\"versions=\"</span> + versions + <span class=\"string\">\", starttime=\"</span> + startTime</span><br><span class=\"line\">                + <span class=\"string\">\", endtime=\"</span> + endTime + <span class=\"string\">\", keepDeletedCells=\"</span> + raw);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (conf.get(TableInputFormat.SCAN_ROW_START) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            sb.append(<span class=\"string\">\", startRow=\"</span> + conf.get(TableInputFormat.SCAN_ROW_START));</span><br><span class=\"line\">            sb.append(<span class=\"string\">\", stopRow=\"</span> + conf.get(TableInputFormat.SCAN_ROW_STOP));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        LOG.info(sb.toString());</span><br><span class=\"line\">        <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Filter <span class=\"title\">getExportFilter</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Filter exportFilter = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        String filterCriteria = (args.length &gt; <span class=\"number\">5</span>) ? args[<span class=\"number\">5</span>] : <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (filterCriteria == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (filterCriteria.startsWith(<span class=\"string\">\"^\"</span>)) &#123;</span><br><span class=\"line\">            String regexPattern = filterCriteria.substring(<span class=\"number\">1</span>,</span><br><span class=\"line\">                    filterCriteria.length());</span><br><span class=\"line\">            exportFilter = <span class=\"keyword\">new</span> RowFilter(CompareOp.EQUAL,</span><br><span class=\"line\">                    <span class=\"keyword\">new</span> RegexStringComparator(regexPattern));</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            exportFilter = <span class=\"keyword\">new</span> PrefixFilter(Bytes.toBytes(filterCriteria));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> exportFilter;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">     * @param errorMsg Error message. Can be null.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">usage</span><span class=\"params\">(<span class=\"keyword\">final</span> String errorMsg)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (errorMsg != <span class=\"keyword\">null</span> &amp;&amp; errorMsg.length() &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            System.err.println(<span class=\"string\">\"ERROR: \"</span> + errorMsg);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"Usage: Export [-D &lt;property=value&gt;]* &lt;tablename&gt; &lt;outputdir&gt; [&lt;versions&gt; \"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"[&lt;starttime&gt; [&lt;endtime&gt;]] [^[regex pattern] or [Prefix] to filter]]\\n\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"  Note: -D properties will be applied to the conf used. \"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"  For example: \"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"   -D mapreduce.output.fileoutputformat.compress=true\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"   -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"   -D mapreduce.output.fileoutputformat.compress.type=BLOCK\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"  Additionally, the following SCAN properties can be specified\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"  to control/limit what is exported..\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"   -D \"</span> + TableInputFormat.SCAN_COLUMN_FAMILY</span><br><span class=\"line\">                + <span class=\"string\">\"=&lt;familyName&gt;\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"   -D \"</span> + RAW_SCAN + <span class=\"string\">\"=true\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"   -D \"</span> + TableInputFormat.SCAN_ROW_START</span><br><span class=\"line\">                + <span class=\"string\">\"=&lt;CompanyID(Short),DeviceID(Short),yyyy-MM-dd(String)&gt;\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"   -D \"</span> + TableInputFormat.SCAN_ROW_STOP</span><br><span class=\"line\">                + <span class=\"string\">\"=&lt;CompanyID(Short),DeviceID(Short),yyyy-MM-dd(String)&gt;\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"For performance consider the following properties:\\n\"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"   -Dhbase.client.scanner.caching=100\\n\"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"   -Dmapreduce.map.speculative=false\\n\"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"   -Dmapreduce.reduce.speculative=false\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"For tables with very wide rows consider setting the batch size as below:\\n\"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"   -D\"</span> + EXPORT_BATCHING + <span class=\"string\">\"=10\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Main entry point.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> args</span></span><br><span class=\"line\"><span class=\"comment\">     *            The command line parameters.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> Exception</span></span><br><span class=\"line\"><span class=\"comment\">     *             When running the job fails.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        System.setProperty(<span class=\"string\">\"HADOOP_USER_NAME\"</span>, <span class=\"string\">\"hdfs\"</span>);</span><br><span class=\"line\">        UnixSystem us = <span class=\"keyword\">new</span> UnixSystem();</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Unix Username : \"</span> + us.getUsername());</span><br><span class=\"line\">        <span class=\"comment\">// -----------------------------------------------------</span></span><br><span class=\"line\">        Configuration conf = HBaseConfiguration.create();</span><br><span class=\"line\">        String[] otherArgs = <span class=\"keyword\">new</span> GenericOptionsParser(conf, args)</span><br><span class=\"line\">                .getRemainingArgs();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (otherArgs.length &lt; <span class=\"number\">2</span>) &#123;</span><br><span class=\"line\">            usage(<span class=\"string\">\"Wrong number of arguments: \"</span> + otherArgs.length);</span><br><span class=\"line\">            System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Check StartRow And StopRow</span></span><br><span class=\"line\">        String rowStart = conf.get(TableInputFormat.SCAN_ROW_START);</span><br><span class=\"line\">        String rowStop = conf.get(TableInputFormat.SCAN_ROW_STOP);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rowStart == <span class=\"keyword\">null</span> &amp;&amp; rowStop == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// do nothing</span></span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(rowStart != <span class=\"keyword\">null</span> &amp;&amp; rowStop != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// check rowStart</span></span><br><span class=\"line\">                String strToCheck[] = rowStart.split(<span class=\"string\">\",\"</span>);</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    Short.valueOf(strToCheck[<span class=\"number\">0</span>]);</span><br><span class=\"line\">                    Short.valueOf(strToCheck[<span class=\"number\">1</span>]);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                    usage(<span class=\"string\">\"String parsed to Short error ! Wrong argument of \"</span> + TableInputFormat.SCAN_ROW_START + <span class=\"string\">\" : \"</span> + rowStart);</span><br><span class=\"line\">                    System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    format.parse(strToCheck[<span class=\"number\">2</span>]);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                    usage(<span class=\"string\">\"yyyy-MM-dd String parsed to Date error ! Wrong argument of \"</span> + TableInputFormat.SCAN_ROW_START + <span class=\"string\">\" : \"</span> + rowStart);</span><br><span class=\"line\">                    System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"comment\">// check rowStop</span></span><br><span class=\"line\">                strToCheck = rowStop.split(<span class=\"string\">\",\"</span>);</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    Short.valueOf(strToCheck[<span class=\"number\">0</span>]);</span><br><span class=\"line\">                    Short.valueOf(strToCheck[<span class=\"number\">1</span>]);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                    usage(<span class=\"string\">\"String parsed to Short error ! Wrong argument of \"</span> + TableInputFormat.SCAN_ROW_STOP + <span class=\"string\">\" : \"</span> + rowStop);</span><br><span class=\"line\">                    System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    format.parse(strToCheck[<span class=\"number\">2</span>]);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                    usage(<span class=\"string\">\"yyyy-MM-dd String parsed to Date error ! Wrong argument of \"</span> + TableInputFormat.SCAN_ROW_STOP + <span class=\"string\">\" : \"</span> + rowStop);</span><br><span class=\"line\">                    System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                usage(TableInputFormat.SCAN_ROW_START + <span class=\"string\">\" and \"</span> + TableInputFormat.SCAN_ROW_STOP + <span class=\"string\">\" must both not be null.\"</span>);</span><br><span class=\"line\">                System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Job job = createSubmittableJob(conf, otherArgs);</span><br><span class=\"line\">        System.exit(job.waitForCompletion(<span class=\"keyword\">true</span>) ? <span class=\"number\">0</span> : <span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>HBase如何增量备份数据呢？</p>","more":"<h2 id=\"传统的Export不支持自定义rowkey增量数据导出\"><a href=\"#传统的Export不支持自定义rowkey增量数据导出\" class=\"headerlink\" title=\"传统的Export不支持自定义rowkey增量数据导出\"></a>传统的Export不支持自定义rowkey增量数据导出</h2><p>导出语法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hbase org.apache.hadoop.hbase.mapreduce.Export your_hbase_table_name your_hdfs_file_path</span><br></pre></td></tr></table></figure>\n<p>下面简单介绍如何实现自定义rowkey增量导出HBase数据。</p>\n<!--more-->\n<h2 id=\"运行环境\"><a href=\"#运行环境\" class=\"headerlink\" title=\"运行环境\"></a>运行环境</h2><p>笔者的hadoop+hbase环境如下：</p>\n<p>$ <code>hadoop version</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Hadoop 2.6.0-cdh5.4.3</span><br><span class=\"line\">Subversion http://github.com/cloudera/hadoop -r 4cd9f51a3f1ef748d45b8d77d0f211ad44296d4b</span><br><span class=\"line\">Compiled by jenkins on 2015-06-25T02:34Z</span><br><span class=\"line\">Compiled with protoc 2.5.0</span><br><span class=\"line\">From source with checksum 4acea6ac185376e0b48b33695e88e7a7</span><br><span class=\"line\">This command was run using /opt/cloudera/parcels/CDH-5.4.3-1.cdh5.4.3.p0.6/jars/hadoop-common-2.6.0-cdh5.4.3.jar</span><br></pre></td></tr></table></figure>\n<p>$ <code>hbase version</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Java HotSpot(TM) 64-Bit Server VM warning: Using incremental CMS is deprecated and will likely be removed in a future release</span><br><span class=\"line\">16/06/04 13:13:30 INFO util.VersionInfo: HBase 1.0.0-cdh5.4.3</span><br><span class=\"line\">16/06/04 13:13:30 INFO util.VersionInfo: Source code repository file:///data/jenkins/workspace/generic-package-ubuntu64-12-04/CDH5.4.3-Packaging-HBase-2015-06-24_19-16-53/hbase-1.0.0+cdh5.4.3+159-1.cdh5.4.3.p0.9~precise revision=Unknown</span><br><span class=\"line\">16/06/04 13:13:30 INFO util.VersionInfo: Compiled by jenkins on Wed Jun 24 19:32:40 PDT 2015</span><br><span class=\"line\">16/06/04 13:13:30 INFO util.VersionInfo: From source with checksum d5809febb1e487265280a25f5c74202e</span><br></pre></td></tr></table></figure>\n<h2 id=\"如何定制自己的Export实现自定义rowkey增量数据导出\"><a href=\"#如何定制自己的Export实现自定义rowkey增量数据导出\" class=\"headerlink\" title=\"如何定制自己的Export实现自定义rowkey增量数据导出\"></a>如何定制自己的Export实现自定义rowkey增量数据导出</h2><p>首先，你需要找到源码org.apache.hadoop.hbase.mapreduce.Export.java，修改它为你想要的，并将其上传到具备hadoop+hbase环境的机器上；</p>\n<p>紧接着，运行如下语句：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 编译并打包</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_CLASSPATH=$(hbase classpath)</span><br><span class=\"line\">hadoop com.sun.tools.javac.Main Export.java</span><br><span class=\"line\">jar cf Export.jar Export.class</span><br><span class=\"line\"><span class=\"comment\"># 准备好hdfs路径</span></span><br><span class=\"line\">su</span><br><span class=\"line\">su hdfs -c <span class=\"string\">'hdfs dfs -mkdir /backup'</span></span><br><span class=\"line\">su hdfs -c <span class=\"string\">'hdfs dfs -mkdir /backup/20160512'</span></span><br><span class=\"line\">su hdfs -c <span class=\"string\">'hdfs dfs -ls  /'</span></span><br><span class=\"line\"><span class=\"comment\"># 使用jar包</span></span><br><span class=\"line\"><span class=\"comment\">## 兼容传统Export</span></span><br><span class=\"line\">hadoop jar Export.jar Export group_hour /backup/20160512/group_hour</span><br><span class=\"line\"><span class=\"comment\">## 实现了自定义rowkey解析</span></span><br><span class=\"line\">hadoop jar Export.jar Export -D hbase.mapreduce.scan.row.start=1,9,2016-05-01 -D hbase.mapreduce.scan.row.stop=1,9,2015-05-02 group_hour /backup/20160512/group_hour_rowkey</span><br></pre></td></tr></table></figure>\n<p>上述命令执行成功后，就可执行<code>hdfs dfs -get your_hdfs_filepath your_filesystem_filepath</code>取得你的导出数据啦！</p>\n<p>笔者修改后的Export.java如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class=\"line\"><span class=\"comment\"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class=\"line\"><span class=\"comment\"> * distributed with this work for additional information</span></span><br><span class=\"line\"><span class=\"comment\"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class=\"line\"><span class=\"comment\"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class=\"line\"><span class=\"comment\"> * \"License\"); you may not use this file except in compliance</span></span><br><span class=\"line\"><span class=\"comment\"> * with the License.  You may obtain a copy of the License at</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> *     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class=\"line\"><span class=\"comment\"> * distributed under the License is distributed on an \"AS IS\" BASIS,</span></span><br><span class=\"line\"><span class=\"comment\"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class=\"line\"><span class=\"comment\"> * See the License for the specific language governing permissions and</span></span><br><span class=\"line\"><span class=\"comment\"> * limitations under the License.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.text.DateFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.text.ParseException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.text.SimpleDateFormat;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.sun.security.auth.<span class=\"keyword\">module</span>.UnixSystem;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.commons.logging.Log;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.commons.logging.LogFactory;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.classification.InterfaceAudience;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.classification.InterfaceStability;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.client.Result;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.client.Scan;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.Filter;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.IncompatibleFilterException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.PrefixFilter;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.RegexStringComparator;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.filter.RowFilter;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.mapreduce.IdentityTableMapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.mapreduce.TableInputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Export an HBase table. Writes content to sequence files up in HDFS. Use</span></span><br><span class=\"line\"><span class=\"comment\"> * &#123;<span class=\"doctag\">@link</span> Import&#125; to read it back in again.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@InterfaceAudience</span>.Public</span><br><span class=\"line\"><span class=\"meta\">@InterfaceStability</span>.Stable</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Export</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Log LOG = LogFactory.getLog(Export.class);</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String NAME = <span class=\"string\">\"export\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String RAW_SCAN = <span class=\"string\">\"hbase.mapreduce.include.deleted.rows\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String EXPORT_BATCHING = <span class=\"string\">\"hbase.export.scanner.batch\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> DateFormat format = <span class=\"keyword\">new</span> SimpleDateFormat(<span class=\"string\">\"yyyy-MM-dd\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Sets up the actual job.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> conf</span></span><br><span class=\"line\"><span class=\"comment\">     *            The current configuration.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> args</span></span><br><span class=\"line\"><span class=\"comment\">     *            The command line parameters.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> The newly created job.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     *             When setting up the job fails.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Job <span class=\"title\">createSubmittableJob</span><span class=\"params\">(Configuration conf, String[] args)</span></span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">        String tableName = args[<span class=\"number\">0</span>];</span><br><span class=\"line\">        Path outputDir = <span class=\"keyword\">new</span> Path(args[<span class=\"number\">1</span>]);</span><br><span class=\"line\">        Job job = <span class=\"keyword\">new</span> Job(conf, NAME + <span class=\"string\">\"_\"</span> + tableName);</span><br><span class=\"line\">        job.setJobName(NAME + <span class=\"string\">\"_\"</span> + tableName);</span><br><span class=\"line\">        job.setJarByClass(Export.class);</span><br><span class=\"line\">        job.setUser(<span class=\"string\">\"hdfs\"</span>);</span><br><span class=\"line\">        <span class=\"comment\">// Set optional scan parameters</span></span><br><span class=\"line\">        Scan s = getConfiguredScanForJob(conf, args);</span><br><span class=\"line\">        IdentityTableMapper.initJob(tableName, s, IdentityTableMapper.class,</span><br><span class=\"line\">                job);</span><br><span class=\"line\">        <span class=\"comment\">// No reducers. Just write straight to output files.</span></span><br><span class=\"line\">        job.setNumReduceTasks(<span class=\"number\">0</span>);</span><br><span class=\"line\">        job.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class=\"line\">        job.setOutputKeyClass(ImmutableBytesWritable.class);</span><br><span class=\"line\">        job.setOutputValueClass(Result.class);</span><br><span class=\"line\">        FileOutputFormat.setOutputPath(job, outputDir); <span class=\"comment\">// job conf doesn't</span></span><br><span class=\"line\">                                                        <span class=\"comment\">// contain the conf so</span></span><br><span class=\"line\">                                                        <span class=\"comment\">// doesn't have a</span></span><br><span class=\"line\">                                                        <span class=\"comment\">// default fs.</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> job;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Scan <span class=\"title\">getConfiguredScanForJob</span><span class=\"params\">(Configuration conf,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">            String[] args)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">        Scan s = <span class=\"keyword\">new</span> Scan();</span><br><span class=\"line\">        <span class=\"comment\">// Optional arguments.</span></span><br><span class=\"line\">        <span class=\"comment\">// Set Scan Versions</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> versions = args.length &gt; <span class=\"number\">2</span> ? Integer.parseInt(args[<span class=\"number\">2</span>]) : <span class=\"number\">1</span>;</span><br><span class=\"line\">        s.setMaxVersions(versions);</span><br><span class=\"line\">        <span class=\"comment\">// Set Scan Range</span></span><br><span class=\"line\">        <span class=\"keyword\">long</span> startTime = args.length &gt; <span class=\"number\">3</span> ? Long.parseLong(args[<span class=\"number\">3</span>]) : <span class=\"number\">0L</span>;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> endTime = args.length &gt; <span class=\"number\">4</span> ? Long.parseLong(args[<span class=\"number\">4</span>])</span><br><span class=\"line\">                : Long.MAX_VALUE;</span><br><span class=\"line\">        s.setTimeRange(startTime, endTime);</span><br><span class=\"line\">        <span class=\"comment\">// Set cache blocks</span></span><br><span class=\"line\">        s.setCacheBlocks(<span class=\"keyword\">false</span>);</span><br><span class=\"line\">        <span class=\"comment\">// set Start and Stop row</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (conf.get(TableInputFormat.SCAN_ROW_START) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            String rowStart[] = conf.get(TableInputFormat.SCAN_ROW_START).split(<span class=\"string\">\",\"</span>);</span><br><span class=\"line\">            Short companyID = Short.valueOf(rowStart[<span class=\"number\">0</span>]);</span><br><span class=\"line\">            Short deviceID = Short.valueOf(rowStart[<span class=\"number\">1</span>]);</span><br><span class=\"line\">            Long insertTime = <span class=\"number\">0l</span>;</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                insertTime = format.parse(rowStart[<span class=\"number\">2</span>]).getTime();</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (ParseException e) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// ignore</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            s.setStartRow(Bytes.add(Bytes.toBytes(companyID),</span><br><span class=\"line\">                    Bytes.toBytes(deviceID), Bytes.toBytes(insertTime)));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (conf.get(TableInputFormat.SCAN_ROW_STOP) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            String rowStop[] = conf.get(TableInputFormat.SCAN_ROW_STOP).split(<span class=\"string\">\",\"</span>);</span><br><span class=\"line\">            Short companyID = Short.valueOf(rowStop[<span class=\"number\">0</span>]);</span><br><span class=\"line\">            Short deviceID = Short.valueOf(rowStop[<span class=\"number\">1</span>]);</span><br><span class=\"line\">            Long insertTime = <span class=\"number\">0l</span>;</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                insertTime = format.parse(rowStop[<span class=\"number\">2</span>]).getTime();</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (ParseException e) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// ignore</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            s.setStopRow(Bytes.add(Bytes.toBytes(companyID),</span><br><span class=\"line\">                    Bytes.toBytes(deviceID), Bytes.toBytes(insertTime)));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Set Scan Column Family</span></span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> raw = Boolean.parseBoolean(conf.get(RAW_SCAN));</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (raw) &#123;</span><br><span class=\"line\">            s.setRaw(raw);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (conf.get(TableInputFormat.SCAN_COLUMN_FAMILY) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            s.addFamily(Bytes.toBytes(conf</span><br><span class=\"line\">                    .get(TableInputFormat.SCAN_COLUMN_FAMILY)));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Set RowFilter or Prefix Filter if applicable.</span></span><br><span class=\"line\">        Filter exportFilter = getExportFilter(args);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (exportFilter != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            LOG.info(<span class=\"string\">\"Setting Scan Filter for Export.\"</span>);</span><br><span class=\"line\">            s.setFilter(exportFilter);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">int</span> batching = conf.getInt(EXPORT_BATCHING, -<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (batching != -<span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                s.setBatch(batching);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (IncompatibleFilterException e) &#123;</span><br><span class=\"line\">                LOG.error(<span class=\"string\">\"Batching could not be set\"</span>, e);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        StringBuffer sb = <span class=\"keyword\">new</span> StringBuffer(<span class=\"string\">\"versions=\"</span> + versions + <span class=\"string\">\", starttime=\"</span> + startTime</span><br><span class=\"line\">                + <span class=\"string\">\", endtime=\"</span> + endTime + <span class=\"string\">\", keepDeletedCells=\"</span> + raw);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (conf.get(TableInputFormat.SCAN_ROW_START) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            sb.append(<span class=\"string\">\", startRow=\"</span> + conf.get(TableInputFormat.SCAN_ROW_START));</span><br><span class=\"line\">            sb.append(<span class=\"string\">\", stopRow=\"</span> + conf.get(TableInputFormat.SCAN_ROW_STOP));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        LOG.info(sb.toString());</span><br><span class=\"line\">        <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Filter <span class=\"title\">getExportFilter</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Filter exportFilter = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        String filterCriteria = (args.length &gt; <span class=\"number\">5</span>) ? args[<span class=\"number\">5</span>] : <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (filterCriteria == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (filterCriteria.startsWith(<span class=\"string\">\"^\"</span>)) &#123;</span><br><span class=\"line\">            String regexPattern = filterCriteria.substring(<span class=\"number\">1</span>,</span><br><span class=\"line\">                    filterCriteria.length());</span><br><span class=\"line\">            exportFilter = <span class=\"keyword\">new</span> RowFilter(CompareOp.EQUAL,</span><br><span class=\"line\">                    <span class=\"keyword\">new</span> RegexStringComparator(regexPattern));</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            exportFilter = <span class=\"keyword\">new</span> PrefixFilter(Bytes.toBytes(filterCriteria));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> exportFilter;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">     * @param errorMsg Error message. Can be null.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">usage</span><span class=\"params\">(<span class=\"keyword\">final</span> String errorMsg)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (errorMsg != <span class=\"keyword\">null</span> &amp;&amp; errorMsg.length() &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            System.err.println(<span class=\"string\">\"ERROR: \"</span> + errorMsg);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"Usage: Export [-D &lt;property=value&gt;]* &lt;tablename&gt; &lt;outputdir&gt; [&lt;versions&gt; \"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"[&lt;starttime&gt; [&lt;endtime&gt;]] [^[regex pattern] or [Prefix] to filter]]\\n\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"  Note: -D properties will be applied to the conf used. \"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"  For example: \"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"   -D mapreduce.output.fileoutputformat.compress=true\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"   -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"   -D mapreduce.output.fileoutputformat.compress.type=BLOCK\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"  Additionally, the following SCAN properties can be specified\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"  to control/limit what is exported..\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"   -D \"</span> + TableInputFormat.SCAN_COLUMN_FAMILY</span><br><span class=\"line\">                + <span class=\"string\">\"=&lt;familyName&gt;\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"   -D \"</span> + RAW_SCAN + <span class=\"string\">\"=true\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"   -D \"</span> + TableInputFormat.SCAN_ROW_START</span><br><span class=\"line\">                + <span class=\"string\">\"=&lt;CompanyID(Short),DeviceID(Short),yyyy-MM-dd(String)&gt;\"</span>);</span><br><span class=\"line\">        System.err.println(<span class=\"string\">\"   -D \"</span> + TableInputFormat.SCAN_ROW_STOP</span><br><span class=\"line\">                + <span class=\"string\">\"=&lt;CompanyID(Short),DeviceID(Short),yyyy-MM-dd(String)&gt;\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"For performance consider the following properties:\\n\"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"   -Dhbase.client.scanner.caching=100\\n\"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"   -Dmapreduce.map.speculative=false\\n\"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"   -Dmapreduce.reduce.speculative=false\"</span>);</span><br><span class=\"line\">        System.err</span><br><span class=\"line\">                .println(<span class=\"string\">\"For tables with very wide rows consider setting the batch size as below:\\n\"</span></span><br><span class=\"line\">                        + <span class=\"string\">\"   -D\"</span> + EXPORT_BATCHING + <span class=\"string\">\"=10\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Main entry point.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> args</span></span><br><span class=\"line\"><span class=\"comment\">     *            The command line parameters.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> Exception</span></span><br><span class=\"line\"><span class=\"comment\">     *             When running the job fails.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        System.setProperty(<span class=\"string\">\"HADOOP_USER_NAME\"</span>, <span class=\"string\">\"hdfs\"</span>);</span><br><span class=\"line\">        UnixSystem us = <span class=\"keyword\">new</span> UnixSystem();</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Unix Username : \"</span> + us.getUsername());</span><br><span class=\"line\">        <span class=\"comment\">// -----------------------------------------------------</span></span><br><span class=\"line\">        Configuration conf = HBaseConfiguration.create();</span><br><span class=\"line\">        String[] otherArgs = <span class=\"keyword\">new</span> GenericOptionsParser(conf, args)</span><br><span class=\"line\">                .getRemainingArgs();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (otherArgs.length &lt; <span class=\"number\">2</span>) &#123;</span><br><span class=\"line\">            usage(<span class=\"string\">\"Wrong number of arguments: \"</span> + otherArgs.length);</span><br><span class=\"line\">            System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Check StartRow And StopRow</span></span><br><span class=\"line\">        String rowStart = conf.get(TableInputFormat.SCAN_ROW_START);</span><br><span class=\"line\">        String rowStop = conf.get(TableInputFormat.SCAN_ROW_STOP);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rowStart == <span class=\"keyword\">null</span> &amp;&amp; rowStop == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// do nothing</span></span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(rowStart != <span class=\"keyword\">null</span> &amp;&amp; rowStop != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// check rowStart</span></span><br><span class=\"line\">                String strToCheck[] = rowStart.split(<span class=\"string\">\",\"</span>);</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    Short.valueOf(strToCheck[<span class=\"number\">0</span>]);</span><br><span class=\"line\">                    Short.valueOf(strToCheck[<span class=\"number\">1</span>]);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                    usage(<span class=\"string\">\"String parsed to Short error ! Wrong argument of \"</span> + TableInputFormat.SCAN_ROW_START + <span class=\"string\">\" : \"</span> + rowStart);</span><br><span class=\"line\">                    System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    format.parse(strToCheck[<span class=\"number\">2</span>]);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                    usage(<span class=\"string\">\"yyyy-MM-dd String parsed to Date error ! Wrong argument of \"</span> + TableInputFormat.SCAN_ROW_START + <span class=\"string\">\" : \"</span> + rowStart);</span><br><span class=\"line\">                    System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"comment\">// check rowStop</span></span><br><span class=\"line\">                strToCheck = rowStop.split(<span class=\"string\">\",\"</span>);</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    Short.valueOf(strToCheck[<span class=\"number\">0</span>]);</span><br><span class=\"line\">                    Short.valueOf(strToCheck[<span class=\"number\">1</span>]);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                    usage(<span class=\"string\">\"String parsed to Short error ! Wrong argument of \"</span> + TableInputFormat.SCAN_ROW_STOP + <span class=\"string\">\" : \"</span> + rowStop);</span><br><span class=\"line\">                    System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    format.parse(strToCheck[<span class=\"number\">2</span>]);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                    usage(<span class=\"string\">\"yyyy-MM-dd String parsed to Date error ! Wrong argument of \"</span> + TableInputFormat.SCAN_ROW_STOP + <span class=\"string\">\" : \"</span> + rowStop);</span><br><span class=\"line\">                    System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                usage(TableInputFormat.SCAN_ROW_START + <span class=\"string\">\" and \"</span> + TableInputFormat.SCAN_ROW_STOP + <span class=\"string\">\" must both not be null.\"</span>);</span><br><span class=\"line\">                System.exit(-<span class=\"number\">1</span>);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Job job = createSubmittableJob(conf, otherArgs);</span><br><span class=\"line\">        System.exit(job.waitForCompletion(<span class=\"keyword\">true</span>) ? <span class=\"number\">0</span> : <span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"layout":"post","title":"2015年3月至2016年3月工作总结","date":"2016-05-11T13:16:00.000Z","comments":1,"_content":"\n软件研发和软件开发是有区别的。\n\n<!--more-->\n\n研发需要技术攻关，它更关注的是软件的基础设施建设（如解决什么样的问题、选用怎样的技术解决问题、整体软件如何架构）；开发需要解决实际问题，最终把产品实现出来（如通信程序如何实现）。过去一年，我的主要工作是云平台的开发，其中包含自己开发以及相互协作去开发，我把这两者各开一个章节来讲，最后再加一章“未来规划”作为结束。\n\n一、具体开发\n\n具体开发过程中，总结起来无外乎刘老师常说的一句话：大处落墨，小处着笔。\n\n（一）“大处落墨”在具体开发中等同于软件架构。\n\n一个糟糕的软件架构花费的人力成本将非常之高。必须先弄清楚软件的模块有哪些，它们相互间的联系是什么，相互间的影响是什么。没有架构的开发意味着完全靠试错来发现和解决问题，最终形成的也是一个脆弱的产品，随时可能会崩溃，维护之前陈森填写的程序就有此感觉。\n\n（二）“小处着笔”在具体开发中等同于实现及验证。\n\n首先，在大框架已经清楚的情况下，如何确保每一行代码不会出错？这时候必须引入编码规范以及代码复查。编码规范迫使你遵循一个良好的编程习惯，不犯下一些低级的错误；代码复查（人力以及机器）可以发现并报告软件可能存在的质量问题。\n其次，在所有代码都完成的情况下，如何确保它真的是对的？这时候必须引入测试。但是一共有多少情况需要验证？这个问题反馈到具体开发就是必须充分考虑所有可能的情况并逐一进行验证。\n\n二、相互协作\n\n主要谈谈实际协作的一些体会。\n\n（一）理解、下放、处理和验证需求。\n首先，理解来自上游的需求，我也曾犯下许多错误。例如：不清楚为什么要这样做然后自己想当然，遗漏一些细节而后偏离主题，确认需求的过程中没有主线思维导致表述不清引发歧义。\n\n其次，对于下放需求，一是必须交代清楚为什么要这么做，在不明白背景的情况下什么错误都可能发生；二是必须清楚下游的能力所在，清楚谁适合做什么以及如何让他做到。\n紧接着，处理需求一定要有时间限制，而且这个时间绝不能给的刚刚好让执行者舒舒服服，否则执行者本身不会有大的进步，企业人力成本也将非常之高（员工的工作产出一定是大于他的工资收入的）。\n\n最后，必须对需求完成情况加以验证，而且最好是执行者本身具备这种验证能力。\n\n（二）如何让错误产生价值。\n\n犯了错误的当下再去责备已没有任何意义，而是应该想办法去解决问题。错误的积极意义在于如何不犯同类型的错误，以及从此少犯错误。相同类型的错误要予以批评，新的错误要做出反思。\n\n（三）改变一个人非常之难。\n\n我曾想要去改变DYF使他变得更积极却发现于事无补，但当我转而想如何提升他的能力来做更多事情，事情变得简单多了。\n\n（四）与同事协作，职责一定要分明。\n\n刚开始与LZQ协助确实有不少苦恼，因为我俩的职责没有一个明确的界定，经常遇到一个问题是到底这个事情归谁管？虽然后面我知道刘老师以及林总可以帮我做这个界定，但长远来讲必须把我俩各自的工作定义清楚才行。\n\n（五）给予的重要性。\n\n一味的向下索取将导致非常糟糕的结果：下游人员没有进步，失去工作激情，甚至离职。必须在管理的过程去给予一些东西：让对方学习新的东西，做更难的事情，传授一些做事情的基本方法，授课培训等。只有这样，当你真正需要他满负荷运行的时候才能调动得起来。\n\n三、未来规划\n\n拳头产品（云平台）必须花心思去打磨好（站在软件的角度）。云平台的下一个里程碑是今年年底做到：稳定、安全、交互便捷、简洁美。稳定指程序不会崩溃，安全指能承受得起外部的攻击，交互便捷指如何让使用者更容易得到他想要的信息，简洁美则是要有统一的美化标准。\n\n另外，研发才是软件团队的真正核心竞争力，而且研发也能给我带来更多乐趣。接下来我想尽可能的朝研发靠拢，这也意味着我要学习更多和承受更多。但是要兼顾一个事情，我必须学习和思考如何把下面的人带好，使他们都成为比我还优秀的开发者。\n","source":"_posts/2016-05-11-2015-work-summary.markdown","raw":"---\nlayout: post\ntitle: 2015年3月至2016年3月工作总结\ndate: '2016-05-11 21:16'\ncomments: true\ncategories: ['职场感悟']  \ntags: ['职场']\n---\n\n软件研发和软件开发是有区别的。\n\n<!--more-->\n\n研发需要技术攻关，它更关注的是软件的基础设施建设（如解决什么样的问题、选用怎样的技术解决问题、整体软件如何架构）；开发需要解决实际问题，最终把产品实现出来（如通信程序如何实现）。过去一年，我的主要工作是云平台的开发，其中包含自己开发以及相互协作去开发，我把这两者各开一个章节来讲，最后再加一章“未来规划”作为结束。\n\n一、具体开发\n\n具体开发过程中，总结起来无外乎刘老师常说的一句话：大处落墨，小处着笔。\n\n（一）“大处落墨”在具体开发中等同于软件架构。\n\n一个糟糕的软件架构花费的人力成本将非常之高。必须先弄清楚软件的模块有哪些，它们相互间的联系是什么，相互间的影响是什么。没有架构的开发意味着完全靠试错来发现和解决问题，最终形成的也是一个脆弱的产品，随时可能会崩溃，维护之前陈森填写的程序就有此感觉。\n\n（二）“小处着笔”在具体开发中等同于实现及验证。\n\n首先，在大框架已经清楚的情况下，如何确保每一行代码不会出错？这时候必须引入编码规范以及代码复查。编码规范迫使你遵循一个良好的编程习惯，不犯下一些低级的错误；代码复查（人力以及机器）可以发现并报告软件可能存在的质量问题。\n其次，在所有代码都完成的情况下，如何确保它真的是对的？这时候必须引入测试。但是一共有多少情况需要验证？这个问题反馈到具体开发就是必须充分考虑所有可能的情况并逐一进行验证。\n\n二、相互协作\n\n主要谈谈实际协作的一些体会。\n\n（一）理解、下放、处理和验证需求。\n首先，理解来自上游的需求，我也曾犯下许多错误。例如：不清楚为什么要这样做然后自己想当然，遗漏一些细节而后偏离主题，确认需求的过程中没有主线思维导致表述不清引发歧义。\n\n其次，对于下放需求，一是必须交代清楚为什么要这么做，在不明白背景的情况下什么错误都可能发生；二是必须清楚下游的能力所在，清楚谁适合做什么以及如何让他做到。\n紧接着，处理需求一定要有时间限制，而且这个时间绝不能给的刚刚好让执行者舒舒服服，否则执行者本身不会有大的进步，企业人力成本也将非常之高（员工的工作产出一定是大于他的工资收入的）。\n\n最后，必须对需求完成情况加以验证，而且最好是执行者本身具备这种验证能力。\n\n（二）如何让错误产生价值。\n\n犯了错误的当下再去责备已没有任何意义，而是应该想办法去解决问题。错误的积极意义在于如何不犯同类型的错误，以及从此少犯错误。相同类型的错误要予以批评，新的错误要做出反思。\n\n（三）改变一个人非常之难。\n\n我曾想要去改变DYF使他变得更积极却发现于事无补，但当我转而想如何提升他的能力来做更多事情，事情变得简单多了。\n\n（四）与同事协作，职责一定要分明。\n\n刚开始与LZQ协助确实有不少苦恼，因为我俩的职责没有一个明确的界定，经常遇到一个问题是到底这个事情归谁管？虽然后面我知道刘老师以及林总可以帮我做这个界定，但长远来讲必须把我俩各自的工作定义清楚才行。\n\n（五）给予的重要性。\n\n一味的向下索取将导致非常糟糕的结果：下游人员没有进步，失去工作激情，甚至离职。必须在管理的过程去给予一些东西：让对方学习新的东西，做更难的事情，传授一些做事情的基本方法，授课培训等。只有这样，当你真正需要他满负荷运行的时候才能调动得起来。\n\n三、未来规划\n\n拳头产品（云平台）必须花心思去打磨好（站在软件的角度）。云平台的下一个里程碑是今年年底做到：稳定、安全、交互便捷、简洁美。稳定指程序不会崩溃，安全指能承受得起外部的攻击，交互便捷指如何让使用者更容易得到他想要的信息，简洁美则是要有统一的美化标准。\n\n另外，研发才是软件团队的真正核心竞争力，而且研发也能给我带来更多乐趣。接下来我想尽可能的朝研发靠拢，这也意味着我要学习更多和承受更多。但是要兼顾一个事情，我必须学习和思考如何把下面的人带好，使他们都成为比我还优秀的开发者。\n","slug":"2015-work-summary","published":1,"updated":"2022-08-09T15:02:00.604Z","photos":[],"link":"","_id":"cl6mbc12v000sigu8ewkd61th","content":"<p>软件研发和软件开发是有区别的。</p>\n<a id=\"more\"></a>\n<p>研发需要技术攻关，它更关注的是软件的基础设施建设（如解决什么样的问题、选用怎样的技术解决问题、整体软件如何架构）；开发需要解决实际问题，最终把产品实现出来（如通信程序如何实现）。过去一年，我的主要工作是云平台的开发，其中包含自己开发以及相互协作去开发，我把这两者各开一个章节来讲，最后再加一章“未来规划”作为结束。</p>\n<p>一、具体开发</p>\n<p>具体开发过程中，总结起来无外乎刘老师常说的一句话：大处落墨，小处着笔。</p>\n<p>（一）“大处落墨”在具体开发中等同于软件架构。</p>\n<p>一个糟糕的软件架构花费的人力成本将非常之高。必须先弄清楚软件的模块有哪些，它们相互间的联系是什么，相互间的影响是什么。没有架构的开发意味着完全靠试错来发现和解决问题，最终形成的也是一个脆弱的产品，随时可能会崩溃，维护之前陈森填写的程序就有此感觉。</p>\n<p>（二）“小处着笔”在具体开发中等同于实现及验证。</p>\n<p>首先，在大框架已经清楚的情况下，如何确保每一行代码不会出错？这时候必须引入编码规范以及代码复查。编码规范迫使你遵循一个良好的编程习惯，不犯下一些低级的错误；代码复查（人力以及机器）可以发现并报告软件可能存在的质量问题。<br>其次，在所有代码都完成的情况下，如何确保它真的是对的？这时候必须引入测试。但是一共有多少情况需要验证？这个问题反馈到具体开发就是必须充分考虑所有可能的情况并逐一进行验证。</p>\n<p>二、相互协作</p>\n<p>主要谈谈实际协作的一些体会。</p>\n<p>（一）理解、下放、处理和验证需求。<br>首先，理解来自上游的需求，我也曾犯下许多错误。例如：不清楚为什么要这样做然后自己想当然，遗漏一些细节而后偏离主题，确认需求的过程中没有主线思维导致表述不清引发歧义。</p>\n<p>其次，对于下放需求，一是必须交代清楚为什么要这么做，在不明白背景的情况下什么错误都可能发生；二是必须清楚下游的能力所在，清楚谁适合做什么以及如何让他做到。<br>紧接着，处理需求一定要有时间限制，而且这个时间绝不能给的刚刚好让执行者舒舒服服，否则执行者本身不会有大的进步，企业人力成本也将非常之高（员工的工作产出一定是大于他的工资收入的）。</p>\n<p>最后，必须对需求完成情况加以验证，而且最好是执行者本身具备这种验证能力。</p>\n<p>（二）如何让错误产生价值。</p>\n<p>犯了错误的当下再去责备已没有任何意义，而是应该想办法去解决问题。错误的积极意义在于如何不犯同类型的错误，以及从此少犯错误。相同类型的错误要予以批评，新的错误要做出反思。</p>\n<p>（三）改变一个人非常之难。</p>\n<p>我曾想要去改变DYF使他变得更积极却发现于事无补，但当我转而想如何提升他的能力来做更多事情，事情变得简单多了。</p>\n<p>（四）与同事协作，职责一定要分明。</p>\n<p>刚开始与LZQ协助确实有不少苦恼，因为我俩的职责没有一个明确的界定，经常遇到一个问题是到底这个事情归谁管？虽然后面我知道刘老师以及林总可以帮我做这个界定，但长远来讲必须把我俩各自的工作定义清楚才行。</p>\n<p>（五）给予的重要性。</p>\n<p>一味的向下索取将导致非常糟糕的结果：下游人员没有进步，失去工作激情，甚至离职。必须在管理的过程去给予一些东西：让对方学习新的东西，做更难的事情，传授一些做事情的基本方法，授课培训等。只有这样，当你真正需要他满负荷运行的时候才能调动得起来。</p>\n<p>三、未来规划</p>\n<p>拳头产品（云平台）必须花心思去打磨好（站在软件的角度）。云平台的下一个里程碑是今年年底做到：稳定、安全、交互便捷、简洁美。稳定指程序不会崩溃，安全指能承受得起外部的攻击，交互便捷指如何让使用者更容易得到他想要的信息，简洁美则是要有统一的美化标准。</p>\n<p>另外，研发才是软件团队的真正核心竞争力，而且研发也能给我带来更多乐趣。接下来我想尽可能的朝研发靠拢，这也意味着我要学习更多和承受更多。但是要兼顾一个事情，我必须学习和思考如何把下面的人带好，使他们都成为比我还优秀的开发者。</p>\n","site":{"data":{}},"excerpt":"<p>软件研发和软件开发是有区别的。</p>","more":"<p>研发需要技术攻关，它更关注的是软件的基础设施建设（如解决什么样的问题、选用怎样的技术解决问题、整体软件如何架构）；开发需要解决实际问题，最终把产品实现出来（如通信程序如何实现）。过去一年，我的主要工作是云平台的开发，其中包含自己开发以及相互协作去开发，我把这两者各开一个章节来讲，最后再加一章“未来规划”作为结束。</p>\n<p>一、具体开发</p>\n<p>具体开发过程中，总结起来无外乎刘老师常说的一句话：大处落墨，小处着笔。</p>\n<p>（一）“大处落墨”在具体开发中等同于软件架构。</p>\n<p>一个糟糕的软件架构花费的人力成本将非常之高。必须先弄清楚软件的模块有哪些，它们相互间的联系是什么，相互间的影响是什么。没有架构的开发意味着完全靠试错来发现和解决问题，最终形成的也是一个脆弱的产品，随时可能会崩溃，维护之前陈森填写的程序就有此感觉。</p>\n<p>（二）“小处着笔”在具体开发中等同于实现及验证。</p>\n<p>首先，在大框架已经清楚的情况下，如何确保每一行代码不会出错？这时候必须引入编码规范以及代码复查。编码规范迫使你遵循一个良好的编程习惯，不犯下一些低级的错误；代码复查（人力以及机器）可以发现并报告软件可能存在的质量问题。<br>其次，在所有代码都完成的情况下，如何确保它真的是对的？这时候必须引入测试。但是一共有多少情况需要验证？这个问题反馈到具体开发就是必须充分考虑所有可能的情况并逐一进行验证。</p>\n<p>二、相互协作</p>\n<p>主要谈谈实际协作的一些体会。</p>\n<p>（一）理解、下放、处理和验证需求。<br>首先，理解来自上游的需求，我也曾犯下许多错误。例如：不清楚为什么要这样做然后自己想当然，遗漏一些细节而后偏离主题，确认需求的过程中没有主线思维导致表述不清引发歧义。</p>\n<p>其次，对于下放需求，一是必须交代清楚为什么要这么做，在不明白背景的情况下什么错误都可能发生；二是必须清楚下游的能力所在，清楚谁适合做什么以及如何让他做到。<br>紧接着，处理需求一定要有时间限制，而且这个时间绝不能给的刚刚好让执行者舒舒服服，否则执行者本身不会有大的进步，企业人力成本也将非常之高（员工的工作产出一定是大于他的工资收入的）。</p>\n<p>最后，必须对需求完成情况加以验证，而且最好是执行者本身具备这种验证能力。</p>\n<p>（二）如何让错误产生价值。</p>\n<p>犯了错误的当下再去责备已没有任何意义，而是应该想办法去解决问题。错误的积极意义在于如何不犯同类型的错误，以及从此少犯错误。相同类型的错误要予以批评，新的错误要做出反思。</p>\n<p>（三）改变一个人非常之难。</p>\n<p>我曾想要去改变DYF使他变得更积极却发现于事无补，但当我转而想如何提升他的能力来做更多事情，事情变得简单多了。</p>\n<p>（四）与同事协作，职责一定要分明。</p>\n<p>刚开始与LZQ协助确实有不少苦恼，因为我俩的职责没有一个明确的界定，经常遇到一个问题是到底这个事情归谁管？虽然后面我知道刘老师以及林总可以帮我做这个界定，但长远来讲必须把我俩各自的工作定义清楚才行。</p>\n<p>（五）给予的重要性。</p>\n<p>一味的向下索取将导致非常糟糕的结果：下游人员没有进步，失去工作激情，甚至离职。必须在管理的过程去给予一些东西：让对方学习新的东西，做更难的事情，传授一些做事情的基本方法，授课培训等。只有这样，当你真正需要他满负荷运行的时候才能调动得起来。</p>\n<p>三、未来规划</p>\n<p>拳头产品（云平台）必须花心思去打磨好（站在软件的角度）。云平台的下一个里程碑是今年年底做到：稳定、安全、交互便捷、简洁美。稳定指程序不会崩溃，安全指能承受得起外部的攻击，交互便捷指如何让使用者更容易得到他想要的信息，简洁美则是要有统一的美化标准。</p>\n<p>另外，研发才是软件团队的真正核心竞争力，而且研发也能给我带来更多乐趣。接下来我想尽可能的朝研发靠拢，这也意味着我要学习更多和承受更多。但是要兼顾一个事情，我必须学习和思考如何把下面的人带好，使他们都成为比我还优秀的开发者。</p>"},{"layout":"post","title":"SVN hooks的使用","date":"2016-06-22T13:05:00.000Z","comments":1,"_content":"\n笔者想要在下属提交SVN代码时收到邮件，查了一下，使用SVN hooks即可做到，简要记录如下：\n\n<!--more-->\n\n进入你的SVN项目的hooks文件夹下，将看到如下文件：\n\n```\n-rwxrwsr-x 1 www-data subversion   2198 6月  22 21:01 post-commit.tmpl\n-rwxrwsr-x 1 www-data subversion   1638 5月   5  2015 post-lock.tmpl\n-rwxrwsr-x 1 www-data subversion   2289 5月   5  2015 post-revprop-change.tmpl\n-rwxrwsr-x 1 www-data subversion   1567 5月   5  2015 post-unlock.tmpl\n-rwxrwsr-x 1 www-data subversion   3426 5月   5  2015 pre-commit.tmpl\n-rwxrwsr-x 1 www-data subversion   2434 5月   5  2015 pre-lock.tmpl\n-rwxrwsr-x 1 www-data subversion   2786 5月   5  2015 pre-revprop-change.tmpl\n-rwxrwsr-x 1 www-data subversion   2122 5月   5  2015 pre-unlock.tmpl\n-rwxrwsr-x 1 www-data subversion   3163 5月   5  2015 start-commit.tmpl\n```\n\n只需要简单执行命令`mv post-commit.tmpl post-commit`（即将post-commit的后缀去掉），就能实现提交代码时触发执行post-commit脚本，笔者的post-commit内容如下：\n\n```bash\n## 设置中文编码\nexport LANG=zh_CN.UTF-8\n## 设置为nohup、丢弃错误流标准流输出、以后台进程运行\nnohup /usr/java/jdk/bin/java -jar /home/svn/myproject/hooks/inv.jar > /dev/null 2>&1 &\nexit 0\n```\n\n注意，若上述不设置为nohup+后台进程，**SVN提交时会阻塞直到此jar包执行完毕**，但发送邮件需要时间，阻塞显然是不合理的。至于笔者的inv.jar包为何物，请移步[SvnPostCommit](https://github.com/JayzeeZhang/SvnPostCommit)。\n","source":"_posts/2016-06-22-svn-hooks.markdown","raw":"---\nlayout: post\ntitle: SVN hooks的使用\ndate: '2016-06-22 21:05'\ncomments: true\ncategories: ['工具篇']  \ntags: ['SVN']\n---\n\n笔者想要在下属提交SVN代码时收到邮件，查了一下，使用SVN hooks即可做到，简要记录如下：\n\n<!--more-->\n\n进入你的SVN项目的hooks文件夹下，将看到如下文件：\n\n```\n-rwxrwsr-x 1 www-data subversion   2198 6月  22 21:01 post-commit.tmpl\n-rwxrwsr-x 1 www-data subversion   1638 5月   5  2015 post-lock.tmpl\n-rwxrwsr-x 1 www-data subversion   2289 5月   5  2015 post-revprop-change.tmpl\n-rwxrwsr-x 1 www-data subversion   1567 5月   5  2015 post-unlock.tmpl\n-rwxrwsr-x 1 www-data subversion   3426 5月   5  2015 pre-commit.tmpl\n-rwxrwsr-x 1 www-data subversion   2434 5月   5  2015 pre-lock.tmpl\n-rwxrwsr-x 1 www-data subversion   2786 5月   5  2015 pre-revprop-change.tmpl\n-rwxrwsr-x 1 www-data subversion   2122 5月   5  2015 pre-unlock.tmpl\n-rwxrwsr-x 1 www-data subversion   3163 5月   5  2015 start-commit.tmpl\n```\n\n只需要简单执行命令`mv post-commit.tmpl post-commit`（即将post-commit的后缀去掉），就能实现提交代码时触发执行post-commit脚本，笔者的post-commit内容如下：\n\n```bash\n## 设置中文编码\nexport LANG=zh_CN.UTF-8\n## 设置为nohup、丢弃错误流标准流输出、以后台进程运行\nnohup /usr/java/jdk/bin/java -jar /home/svn/myproject/hooks/inv.jar > /dev/null 2>&1 &\nexit 0\n```\n\n注意，若上述不设置为nohup+后台进程，**SVN提交时会阻塞直到此jar包执行完毕**，但发送邮件需要时间，阻塞显然是不合理的。至于笔者的inv.jar包为何物，请移步[SvnPostCommit](https://github.com/JayzeeZhang/SvnPostCommit)。\n","slug":"svn-hooks","published":1,"updated":"2022-08-09T15:02:00.608Z","photos":[],"link":"","_id":"cl6mbc12x000vigu8duqsea4c","content":"<p>笔者想要在下属提交SVN代码时收到邮件，查了一下，使用SVN hooks即可做到，简要记录如下：</p>\n<a id=\"more\"></a>\n<p>进入你的SVN项目的hooks文件夹下，将看到如下文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2198 6月  22 21:01 post-commit.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   1638 5月   5  2015 post-lock.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2289 5月   5  2015 post-revprop-change.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   1567 5月   5  2015 post-unlock.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   3426 5月   5  2015 pre-commit.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2434 5月   5  2015 pre-lock.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2786 5月   5  2015 pre-revprop-change.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2122 5月   5  2015 pre-unlock.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   3163 5月   5  2015 start-commit.tmpl</span><br></pre></td></tr></table></figure>\n<p>只需要简单执行命令<code>mv post-commit.tmpl post-commit</code>（即将post-commit的后缀去掉），就能实现提交代码时触发执行post-commit脚本，笔者的post-commit内容如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 设置中文编码</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> LANG=zh_CN.UTF-8</span><br><span class=\"line\"><span class=\"comment\">## 设置为nohup、丢弃错误流标准流输出、以后台进程运行</span></span><br><span class=\"line\">nohup /usr/java/jdk/bin/java -jar /home/svn/myproject/hooks/inv.jar &gt; /dev/null 2&gt;&amp;1 &amp;</span><br><span class=\"line\"><span class=\"built_in\">exit</span> 0</span><br></pre></td></tr></table></figure>\n<p>注意，若上述不设置为nohup+后台进程，<strong>SVN提交时会阻塞直到此jar包执行完毕</strong>，但发送邮件需要时间，阻塞显然是不合理的。至于笔者的inv.jar包为何物，请移步<a href=\"https://github.com/JayzeeZhang/SvnPostCommit\" target=\"_blank\" rel=\"noopener\">SvnPostCommit</a>。</p>\n","site":{"data":{}},"excerpt":"<p>笔者想要在下属提交SVN代码时收到邮件，查了一下，使用SVN hooks即可做到，简要记录如下：</p>","more":"<p>进入你的SVN项目的hooks文件夹下，将看到如下文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2198 6月  22 21:01 post-commit.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   1638 5月   5  2015 post-lock.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2289 5月   5  2015 post-revprop-change.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   1567 5月   5  2015 post-unlock.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   3426 5月   5  2015 pre-commit.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2434 5月   5  2015 pre-lock.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2786 5月   5  2015 pre-revprop-change.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   2122 5月   5  2015 pre-unlock.tmpl</span><br><span class=\"line\">-rwxrwsr-x 1 www-data subversion   3163 5月   5  2015 start-commit.tmpl</span><br></pre></td></tr></table></figure>\n<p>只需要简单执行命令<code>mv post-commit.tmpl post-commit</code>（即将post-commit的后缀去掉），就能实现提交代码时触发执行post-commit脚本，笔者的post-commit内容如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 设置中文编码</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> LANG=zh_CN.UTF-8</span><br><span class=\"line\"><span class=\"comment\">## 设置为nohup、丢弃错误流标准流输出、以后台进程运行</span></span><br><span class=\"line\">nohup /usr/java/jdk/bin/java -jar /home/svn/myproject/hooks/inv.jar &gt; /dev/null 2&gt;&amp;1 &amp;</span><br><span class=\"line\"><span class=\"built_in\">exit</span> 0</span><br></pre></td></tr></table></figure>\n<p>注意，若上述不设置为nohup+后台进程，<strong>SVN提交时会阻塞直到此jar包执行完毕</strong>，但发送邮件需要时间，阻塞显然是不合理的。至于笔者的inv.jar包为何物，请移步<a href=\"https://github.com/JayzeeZhang/SvnPostCommit\" target=\"_blank\" rel=\"noopener\">SvnPostCommit</a>。</p>"},{"layout":"post","title":"docker初探","date":"2016-06-29T09:57:00.000Z","comments":1,"_content":"\n想在公司安装bugzilla用于bug跟踪，又不想做太多的安装配置，这时候使用docker是非常不错的方式，记录一些安装过程中用到的命令参数。我的bugzilla在docker中的容器名称为bugzilla。\n\n<!--more-->\n\n1. 启动/停止容器bugzilla：`docker start/stop bugzilla`；\n1. 查看容器bugzilla日志：`docker logs bugzilla`；\n1. 查看运行中的容器：`docker ps`；\n1. 与容器bugzilla进行内容传输：\n    ```\n    docker cp [OPTIONS] CONTAINER:PATH LOCALPATH|-\n    docker cp [OPTIONS] LOCALPATH|- CONTAINER:PATH\n    ```\n1. 在容器bugzilla内执行命令：\n    ```\n    docker exec [OPTIONS] CONTAINER COMMAND [ARG...]\n    ```\n1. 登入容器bugzilla：\n   ```\n   docker exec -it bugzilla bash\n   ```\n","source":"_posts/2016-06-29-bugzilla-in-docker.markdown","raw":"---\nlayout: post\ntitle: docker初探\ndate: '2016-06-29 17:57'\ncomments: true\ncategories: ['工具篇'] \ntags: ['Docker']\n---\n\n想在公司安装bugzilla用于bug跟踪，又不想做太多的安装配置，这时候使用docker是非常不错的方式，记录一些安装过程中用到的命令参数。我的bugzilla在docker中的容器名称为bugzilla。\n\n<!--more-->\n\n1. 启动/停止容器bugzilla：`docker start/stop bugzilla`；\n1. 查看容器bugzilla日志：`docker logs bugzilla`；\n1. 查看运行中的容器：`docker ps`；\n1. 与容器bugzilla进行内容传输：\n    ```\n    docker cp [OPTIONS] CONTAINER:PATH LOCALPATH|-\n    docker cp [OPTIONS] LOCALPATH|- CONTAINER:PATH\n    ```\n1. 在容器bugzilla内执行命令：\n    ```\n    docker exec [OPTIONS] CONTAINER COMMAND [ARG...]\n    ```\n1. 登入容器bugzilla：\n   ```\n   docker exec -it bugzilla bash\n   ```\n","slug":"bugzilla-in-docker","published":1,"updated":"2022-08-09T15:02:00.615Z","photos":[],"link":"","_id":"cl6mbc12z000yigu8qsnbdljq","content":"<p>想在公司安装bugzilla用于bug跟踪，又不想做太多的安装配置，这时候使用docker是非常不错的方式，记录一些安装过程中用到的命令参数。我的bugzilla在docker中的容器名称为bugzilla。</p>\n<a id=\"more\"></a>\n<ol>\n<li>启动/停止容器bugzilla：<code>docker start/stop bugzilla</code>；</li>\n<li>查看容器bugzilla日志：<code>docker logs bugzilla</code>；</li>\n<li>查看运行中的容器：<code>docker ps</code>；</li>\n<li><p>与容器bugzilla进行内容传输：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker cp [OPTIONS] CONTAINER:PATH LOCALPATH|-</span><br><span class=\"line\">docker cp [OPTIONS] LOCALPATH|- CONTAINER:PATH</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在容器bugzilla内执行命令：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec [OPTIONS] CONTAINER COMMAND [ARG...]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>登入容器bugzilla：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -it bugzilla bash</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>想在公司安装bugzilla用于bug跟踪，又不想做太多的安装配置，这时候使用docker是非常不错的方式，记录一些安装过程中用到的命令参数。我的bugzilla在docker中的容器名称为bugzilla。</p>","more":"<ol>\n<li>启动/停止容器bugzilla：<code>docker start/stop bugzilla</code>；</li>\n<li>查看容器bugzilla日志：<code>docker logs bugzilla</code>；</li>\n<li>查看运行中的容器：<code>docker ps</code>；</li>\n<li><p>与容器bugzilla进行内容传输：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker cp [OPTIONS] CONTAINER:PATH LOCALPATH|-</span><br><span class=\"line\">docker cp [OPTIONS] LOCALPATH|- CONTAINER:PATH</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在容器bugzilla内执行命令：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec [OPTIONS] CONTAINER COMMAND [ARG...]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>登入容器bugzilla：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -it bugzilla bash</span><br></pre></td></tr></table></figure>\n</li>\n</ol>"},{"layout":"post","title":"关于SIGPIPE","date":"2016-08-05T12:14:00.000Z","comments":1,"_content":"\nUnix有一个信号名称为SIGPIPE，wiki上的解释是：\n\n<!--more-->\n\nThe SIGPIPE signal is sent to a process when it attempts to write to a pipe without a process connected to the other end。通俗翻译下：如果连接的另一端已断开，那么此时写数据到另一端会产生SIGPIPE信号。\n\n## SIGPIPE的原因\n\nSIGPIPE的根本原因是：已连接套接字收到RST分节，但应用程序没有发现，继续调用send()或write()往该套接字写数据，而导致内核产生SIGPIPE信号。那什么情况下对端会发送RST分节呢？UNP卷1的解释有以下三种：\n\n1. **对端无应用监听**：数据（含目的端口target_port）到达对端机器，到对端根本就没有应用在target_port等待数据（有可能是该应用被强制杀死），这时对端返回一个RST分节；\n2. **对端想取消已建立的连接**：对端通过设置linger，调用close强制发送RST分节，直接略过了TIME_WAIT的状态；\n3. **对端认为收到的数据无效**：假定对端崩溃后重启，其TCP丢失了之前的所有连接信息（根据ACK数值大小来决策？），因此对端收到数据后发回一个RST分节；\n\n关于上面提到的第2点，UNP卷1认为它存在隐患：2MSL内，双端又建立了连接，此时上一次连接的数据可能还未消逝，从而导致“新生”连接收到脏数据（丢弃还是发生RST分节？）。\n\n## SIGPIPE的处理\n\n如果能在发送前检测是否收到RST分节，再决策是否发送，能否解决问题呢？答案是不能。因为有可能在检测完之后，发送之前，应用收到了一个RST分节。况且，调用send()和write()并不意味着真的把数据发送出去，而**只是数据写入到了已连接套接字的发送缓冲区**，何时真正发送出去不是应用层所能够决策的。\n\n处理方法有以下2种：\n\n**全局忽略SIGPIPE**：掉用`signal(SIGPIPE, SIG_IGN);`忽略该信号，然后在调用write()或send()之后检查其返回值和errno，若返回值为-1则表明出错，同时errno会被置为EPIPE，应用再做相应的清理工作；\n\n**仅相关线程忽略SIGPIPE**：参考[Ignore SIGPIPE without affecting other threads in a process](http://www.microhowto.info/howto/ignore_sigpipe_without_affecting_other_threads_in_a_process.html)，该文章给出了非常详细的示范。\n","source":"_posts/2016-08-05-about-sigpipe.markdown","raw":"---\nlayout: post\ntitle: 关于SIGPIPE\ndate: '2016-08-05 20:14'\ncomments: true\ncategories: ['操作系统'] \ntags: ['C/C++', 'TCP/IP', 'Linux']\n---\n\nUnix有一个信号名称为SIGPIPE，wiki上的解释是：\n\n<!--more-->\n\nThe SIGPIPE signal is sent to a process when it attempts to write to a pipe without a process connected to the other end。通俗翻译下：如果连接的另一端已断开，那么此时写数据到另一端会产生SIGPIPE信号。\n\n## SIGPIPE的原因\n\nSIGPIPE的根本原因是：已连接套接字收到RST分节，但应用程序没有发现，继续调用send()或write()往该套接字写数据，而导致内核产生SIGPIPE信号。那什么情况下对端会发送RST分节呢？UNP卷1的解释有以下三种：\n\n1. **对端无应用监听**：数据（含目的端口target_port）到达对端机器，到对端根本就没有应用在target_port等待数据（有可能是该应用被强制杀死），这时对端返回一个RST分节；\n2. **对端想取消已建立的连接**：对端通过设置linger，调用close强制发送RST分节，直接略过了TIME_WAIT的状态；\n3. **对端认为收到的数据无效**：假定对端崩溃后重启，其TCP丢失了之前的所有连接信息（根据ACK数值大小来决策？），因此对端收到数据后发回一个RST分节；\n\n关于上面提到的第2点，UNP卷1认为它存在隐患：2MSL内，双端又建立了连接，此时上一次连接的数据可能还未消逝，从而导致“新生”连接收到脏数据（丢弃还是发生RST分节？）。\n\n## SIGPIPE的处理\n\n如果能在发送前检测是否收到RST分节，再决策是否发送，能否解决问题呢？答案是不能。因为有可能在检测完之后，发送之前，应用收到了一个RST分节。况且，调用send()和write()并不意味着真的把数据发送出去，而**只是数据写入到了已连接套接字的发送缓冲区**，何时真正发送出去不是应用层所能够决策的。\n\n处理方法有以下2种：\n\n**全局忽略SIGPIPE**：掉用`signal(SIGPIPE, SIG_IGN);`忽略该信号，然后在调用write()或send()之后检查其返回值和errno，若返回值为-1则表明出错，同时errno会被置为EPIPE，应用再做相应的清理工作；\n\n**仅相关线程忽略SIGPIPE**：参考[Ignore SIGPIPE without affecting other threads in a process](http://www.microhowto.info/howto/ignore_sigpipe_without_affecting_other_threads_in_a_process.html)，该文章给出了非常详细的示范。\n","slug":"about-sigpipe","published":1,"updated":"2022-08-09T15:02:00.623Z","photos":[],"link":"","_id":"cl6mbc1320012igu801pp69ha","content":"<p>Unix有一个信号名称为SIGPIPE，wiki上的解释是：</p>\n<a id=\"more\"></a>\n<p>The SIGPIPE signal is sent to a process when it attempts to write to a pipe without a process connected to the other end。通俗翻译下：如果连接的另一端已断开，那么此时写数据到另一端会产生SIGPIPE信号。</p>\n<h2 id=\"SIGPIPE的原因\"><a href=\"#SIGPIPE的原因\" class=\"headerlink\" title=\"SIGPIPE的原因\"></a>SIGPIPE的原因</h2><p>SIGPIPE的根本原因是：已连接套接字收到RST分节，但应用程序没有发现，继续调用send()或write()往该套接字写数据，而导致内核产生SIGPIPE信号。那什么情况下对端会发送RST分节呢？UNP卷1的解释有以下三种：</p>\n<ol>\n<li><strong>对端无应用监听</strong>：数据（含目的端口target_port）到达对端机器，到对端根本就没有应用在target_port等待数据（有可能是该应用被强制杀死），这时对端返回一个RST分节；</li>\n<li><strong>对端想取消已建立的连接</strong>：对端通过设置linger，调用close强制发送RST分节，直接略过了TIME_WAIT的状态；</li>\n<li><strong>对端认为收到的数据无效</strong>：假定对端崩溃后重启，其TCP丢失了之前的所有连接信息（根据ACK数值大小来决策？），因此对端收到数据后发回一个RST分节；</li>\n</ol>\n<p>关于上面提到的第2点，UNP卷1认为它存在隐患：2MSL内，双端又建立了连接，此时上一次连接的数据可能还未消逝，从而导致“新生”连接收到脏数据（丢弃还是发生RST分节？）。</p>\n<h2 id=\"SIGPIPE的处理\"><a href=\"#SIGPIPE的处理\" class=\"headerlink\" title=\"SIGPIPE的处理\"></a>SIGPIPE的处理</h2><p>如果能在发送前检测是否收到RST分节，再决策是否发送，能否解决问题呢？答案是不能。因为有可能在检测完之后，发送之前，应用收到了一个RST分节。况且，调用send()和write()并不意味着真的把数据发送出去，而<strong>只是数据写入到了已连接套接字的发送缓冲区</strong>，何时真正发送出去不是应用层所能够决策的。</p>\n<p>处理方法有以下2种：</p>\n<p><strong>全局忽略SIGPIPE</strong>：掉用<code>signal(SIGPIPE, SIG_IGN);</code>忽略该信号，然后在调用write()或send()之后检查其返回值和errno，若返回值为-1则表明出错，同时errno会被置为EPIPE，应用再做相应的清理工作；</p>\n<p><strong>仅相关线程忽略SIGPIPE</strong>：参考<a href=\"http://www.microhowto.info/howto/ignore_sigpipe_without_affecting_other_threads_in_a_process.html\" target=\"_blank\" rel=\"noopener\">Ignore SIGPIPE without affecting other threads in a process</a>，该文章给出了非常详细的示范。</p>\n","site":{"data":{}},"excerpt":"<p>Unix有一个信号名称为SIGPIPE，wiki上的解释是：</p>","more":"<p>The SIGPIPE signal is sent to a process when it attempts to write to a pipe without a process connected to the other end。通俗翻译下：如果连接的另一端已断开，那么此时写数据到另一端会产生SIGPIPE信号。</p>\n<h2 id=\"SIGPIPE的原因\"><a href=\"#SIGPIPE的原因\" class=\"headerlink\" title=\"SIGPIPE的原因\"></a>SIGPIPE的原因</h2><p>SIGPIPE的根本原因是：已连接套接字收到RST分节，但应用程序没有发现，继续调用send()或write()往该套接字写数据，而导致内核产生SIGPIPE信号。那什么情况下对端会发送RST分节呢？UNP卷1的解释有以下三种：</p>\n<ol>\n<li><strong>对端无应用监听</strong>：数据（含目的端口target_port）到达对端机器，到对端根本就没有应用在target_port等待数据（有可能是该应用被强制杀死），这时对端返回一个RST分节；</li>\n<li><strong>对端想取消已建立的连接</strong>：对端通过设置linger，调用close强制发送RST分节，直接略过了TIME_WAIT的状态；</li>\n<li><strong>对端认为收到的数据无效</strong>：假定对端崩溃后重启，其TCP丢失了之前的所有连接信息（根据ACK数值大小来决策？），因此对端收到数据后发回一个RST分节；</li>\n</ol>\n<p>关于上面提到的第2点，UNP卷1认为它存在隐患：2MSL内，双端又建立了连接，此时上一次连接的数据可能还未消逝，从而导致“新生”连接收到脏数据（丢弃还是发生RST分节？）。</p>\n<h2 id=\"SIGPIPE的处理\"><a href=\"#SIGPIPE的处理\" class=\"headerlink\" title=\"SIGPIPE的处理\"></a>SIGPIPE的处理</h2><p>如果能在发送前检测是否收到RST分节，再决策是否发送，能否解决问题呢？答案是不能。因为有可能在检测完之后，发送之前，应用收到了一个RST分节。况且，调用send()和write()并不意味着真的把数据发送出去，而<strong>只是数据写入到了已连接套接字的发送缓冲区</strong>，何时真正发送出去不是应用层所能够决策的。</p>\n<p>处理方法有以下2种：</p>\n<p><strong>全局忽略SIGPIPE</strong>：掉用<code>signal(SIGPIPE, SIG_IGN);</code>忽略该信号，然后在调用write()或send()之后检查其返回值和errno，若返回值为-1则表明出错，同时errno会被置为EPIPE，应用再做相应的清理工作；</p>\n<p><strong>仅相关线程忽略SIGPIPE</strong>：参考<a href=\"http://www.microhowto.info/howto/ignore_sigpipe_without_affecting_other_threads_in_a_process.html\" target=\"_blank\" rel=\"noopener\">Ignore SIGPIPE without affecting other threads in a process</a>，该文章给出了非常详细的示范。</p>"},{"layout":"post","title":"C/C++的const","date":"2016-08-02T01:04:00.000Z","comments":1,"_content":"\nC/C++都有const关键字？它有什么用途以及用来干嘛呢？\n\n<!--more-->\n\n## const variable\n\nconst修饰variable，意味着**该变量不可修改**，即变量是readonly的，这一点C和C++相同。例子如下：\n\n```c\nint main() {\n    const int a = 0; // 等价于：int const a = 0;\n    a = 1; // error：a是readonly的，不可修改\n    return 0;\n}\n```\n\n考虑到指针也是variable，上述特点对指针也适用，称为const pointer，const pointer的**dereference（*号取值）不受影响**。例子如下：\n\n```c\nint main() {\n    typedef int * int_ptr;\n    int a = 0, b = 1;\n    const int_ptr ip = &a; // 等价于：int_ptr const ip = &a;\n    ip = &b; // error：ip是readonly的，其值（标识地址）不可修改\n    *ip = 2; // 不影响指针的dereference\n    return 0;\n}\n```\n\n假如不想使用typedef的方式表示上述的const pointer，则必须写成如下形式：\n\n```c\nint a = 0;\nint * const ptr = &a;\nint const * ptr = &a; // error：这表示指向const int的指针\nconst int * ptr = &a; // error：这表示指向const int的指针\n```\n\nconst variable的特点如下：\n\n1. 声明和定义必须在同一个地方（声明变量时实例化）；\n2. const variable不可修改；\n3. const和type类型可以互换（指针不使用typedef的方式定义时需要格外注意）；\n\n## pointer to const variable\n\n指针指向const variable，意味着**不能通过指针去修改指针指向的内存**，即指针指向的内存是readonly的，但**指针本身的值修改不受影响（即可以重新绑定地址）**，这一点C和C++也相同，例子如下：\n\n```c\nint main() {\n    typedef int * const int_cst_ptr; // const pointer\n    typedef int const int_cst; // const int\n    int a = 0;\n    int *b = &a;\n    int_cst_ptr *ptr1 = &b;\n    int_cst *ptr2 = &a;\n    *ptr1 = NULL; // error：pointer to const，指针指向内存readonly\n    *ptr2 = 1; // error：pointer to const，指针指向内存readonly\n    ptr1 = NULL; // 指针本身的值修改不受影响（即可以重新绑定地址）\n    ptr2 = NULL;\n}\n```\n\n假设不使用typedef，上述例子需写成：\n\n```c\nint main() {\n    int a = 0;\n    int *b = &a;\n    int * const *ptr1 = &b; // 从右到左：ptr1 is a pointer to const pointer to int\n    int const *ptr2 = &a;\n    *ptr1 = NULL; // error：pointer to const，指针指向内存readonly\n    *ptr2 = 1; // error：pointer to const，指针指向内存readonly\n    ptr1 = NULL; // 指针本身的值修改不受影响（即可以重新绑定地址）\n    ptr2 = NULL;\n}\n```\n\npointer to const variable的特点：\n\n1. 指针指向内存不可修改；\n2. 指针本身的值（代表的地址）可以修改；\n\n举一个复杂点的例子，即有指针又有数组的情况：\n\n```c\n#include <stdio.h>\n#include <string.h>\n\nint main(int argc,char *argv[]) {\n    int i = 0;\n    for(; i<argc; i++) {\n        printf(\"argv[%d] : %s\\n\", i, argv[i]);\n        argv[i] = \"a\";\n    }\n    // char *const argv2[] = argv;\n    char *const argv3[] = {\"a\", \"b\"};\n    // argv3[0] = \"test\";\n    char *const argv4[2];\n    char *str = argv4[0];\n    printf(\"str: %s\\n\", str);\n    printf(\"strlen(str): %d\\n\", strlen(str));\n    *str = 'a';\n    *(str+1) = '\\0';\n    printf(\"str: %s\\n\", str);\n    return 0;\n}\n```\n\n上述代码可正常编译，被注释掉的行是因为其会在编译时出错。在x86的Linux下运行得到的结果为，\n\n```\nargv[0] : ./a.out\nstr: ,ݳ▒\nstrlen(str): 4\nstr: a\n```\n\n而在x64的Linux下运行得到的结果为，\n\n```\nargv[0] : ./a.out\nstr: AWA▒▒AVI▒▒AUI▒▒ATL▒%h\nstrlen(str): 23\n段错误\n```\n\n关于该代码的几点说明如下，\n\n1. `char *const argv2[] = argv;`之所以被注释是因为不能够将一个数组赋值给另外一个数组；\n2. `char *const argv3[] = {\"a\", \"b\"};`定义并显示实例化了argv3，argv3是一个数组，它包含2个char * const（const pointer to char）元素，因此argv3[0]的指针值不可修改；\n3. 在两个平台下运行结果不同说明若不显示实例化数组内容，数组的内容是不可预料的，对数组内容的修改结果也是不可预料的；\n\n## const pointer to const variable\n\nconst pointer指向const variable，这意外着**指针本身值（代表的地址）不可修改**，同时**指针指向的内存也不可修改**，这点C和C++也相同。例子如下：\n\n```c\nint main() {\n    typedef int * const int_cst_ptr; // const pointer\n    typedef int const int_cst; // const int\n    int a = 0;\n    int *b = &a;\n    int_cst_ptr * const ptr1 = &b;\n    int_cst * const ptr2 = &a;\n    *ptr1 = NULL; // error：pointer to const，指针指向内存readonly\n    *ptr2 = 1; // error：pointer to const，指针指向内存readonly\n    ptr1 = NULL; // error：const pointer，指针本身值不可修改\n    ptr2 = NULL; // error：const pointer，指针本身值不可修改\n}\n```\n\n假设不使用typedef，上述例子需写成：\n\n```c\nint main() {\n    int a = 0;\n    int *b = &a;\n    int * const * const ptr1 = &b; // 这时候表达式越来越复杂\n    int const * const ptr2 = &a;\n    *ptr1 = NULL; // error：pointer to const，指针指向内存readonly\n    *ptr2 = 1; // error：pointer to const，指针指向内存readonly\n    ptr1 = NULL; // error：const pointer，指针本身值不可修改\n    ptr2 = NULL; // error：const pointer，指针本身值不可修改\n}\n```\n\nconst pointer to const variable的特点：\n\n1. 指针本身值（代表的地址）不可修改；\n2. 指针指向的内存也不可修改；\n\n## linkage\n\n有以下代码文件：\n\n头文件linkage.h，\n\n```c\nextern const int counter;\nvoid print_counter();\n```\n\nc文件linkage.c，\n\n```c\n#include \"stdio.h\"\n#include \"linkage.h\"\n\nvoid print_counter() {\n    printf(\"counter: %d\\n\", counter);\n}\n```\n\nc文件main.c，\n\n```c\n#include \"linkage.h\"\n\nconst int counter = 12;\n\nint main(int argc,char *argv[]) {\n    print_counter();\n    return 0;\n}\n```\n\n执行下述语句，\n\n```\ngcc -c linkage.cpp -o linkage.o\ngcc -c main.cpp -o main.o\ngcc linkage.o main.o -o main\n./main\n```\n\n得到的输出是预期的值：12。\n\n将上述的linkage.c文件重命名为linkage.cpp，main.c重命名为main.cpp，执行下述语句，\n\n```\ng++ -c linkage.cpp -o linkage.o\ng++ -c main.cpp -o main.o\ng++ linkage.o main.o -o main\n./main\n```\n\n得到的输出却是：0。\n\n回想一下在C语言里面使用全局变量的注意点，\n\n1. 在一个头文件声明该变量，即上述代码的`extern const int counter;`，它的作用是告诉编译器，我有这么一个类型的变量存在；\n2. 在一个C文件定义该变量，即上述代码的`const int counter = 12;`，它的作用是为该全局变量申请存储；\n3. 在其他需要此全局变量的C文件，include步骤1提到的头文件，全局变量得以共享；\n\n对于C语言，const全局变量与非const变量一样，都是全局共享的，C++ Primer将此称为**external linkage**；\n但对于C++，const全局变量确是local to file的（作用域仅限于文件内），问题就处在于`const int counter = 12;`这一行代码，在C++里这意味着定义了一个const int变量，但仅限于文件内部使用，C++ Primer将此称为**internal linkage**。\n\n那么，如何在C++共享const全局变量呢？方法很简单，将步骤2的定义代码修改为`extern const int counter = 12;`即可。\n\n## top-level const和low-level const\n\nC++里面，将const variable称为**top-level const**，将pointer to const variable称为**low-level const**，而且还规定，\n\n1. const variable赋值给普通variable或pointer to const variable时，top-level const的const被忽略，等同于普通变量间赋值；\n2. pointer to const variable赋值给普通variable或const variable时，low-level const的const不能被忽略；\n\n有以下main.cpp文件，\n\n```c\nint main() {\n    const int a = 0;\n    int b = a; // const int --> int, top to normal\n    const int c = b; // int --> const int, normal to top\n    int * const ptr = &a; // const int * --> int * const, low to top\n    int * ptr2 = &a; // const int * --> int *, low to normal\n    int * ptr3 = ptr; // int * const --> int *, top to normal\n    const int * ptr4 = ptr; // int * const --> const int *, top to low\n    return 0;\n}\n```\n\n运行`g++ main.c`，得到的输出如下：\n\n```\nmain.cpp: In function ‘int main()’:\nmain.cpp:5:24: error: invalid conversion from ‘const int*’ to ‘int*’ [-fpermissive]\n     int * const ptr = &a; // const int * --> int * const, low to top\n                        ^\nmain.cpp:6:19: error: invalid conversion from ‘const int*’ to ‘int*’ [-fpermissive]\n     int * ptr2 = &a; // const int * --> int *, low to normal\n                   ^\n```\n\n这说明在C++里面，low-level const赋值或强转给其他类型时，const是不能被忽略的，否则会在编译时报错。\n\n将上述代码保存为main.c后执行`gcc main.c`，得到的输出如下：\n\n```\nmain.c: In function ‘main’:\nmain.c:4:23: warning: initialization discards ‘const’ qualifier from pointer target type [enabled by default]\n     int * const ptr = &a; // const int * --> int * const, low to top\n                       ^\nmain.c:5:18: warning: initialization discards ‘const’ qualifier from pointer target type [enabled by default]\n     int * ptr2 = &a; // const int * --> int *, low to normal\n                  ^\n```\n\n这说明在C里面，并没有严格规定top-level const和low-level const，但是对于low-level const的情况，还是会有warning，因此必须小心使用，同时必须注意编译器的所有warning。\n","source":"_posts/2016-08-02-summary-of-const.markdown","raw":"---\nlayout: post\ntitle: C/C++的const\ndate: '2016-08-02 09:04'\ncomments: true\ncategories: ['编程语言'] \ntags: ['C/C++']\n---\n\nC/C++都有const关键字？它有什么用途以及用来干嘛呢？\n\n<!--more-->\n\n## const variable\n\nconst修饰variable，意味着**该变量不可修改**，即变量是readonly的，这一点C和C++相同。例子如下：\n\n```c\nint main() {\n    const int a = 0; // 等价于：int const a = 0;\n    a = 1; // error：a是readonly的，不可修改\n    return 0;\n}\n```\n\n考虑到指针也是variable，上述特点对指针也适用，称为const pointer，const pointer的**dereference（*号取值）不受影响**。例子如下：\n\n```c\nint main() {\n    typedef int * int_ptr;\n    int a = 0, b = 1;\n    const int_ptr ip = &a; // 等价于：int_ptr const ip = &a;\n    ip = &b; // error：ip是readonly的，其值（标识地址）不可修改\n    *ip = 2; // 不影响指针的dereference\n    return 0;\n}\n```\n\n假如不想使用typedef的方式表示上述的const pointer，则必须写成如下形式：\n\n```c\nint a = 0;\nint * const ptr = &a;\nint const * ptr = &a; // error：这表示指向const int的指针\nconst int * ptr = &a; // error：这表示指向const int的指针\n```\n\nconst variable的特点如下：\n\n1. 声明和定义必须在同一个地方（声明变量时实例化）；\n2. const variable不可修改；\n3. const和type类型可以互换（指针不使用typedef的方式定义时需要格外注意）；\n\n## pointer to const variable\n\n指针指向const variable，意味着**不能通过指针去修改指针指向的内存**，即指针指向的内存是readonly的，但**指针本身的值修改不受影响（即可以重新绑定地址）**，这一点C和C++也相同，例子如下：\n\n```c\nint main() {\n    typedef int * const int_cst_ptr; // const pointer\n    typedef int const int_cst; // const int\n    int a = 0;\n    int *b = &a;\n    int_cst_ptr *ptr1 = &b;\n    int_cst *ptr2 = &a;\n    *ptr1 = NULL; // error：pointer to const，指针指向内存readonly\n    *ptr2 = 1; // error：pointer to const，指针指向内存readonly\n    ptr1 = NULL; // 指针本身的值修改不受影响（即可以重新绑定地址）\n    ptr2 = NULL;\n}\n```\n\n假设不使用typedef，上述例子需写成：\n\n```c\nint main() {\n    int a = 0;\n    int *b = &a;\n    int * const *ptr1 = &b; // 从右到左：ptr1 is a pointer to const pointer to int\n    int const *ptr2 = &a;\n    *ptr1 = NULL; // error：pointer to const，指针指向内存readonly\n    *ptr2 = 1; // error：pointer to const，指针指向内存readonly\n    ptr1 = NULL; // 指针本身的值修改不受影响（即可以重新绑定地址）\n    ptr2 = NULL;\n}\n```\n\npointer to const variable的特点：\n\n1. 指针指向内存不可修改；\n2. 指针本身的值（代表的地址）可以修改；\n\n举一个复杂点的例子，即有指针又有数组的情况：\n\n```c\n#include <stdio.h>\n#include <string.h>\n\nint main(int argc,char *argv[]) {\n    int i = 0;\n    for(; i<argc; i++) {\n        printf(\"argv[%d] : %s\\n\", i, argv[i]);\n        argv[i] = \"a\";\n    }\n    // char *const argv2[] = argv;\n    char *const argv3[] = {\"a\", \"b\"};\n    // argv3[0] = \"test\";\n    char *const argv4[2];\n    char *str = argv4[0];\n    printf(\"str: %s\\n\", str);\n    printf(\"strlen(str): %d\\n\", strlen(str));\n    *str = 'a';\n    *(str+1) = '\\0';\n    printf(\"str: %s\\n\", str);\n    return 0;\n}\n```\n\n上述代码可正常编译，被注释掉的行是因为其会在编译时出错。在x86的Linux下运行得到的结果为，\n\n```\nargv[0] : ./a.out\nstr: ,ݳ▒\nstrlen(str): 4\nstr: a\n```\n\n而在x64的Linux下运行得到的结果为，\n\n```\nargv[0] : ./a.out\nstr: AWA▒▒AVI▒▒AUI▒▒ATL▒%h\nstrlen(str): 23\n段错误\n```\n\n关于该代码的几点说明如下，\n\n1. `char *const argv2[] = argv;`之所以被注释是因为不能够将一个数组赋值给另外一个数组；\n2. `char *const argv3[] = {\"a\", \"b\"};`定义并显示实例化了argv3，argv3是一个数组，它包含2个char * const（const pointer to char）元素，因此argv3[0]的指针值不可修改；\n3. 在两个平台下运行结果不同说明若不显示实例化数组内容，数组的内容是不可预料的，对数组内容的修改结果也是不可预料的；\n\n## const pointer to const variable\n\nconst pointer指向const variable，这意外着**指针本身值（代表的地址）不可修改**，同时**指针指向的内存也不可修改**，这点C和C++也相同。例子如下：\n\n```c\nint main() {\n    typedef int * const int_cst_ptr; // const pointer\n    typedef int const int_cst; // const int\n    int a = 0;\n    int *b = &a;\n    int_cst_ptr * const ptr1 = &b;\n    int_cst * const ptr2 = &a;\n    *ptr1 = NULL; // error：pointer to const，指针指向内存readonly\n    *ptr2 = 1; // error：pointer to const，指针指向内存readonly\n    ptr1 = NULL; // error：const pointer，指针本身值不可修改\n    ptr2 = NULL; // error：const pointer，指针本身值不可修改\n}\n```\n\n假设不使用typedef，上述例子需写成：\n\n```c\nint main() {\n    int a = 0;\n    int *b = &a;\n    int * const * const ptr1 = &b; // 这时候表达式越来越复杂\n    int const * const ptr2 = &a;\n    *ptr1 = NULL; // error：pointer to const，指针指向内存readonly\n    *ptr2 = 1; // error：pointer to const，指针指向内存readonly\n    ptr1 = NULL; // error：const pointer，指针本身值不可修改\n    ptr2 = NULL; // error：const pointer，指针本身值不可修改\n}\n```\n\nconst pointer to const variable的特点：\n\n1. 指针本身值（代表的地址）不可修改；\n2. 指针指向的内存也不可修改；\n\n## linkage\n\n有以下代码文件：\n\n头文件linkage.h，\n\n```c\nextern const int counter;\nvoid print_counter();\n```\n\nc文件linkage.c，\n\n```c\n#include \"stdio.h\"\n#include \"linkage.h\"\n\nvoid print_counter() {\n    printf(\"counter: %d\\n\", counter);\n}\n```\n\nc文件main.c，\n\n```c\n#include \"linkage.h\"\n\nconst int counter = 12;\n\nint main(int argc,char *argv[]) {\n    print_counter();\n    return 0;\n}\n```\n\n执行下述语句，\n\n```\ngcc -c linkage.cpp -o linkage.o\ngcc -c main.cpp -o main.o\ngcc linkage.o main.o -o main\n./main\n```\n\n得到的输出是预期的值：12。\n\n将上述的linkage.c文件重命名为linkage.cpp，main.c重命名为main.cpp，执行下述语句，\n\n```\ng++ -c linkage.cpp -o linkage.o\ng++ -c main.cpp -o main.o\ng++ linkage.o main.o -o main\n./main\n```\n\n得到的输出却是：0。\n\n回想一下在C语言里面使用全局变量的注意点，\n\n1. 在一个头文件声明该变量，即上述代码的`extern const int counter;`，它的作用是告诉编译器，我有这么一个类型的变量存在；\n2. 在一个C文件定义该变量，即上述代码的`const int counter = 12;`，它的作用是为该全局变量申请存储；\n3. 在其他需要此全局变量的C文件，include步骤1提到的头文件，全局变量得以共享；\n\n对于C语言，const全局变量与非const变量一样，都是全局共享的，C++ Primer将此称为**external linkage**；\n但对于C++，const全局变量确是local to file的（作用域仅限于文件内），问题就处在于`const int counter = 12;`这一行代码，在C++里这意味着定义了一个const int变量，但仅限于文件内部使用，C++ Primer将此称为**internal linkage**。\n\n那么，如何在C++共享const全局变量呢？方法很简单，将步骤2的定义代码修改为`extern const int counter = 12;`即可。\n\n## top-level const和low-level const\n\nC++里面，将const variable称为**top-level const**，将pointer to const variable称为**low-level const**，而且还规定，\n\n1. const variable赋值给普通variable或pointer to const variable时，top-level const的const被忽略，等同于普通变量间赋值；\n2. pointer to const variable赋值给普通variable或const variable时，low-level const的const不能被忽略；\n\n有以下main.cpp文件，\n\n```c\nint main() {\n    const int a = 0;\n    int b = a; // const int --> int, top to normal\n    const int c = b; // int --> const int, normal to top\n    int * const ptr = &a; // const int * --> int * const, low to top\n    int * ptr2 = &a; // const int * --> int *, low to normal\n    int * ptr3 = ptr; // int * const --> int *, top to normal\n    const int * ptr4 = ptr; // int * const --> const int *, top to low\n    return 0;\n}\n```\n\n运行`g++ main.c`，得到的输出如下：\n\n```\nmain.cpp: In function ‘int main()’:\nmain.cpp:5:24: error: invalid conversion from ‘const int*’ to ‘int*’ [-fpermissive]\n     int * const ptr = &a; // const int * --> int * const, low to top\n                        ^\nmain.cpp:6:19: error: invalid conversion from ‘const int*’ to ‘int*’ [-fpermissive]\n     int * ptr2 = &a; // const int * --> int *, low to normal\n                   ^\n```\n\n这说明在C++里面，low-level const赋值或强转给其他类型时，const是不能被忽略的，否则会在编译时报错。\n\n将上述代码保存为main.c后执行`gcc main.c`，得到的输出如下：\n\n```\nmain.c: In function ‘main’:\nmain.c:4:23: warning: initialization discards ‘const’ qualifier from pointer target type [enabled by default]\n     int * const ptr = &a; // const int * --> int * const, low to top\n                       ^\nmain.c:5:18: warning: initialization discards ‘const’ qualifier from pointer target type [enabled by default]\n     int * ptr2 = &a; // const int * --> int *, low to normal\n                  ^\n```\n\n这说明在C里面，并没有严格规定top-level const和low-level const，但是对于low-level const的情况，还是会有warning，因此必须小心使用，同时必须注意编译器的所有warning。\n","slug":"summary-of-const","published":1,"updated":"2022-08-09T15:02:00.622Z","photos":[],"link":"","_id":"cl6mbc1340015igu8ia5xygqs","content":"<p>C/C++都有const关键字？它有什么用途以及用来干嘛呢？</p>\n<a id=\"more\"></a>\n<h2 id=\"const-variable\"><a href=\"#const-variable\" class=\"headerlink\" title=\"const variable\"></a>const variable</h2><p>const修饰variable，意味着<strong>该变量不可修改</strong>，即变量是readonly的，这一点C和C++相同。例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>; <span class=\"comment\">// 等价于：int const a = 0;</span></span><br><span class=\"line\">    a = <span class=\"number\">1</span>; <span class=\"comment\">// error：a是readonly的，不可修改</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>考虑到指针也是variable，上述特点对指针也适用，称为const pointer，const pointer的<strong>dereference（*号取值）不受影响</strong>。例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> * int_ptr;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>, b = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> int_ptr ip = &amp;a; <span class=\"comment\">// 等价于：int_ptr const ip = &amp;a;</span></span><br><span class=\"line\">    ip = &amp;b; <span class=\"comment\">// error：ip是readonly的，其值（标识地址）不可修改</span></span><br><span class=\"line\">    *ip = <span class=\"number\">2</span>; <span class=\"comment\">// 不影响指针的dereference</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>假如不想使用typedef的方式表示上述的const pointer，则必须写成如下形式：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> ptr = &amp;a;</span><br><span class=\"line\"><span class=\"keyword\">int</span> <span class=\"keyword\">const</span> * ptr = &amp;a; <span class=\"comment\">// error：这表示指向const int的指针</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> * ptr = &amp;a; <span class=\"comment\">// error：这表示指向const int的指针</span></span><br></pre></td></tr></table></figure>\n<p>const variable的特点如下：</p>\n<ol>\n<li>声明和定义必须在同一个地方（声明变量时实例化）；</li>\n<li>const variable不可修改；</li>\n<li>const和type类型可以互换（指针不使用typedef的方式定义时需要格外注意）；</li>\n</ol>\n<h2 id=\"pointer-to-const-variable\"><a href=\"#pointer-to-const-variable\" class=\"headerlink\" title=\"pointer to const variable\"></a>pointer to const variable</h2><p>指针指向const variable，意味着<strong>不能通过指针去修改指针指向的内存</strong>，即指针指向的内存是readonly的，但<strong>指针本身的值修改不受影响（即可以重新绑定地址）</strong>，这一点C和C++也相同，例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> int_cst_ptr; <span class=\"comment\">// const pointer</span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> <span class=\"keyword\">const</span> int_cst; <span class=\"comment\">// const int</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *b = &amp;a;</span><br><span class=\"line\">    int_cst_ptr *ptr1 = &amp;b;</span><br><span class=\"line\">    int_cst *ptr2 = &amp;a;</span><br><span class=\"line\">    *ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    *ptr2 = <span class=\"number\">1</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// 指针本身的值修改不受影响（即可以重新绑定地址）</span></span><br><span class=\"line\">    ptr2 = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>假设不使用typedef，上述例子需写成：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *b = &amp;a;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> *ptr1 = &amp;b; <span class=\"comment\">// 从右到左：ptr1 is a pointer to const pointer to int</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> <span class=\"keyword\">const</span> *ptr2 = &amp;a;</span><br><span class=\"line\">    *ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    *ptr2 = <span class=\"number\">1</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// 指针本身的值修改不受影响（即可以重新绑定地址）</span></span><br><span class=\"line\">    ptr2 = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>pointer to const variable的特点：</p>\n<ol>\n<li>指针指向内存不可修改；</li>\n<li>指针本身的值（代表的地址）可以修改；</li>\n</ol>\n<p>举一个复杂点的例子，即有指针又有数组的情况：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc,<span class=\"keyword\">char</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(; i&lt;argc; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"argv[%d] : %s\\n\"</span>, i, argv[i]);</span><br><span class=\"line\">        argv[i] = <span class=\"string\">\"a\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// char *const argv2[] = argv;</span></span><br><span class=\"line\">    <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv3[] = &#123;<span class=\"string\">\"a\"</span>, <span class=\"string\">\"b\"</span>&#125;;</span><br><span class=\"line\">    <span class=\"comment\">// argv3[0] = \"test\";</span></span><br><span class=\"line\">    <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv4[<span class=\"number\">2</span>];</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *str = argv4[<span class=\"number\">0</span>];</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"str: %s\\n\"</span>, str);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"strlen(str): %d\\n\"</span>, <span class=\"built_in\">strlen</span>(str));</span><br><span class=\"line\">    *str = <span class=\"string\">'a'</span>;</span><br><span class=\"line\">    *(str+<span class=\"number\">1</span>) = <span class=\"string\">'\\0'</span>;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"str: %s\\n\"</span>, str);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上述代码可正常编译，被注释掉的行是因为其会在编译时出错。在x86的Linux下运行得到的结果为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">argv[0] : ./a.out</span><br><span class=\"line\">str: ,ݳ▒</span><br><span class=\"line\">strlen(str): 4</span><br><span class=\"line\">str: a</span><br></pre></td></tr></table></figure>\n<p>而在x64的Linux下运行得到的结果为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">argv[0] : ./a.out</span><br><span class=\"line\">str: AWA▒▒AVI▒▒AUI▒▒ATL▒%h</span><br><span class=\"line\">strlen(str): 23</span><br><span class=\"line\">段错误</span><br></pre></td></tr></table></figure>\n<p>关于该代码的几点说明如下，</p>\n<ol>\n<li><code>char *const argv2[] = argv;</code>之所以被注释是因为不能够将一个数组赋值给另外一个数组；</li>\n<li><code>char *const argv3[] = {&quot;a&quot;, &quot;b&quot;};</code>定义并显示实例化了argv3，argv3是一个数组，它包含2个char * const（const pointer to char）元素，因此argv3[0]的指针值不可修改；</li>\n<li>在两个平台下运行结果不同说明若不显示实例化数组内容，数组的内容是不可预料的，对数组内容的修改结果也是不可预料的；</li>\n</ol>\n<h2 id=\"const-pointer-to-const-variable\"><a href=\"#const-pointer-to-const-variable\" class=\"headerlink\" title=\"const pointer to const variable\"></a>const pointer to const variable</h2><p>const pointer指向const variable，这意外着<strong>指针本身值（代表的地址）不可修改</strong>，同时<strong>指针指向的内存也不可修改</strong>，这点C和C++也相同。例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> int_cst_ptr; <span class=\"comment\">// const pointer</span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> <span class=\"keyword\">const</span> int_cst; <span class=\"comment\">// const int</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *b = &amp;a;</span><br><span class=\"line\">    int_cst_ptr * <span class=\"keyword\">const</span> ptr1 = &amp;b;</span><br><span class=\"line\">    int_cst * <span class=\"keyword\">const</span> ptr2 = &amp;a;</span><br><span class=\"line\">    *ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    *ptr2 = <span class=\"number\">1</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：const pointer，指针本身值不可修改</span></span><br><span class=\"line\">    ptr2 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：const pointer，指针本身值不可修改</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>假设不使用typedef，上述例子需写成：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *b = &amp;a;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> * <span class=\"keyword\">const</span> ptr1 = &amp;b; <span class=\"comment\">// 这时候表达式越来越复杂</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> <span class=\"keyword\">const</span> * <span class=\"keyword\">const</span> ptr2 = &amp;a;</span><br><span class=\"line\">    *ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    *ptr2 = <span class=\"number\">1</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：const pointer，指针本身值不可修改</span></span><br><span class=\"line\">    ptr2 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：const pointer，指针本身值不可修改</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>const pointer to const variable的特点：</p>\n<ol>\n<li>指针本身值（代表的地址）不可修改；</li>\n<li>指针指向的内存也不可修改；</li>\n</ol>\n<h2 id=\"linkage\"><a href=\"#linkage\" class=\"headerlink\" title=\"linkage\"></a>linkage</h2><p>有以下代码文件：</p>\n<p>头文件linkage.h，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> counter;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_counter</span><span class=\"params\">()</span></span>;</span><br></pre></td></tr></table></figure>\n<p>c文件linkage.c，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"stdio.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"linkage.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_counter</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"counter: %d\\n\"</span>, counter);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>c文件main.c，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"linkage.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> counter = <span class=\"number\">12</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc,<span class=\"keyword\">char</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\">    print_counter();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行下述语句，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -c linkage.cpp -o linkage.o</span><br><span class=\"line\">gcc -c main.cpp -o main.o</span><br><span class=\"line\">gcc linkage.o main.o -o main</span><br><span class=\"line\">./main</span><br></pre></td></tr></table></figure>\n<p>得到的输出是预期的值：12。</p>\n<p>将上述的linkage.c文件重命名为linkage.cpp，main.c重命名为main.cpp，执行下述语句，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ -c linkage.cpp -o linkage.o</span><br><span class=\"line\">g++ -c main.cpp -o main.o</span><br><span class=\"line\">g++ linkage.o main.o -o main</span><br><span class=\"line\">./main</span><br></pre></td></tr></table></figure>\n<p>得到的输出却是：0。</p>\n<p>回想一下在C语言里面使用全局变量的注意点，</p>\n<ol>\n<li>在一个头文件声明该变量，即上述代码的<code>extern const int counter;</code>，它的作用是告诉编译器，我有这么一个类型的变量存在；</li>\n<li>在一个C文件定义该变量，即上述代码的<code>const int counter = 12;</code>，它的作用是为该全局变量申请存储；</li>\n<li>在其他需要此全局变量的C文件，include步骤1提到的头文件，全局变量得以共享；</li>\n</ol>\n<p>对于C语言，const全局变量与非const变量一样，都是全局共享的，C++ Primer将此称为<strong>external linkage</strong>；<br>但对于C++，const全局变量确是local to file的（作用域仅限于文件内），问题就处在于<code>const int counter = 12;</code>这一行代码，在C++里这意味着定义了一个const int变量，但仅限于文件内部使用，C++ Primer将此称为<strong>internal linkage</strong>。</p>\n<p>那么，如何在C++共享const全局变量呢？方法很简单，将步骤2的定义代码修改为<code>extern const int counter = 12;</code>即可。</p>\n<h2 id=\"top-level-const和low-level-const\"><a href=\"#top-level-const和low-level-const\" class=\"headerlink\" title=\"top-level const和low-level const\"></a>top-level const和low-level const</h2><p>C++里面，将const variable称为<strong>top-level const</strong>，将pointer to const variable称为<strong>low-level const</strong>，而且还规定，</p>\n<ol>\n<li>const variable赋值给普通variable或pointer to const variable时，top-level const的const被忽略，等同于普通变量间赋值；</li>\n<li>pointer to const variable赋值给普通variable或const variable时，low-level const的const不能被忽略；</li>\n</ol>\n<p>有以下main.cpp文件，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> b = a; <span class=\"comment\">// const int --&gt; int, top to normal</span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> c = b; <span class=\"comment\">// int --&gt; const int, normal to top</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> ptr = &amp;a; <span class=\"comment\">// const int * --&gt; int * const, low to top</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> * ptr2 = &amp;a; <span class=\"comment\">// const int * --&gt; int *, low to normal</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> * ptr3 = ptr; <span class=\"comment\">// int * const --&gt; int *, top to normal</span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> * ptr4 = ptr; <span class=\"comment\">// int * const --&gt; const int *, top to low</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行<code>g++ main.c</code>，得到的输出如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main.cpp: In function ‘int main()’:</span><br><span class=\"line\">main.cpp:5:24: error: invalid conversion from ‘const int*’ to ‘int*’ [-fpermissive]</span><br><span class=\"line\">     int * const ptr = &amp;a; // const int * --&gt; int * const, low to top</span><br><span class=\"line\">                        ^</span><br><span class=\"line\">main.cpp:6:19: error: invalid conversion from ‘const int*’ to ‘int*’ [-fpermissive]</span><br><span class=\"line\">     int * ptr2 = &amp;a; // const int * --&gt; int *, low to normal</span><br><span class=\"line\">                   ^</span><br></pre></td></tr></table></figure>\n<p>这说明在C++里面，low-level const赋值或强转给其他类型时，const是不能被忽略的，否则会在编译时报错。</p>\n<p>将上述代码保存为main.c后执行<code>gcc main.c</code>，得到的输出如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main.c: In function ‘main’:</span><br><span class=\"line\">main.c:4:23: warning: initialization discards ‘const’ qualifier from pointer target type [enabled by default]</span><br><span class=\"line\">     int * const ptr = &amp;a; // const int * --&gt; int * const, low to top</span><br><span class=\"line\">                       ^</span><br><span class=\"line\">main.c:5:18: warning: initialization discards ‘const’ qualifier from pointer target type [enabled by default]</span><br><span class=\"line\">     int * ptr2 = &amp;a; // const int * --&gt; int *, low to normal</span><br><span class=\"line\">                  ^</span><br></pre></td></tr></table></figure>\n<p>这说明在C里面，并没有严格规定top-level const和low-level const，但是对于low-level const的情况，还是会有warning，因此必须小心使用，同时必须注意编译器的所有warning。</p>\n","site":{"data":{}},"excerpt":"<p>C/C++都有const关键字？它有什么用途以及用来干嘛呢？</p>","more":"<h2 id=\"const-variable\"><a href=\"#const-variable\" class=\"headerlink\" title=\"const variable\"></a>const variable</h2><p>const修饰variable，意味着<strong>该变量不可修改</strong>，即变量是readonly的，这一点C和C++相同。例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>; <span class=\"comment\">// 等价于：int const a = 0;</span></span><br><span class=\"line\">    a = <span class=\"number\">1</span>; <span class=\"comment\">// error：a是readonly的，不可修改</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>考虑到指针也是variable，上述特点对指针也适用，称为const pointer，const pointer的<strong>dereference（*号取值）不受影响</strong>。例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> * int_ptr;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>, b = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> int_ptr ip = &amp;a; <span class=\"comment\">// 等价于：int_ptr const ip = &amp;a;</span></span><br><span class=\"line\">    ip = &amp;b; <span class=\"comment\">// error：ip是readonly的，其值（标识地址）不可修改</span></span><br><span class=\"line\">    *ip = <span class=\"number\">2</span>; <span class=\"comment\">// 不影响指针的dereference</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>假如不想使用typedef的方式表示上述的const pointer，则必须写成如下形式：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> ptr = &amp;a;</span><br><span class=\"line\"><span class=\"keyword\">int</span> <span class=\"keyword\">const</span> * ptr = &amp;a; <span class=\"comment\">// error：这表示指向const int的指针</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> * ptr = &amp;a; <span class=\"comment\">// error：这表示指向const int的指针</span></span><br></pre></td></tr></table></figure>\n<p>const variable的特点如下：</p>\n<ol>\n<li>声明和定义必须在同一个地方（声明变量时实例化）；</li>\n<li>const variable不可修改；</li>\n<li>const和type类型可以互换（指针不使用typedef的方式定义时需要格外注意）；</li>\n</ol>\n<h2 id=\"pointer-to-const-variable\"><a href=\"#pointer-to-const-variable\" class=\"headerlink\" title=\"pointer to const variable\"></a>pointer to const variable</h2><p>指针指向const variable，意味着<strong>不能通过指针去修改指针指向的内存</strong>，即指针指向的内存是readonly的，但<strong>指针本身的值修改不受影响（即可以重新绑定地址）</strong>，这一点C和C++也相同，例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> int_cst_ptr; <span class=\"comment\">// const pointer</span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> <span class=\"keyword\">const</span> int_cst; <span class=\"comment\">// const int</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *b = &amp;a;</span><br><span class=\"line\">    int_cst_ptr *ptr1 = &amp;b;</span><br><span class=\"line\">    int_cst *ptr2 = &amp;a;</span><br><span class=\"line\">    *ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    *ptr2 = <span class=\"number\">1</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// 指针本身的值修改不受影响（即可以重新绑定地址）</span></span><br><span class=\"line\">    ptr2 = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>假设不使用typedef，上述例子需写成：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *b = &amp;a;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> *ptr1 = &amp;b; <span class=\"comment\">// 从右到左：ptr1 is a pointer to const pointer to int</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> <span class=\"keyword\">const</span> *ptr2 = &amp;a;</span><br><span class=\"line\">    *ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    *ptr2 = <span class=\"number\">1</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// 指针本身的值修改不受影响（即可以重新绑定地址）</span></span><br><span class=\"line\">    ptr2 = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>pointer to const variable的特点：</p>\n<ol>\n<li>指针指向内存不可修改；</li>\n<li>指针本身的值（代表的地址）可以修改；</li>\n</ol>\n<p>举一个复杂点的例子，即有指针又有数组的情况：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc,<span class=\"keyword\">char</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(; i&lt;argc; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"argv[%d] : %s\\n\"</span>, i, argv[i]);</span><br><span class=\"line\">        argv[i] = <span class=\"string\">\"a\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// char *const argv2[] = argv;</span></span><br><span class=\"line\">    <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv3[] = &#123;<span class=\"string\">\"a\"</span>, <span class=\"string\">\"b\"</span>&#125;;</span><br><span class=\"line\">    <span class=\"comment\">// argv3[0] = \"test\";</span></span><br><span class=\"line\">    <span class=\"keyword\">char</span> *<span class=\"keyword\">const</span> argv4[<span class=\"number\">2</span>];</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *str = argv4[<span class=\"number\">0</span>];</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"str: %s\\n\"</span>, str);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"strlen(str): %d\\n\"</span>, <span class=\"built_in\">strlen</span>(str));</span><br><span class=\"line\">    *str = <span class=\"string\">'a'</span>;</span><br><span class=\"line\">    *(str+<span class=\"number\">1</span>) = <span class=\"string\">'\\0'</span>;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"str: %s\\n\"</span>, str);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上述代码可正常编译，被注释掉的行是因为其会在编译时出错。在x86的Linux下运行得到的结果为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">argv[0] : ./a.out</span><br><span class=\"line\">str: ,ݳ▒</span><br><span class=\"line\">strlen(str): 4</span><br><span class=\"line\">str: a</span><br></pre></td></tr></table></figure>\n<p>而在x64的Linux下运行得到的结果为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">argv[0] : ./a.out</span><br><span class=\"line\">str: AWA▒▒AVI▒▒AUI▒▒ATL▒%h</span><br><span class=\"line\">strlen(str): 23</span><br><span class=\"line\">段错误</span><br></pre></td></tr></table></figure>\n<p>关于该代码的几点说明如下，</p>\n<ol>\n<li><code>char *const argv2[] = argv;</code>之所以被注释是因为不能够将一个数组赋值给另外一个数组；</li>\n<li><code>char *const argv3[] = {&quot;a&quot;, &quot;b&quot;};</code>定义并显示实例化了argv3，argv3是一个数组，它包含2个char * const（const pointer to char）元素，因此argv3[0]的指针值不可修改；</li>\n<li>在两个平台下运行结果不同说明若不显示实例化数组内容，数组的内容是不可预料的，对数组内容的修改结果也是不可预料的；</li>\n</ol>\n<h2 id=\"const-pointer-to-const-variable\"><a href=\"#const-pointer-to-const-variable\" class=\"headerlink\" title=\"const pointer to const variable\"></a>const pointer to const variable</h2><p>const pointer指向const variable，这意外着<strong>指针本身值（代表的地址）不可修改</strong>，同时<strong>指针指向的内存也不可修改</strong>，这点C和C++也相同。例子如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> int_cst_ptr; <span class=\"comment\">// const pointer</span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> <span class=\"keyword\">const</span> int_cst; <span class=\"comment\">// const int</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *b = &amp;a;</span><br><span class=\"line\">    int_cst_ptr * <span class=\"keyword\">const</span> ptr1 = &amp;b;</span><br><span class=\"line\">    int_cst * <span class=\"keyword\">const</span> ptr2 = &amp;a;</span><br><span class=\"line\">    *ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    *ptr2 = <span class=\"number\">1</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：const pointer，指针本身值不可修改</span></span><br><span class=\"line\">    ptr2 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：const pointer，指针本身值不可修改</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>假设不使用typedef，上述例子需写成：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> *b = &amp;a;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> * <span class=\"keyword\">const</span> ptr1 = &amp;b; <span class=\"comment\">// 这时候表达式越来越复杂</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> <span class=\"keyword\">const</span> * <span class=\"keyword\">const</span> ptr2 = &amp;a;</span><br><span class=\"line\">    *ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    *ptr2 = <span class=\"number\">1</span>; <span class=\"comment\">// error：pointer to const，指针指向内存readonly</span></span><br><span class=\"line\">    ptr1 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：const pointer，指针本身值不可修改</span></span><br><span class=\"line\">    ptr2 = <span class=\"literal\">NULL</span>; <span class=\"comment\">// error：const pointer，指针本身值不可修改</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>const pointer to const variable的特点：</p>\n<ol>\n<li>指针本身值（代表的地址）不可修改；</li>\n<li>指针指向的内存也不可修改；</li>\n</ol>\n<h2 id=\"linkage\"><a href=\"#linkage\" class=\"headerlink\" title=\"linkage\"></a>linkage</h2><p>有以下代码文件：</p>\n<p>头文件linkage.h，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> counter;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_counter</span><span class=\"params\">()</span></span>;</span><br></pre></td></tr></table></figure>\n<p>c文件linkage.c，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"stdio.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"linkage.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_counter</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"counter: %d\\n\"</span>, counter);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>c文件main.c，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"linkage.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> counter = <span class=\"number\">12</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc,<span class=\"keyword\">char</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\">    print_counter();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行下述语句，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -c linkage.cpp -o linkage.o</span><br><span class=\"line\">gcc -c main.cpp -o main.o</span><br><span class=\"line\">gcc linkage.o main.o -o main</span><br><span class=\"line\">./main</span><br></pre></td></tr></table></figure>\n<p>得到的输出是预期的值：12。</p>\n<p>将上述的linkage.c文件重命名为linkage.cpp，main.c重命名为main.cpp，执行下述语句，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ -c linkage.cpp -o linkage.o</span><br><span class=\"line\">g++ -c main.cpp -o main.o</span><br><span class=\"line\">g++ linkage.o main.o -o main</span><br><span class=\"line\">./main</span><br></pre></td></tr></table></figure>\n<p>得到的输出却是：0。</p>\n<p>回想一下在C语言里面使用全局变量的注意点，</p>\n<ol>\n<li>在一个头文件声明该变量，即上述代码的<code>extern const int counter;</code>，它的作用是告诉编译器，我有这么一个类型的变量存在；</li>\n<li>在一个C文件定义该变量，即上述代码的<code>const int counter = 12;</code>，它的作用是为该全局变量申请存储；</li>\n<li>在其他需要此全局变量的C文件，include步骤1提到的头文件，全局变量得以共享；</li>\n</ol>\n<p>对于C语言，const全局变量与非const变量一样，都是全局共享的，C++ Primer将此称为<strong>external linkage</strong>；<br>但对于C++，const全局变量确是local to file的（作用域仅限于文件内），问题就处在于<code>const int counter = 12;</code>这一行代码，在C++里这意味着定义了一个const int变量，但仅限于文件内部使用，C++ Primer将此称为<strong>internal linkage</strong>。</p>\n<p>那么，如何在C++共享const全局变量呢？方法很简单，将步骤2的定义代码修改为<code>extern const int counter = 12;</code>即可。</p>\n<h2 id=\"top-level-const和low-level-const\"><a href=\"#top-level-const和low-level-const\" class=\"headerlink\" title=\"top-level const和low-level const\"></a>top-level const和low-level const</h2><p>C++里面，将const variable称为<strong>top-level const</strong>，将pointer to const variable称为<strong>low-level const</strong>，而且还规定，</p>\n<ol>\n<li>const variable赋值给普通variable或pointer to const variable时，top-level const的const被忽略，等同于普通变量间赋值；</li>\n<li>pointer to const variable赋值给普通variable或const variable时，low-level const的const不能被忽略；</li>\n</ol>\n<p>有以下main.cpp文件，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> a = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> b = a; <span class=\"comment\">// const int --&gt; int, top to normal</span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> c = b; <span class=\"comment\">// int --&gt; const int, normal to top</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> ptr = &amp;a; <span class=\"comment\">// const int * --&gt; int * const, low to top</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> * ptr2 = &amp;a; <span class=\"comment\">// const int * --&gt; int *, low to normal</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> * ptr3 = ptr; <span class=\"comment\">// int * const --&gt; int *, top to normal</span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> * ptr4 = ptr; <span class=\"comment\">// int * const --&gt; const int *, top to low</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行<code>g++ main.c</code>，得到的输出如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main.cpp: In function ‘int main()’:</span><br><span class=\"line\">main.cpp:5:24: error: invalid conversion from ‘const int*’ to ‘int*’ [-fpermissive]</span><br><span class=\"line\">     int * const ptr = &amp;a; // const int * --&gt; int * const, low to top</span><br><span class=\"line\">                        ^</span><br><span class=\"line\">main.cpp:6:19: error: invalid conversion from ‘const int*’ to ‘int*’ [-fpermissive]</span><br><span class=\"line\">     int * ptr2 = &amp;a; // const int * --&gt; int *, low to normal</span><br><span class=\"line\">                   ^</span><br></pre></td></tr></table></figure>\n<p>这说明在C++里面，low-level const赋值或强转给其他类型时，const是不能被忽略的，否则会在编译时报错。</p>\n<p>将上述代码保存为main.c后执行<code>gcc main.c</code>，得到的输出如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main.c: In function ‘main’:</span><br><span class=\"line\">main.c:4:23: warning: initialization discards ‘const’ qualifier from pointer target type [enabled by default]</span><br><span class=\"line\">     int * const ptr = &amp;a; // const int * --&gt; int * const, low to top</span><br><span class=\"line\">                       ^</span><br><span class=\"line\">main.c:5:18: warning: initialization discards ‘const’ qualifier from pointer target type [enabled by default]</span><br><span class=\"line\">     int * ptr2 = &amp;a; // const int * --&gt; int *, low to normal</span><br><span class=\"line\">                  ^</span><br></pre></td></tr></table></figure>\n<p>这说明在C里面，并没有严格规定top-level const和low-level const，但是对于low-level const的情况，还是会有warning，因此必须小心使用，同时必须注意编译器的所有warning。</p>"},{"layout":"post","title":"使用ant自动生成WAR包需知","date":"2016-06-28T03:07:00.000Z","comments":1,"_content":"\n由于早期的eclipse web工程没有使用Maven管理，每次生成WAR包都得在IDE下执行编译、打包，觉得很繁琐，遂决定使用ant自动生成WAR包。记录注意点如下：\n\n<!--more-->\n\n- 下载、安装、配置[ant](http://ant.apache.org/bindownload.cgi)；\n- 使用IDE如eclipse自动生成工程的ant文件到工程根目录，取名为build.xml，在build.xml找到`<javac`开头的标签并配置上`encoding=\"UTF-8\"`（按你的实际编码设定，否则会出现编译问题），并新增`target`标签如下：\n```\n    <target name=\"war\">\n        <war destfile = \"releases/gx-desk.war\" webxml = \"WebContent/WEB-INF/web.xml\">\n           <fileset dir = \"WebContent\">\n              <include name = \"**/*\"/>\n           </fileset>\n           <classes dir=\"build/classes\"/>\n           <webinf dir=\"WebContent/WEB-INF/lib\"/>\n        </war>\n    </target>\n```\n- 写一个bash脚本自动化编译和打包；\n\n------\n\n附件1：bash脚本\n\n```bash\n#!/bin/sh\n\n## dependency : sencha cmd\n\n## 1. export build.xml, setup javac and war\n## 2. download ant\n## 3. add ant/bin to $PATH\n## 4. setup ANT_HOME\n\ncd /d/SVN/Workspace/gx-desk/\n\nif [ -d \"WebContent2\" ]; then\n    echo \"ERROR: WebContent2 exists, please check !\"\n    exit 0\nfi\n\ncd WebContent/\n\nsencha app build\n\nif [ $? -ne 0 ] ; then\n    echo \"ERROR: sencha build error !\"\n    exit 0\nelse\n    # frontend\n    cd ..\n    mv WebContent WebContent2 \n    mkdir WebContent\n    cp WebContent2/build/production/Desktop/* WebContent/ -rf\n    cp WebContent2/WEB-INF WebContent/ -rf\n    rm WebContent/WEB-INF/lib/* -rf\n\n    # backend\n    cd src/main/resources/\n    mv config.properties config.properties.bak\n    mv config.properties.hwcloud config.properties\n    mv spring/applicationContext.xml spring/applicationContext.xml.bak\n    mv spring/applicationContext.xml.hwcloud spring/applicationContext.xml\n    cd -\n\n    # ant\n    ant clean\n    ant\n    if [ $? -ne 0 ] ; then\n        echo \"ERROR: ant build error !\"\n    else\n        ant war\n    if [ $? -ne 0 ] ; then\n        echo \"ERROR: ant war error !\"\n    else\n       scp -v -P62627 releases/gx-desk.war gx@125.94.212.178:~/\n    fi\n    fi\n    # reverse\n    rm WebContent -rf\n    mv WebContent2 WebContent\n    cd src/main/resources/\n    mv config.properties config.properties.hwcloud\n    mv config.properties.bak config.properties\n    mv spring/applicationContext.xml spring/applicationContext.xml.hwcloud\n    mv spring/applicationContext.xml.bak spring/applicationContext.xml\n    \nfi\n\nexit 0\n\n```\n\n附件2：build.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!-- WARNING: Eclipse auto-generated file.\n              Any modifications will be overwritten.\n              To include a user specific buildfile here, simply create one in the same\n              directory with the processing instruction <?eclipse.ant.import?>\n              as the first entry and export the buildfile again. --><project basedir=\".\" default=\"build\" name=\"gx-desk\">\n    <property environment=\"env\"/>\n    <property name=\"ECLIPSE_HOME\" value=\"../../../Softwares/IDE/eclipse/\"/>\n    <property name=\"junit.output.dir\" value=\"junit\"/>\n    <property name=\"debuglevel\" value=\"source,lines,vars\"/>\n    <property name=\"target\" value=\"1.8\"/>\n    <property name=\"source\" value=\"1.8\"/>\n    <path id=\"Web App Libraries.libraryclasspath\"/>\n    <path id=\"EAR Libraries.libraryclasspath\"/>\n    <path id=\"Apache Tomcat v8.0 [Apache Tomcat v8.0 GX].libraryclasspath\">\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/annotations-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/antlr-2.7.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/aopalliance-1.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/asm-all-3.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/aspectjweaver-1.8.9.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/aspose-cells-7.7.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/bcprov-jdk16-146.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/c3p0-0.9.1.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/cas-client-core-3.4.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-ant.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-ha.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-storeconfig.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-tribes.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/cglib-2.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/com.springsource.org.codehaus.jackson-1.4.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-beanutils.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-codec-1.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-codec-1.7.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-collections-3.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-configuration-1.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-dbcp.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-digester-2.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-fileupload-1.2.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-io-2.0.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-lang-2.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-lang-2.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-logging-1.1.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-logging-1.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-math3-3.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-pool.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/dom4j-1.6.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/ecj-4.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/ehcache-core-2.6.7.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/el-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/ezmorph-1.0.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/groovy-all-1.8.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/gson-2.2.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/guava-12.0.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/guice-2.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hadoop-auth-2.2.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hadoop-common-2.2.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-client-0.98.3-hadoop2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-common-0.98.3-hadoop2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-protocol-0.98.3-hadoop2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hibernate-jpa-2.0-api-1.0.0.Final.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hibernate3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/htrace-core-2.04.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpclient-4.3.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpclient-cache-4.3.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpcore-4.3.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/iText-2.1.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/iTextAsian.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-annotations-2.7.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-core-2.7.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-core-asl-1.4.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-databind-2.7.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-mapper-asl-1.4.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasper-el.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasper.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-5.0.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-applet-5.0.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-fonts-5.0.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/javassist-3.9.0.GA.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/javax.ws.rs.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jcip-annotations-1.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jcommon-1.0.13.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jedis-2.6.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jfreechart-1.0.10.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/json-lib-2.2.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jsp-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jsr311-api-1.1.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jta-1.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jtransforms-2.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/junit-4.8.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jxl.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/log4j-over-slf4j-1.7.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/log4j.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/logback-classic-1.0.13.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/logback-core-1.0.13.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mail.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mina-core-2.0.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-3.0.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-ehcache-1.0.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-spring-1.0.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mysql-connector-java-5.1.17-bin.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/nekohtml-1.9.20.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/netty-3.6.6.Final.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/ojdbc5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/openid4java-nodeps-0.9.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/poi-3.9-20121203.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/protobuf-java-2.5.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/quartz-2.2.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/servlet-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/slf4j-api-1.6.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-aop-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-asm-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-aspects-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-beans-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-beans-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-support-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-core-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-core-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-expression-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-expression-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-instrument-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-instrument-tomcat-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-jdbc-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-jms-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-ldap-core-2.0.2.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-messaging-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-orm-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-oxm-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-acl-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-aspects-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-cas-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-config-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-core-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-ldap-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-openid-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-taglibs-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-web-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-test-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-tx-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-web-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-web-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-portlet-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-websocket-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-coyote.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-dbcp.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-es.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-fr.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-ja.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-jdbc.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-jni.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-spdy.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-util-scan.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-util.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-websocket.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/websocket-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/xercesImpl-2.10.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/xml-apis-1.4.01.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/xstream-1.4.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/zmq.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/zookeeper-3.4.6.jar\"/>\n    </path>\n    <path id=\"gx-desk.classpath\">\n        <pathelement location=\"build/classes\"/>\n        <path refid=\"Web App Libraries.libraryclasspath\"/>\n        <path refid=\"EAR Libraries.libraryclasspath\"/>\n        <path refid=\"Apache Tomcat v8.0 [Apache Tomcat v8.0 GX].libraryclasspath\"/>\n    </path>\n    <target name=\"init\">\n        <mkdir dir=\"build/classes\"/>\n        <copy includeemptydirs=\"false\" todir=\"build/classes\">\n            <fileset dir=\"src/main/java\">\n                <exclude name=\"**/*.java\"/>\n            </fileset>\n        </copy>\n        <copy includeemptydirs=\"false\" todir=\"build/classes\">\n            <fileset dir=\"src/main/resources\">\n                <exclude name=\"**/*.java\"/>\n            </fileset>\n        </copy>\n        <copy includeemptydirs=\"false\" todir=\"build/classes\">\n            <fileset dir=\"src/test/java\">\n                <exclude name=\"**/*.java\"/>\n            </fileset>\n        </copy>\n        <copy includeemptydirs=\"false\" todir=\"build/classes\">\n            <fileset dir=\"src/test/resources\">\n                <exclude name=\"**/*.java\"/>\n            </fileset>\n        </copy>\n    </target>\n    <target name=\"clean\">\n        <delete dir=\"build/classes\"/>\n    </target>\n    <target depends=\"clean\" name=\"cleanall\"/>\n    <target depends=\"build-subprojects,build-project\" name=\"build\"/>\n    <target name=\"build-subprojects\"/>\n    <target depends=\"init\" name=\"build-project\">\n        <echo message=\"${ant.project.name}: ${ant.file}\"/>\n        <javac encoding=\"UTF-8\" debug=\"true\" debuglevel=\"${debuglevel}\" destdir=\"build/classes\" includeantruntime=\"false\" source=\"${source}\" target=\"${target}\">\n            <src path=\"src/main/java\"/>\n            <src path=\"src/main/resources\"/>\n            <src path=\"src/test/java\"/>\n            <src path=\"src/test/resources\"/>\n            <classpath refid=\"gx-desk.classpath\"/>\n        </javac>\n    </target>\n    <target description=\"Build all projects which reference this project. Useful to propagate changes.\" name=\"build-refprojects\"/>\n    <target description=\"copy Eclipse compiler jars to ant lib directory\" name=\"init-eclipse-compiler\">\n        <copy todir=\"${ant.library.dir}\">\n            <fileset dir=\"${ECLIPSE_HOME}/plugins\" includes=\"org.eclipse.jdt.core_*.jar\"/>\n        </copy>\n        <unzip dest=\"${ant.library.dir}\">\n            <patternset includes=\"jdtCompilerAdapter.jar\"/>\n            <fileset dir=\"${ECLIPSE_HOME}/plugins\" includes=\"org.eclipse.jdt.core_*.jar\"/>\n        </unzip>\n    </target>\n    <target description=\"compile project with Eclipse compiler\" name=\"build-eclipse-compiler\">\n        <property name=\"build.compiler\" value=\"org.eclipse.jdt.core.JDTCompilerAdapter\"/>\n        <antcall target=\"build\"/>\n    </target>\n    <target name=\"war\">\n        <war destfile = \"releases/gx-desk.war\" webxml = \"WebContent/WEB-INF/web.xml\">\n           <fileset dir = \"WebContent\">\n              <include name = \"**/*\"/>\n           </fileset>\n           <classes dir=\"build/classes\"/>\n           <webinf dir=\"WebContent/WEB-INF/lib\"/>\n        </war>\n    </target>\n</project>\n```\n","source":"_posts/2016-06-28-ant-war-task.markdown","raw":"---\nlayout: post\ntitle: 使用ant自动生成WAR包需知\ndate: '2016-06-28 11:07'\ncomments: true\ncategories: ['工具篇']  \ntags: ['Java', 'Eclipse']\n---\n\n由于早期的eclipse web工程没有使用Maven管理，每次生成WAR包都得在IDE下执行编译、打包，觉得很繁琐，遂决定使用ant自动生成WAR包。记录注意点如下：\n\n<!--more-->\n\n- 下载、安装、配置[ant](http://ant.apache.org/bindownload.cgi)；\n- 使用IDE如eclipse自动生成工程的ant文件到工程根目录，取名为build.xml，在build.xml找到`<javac`开头的标签并配置上`encoding=\"UTF-8\"`（按你的实际编码设定，否则会出现编译问题），并新增`target`标签如下：\n```\n    <target name=\"war\">\n        <war destfile = \"releases/gx-desk.war\" webxml = \"WebContent/WEB-INF/web.xml\">\n           <fileset dir = \"WebContent\">\n              <include name = \"**/*\"/>\n           </fileset>\n           <classes dir=\"build/classes\"/>\n           <webinf dir=\"WebContent/WEB-INF/lib\"/>\n        </war>\n    </target>\n```\n- 写一个bash脚本自动化编译和打包；\n\n------\n\n附件1：bash脚本\n\n```bash\n#!/bin/sh\n\n## dependency : sencha cmd\n\n## 1. export build.xml, setup javac and war\n## 2. download ant\n## 3. add ant/bin to $PATH\n## 4. setup ANT_HOME\n\ncd /d/SVN/Workspace/gx-desk/\n\nif [ -d \"WebContent2\" ]; then\n    echo \"ERROR: WebContent2 exists, please check !\"\n    exit 0\nfi\n\ncd WebContent/\n\nsencha app build\n\nif [ $? -ne 0 ] ; then\n    echo \"ERROR: sencha build error !\"\n    exit 0\nelse\n    # frontend\n    cd ..\n    mv WebContent WebContent2 \n    mkdir WebContent\n    cp WebContent2/build/production/Desktop/* WebContent/ -rf\n    cp WebContent2/WEB-INF WebContent/ -rf\n    rm WebContent/WEB-INF/lib/* -rf\n\n    # backend\n    cd src/main/resources/\n    mv config.properties config.properties.bak\n    mv config.properties.hwcloud config.properties\n    mv spring/applicationContext.xml spring/applicationContext.xml.bak\n    mv spring/applicationContext.xml.hwcloud spring/applicationContext.xml\n    cd -\n\n    # ant\n    ant clean\n    ant\n    if [ $? -ne 0 ] ; then\n        echo \"ERROR: ant build error !\"\n    else\n        ant war\n    if [ $? -ne 0 ] ; then\n        echo \"ERROR: ant war error !\"\n    else\n       scp -v -P62627 releases/gx-desk.war gx@125.94.212.178:~/\n    fi\n    fi\n    # reverse\n    rm WebContent -rf\n    mv WebContent2 WebContent\n    cd src/main/resources/\n    mv config.properties config.properties.hwcloud\n    mv config.properties.bak config.properties\n    mv spring/applicationContext.xml spring/applicationContext.xml.hwcloud\n    mv spring/applicationContext.xml.bak spring/applicationContext.xml\n    \nfi\n\nexit 0\n\n```\n\n附件2：build.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!-- WARNING: Eclipse auto-generated file.\n              Any modifications will be overwritten.\n              To include a user specific buildfile here, simply create one in the same\n              directory with the processing instruction <?eclipse.ant.import?>\n              as the first entry and export the buildfile again. --><project basedir=\".\" default=\"build\" name=\"gx-desk\">\n    <property environment=\"env\"/>\n    <property name=\"ECLIPSE_HOME\" value=\"../../../Softwares/IDE/eclipse/\"/>\n    <property name=\"junit.output.dir\" value=\"junit\"/>\n    <property name=\"debuglevel\" value=\"source,lines,vars\"/>\n    <property name=\"target\" value=\"1.8\"/>\n    <property name=\"source\" value=\"1.8\"/>\n    <path id=\"Web App Libraries.libraryclasspath\"/>\n    <path id=\"EAR Libraries.libraryclasspath\"/>\n    <path id=\"Apache Tomcat v8.0 [Apache Tomcat v8.0 GX].libraryclasspath\">\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/annotations-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/antlr-2.7.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/aopalliance-1.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/asm-all-3.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/aspectjweaver-1.8.9.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/aspose-cells-7.7.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/bcprov-jdk16-146.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/c3p0-0.9.1.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/cas-client-core-3.4.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-ant.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-ha.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-storeconfig.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-tribes.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/cglib-2.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/com.springsource.org.codehaus.jackson-1.4.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-beanutils.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-codec-1.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-codec-1.7.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-collections-3.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-configuration-1.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-dbcp.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-digester-2.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-fileupload-1.2.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-io-2.0.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-lang-2.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-lang-2.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-logging-1.1.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-logging-1.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-math3-3.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-pool.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/dom4j-1.6.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/ecj-4.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/ehcache-core-2.6.7.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/el-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/ezmorph-1.0.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/groovy-all-1.8.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/gson-2.2.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/guava-12.0.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/guice-2.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hadoop-auth-2.2.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hadoop-common-2.2.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-client-0.98.3-hadoop2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-common-0.98.3-hadoop2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-protocol-0.98.3-hadoop2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hibernate-jpa-2.0-api-1.0.0.Final.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/hibernate3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/htrace-core-2.04.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpclient-4.3.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpclient-cache-4.3.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpcore-4.3.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/iText-2.1.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/iTextAsian.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-annotations-2.7.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-core-2.7.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-core-asl-1.4.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-databind-2.7.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-mapper-asl-1.4.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasper-el.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasper.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-5.0.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-applet-5.0.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-fonts-5.0.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/javassist-3.9.0.GA.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/javax.ws.rs.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jcip-annotations-1.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jcommon-1.0.13.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jedis-2.6.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jfreechart-1.0.10.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/json-lib-2.2.3.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jsp-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jsr311-api-1.1.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jta-1.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jtransforms-2.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/junit-4.8.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/jxl.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/log4j-over-slf4j-1.7.2.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/log4j.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/logback-classic-1.0.13.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/logback-core-1.0.13.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mail.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mina-core-2.0.4.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-3.0.5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-ehcache-1.0.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-spring-1.0.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/mysql-connector-java-5.1.17-bin.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/nekohtml-1.9.20.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/netty-3.6.6.Final.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/ojdbc5.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/openid4java-nodeps-0.9.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/poi-3.9-20121203.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/protobuf-java-2.5.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/quartz-2.2.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/servlet-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/slf4j-api-1.6.6.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-aop-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-asm-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-aspects-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-beans-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-beans-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-support-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-core-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-core-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-expression-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-expression-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-instrument-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-instrument-tomcat-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-jdbc-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-jms-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-ldap-core-2.0.2.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-messaging-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-orm-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-oxm-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-acl-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-aspects-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-cas-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-config-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-core-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-ldap-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-openid-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-taglibs-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-web-4.1.0.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-test-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-tx-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-web-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-web-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-3.2.0.M1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-portlet-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-websocket-4.3.1.RELEASE.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-coyote.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-dbcp.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-es.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-fr.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-ja.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-jdbc.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-jni.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-spdy.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-util-scan.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-util.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-websocket.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/websocket-api.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/xercesImpl-2.10.0.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/xml-apis-1.4.01.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/xstream-1.4.1.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/zmq.jar\"/>\n        <pathelement location=\"../../../Softwares/Apache/apache-tomcat-gx/lib/zookeeper-3.4.6.jar\"/>\n    </path>\n    <path id=\"gx-desk.classpath\">\n        <pathelement location=\"build/classes\"/>\n        <path refid=\"Web App Libraries.libraryclasspath\"/>\n        <path refid=\"EAR Libraries.libraryclasspath\"/>\n        <path refid=\"Apache Tomcat v8.0 [Apache Tomcat v8.0 GX].libraryclasspath\"/>\n    </path>\n    <target name=\"init\">\n        <mkdir dir=\"build/classes\"/>\n        <copy includeemptydirs=\"false\" todir=\"build/classes\">\n            <fileset dir=\"src/main/java\">\n                <exclude name=\"**/*.java\"/>\n            </fileset>\n        </copy>\n        <copy includeemptydirs=\"false\" todir=\"build/classes\">\n            <fileset dir=\"src/main/resources\">\n                <exclude name=\"**/*.java\"/>\n            </fileset>\n        </copy>\n        <copy includeemptydirs=\"false\" todir=\"build/classes\">\n            <fileset dir=\"src/test/java\">\n                <exclude name=\"**/*.java\"/>\n            </fileset>\n        </copy>\n        <copy includeemptydirs=\"false\" todir=\"build/classes\">\n            <fileset dir=\"src/test/resources\">\n                <exclude name=\"**/*.java\"/>\n            </fileset>\n        </copy>\n    </target>\n    <target name=\"clean\">\n        <delete dir=\"build/classes\"/>\n    </target>\n    <target depends=\"clean\" name=\"cleanall\"/>\n    <target depends=\"build-subprojects,build-project\" name=\"build\"/>\n    <target name=\"build-subprojects\"/>\n    <target depends=\"init\" name=\"build-project\">\n        <echo message=\"${ant.project.name}: ${ant.file}\"/>\n        <javac encoding=\"UTF-8\" debug=\"true\" debuglevel=\"${debuglevel}\" destdir=\"build/classes\" includeantruntime=\"false\" source=\"${source}\" target=\"${target}\">\n            <src path=\"src/main/java\"/>\n            <src path=\"src/main/resources\"/>\n            <src path=\"src/test/java\"/>\n            <src path=\"src/test/resources\"/>\n            <classpath refid=\"gx-desk.classpath\"/>\n        </javac>\n    </target>\n    <target description=\"Build all projects which reference this project. Useful to propagate changes.\" name=\"build-refprojects\"/>\n    <target description=\"copy Eclipse compiler jars to ant lib directory\" name=\"init-eclipse-compiler\">\n        <copy todir=\"${ant.library.dir}\">\n            <fileset dir=\"${ECLIPSE_HOME}/plugins\" includes=\"org.eclipse.jdt.core_*.jar\"/>\n        </copy>\n        <unzip dest=\"${ant.library.dir}\">\n            <patternset includes=\"jdtCompilerAdapter.jar\"/>\n            <fileset dir=\"${ECLIPSE_HOME}/plugins\" includes=\"org.eclipse.jdt.core_*.jar\"/>\n        </unzip>\n    </target>\n    <target description=\"compile project with Eclipse compiler\" name=\"build-eclipse-compiler\">\n        <property name=\"build.compiler\" value=\"org.eclipse.jdt.core.JDTCompilerAdapter\"/>\n        <antcall target=\"build\"/>\n    </target>\n    <target name=\"war\">\n        <war destfile = \"releases/gx-desk.war\" webxml = \"WebContent/WEB-INF/web.xml\">\n           <fileset dir = \"WebContent\">\n              <include name = \"**/*\"/>\n           </fileset>\n           <classes dir=\"build/classes\"/>\n           <webinf dir=\"WebContent/WEB-INF/lib\"/>\n        </war>\n    </target>\n</project>\n```\n","slug":"ant-war-task","published":1,"updated":"2022-08-09T15:02:00.615Z","photos":[],"link":"","_id":"cl6mbc1360018igu853srrix8","content":"<p>由于早期的eclipse web工程没有使用Maven管理，每次生成WAR包都得在IDE下执行编译、打包，觉得很繁琐，遂决定使用ant自动生成WAR包。记录注意点如下：</p>\n<a id=\"more\"></a>\n<ul>\n<li>下载、安装、配置<a href=\"http://ant.apache.org/bindownload.cgi\" target=\"_blank\" rel=\"noopener\">ant</a>；</li>\n<li><p>使用IDE如eclipse自动生成工程的ant文件到工程根目录，取名为build.xml，在build.xml找到<code>&lt;javac</code>开头的标签并配置上<code>encoding=&quot;UTF-8&quot;</code>（按你的实际编码设定，否则会出现编译问题），并新增<code>target</code>标签如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;target name=&quot;war&quot;&gt;</span><br><span class=\"line\">    &lt;war destfile = &quot;releases/gx-desk.war&quot; webxml = &quot;WebContent/WEB-INF/web.xml&quot;&gt;</span><br><span class=\"line\">       &lt;fileset dir = &quot;WebContent&quot;&gt;</span><br><span class=\"line\">          &lt;include name = &quot;**/*&quot;/&gt;</span><br><span class=\"line\">       &lt;/fileset&gt;</span><br><span class=\"line\">       &lt;classes dir=&quot;build/classes&quot;/&gt;</span><br><span class=\"line\">       &lt;webinf dir=&quot;WebContent/WEB-INF/lib&quot;/&gt;</span><br><span class=\"line\">    &lt;/war&gt;</span><br><span class=\"line\">&lt;/target&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>写一个bash脚本自动化编译和打包；</p>\n</li>\n</ul>\n<hr>\n<p>附件1：bash脚本</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## dependency : sencha cmd</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 1. export build.xml, setup javac and war</span></span><br><span class=\"line\"><span class=\"comment\">## 2. download ant</span></span><br><span class=\"line\"><span class=\"comment\">## 3. add ant/bin to $PATH</span></span><br><span class=\"line\"><span class=\"comment\">## 4. setup ANT_HOME</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /d/SVN/Workspace/gx-desk/</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ -d <span class=\"string\">\"WebContent2\"</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"ERROR: WebContent2 exists, please check !\"</span></span><br><span class=\"line\">    <span class=\"built_in\">exit</span> 0</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">cd</span> WebContent/</span><br><span class=\"line\"></span><br><span class=\"line\">sencha app build</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ $? -ne 0 ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"ERROR: sencha build error !\"</span></span><br><span class=\"line\">    <span class=\"built_in\">exit</span> 0</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"comment\"># frontend</span></span><br><span class=\"line\">    <span class=\"built_in\">cd</span> ..</span><br><span class=\"line\">    mv WebContent WebContent2 </span><br><span class=\"line\">    mkdir WebContent</span><br><span class=\"line\">    cp WebContent2/build/production/Desktop/* WebContent/ -rf</span><br><span class=\"line\">    cp WebContent2/WEB-INF WebContent/ -rf</span><br><span class=\"line\">    rm WebContent/WEB-INF/lib/* -rf</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># backend</span></span><br><span class=\"line\">    <span class=\"built_in\">cd</span> src/main/resources/</span><br><span class=\"line\">    mv config.properties config.properties.bak</span><br><span class=\"line\">    mv config.properties.hwcloud config.properties</span><br><span class=\"line\">    mv spring/applicationContext.xml spring/applicationContext.xml.bak</span><br><span class=\"line\">    mv spring/applicationContext.xml.hwcloud spring/applicationContext.xml</span><br><span class=\"line\">    <span class=\"built_in\">cd</span> -</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ant</span></span><br><span class=\"line\">    ant clean</span><br><span class=\"line\">    ant</span><br><span class=\"line\">    <span class=\"keyword\">if</span> [ $? -ne 0 ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"ERROR: ant build error !\"</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        ant war</span><br><span class=\"line\">    <span class=\"keyword\">if</span> [ $? -ne 0 ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"ERROR: ant war error !\"</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">       scp -v -P62627 releases/gx-desk.war gx@125.94.212.178:~/</span><br><span class=\"line\">    <span class=\"keyword\">fi</span></span><br><span class=\"line\">    <span class=\"keyword\">fi</span></span><br><span class=\"line\">    <span class=\"comment\"># reverse</span></span><br><span class=\"line\">    rm WebContent -rf</span><br><span class=\"line\">    mv WebContent2 WebContent</span><br><span class=\"line\">    <span class=\"built_in\">cd</span> src/main/resources/</span><br><span class=\"line\">    mv config.properties config.properties.hwcloud</span><br><span class=\"line\">    mv config.properties.bak config.properties</span><br><span class=\"line\">    mv spring/applicationContext.xml spring/applicationContext.xml.hwcloud</span><br><span class=\"line\">    mv spring/applicationContext.xml.bak spring/applicationContext.xml</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">exit</span> 0</span><br></pre></td></tr></table></figure>\n<p>附件2：build.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;</span><br><span class=\"line\"><span class=\"comment\">&lt;!-- WARNING: Eclipse auto-generated file.</span></span><br><span class=\"line\"><span class=\"comment\">              Any modifications will be overwritten.</span></span><br><span class=\"line\"><span class=\"comment\">              To include a user specific buildfile here, simply create one in the same</span></span><br><span class=\"line\"><span class=\"comment\">              directory with the processing instruction &lt;?eclipse.ant.import?&gt;</span></span><br><span class=\"line\"><span class=\"comment\">              as the first entry and export the buildfile again. --&gt;</span><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">basedir</span>=<span class=\"string\">\".\"</span> <span class=\"attr\">default</span>=<span class=\"string\">\"build\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"gx-desk\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">environment</span>=<span class=\"string\">\"env\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"ECLIPSE_HOME\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"../../../Softwares/IDE/eclipse/\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"junit.output.dir\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"junit\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"debuglevel\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"source,lines,vars\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"target\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"1.8\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"source\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"1.8\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">id</span>=<span class=\"string\">\"Web App Libraries.libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">id</span>=<span class=\"string\">\"EAR Libraries.libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">id</span>=<span class=\"string\">\"Apache Tomcat v8.0 [Apache Tomcat v8.0 GX].libraryclasspath\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/annotations-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/antlr-2.7.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/aopalliance-1.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/asm-all-3.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/aspectjweaver-1.8.9.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/aspose-cells-7.7.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/bcprov-jdk16-146.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/c3p0-0.9.1.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/cas-client-core-3.4.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-ant.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-ha.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-storeconfig.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-tribes.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/cglib-2.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/com.springsource.org.codehaus.jackson-1.4.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-beanutils.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-codec-1.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-codec-1.7.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-collections-3.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-configuration-1.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-dbcp.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-digester-2.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-fileupload-1.2.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-io-2.0.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-lang-2.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-lang-2.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-logging-1.1.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-logging-1.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-math3-3.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-pool.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/dom4j-1.6.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/ecj-4.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/ehcache-core-2.6.7.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/el-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/ezmorph-1.0.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/groovy-all-1.8.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/gson-2.2.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/guava-12.0.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/guice-2.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hadoop-auth-2.2.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hadoop-common-2.2.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-client-0.98.3-hadoop2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-common-0.98.3-hadoop2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-protocol-0.98.3-hadoop2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hibernate-jpa-2.0-api-1.0.0.Final.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hibernate3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/htrace-core-2.04.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpclient-4.3.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpclient-cache-4.3.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpcore-4.3.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/iText-2.1.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/iTextAsian.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-annotations-2.7.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-core-2.7.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-core-asl-1.4.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-databind-2.7.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-mapper-asl-1.4.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasper-el.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasper.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-5.0.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-applet-5.0.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-fonts-5.0.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/javassist-3.9.0.GA.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/javax.ws.rs.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jcip-annotations-1.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jcommon-1.0.13.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jedis-2.6.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jfreechart-1.0.10.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/json-lib-2.2.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jsp-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jsr311-api-1.1.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jta-1.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jtransforms-2.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/junit-4.8.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jxl.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/log4j-over-slf4j-1.7.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/log4j.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/logback-classic-1.0.13.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/logback-core-1.0.13.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mail.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mina-core-2.0.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-3.0.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-ehcache-1.0.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-spring-1.0.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mysql-connector-java-5.1.17-bin.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/nekohtml-1.9.20.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/netty-3.6.6.Final.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/ojdbc5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/openid4java-nodeps-0.9.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/poi-3.9-20121203.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/protobuf-java-2.5.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/quartz-2.2.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/servlet-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/slf4j-api-1.6.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-aop-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-asm-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-aspects-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-beans-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-beans-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-support-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-core-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-core-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-expression-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-expression-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-instrument-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-instrument-tomcat-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-jdbc-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-jms-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-ldap-core-2.0.2.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-messaging-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-orm-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-oxm-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-acl-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-aspects-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-cas-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-config-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-core-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-ldap-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-openid-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-taglibs-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-web-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-test-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-tx-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-web-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-web-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-portlet-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-websocket-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-coyote.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-dbcp.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-es.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-fr.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-ja.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-jdbc.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-jni.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-spdy.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-util-scan.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-util.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-websocket.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/websocket-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/xercesImpl-2.10.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/xml-apis-1.4.01.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/xstream-1.4.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/zmq.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/zookeeper-3.4.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">path</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">id</span>=<span class=\"string\">\"gx-desk.classpath\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"build/classes\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">refid</span>=<span class=\"string\">\"Web App Libraries.libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">refid</span>=<span class=\"string\">\"EAR Libraries.libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">refid</span>=<span class=\"string\">\"Apache Tomcat v8.0 [Apache Tomcat v8.0 GX].libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">path</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">name</span>=<span class=\"string\">\"init\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">mkdir</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"build/classes\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">includeemptydirs</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"build/classes\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"src/main/java\"</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span> <span class=\"attr\">name</span>=<span class=\"string\">\"**/*.java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">includeemptydirs</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"build/classes\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"src/main/resources\"</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span> <span class=\"attr\">name</span>=<span class=\"string\">\"**/*.java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">includeemptydirs</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"build/classes\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"src/test/java\"</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span> <span class=\"attr\">name</span>=<span class=\"string\">\"**/*.java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">includeemptydirs</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"build/classes\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"src/test/resources\"</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span> <span class=\"attr\">name</span>=<span class=\"string\">\"**/*.java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">name</span>=<span class=\"string\">\"clean\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">delete</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"build/classes\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">depends</span>=<span class=\"string\">\"clean\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"cleanall\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">depends</span>=<span class=\"string\">\"build-subprojects,build-project\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build-subprojects\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">depends</span>=<span class=\"string\">\"init\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build-project\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">echo</span> <span class=\"attr\">message</span>=<span class=\"string\">\"$&#123;ant.project.name&#125;: $&#123;ant.file&#125;\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">javac</span> <span class=\"attr\">encoding</span>=<span class=\"string\">\"UTF-8\"</span> <span class=\"attr\">debug</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">debuglevel</span>=<span class=\"string\">\"$&#123;debuglevel&#125;\"</span> <span class=\"attr\">destdir</span>=<span class=\"string\">\"build/classes\"</span> <span class=\"attr\">includeantruntime</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">source</span>=<span class=\"string\">\"$&#123;source&#125;\"</span> <span class=\"attr\">target</span>=<span class=\"string\">\"$&#123;target&#125;\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">src</span> <span class=\"attr\">path</span>=<span class=\"string\">\"src/main/java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">src</span> <span class=\"attr\">path</span>=<span class=\"string\">\"src/main/resources\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">src</span> <span class=\"attr\">path</span>=<span class=\"string\">\"src/test/java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">src</span> <span class=\"attr\">path</span>=<span class=\"string\">\"src/test/resources\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">classpath</span> <span class=\"attr\">refid</span>=<span class=\"string\">\"gx-desk.classpath\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">javac</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">description</span>=<span class=\"string\">\"Build all projects which reference this project. Useful to propagate changes.\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build-refprojects\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">description</span>=<span class=\"string\">\"copy Eclipse compiler jars to ant lib directory\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"init-eclipse-compiler\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"$&#123;ant.library.dir&#125;\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"$&#123;ECLIPSE_HOME&#125;/plugins\"</span> <span class=\"attr\">includes</span>=<span class=\"string\">\"org.eclipse.jdt.core_*.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">unzip</span> <span class=\"attr\">dest</span>=<span class=\"string\">\"$&#123;ant.library.dir&#125;\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">patternset</span> <span class=\"attr\">includes</span>=<span class=\"string\">\"jdtCompilerAdapter.jar\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"$&#123;ECLIPSE_HOME&#125;/plugins\"</span> <span class=\"attr\">includes</span>=<span class=\"string\">\"org.eclipse.jdt.core_*.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">unzip</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">description</span>=<span class=\"string\">\"compile project with Eclipse compiler\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build-eclipse-compiler\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build.compiler\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"org.eclipse.jdt.core.JDTCompilerAdapter\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">antcall</span> <span class=\"attr\">target</span>=<span class=\"string\">\"build\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">name</span>=<span class=\"string\">\"war\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">war</span> <span class=\"attr\">destfile</span> = <span class=\"string\">\"releases/gx-desk.war\"</span> <span class=\"attr\">webxml</span> = <span class=\"string\">\"WebContent/WEB-INF/web.xml\"</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span> = <span class=\"string\">\"WebContent\"</span>&gt;</span></span><br><span class=\"line\">              <span class=\"tag\">&lt;<span class=\"name\">include</span> <span class=\"attr\">name</span> = <span class=\"string\">\"**/*\"</span>/&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">classes</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"build/classes\"</span>/&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">webinf</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"WebContent/WEB-INF/lib\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">war</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>由于早期的eclipse web工程没有使用Maven管理，每次生成WAR包都得在IDE下执行编译、打包，觉得很繁琐，遂决定使用ant自动生成WAR包。记录注意点如下：</p>","more":"<ul>\n<li>下载、安装、配置<a href=\"http://ant.apache.org/bindownload.cgi\" target=\"_blank\" rel=\"noopener\">ant</a>；</li>\n<li><p>使用IDE如eclipse自动生成工程的ant文件到工程根目录，取名为build.xml，在build.xml找到<code>&lt;javac</code>开头的标签并配置上<code>encoding=&quot;UTF-8&quot;</code>（按你的实际编码设定，否则会出现编译问题），并新增<code>target</code>标签如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;target name=&quot;war&quot;&gt;</span><br><span class=\"line\">    &lt;war destfile = &quot;releases/gx-desk.war&quot; webxml = &quot;WebContent/WEB-INF/web.xml&quot;&gt;</span><br><span class=\"line\">       &lt;fileset dir = &quot;WebContent&quot;&gt;</span><br><span class=\"line\">          &lt;include name = &quot;**/*&quot;/&gt;</span><br><span class=\"line\">       &lt;/fileset&gt;</span><br><span class=\"line\">       &lt;classes dir=&quot;build/classes&quot;/&gt;</span><br><span class=\"line\">       &lt;webinf dir=&quot;WebContent/WEB-INF/lib&quot;/&gt;</span><br><span class=\"line\">    &lt;/war&gt;</span><br><span class=\"line\">&lt;/target&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>写一个bash脚本自动化编译和打包；</p>\n</li>\n</ul>\n<hr>\n<p>附件1：bash脚本</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## dependency : sencha cmd</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 1. export build.xml, setup javac and war</span></span><br><span class=\"line\"><span class=\"comment\">## 2. download ant</span></span><br><span class=\"line\"><span class=\"comment\">## 3. add ant/bin to $PATH</span></span><br><span class=\"line\"><span class=\"comment\">## 4. setup ANT_HOME</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /d/SVN/Workspace/gx-desk/</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ -d <span class=\"string\">\"WebContent2\"</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"ERROR: WebContent2 exists, please check !\"</span></span><br><span class=\"line\">    <span class=\"built_in\">exit</span> 0</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">cd</span> WebContent/</span><br><span class=\"line\"></span><br><span class=\"line\">sencha app build</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ $? -ne 0 ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"ERROR: sencha build error !\"</span></span><br><span class=\"line\">    <span class=\"built_in\">exit</span> 0</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"comment\"># frontend</span></span><br><span class=\"line\">    <span class=\"built_in\">cd</span> ..</span><br><span class=\"line\">    mv WebContent WebContent2 </span><br><span class=\"line\">    mkdir WebContent</span><br><span class=\"line\">    cp WebContent2/build/production/Desktop/* WebContent/ -rf</span><br><span class=\"line\">    cp WebContent2/WEB-INF WebContent/ -rf</span><br><span class=\"line\">    rm WebContent/WEB-INF/lib/* -rf</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># backend</span></span><br><span class=\"line\">    <span class=\"built_in\">cd</span> src/main/resources/</span><br><span class=\"line\">    mv config.properties config.properties.bak</span><br><span class=\"line\">    mv config.properties.hwcloud config.properties</span><br><span class=\"line\">    mv spring/applicationContext.xml spring/applicationContext.xml.bak</span><br><span class=\"line\">    mv spring/applicationContext.xml.hwcloud spring/applicationContext.xml</span><br><span class=\"line\">    <span class=\"built_in\">cd</span> -</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ant</span></span><br><span class=\"line\">    ant clean</span><br><span class=\"line\">    ant</span><br><span class=\"line\">    <span class=\"keyword\">if</span> [ $? -ne 0 ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"ERROR: ant build error !\"</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        ant war</span><br><span class=\"line\">    <span class=\"keyword\">if</span> [ $? -ne 0 ] ; <span class=\"keyword\">then</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"ERROR: ant war error !\"</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">       scp -v -P62627 releases/gx-desk.war gx@125.94.212.178:~/</span><br><span class=\"line\">    <span class=\"keyword\">fi</span></span><br><span class=\"line\">    <span class=\"keyword\">fi</span></span><br><span class=\"line\">    <span class=\"comment\"># reverse</span></span><br><span class=\"line\">    rm WebContent -rf</span><br><span class=\"line\">    mv WebContent2 WebContent</span><br><span class=\"line\">    <span class=\"built_in\">cd</span> src/main/resources/</span><br><span class=\"line\">    mv config.properties config.properties.hwcloud</span><br><span class=\"line\">    mv config.properties.bak config.properties</span><br><span class=\"line\">    mv spring/applicationContext.xml spring/applicationContext.xml.hwcloud</span><br><span class=\"line\">    mv spring/applicationContext.xml.bak spring/applicationContext.xml</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">exit</span> 0</span><br></pre></td></tr></table></figure>\n<p>附件2：build.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;</span><br><span class=\"line\"><span class=\"comment\">&lt;!-- WARNING: Eclipse auto-generated file.</span></span><br><span class=\"line\"><span class=\"comment\">              Any modifications will be overwritten.</span></span><br><span class=\"line\"><span class=\"comment\">              To include a user specific buildfile here, simply create one in the same</span></span><br><span class=\"line\"><span class=\"comment\">              directory with the processing instruction &lt;?eclipse.ant.import?&gt;</span></span><br><span class=\"line\"><span class=\"comment\">              as the first entry and export the buildfile again. --&gt;</span><span class=\"tag\">&lt;<span class=\"name\">project</span> <span class=\"attr\">basedir</span>=<span class=\"string\">\".\"</span> <span class=\"attr\">default</span>=<span class=\"string\">\"build\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"gx-desk\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">environment</span>=<span class=\"string\">\"env\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"ECLIPSE_HOME\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"../../../Softwares/IDE/eclipse/\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"junit.output.dir\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"junit\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"debuglevel\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"source,lines,vars\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"target\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"1.8\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"source\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"1.8\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">id</span>=<span class=\"string\">\"Web App Libraries.libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">id</span>=<span class=\"string\">\"EAR Libraries.libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">id</span>=<span class=\"string\">\"Apache Tomcat v8.0 [Apache Tomcat v8.0 GX].libraryclasspath\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/annotations-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/antlr-2.7.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/aopalliance-1.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/asm-all-3.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/aspectjweaver-1.8.9.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/aspose-cells-7.7.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/bcprov-jdk16-146.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/c3p0-0.9.1.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/cas-client-core-3.4.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-ant.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-ha.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-storeconfig.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina-tribes.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/catalina.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/cglib-2.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/com.springsource.org.codehaus.jackson-1.4.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-beanutils.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-codec-1.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-codec-1.7.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-collections-3.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-configuration-1.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-dbcp.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-digester-2.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-fileupload-1.2.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-io-2.0.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-lang-2.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-lang-2.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-logging-1.1.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-logging-1.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-math3-3.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/commons-pool.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/dom4j-1.6.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/ecj-4.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/ehcache-core-2.6.7.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/el-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/ezmorph-1.0.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/groovy-all-1.8.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/gson-2.2.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/guava-12.0.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/guice-2.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hadoop-auth-2.2.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hadoop-common-2.2.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-client-0.98.3-hadoop2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-common-0.98.3-hadoop2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hbase-protocol-0.98.3-hadoop2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hibernate-jpa-2.0-api-1.0.0.Final.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/hibernate3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/htrace-core-2.04.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpclient-4.3.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpclient-cache-4.3.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/httpcore-4.3.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/iText-2.1.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/iTextAsian.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-annotations-2.7.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-core-2.7.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-core-asl-1.4.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-databind-2.7.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jackson-mapper-asl-1.4.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasper-el.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasper.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-5.0.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-applet-5.0.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jasperreports-fonts-5.0.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/javassist-3.9.0.GA.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/javax.ws.rs.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jcip-annotations-1.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jcommon-1.0.13.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jedis-2.6.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jfreechart-1.0.10.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/json-lib-2.2.3.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jsp-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jsr311-api-1.1.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jta-1.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jtransforms-2.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/junit-4.8.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/jxl.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/log4j-over-slf4j-1.7.2.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/log4j.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/logback-classic-1.0.13.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/logback-core-1.0.13.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mail.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mina-core-2.0.4.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-3.0.5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-ehcache-1.0.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mybatis-spring-1.0.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/mysql-connector-java-5.1.17-bin.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/nekohtml-1.9.20.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/netty-3.6.6.Final.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/ojdbc5.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/openid4java-nodeps-0.9.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/poi-3.9-20121203.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/protobuf-java-2.5.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/quartz-2.2.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/servlet-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/slf4j-api-1.6.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-aop-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-asm-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-aspects-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-beans-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-beans-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-context-support-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-core-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-core-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-expression-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-expression-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-instrument-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-instrument-tomcat-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-jdbc-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-jms-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-ldap-core-2.0.2.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-messaging-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-orm-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-oxm-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-acl-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-aspects-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-cas-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-config-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-core-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-ldap-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-openid-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-taglibs-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-security-web-4.1.0.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-test-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-tx-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-web-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-web-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-3.2.0.M1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-webmvc-portlet-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/spring-websocket-4.3.1.RELEASE.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-coyote.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-dbcp.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-es.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-fr.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-i18n-ja.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-jdbc.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-jni.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-spdy.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-util-scan.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-util.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/tomcat-websocket.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/websocket-api.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/xercesImpl-2.10.0.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/xml-apis-1.4.01.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/xstream-1.4.1.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/zmq.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"../../../Softwares/Apache/apache-tomcat-gx/lib/zookeeper-3.4.6.jar\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">path</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">id</span>=<span class=\"string\">\"gx-desk.classpath\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">pathelement</span> <span class=\"attr\">location</span>=<span class=\"string\">\"build/classes\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">refid</span>=<span class=\"string\">\"Web App Libraries.libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">refid</span>=<span class=\"string\">\"EAR Libraries.libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">path</span> <span class=\"attr\">refid</span>=<span class=\"string\">\"Apache Tomcat v8.0 [Apache Tomcat v8.0 GX].libraryclasspath\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">path</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">name</span>=<span class=\"string\">\"init\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">mkdir</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"build/classes\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">includeemptydirs</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"build/classes\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"src/main/java\"</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span> <span class=\"attr\">name</span>=<span class=\"string\">\"**/*.java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">includeemptydirs</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"build/classes\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"src/main/resources\"</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span> <span class=\"attr\">name</span>=<span class=\"string\">\"**/*.java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">includeemptydirs</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"build/classes\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"src/test/java\"</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span> <span class=\"attr\">name</span>=<span class=\"string\">\"**/*.java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">includeemptydirs</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"build/classes\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"src/test/resources\"</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">exclude</span> <span class=\"attr\">name</span>=<span class=\"string\">\"**/*.java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">name</span>=<span class=\"string\">\"clean\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">delete</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"build/classes\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">depends</span>=<span class=\"string\">\"clean\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"cleanall\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">depends</span>=<span class=\"string\">\"build-subprojects,build-project\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build-subprojects\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">depends</span>=<span class=\"string\">\"init\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build-project\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">echo</span> <span class=\"attr\">message</span>=<span class=\"string\">\"$&#123;ant.project.name&#125;: $&#123;ant.file&#125;\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">javac</span> <span class=\"attr\">encoding</span>=<span class=\"string\">\"UTF-8\"</span> <span class=\"attr\">debug</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">debuglevel</span>=<span class=\"string\">\"$&#123;debuglevel&#125;\"</span> <span class=\"attr\">destdir</span>=<span class=\"string\">\"build/classes\"</span> <span class=\"attr\">includeantruntime</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">source</span>=<span class=\"string\">\"$&#123;source&#125;\"</span> <span class=\"attr\">target</span>=<span class=\"string\">\"$&#123;target&#125;\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">src</span> <span class=\"attr\">path</span>=<span class=\"string\">\"src/main/java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">src</span> <span class=\"attr\">path</span>=<span class=\"string\">\"src/main/resources\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">src</span> <span class=\"attr\">path</span>=<span class=\"string\">\"src/test/java\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">src</span> <span class=\"attr\">path</span>=<span class=\"string\">\"src/test/resources\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">classpath</span> <span class=\"attr\">refid</span>=<span class=\"string\">\"gx-desk.classpath\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">javac</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">description</span>=<span class=\"string\">\"Build all projects which reference this project. Useful to propagate changes.\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build-refprojects\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">description</span>=<span class=\"string\">\"copy Eclipse compiler jars to ant lib directory\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"init-eclipse-compiler\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"$&#123;ant.library.dir&#125;\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"$&#123;ECLIPSE_HOME&#125;/plugins\"</span> <span class=\"attr\">includes</span>=<span class=\"string\">\"org.eclipse.jdt.core_*.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">unzip</span> <span class=\"attr\">dest</span>=<span class=\"string\">\"$&#123;ant.library.dir&#125;\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">patternset</span> <span class=\"attr\">includes</span>=<span class=\"string\">\"jdtCompilerAdapter.jar\"</span>/&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"$&#123;ECLIPSE_HOME&#125;/plugins\"</span> <span class=\"attr\">includes</span>=<span class=\"string\">\"org.eclipse.jdt.core_*.jar\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">unzip</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">description</span>=<span class=\"string\">\"compile project with Eclipse compiler\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build-eclipse-compiler\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"build.compiler\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"org.eclipse.jdt.core.JDTCompilerAdapter\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">antcall</span> <span class=\"attr\">target</span>=<span class=\"string\">\"build\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">target</span> <span class=\"attr\">name</span>=<span class=\"string\">\"war\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">war</span> <span class=\"attr\">destfile</span> = <span class=\"string\">\"releases/gx-desk.war\"</span> <span class=\"attr\">webxml</span> = <span class=\"string\">\"WebContent/WEB-INF/web.xml\"</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span> = <span class=\"string\">\"WebContent\"</span>&gt;</span></span><br><span class=\"line\">              <span class=\"tag\">&lt;<span class=\"name\">include</span> <span class=\"attr\">name</span> = <span class=\"string\">\"**/*\"</span>/&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">classes</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"build/classes\"</span>/&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">webinf</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"WebContent/WEB-INF/lib\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">war</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">project</span>&gt;</span></span><br></pre></td></tr></table></figure>"},{"layout":"post","title":"使用C语言调用sendmail的一些注意点","date":"2016-08-13T00:46:00.000Z","comments":1,"_content":"\n本文简单介绍C语言调用sendmail遇到的一些问题。\n\n<!--more-->\n\n## sendmail原理\n\n先附上邮件发送的原理图如下，该图转自[基础邮件原理（MUA/MTA/MDA）](http://www.itye.org/archives/1304)，\n\n![mail](/images/pics/mail.jpg)\n\nsendmail作为MTA，在DNS定位到对方的MTA地址后，将邮件发送到对端MTA。\n\n## 使用sendmail注意\n\n笔者在Shell下调用sendmail的语法如下（当然，这不是唯一的调用方式，详细请`man sendmail`），\n\n```\nsendmail -f<sender> -vt receiver < mail.txt\n```\n\n其中，\n\n- `-f`指定发件人邮箱；\n- `receiver`指定收件人邮箱；\n- `-v`表示以调试输出的模式打印；\n- `-t`表示读取mail.txt里面的`To`和`Cc`等字段；\n\n举个实际的例子如下，\n\n```\nsendmail -fjayzee@jayzee.com -vt jayzee@qq.com < mail.txt\n```\n\nmail.txt的内容，\n\n```\nSuject: Hello\n\nWorld\n```\n\n但是，在执行上述语句前，你需要注意以下事项，\n\n- 你的发件邮箱不需要是真实邮箱，但必须符合`xxx@xxx.com`的格式，否则会被你的收件人的邮件服务器拒绝；\n- 将你的发件邮箱添加到收件邮箱的白名单，否则极有可能被当成垃圾邮件拦截；\n- 你的mail.txt的`Subject`表示标题，紧接着是一个空行和正文，建议加上该空行，因为笔者在debian wheezy上使用sendmail发邮件时没有空行会报错，但在ubuntu又不会；\n- 配置你的/etc/hosts如下，\n```\n127.0.0.1\tlocalhost\tjayzee.com\n```\n\n为什么hosts要如上配置呢？原因是在邮件发送失败时，sendmail会把邮件返回给sender，在此例子中即`jayzee@jayzee.com`，而由于配置了hosts，相当于收件人其实是`jayzee@127.0.0.1`，这就保证了在邮件发送失败时邮件会回送给本机的jayzee用户，然后便可在本机的`/var/mail/jayzee`回溯到发送失败的详细信息啦。\n\n关于为什么本机会收到邮件，stackoverflow上有一段很好的解释，\n> Just to offer some clarification, it's been the tradition for a long time for UNIX boxes to run a \"locally configured\" mailer daemon that ** doesn't route messages through the Internet, but only copies messages to other users spool directories ** (as @John T mentioned). It is real SMTP-compliant email, it's just not routed over the Internet because it doesn't need to be.\n\n## 使用C语言调用sendmail\n\n使用C语言调用sendmail，\n\n- 首先，准备好mail.txt；\n- 其次，如果你想在调用结束时读取到调用信息，可考虑使用管道，如`popen(...)`；否则，使用`system(...)`就足够了。\n\n## sendmail错误处理\n\n`sysexits.h`标识出了sendmail调用的返回值，但没有一个是标识邮件是否发送成功的。C编程时若要判断sendmail是否发送成功，只能在程序端对回显信息（使用`popen`才取得回显信息）进行分析。\n\n还有一个思路是，专门建一个用户用于发送邮件，且需要保证该用户发送邮件是同步的，这样通过检测`/var/mail/$USER`的文件状态变化（比如配置邮件发送失败才回送，这样该文件的最后修改时间就发生了变化）就能判断是否发送成功了，这里需要在调用sendmail时恰当配置其`-N`选项。\n\n> `-N dsn` Set delivery status notification conditions to dsn, which can be 'never' for no notifications or a comma separated list of the values 'failure' to be notified if  delivery  failed, 'delay' to be notified if delivery is delayed, and 'success' to be notified when the message is successfully delivered.\n\n至于这里为什吗不考虑邮件delay的情况，文章[Why Am I Getting a “Delivery Status Notification (Delay)” on an Email I Sent?](https://askleo.com/why_am_i_getting_a_delay_notification_on_an_email_i_sent-2/)给出解释如下，\n> Delivery Status Notification (Delay)\n> This is an automatically generated Delivery Status Notification.\n> THIS IS A WARNING MESSAGE ONLY.\n> **YOU DO NOT NEED TO RESEND YOUR MESSAGE**.\n> Delivery to the following recipients has been delayed.\n> \n> if you get this “Delivery Status Notification (Delay)” warning, there’s nothing you can really do, other than to **make sure you sent it to the correct address.**\n\n## 伪代码\n\n```c\n#include 相关头文件\n\nint main() {\n    if(网络在线) {\n        stat1=/var/mail/user最后修改时间\n        system(sendmail -N failure -fuser@user.com -vt 收件人邮箱 < mail.txt);\n        stat2=/var/mail/user最后修改时间\n        if(stat1 != stat2) {\n            发送失败\n            清空user@user.com的邮件队列避免重发\n        } else {\n            发送成功\n        }\n    } else {\n        发送失败\n    }\n    return 0;\n}\n```\n\n## 参考文献\n\n\n1. 360converter博客：[基础邮件原理（MUA/MTA/MDA）](http://www.itye.org/archives/1304)\n2. Ask Leo：[Why Am I Getting a “Delivery Status Notification (Delay)” on an Email I Sent?](https://askleo.com/why_am_i_getting_a_delay_notification_on_an_email_i_sent-2/)\n","source":"_posts/2016-08-13-c-sendmail.markdown","raw":"---\nlayout: post\ntitle: 使用C语言调用sendmail的一些注意点\ndate: '2016-08-13 08:46'\ncomments: true\ncategories: ['编程实践']\ntags: ['C/C++', 'Linux']\n---\n\n本文简单介绍C语言调用sendmail遇到的一些问题。\n\n<!--more-->\n\n## sendmail原理\n\n先附上邮件发送的原理图如下，该图转自[基础邮件原理（MUA/MTA/MDA）](http://www.itye.org/archives/1304)，\n\n![mail](/images/pics/mail.jpg)\n\nsendmail作为MTA，在DNS定位到对方的MTA地址后，将邮件发送到对端MTA。\n\n## 使用sendmail注意\n\n笔者在Shell下调用sendmail的语法如下（当然，这不是唯一的调用方式，详细请`man sendmail`），\n\n```\nsendmail -f<sender> -vt receiver < mail.txt\n```\n\n其中，\n\n- `-f`指定发件人邮箱；\n- `receiver`指定收件人邮箱；\n- `-v`表示以调试输出的模式打印；\n- `-t`表示读取mail.txt里面的`To`和`Cc`等字段；\n\n举个实际的例子如下，\n\n```\nsendmail -fjayzee@jayzee.com -vt jayzee@qq.com < mail.txt\n```\n\nmail.txt的内容，\n\n```\nSuject: Hello\n\nWorld\n```\n\n但是，在执行上述语句前，你需要注意以下事项，\n\n- 你的发件邮箱不需要是真实邮箱，但必须符合`xxx@xxx.com`的格式，否则会被你的收件人的邮件服务器拒绝；\n- 将你的发件邮箱添加到收件邮箱的白名单，否则极有可能被当成垃圾邮件拦截；\n- 你的mail.txt的`Subject`表示标题，紧接着是一个空行和正文，建议加上该空行，因为笔者在debian wheezy上使用sendmail发邮件时没有空行会报错，但在ubuntu又不会；\n- 配置你的/etc/hosts如下，\n```\n127.0.0.1\tlocalhost\tjayzee.com\n```\n\n为什么hosts要如上配置呢？原因是在邮件发送失败时，sendmail会把邮件返回给sender，在此例子中即`jayzee@jayzee.com`，而由于配置了hosts，相当于收件人其实是`jayzee@127.0.0.1`，这就保证了在邮件发送失败时邮件会回送给本机的jayzee用户，然后便可在本机的`/var/mail/jayzee`回溯到发送失败的详细信息啦。\n\n关于为什么本机会收到邮件，stackoverflow上有一段很好的解释，\n> Just to offer some clarification, it's been the tradition for a long time for UNIX boxes to run a \"locally configured\" mailer daemon that ** doesn't route messages through the Internet, but only copies messages to other users spool directories ** (as @John T mentioned). It is real SMTP-compliant email, it's just not routed over the Internet because it doesn't need to be.\n\n## 使用C语言调用sendmail\n\n使用C语言调用sendmail，\n\n- 首先，准备好mail.txt；\n- 其次，如果你想在调用结束时读取到调用信息，可考虑使用管道，如`popen(...)`；否则，使用`system(...)`就足够了。\n\n## sendmail错误处理\n\n`sysexits.h`标识出了sendmail调用的返回值，但没有一个是标识邮件是否发送成功的。C编程时若要判断sendmail是否发送成功，只能在程序端对回显信息（使用`popen`才取得回显信息）进行分析。\n\n还有一个思路是，专门建一个用户用于发送邮件，且需要保证该用户发送邮件是同步的，这样通过检测`/var/mail/$USER`的文件状态变化（比如配置邮件发送失败才回送，这样该文件的最后修改时间就发生了变化）就能判断是否发送成功了，这里需要在调用sendmail时恰当配置其`-N`选项。\n\n> `-N dsn` Set delivery status notification conditions to dsn, which can be 'never' for no notifications or a comma separated list of the values 'failure' to be notified if  delivery  failed, 'delay' to be notified if delivery is delayed, and 'success' to be notified when the message is successfully delivered.\n\n至于这里为什吗不考虑邮件delay的情况，文章[Why Am I Getting a “Delivery Status Notification (Delay)” on an Email I Sent?](https://askleo.com/why_am_i_getting_a_delay_notification_on_an_email_i_sent-2/)给出解释如下，\n> Delivery Status Notification (Delay)\n> This is an automatically generated Delivery Status Notification.\n> THIS IS A WARNING MESSAGE ONLY.\n> **YOU DO NOT NEED TO RESEND YOUR MESSAGE**.\n> Delivery to the following recipients has been delayed.\n> \n> if you get this “Delivery Status Notification (Delay)” warning, there’s nothing you can really do, other than to **make sure you sent it to the correct address.**\n\n## 伪代码\n\n```c\n#include 相关头文件\n\nint main() {\n    if(网络在线) {\n        stat1=/var/mail/user最后修改时间\n        system(sendmail -N failure -fuser@user.com -vt 收件人邮箱 < mail.txt);\n        stat2=/var/mail/user最后修改时间\n        if(stat1 != stat2) {\n            发送失败\n            清空user@user.com的邮件队列避免重发\n        } else {\n            发送成功\n        }\n    } else {\n        发送失败\n    }\n    return 0;\n}\n```\n\n## 参考文献\n\n\n1. 360converter博客：[基础邮件原理（MUA/MTA/MDA）](http://www.itye.org/archives/1304)\n2. Ask Leo：[Why Am I Getting a “Delivery Status Notification (Delay)” on an Email I Sent?](https://askleo.com/why_am_i_getting_a_delay_notification_on_an_email_i_sent-2/)\n","slug":"c-sendmail","published":1,"updated":"2022-08-09T15:02:00.624Z","photos":[],"link":"","_id":"cl6mbc138001bigu8j7txwago","content":"<p>本文简单介绍C语言调用sendmail遇到的一些问题。</p>\n<a id=\"more\"></a>\n<h2 id=\"sendmail原理\"><a href=\"#sendmail原理\" class=\"headerlink\" title=\"sendmail原理\"></a>sendmail原理</h2><p>先附上邮件发送的原理图如下，该图转自<a href=\"http://www.itye.org/archives/1304\" target=\"_blank\" rel=\"noopener\">基础邮件原理（MUA/MTA/MDA）</a>，</p>\n<p><img src=\"/images/pics/mail.jpg\" alt=\"mail\"></p>\n<p>sendmail作为MTA，在DNS定位到对方的MTA地址后，将邮件发送到对端MTA。</p>\n<h2 id=\"使用sendmail注意\"><a href=\"#使用sendmail注意\" class=\"headerlink\" title=\"使用sendmail注意\"></a>使用sendmail注意</h2><p>笔者在Shell下调用sendmail的语法如下（当然，这不是唯一的调用方式，详细请<code>man sendmail</code>），</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sendmail -f&lt;sender&gt; -vt receiver &lt; mail.txt</span><br></pre></td></tr></table></figure>\n<p>其中，</p>\n<ul>\n<li><code>-f</code>指定发件人邮箱；</li>\n<li><code>receiver</code>指定收件人邮箱；</li>\n<li><code>-v</code>表示以调试输出的模式打印；</li>\n<li><code>-t</code>表示读取mail.txt里面的<code>To</code>和<code>Cc</code>等字段；</li>\n</ul>\n<p>举个实际的例子如下，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sendmail -fjayzee@jayzee.com -vt jayzee@qq.com &lt; mail.txt</span><br></pre></td></tr></table></figure>\n<p>mail.txt的内容，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Suject: Hello</span><br><span class=\"line\"></span><br><span class=\"line\">World</span><br></pre></td></tr></table></figure>\n<p>但是，在执行上述语句前，你需要注意以下事项，</p>\n<ul>\n<li>你的发件邮箱不需要是真实邮箱，但必须符合<a href=\"mailto:`xxx@xxx.com\" target=\"_blank\" rel=\"noopener\">`xxx@xxx.com</a>`的格式，否则会被你的收件人的邮件服务器拒绝；</li>\n<li>将你的发件邮箱添加到收件邮箱的白名单，否则极有可能被当成垃圾邮件拦截；</li>\n<li>你的mail.txt的<code>Subject</code>表示标题，紧接着是一个空行和正文，建议加上该空行，因为笔者在debian wheezy上使用sendmail发邮件时没有空行会报错，但在ubuntu又不会；</li>\n<li>配置你的/etc/hosts如下，<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1\tlocalhost\tjayzee.com</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>为什么hosts要如上配置呢？原因是在邮件发送失败时，sendmail会把邮件返回给sender，在此例子中即<a href=\"mailto:`jayzee@jayzee.com\" target=\"_blank\" rel=\"noopener\">`jayzee@jayzee.com</a><code>，而由于配置了hosts，相当于收件人其实是</code><a href=\"mailto:jayzee@127.0.0.1\" target=\"_blank\" rel=\"noopener\">jayzee@127.0.0.1</a><code>，这就保证了在邮件发送失败时邮件会回送给本机的jayzee用户，然后便可在本机的</code>/var/mail/jayzee`回溯到发送失败的详细信息啦。</p>\n<p>关于为什么本机会收到邮件，stackoverflow上有一段很好的解释，</p>\n<blockquote>\n<p>Just to offer some clarification, it’s been the tradition for a long time for UNIX boxes to run a “locally configured” mailer daemon that <strong> doesn’t route messages through the Internet, but only copies messages to other users spool directories </strong> (as @John T mentioned). It is real SMTP-compliant email, it’s just not routed over the Internet because it doesn’t need to be.</p>\n</blockquote>\n<h2 id=\"使用C语言调用sendmail\"><a href=\"#使用C语言调用sendmail\" class=\"headerlink\" title=\"使用C语言调用sendmail\"></a>使用C语言调用sendmail</h2><p>使用C语言调用sendmail，</p>\n<ul>\n<li>首先，准备好mail.txt；</li>\n<li>其次，如果你想在调用结束时读取到调用信息，可考虑使用管道，如<code>popen(...)</code>；否则，使用<code>system(...)</code>就足够了。</li>\n</ul>\n<h2 id=\"sendmail错误处理\"><a href=\"#sendmail错误处理\" class=\"headerlink\" title=\"sendmail错误处理\"></a>sendmail错误处理</h2><p><code>sysexits.h</code>标识出了sendmail调用的返回值，但没有一个是标识邮件是否发送成功的。C编程时若要判断sendmail是否发送成功，只能在程序端对回显信息（使用<code>popen</code>才取得回显信息）进行分析。</p>\n<p>还有一个思路是，专门建一个用户用于发送邮件，且需要保证该用户发送邮件是同步的，这样通过检测<code>/var/mail/$USER</code>的文件状态变化（比如配置邮件发送失败才回送，这样该文件的最后修改时间就发生了变化）就能判断是否发送成功了，这里需要在调用sendmail时恰当配置其<code>-N</code>选项。</p>\n<blockquote>\n<p><code>-N dsn</code> Set delivery status notification conditions to dsn, which can be ‘never’ for no notifications or a comma separated list of the values ‘failure’ to be notified if  delivery  failed, ‘delay’ to be notified if delivery is delayed, and ‘success’ to be notified when the message is successfully delivered.</p>\n</blockquote>\n<p>至于这里为什吗不考虑邮件delay的情况，文章<a href=\"https://askleo.com/why_am_i_getting_a_delay_notification_on_an_email_i_sent-2/\" target=\"_blank\" rel=\"noopener\">Why Am I Getting a “Delivery Status Notification (Delay)” on an Email I Sent?</a>给出解释如下，</p>\n<blockquote>\n<p>Delivery Status Notification (Delay)<br>This is an automatically generated Delivery Status Notification.<br>THIS IS A WARNING MESSAGE ONLY.<br><strong>YOU DO NOT NEED TO RESEND YOUR MESSAGE</strong>.<br>Delivery to the following recipients has been delayed.</p>\n<p>if you get this “Delivery Status Notification (Delay)” warning, there’s nothing you can really do, other than to <strong>make sure you sent it to the correct address.</strong></p>\n</blockquote>\n<h2 id=\"伪代码\"><a href=\"#伪代码\" class=\"headerlink\" title=\"伪代码\"></a>伪代码</h2><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> 相关头文件</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(网络在线) &#123;</span><br><span class=\"line\">        stat1=/var/mail/user最后修改时间</span><br><span class=\"line\">        system(sendmail -N failure -fuser@user.com -vt 收件人邮箱 &lt; mail.txt);</span><br><span class=\"line\">        stat2=/var/mail/user最后修改时间</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(stat1 != stat2) &#123;</span><br><span class=\"line\">            发送失败</span><br><span class=\"line\">            清空user@user.com的邮件队列避免重发</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            发送成功</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        发送失败</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ol>\n<li>360converter博客：<a href=\"http://www.itye.org/archives/1304\" target=\"_blank\" rel=\"noopener\">基础邮件原理（MUA/MTA/MDA）</a></li>\n<li>Ask Leo：<a href=\"https://askleo.com/why_am_i_getting_a_delay_notification_on_an_email_i_sent-2/\" target=\"_blank\" rel=\"noopener\">Why Am I Getting a “Delivery Status Notification (Delay)” on an Email I Sent?</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>本文简单介绍C语言调用sendmail遇到的一些问题。</p>","more":"<h2 id=\"sendmail原理\"><a href=\"#sendmail原理\" class=\"headerlink\" title=\"sendmail原理\"></a>sendmail原理</h2><p>先附上邮件发送的原理图如下，该图转自<a href=\"http://www.itye.org/archives/1304\" target=\"_blank\" rel=\"noopener\">基础邮件原理（MUA/MTA/MDA）</a>，</p>\n<p><img src=\"/images/pics/mail.jpg\" alt=\"mail\"></p>\n<p>sendmail作为MTA，在DNS定位到对方的MTA地址后，将邮件发送到对端MTA。</p>\n<h2 id=\"使用sendmail注意\"><a href=\"#使用sendmail注意\" class=\"headerlink\" title=\"使用sendmail注意\"></a>使用sendmail注意</h2><p>笔者在Shell下调用sendmail的语法如下（当然，这不是唯一的调用方式，详细请<code>man sendmail</code>），</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sendmail -f&lt;sender&gt; -vt receiver &lt; mail.txt</span><br></pre></td></tr></table></figure>\n<p>其中，</p>\n<ul>\n<li><code>-f</code>指定发件人邮箱；</li>\n<li><code>receiver</code>指定收件人邮箱；</li>\n<li><code>-v</code>表示以调试输出的模式打印；</li>\n<li><code>-t</code>表示读取mail.txt里面的<code>To</code>和<code>Cc</code>等字段；</li>\n</ul>\n<p>举个实际的例子如下，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sendmail -fjayzee@jayzee.com -vt jayzee@qq.com &lt; mail.txt</span><br></pre></td></tr></table></figure>\n<p>mail.txt的内容，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Suject: Hello</span><br><span class=\"line\"></span><br><span class=\"line\">World</span><br></pre></td></tr></table></figure>\n<p>但是，在执行上述语句前，你需要注意以下事项，</p>\n<ul>\n<li>你的发件邮箱不需要是真实邮箱，但必须符合<a href=\"mailto:`xxx@xxx.com\" target=\"_blank\" rel=\"noopener\">`xxx@xxx.com</a>`的格式，否则会被你的收件人的邮件服务器拒绝；</li>\n<li>将你的发件邮箱添加到收件邮箱的白名单，否则极有可能被当成垃圾邮件拦截；</li>\n<li>你的mail.txt的<code>Subject</code>表示标题，紧接着是一个空行和正文，建议加上该空行，因为笔者在debian wheezy上使用sendmail发邮件时没有空行会报错，但在ubuntu又不会；</li>\n<li>配置你的/etc/hosts如下，<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1\tlocalhost\tjayzee.com</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>为什么hosts要如上配置呢？原因是在邮件发送失败时，sendmail会把邮件返回给sender，在此例子中即<a href=\"mailto:`jayzee@jayzee.com\" target=\"_blank\" rel=\"noopener\">`jayzee@jayzee.com</a><code>，而由于配置了hosts，相当于收件人其实是</code><a href=\"mailto:jayzee@127.0.0.1\" target=\"_blank\" rel=\"noopener\">jayzee@127.0.0.1</a><code>，这就保证了在邮件发送失败时邮件会回送给本机的jayzee用户，然后便可在本机的</code>/var/mail/jayzee`回溯到发送失败的详细信息啦。</p>\n<p>关于为什么本机会收到邮件，stackoverflow上有一段很好的解释，</p>\n<blockquote>\n<p>Just to offer some clarification, it’s been the tradition for a long time for UNIX boxes to run a “locally configured” mailer daemon that <strong> doesn’t route messages through the Internet, but only copies messages to other users spool directories </strong> (as @John T mentioned). It is real SMTP-compliant email, it’s just not routed over the Internet because it doesn’t need to be.</p>\n</blockquote>\n<h2 id=\"使用C语言调用sendmail\"><a href=\"#使用C语言调用sendmail\" class=\"headerlink\" title=\"使用C语言调用sendmail\"></a>使用C语言调用sendmail</h2><p>使用C语言调用sendmail，</p>\n<ul>\n<li>首先，准备好mail.txt；</li>\n<li>其次，如果你想在调用结束时读取到调用信息，可考虑使用管道，如<code>popen(...)</code>；否则，使用<code>system(...)</code>就足够了。</li>\n</ul>\n<h2 id=\"sendmail错误处理\"><a href=\"#sendmail错误处理\" class=\"headerlink\" title=\"sendmail错误处理\"></a>sendmail错误处理</h2><p><code>sysexits.h</code>标识出了sendmail调用的返回值，但没有一个是标识邮件是否发送成功的。C编程时若要判断sendmail是否发送成功，只能在程序端对回显信息（使用<code>popen</code>才取得回显信息）进行分析。</p>\n<p>还有一个思路是，专门建一个用户用于发送邮件，且需要保证该用户发送邮件是同步的，这样通过检测<code>/var/mail/$USER</code>的文件状态变化（比如配置邮件发送失败才回送，这样该文件的最后修改时间就发生了变化）就能判断是否发送成功了，这里需要在调用sendmail时恰当配置其<code>-N</code>选项。</p>\n<blockquote>\n<p><code>-N dsn</code> Set delivery status notification conditions to dsn, which can be ‘never’ for no notifications or a comma separated list of the values ‘failure’ to be notified if  delivery  failed, ‘delay’ to be notified if delivery is delayed, and ‘success’ to be notified when the message is successfully delivered.</p>\n</blockquote>\n<p>至于这里为什吗不考虑邮件delay的情况，文章<a href=\"https://askleo.com/why_am_i_getting_a_delay_notification_on_an_email_i_sent-2/\" target=\"_blank\" rel=\"noopener\">Why Am I Getting a “Delivery Status Notification (Delay)” on an Email I Sent?</a>给出解释如下，</p>\n<blockquote>\n<p>Delivery Status Notification (Delay)<br>This is an automatically generated Delivery Status Notification.<br>THIS IS A WARNING MESSAGE ONLY.<br><strong>YOU DO NOT NEED TO RESEND YOUR MESSAGE</strong>.<br>Delivery to the following recipients has been delayed.</p>\n<p>if you get this “Delivery Status Notification (Delay)” warning, there’s nothing you can really do, other than to <strong>make sure you sent it to the correct address.</strong></p>\n</blockquote>\n<h2 id=\"伪代码\"><a href=\"#伪代码\" class=\"headerlink\" title=\"伪代码\"></a>伪代码</h2><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> 相关头文件</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(网络在线) &#123;</span><br><span class=\"line\">        stat1=/var/mail/user最后修改时间</span><br><span class=\"line\">        system(sendmail -N failure -fuser@user.com -vt 收件人邮箱 &lt; mail.txt);</span><br><span class=\"line\">        stat2=/var/mail/user最后修改时间</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(stat1 != stat2) &#123;</span><br><span class=\"line\">            发送失败</span><br><span class=\"line\">            清空user@user.com的邮件队列避免重发</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            发送成功</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        发送失败</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ol>\n<li>360converter博客：<a href=\"http://www.itye.org/archives/1304\" target=\"_blank\" rel=\"noopener\">基础邮件原理（MUA/MTA/MDA）</a></li>\n<li>Ask Leo：<a href=\"https://askleo.com/why_am_i_getting_a_delay_notification_on_an_email_i_sent-2/\" target=\"_blank\" rel=\"noopener\">Why Am I Getting a “Delivery Status Notification (Delay)” on an Email I Sent?</a></li>\n</ol>"},{"layout":"post","title":"linux程序崩溃时无corefile","date":"2016-07-04T09:52:00.000Z","comments":1,"_content":"\n运行在beaglebone上的linux程序崩溃时（非daemon）没有生成corefile，解决思路如下：\n\n<!--more-->\n\n运行程序前设置`ulimit -c unlimited`（可配置在其start脚本）；\n\n若上述设置还不能解决问题，则\n1. 安装libc的调试包：`apt-get install libc6-dbg`；\n2. 使用gdb包裹你的程序（这时候不能是daemon了），命令如下：\n`gdb --batch -x your_gdbinit_file your_program`\n\n注1：libc6-dbg的作用如下，\n> libc6-dbg - Embedded GNU C Library: detached debugging symbols\n\n注2：`your_gdbinit_file`是gdbinit文件，用于指示gdb在batch模式下该执行何种指令，内容举例如下：\n\n```\nrun\nbt\ngenerate-core-file\nquit\n```\n\n其中`bt`用于输出错误堆栈，`generate-core-file`用于生成core文件（文件格式为core.pid）；\n","source":"_posts/2016-07-04-generate-core-file.markdown","raw":"---\nlayout: post\ntitle: linux程序崩溃时无corefile\ndate: '2016-07-04 17:52'\ncomments: true\ncategories: ['编程实践'] \ntags: ['Linux']\n---\n\n运行在beaglebone上的linux程序崩溃时（非daemon）没有生成corefile，解决思路如下：\n\n<!--more-->\n\n运行程序前设置`ulimit -c unlimited`（可配置在其start脚本）；\n\n若上述设置还不能解决问题，则\n1. 安装libc的调试包：`apt-get install libc6-dbg`；\n2. 使用gdb包裹你的程序（这时候不能是daemon了），命令如下：\n`gdb --batch -x your_gdbinit_file your_program`\n\n注1：libc6-dbg的作用如下，\n> libc6-dbg - Embedded GNU C Library: detached debugging symbols\n\n注2：`your_gdbinit_file`是gdbinit文件，用于指示gdb在batch模式下该执行何种指令，内容举例如下：\n\n```\nrun\nbt\ngenerate-core-file\nquit\n```\n\n其中`bt`用于输出错误堆栈，`generate-core-file`用于生成core文件（文件格式为core.pid）；\n","slug":"generate-core-file","published":1,"updated":"2022-08-09T15:02:00.620Z","photos":[],"link":"","_id":"cl6mbc13c001gigu8ru64jmav","content":"<p>运行在beaglebone上的linux程序崩溃时（非daemon）没有生成corefile，解决思路如下：</p>\n<a id=\"more\"></a>\n<p>运行程序前设置<code>ulimit -c unlimited</code>（可配置在其start脚本）；</p>\n<p>若上述设置还不能解决问题，则</p>\n<ol>\n<li>安装libc的调试包：<code>apt-get install libc6-dbg</code>；</li>\n<li>使用gdb包裹你的程序（这时候不能是daemon了），命令如下：<br><code>gdb --batch -x your_gdbinit_file your_program</code></li>\n</ol>\n<p>注1：libc6-dbg的作用如下，</p>\n<blockquote>\n<p>libc6-dbg - Embedded GNU C Library: detached debugging symbols</p>\n</blockquote>\n<p>注2：<code>your_gdbinit_file</code>是gdbinit文件，用于指示gdb在batch模式下该执行何种指令，内容举例如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">run</span><br><span class=\"line\">bt</span><br><span class=\"line\">generate-core-file</span><br><span class=\"line\">quit</span><br></pre></td></tr></table></figure>\n<p>其中<code>bt</code>用于输出错误堆栈，<code>generate-core-file</code>用于生成core文件（文件格式为core.pid）；</p>\n","site":{"data":{}},"excerpt":"<p>运行在beaglebone上的linux程序崩溃时（非daemon）没有生成corefile，解决思路如下：</p>","more":"<p>运行程序前设置<code>ulimit -c unlimited</code>（可配置在其start脚本）；</p>\n<p>若上述设置还不能解决问题，则</p>\n<ol>\n<li>安装libc的调试包：<code>apt-get install libc6-dbg</code>；</li>\n<li>使用gdb包裹你的程序（这时候不能是daemon了），命令如下：<br><code>gdb --batch -x your_gdbinit_file your_program</code></li>\n</ol>\n<p>注1：libc6-dbg的作用如下，</p>\n<blockquote>\n<p>libc6-dbg - Embedded GNU C Library: detached debugging symbols</p>\n</blockquote>\n<p>注2：<code>your_gdbinit_file</code>是gdbinit文件，用于指示gdb在batch模式下该执行何种指令，内容举例如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">run</span><br><span class=\"line\">bt</span><br><span class=\"line\">generate-core-file</span><br><span class=\"line\">quit</span><br></pre></td></tr></table></figure>\n<p>其中<code>bt</code>用于输出错误堆栈，<code>generate-core-file</code>用于生成core文件（文件格式为core.pid）；</p>"},{"layout":"post","title":"《UNP卷1》的一些问题","date":"2016-08-02T01:01:00.000Z","comments":1,"_content":"\n《Unix Network Programing》的一些问题。\n\n<!--more-->\n\n## Q&A\n\nQ: TIME_WAIT能否去除？能否简化？\n\nA: TIME_WAIT的原理图如下，\n\n![time_wait](/images/pics/time_wait.jpg)\n\n- 如果C端不维持TIME_WAIT状态，而是FIN_WAIT2后直接进入CLOSED状态，那么C端将响应RST分节，S端收到后将此分节解释成一个错误，因此若想实现正常关闭，此环节必不可少；\n- MSL是一个IP数据报能在互联网上存在的最长时间，而TIME_WAIT持续的时间是两个MSL，这实际上是对路由器异常的容错，防止程序收到脏数据；\n\n------\n\nQ: Linux下listen()的backlog的真实含义是什么？有何问题？\n\nA: [How TCP backlog works in Linux](http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html)给出的解释如下，\n\n> The behavior of the backlog argument on TCP sockets changed with Linux 2.2. Now it **specifies the queue length for completely established sockets waiting to be accepted**, instead of the number of incomplete connection requests. The maximum length of the queue for **incomplete sockets can be set using /proc/sys/net/ipv4/tcp_max_syn_backlog**.\n\n即backlog指示的是ESTABLISHED Queue的大小，而SYN RECV Queue的大小则需要在系统配置。\n\n## 参考文献\n\n1. veithen.github.io: [How TCP backlog works in Linux](http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html)","source":"_posts/2016-08-02-qa-of-unp.markdown","raw":"---\nlayout: post\ntitle: 《UNP卷1》的一些问题\ndate: '2016-08-02 09:01'\ncomments: true\ncategories: ['计算机网络']\ntags: ['C/C++', 'Linux', 'Network']\n---\n\n《Unix Network Programing》的一些问题。\n\n<!--more-->\n\n## Q&A\n\nQ: TIME_WAIT能否去除？能否简化？\n\nA: TIME_WAIT的原理图如下，\n\n![time_wait](/images/pics/time_wait.jpg)\n\n- 如果C端不维持TIME_WAIT状态，而是FIN_WAIT2后直接进入CLOSED状态，那么C端将响应RST分节，S端收到后将此分节解释成一个错误，因此若想实现正常关闭，此环节必不可少；\n- MSL是一个IP数据报能在互联网上存在的最长时间，而TIME_WAIT持续的时间是两个MSL，这实际上是对路由器异常的容错，防止程序收到脏数据；\n\n------\n\nQ: Linux下listen()的backlog的真实含义是什么？有何问题？\n\nA: [How TCP backlog works in Linux](http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html)给出的解释如下，\n\n> The behavior of the backlog argument on TCP sockets changed with Linux 2.2. Now it **specifies the queue length for completely established sockets waiting to be accepted**, instead of the number of incomplete connection requests. The maximum length of the queue for **incomplete sockets can be set using /proc/sys/net/ipv4/tcp_max_syn_backlog**.\n\n即backlog指示的是ESTABLISHED Queue的大小，而SYN RECV Queue的大小则需要在系统配置。\n\n## 参考文献\n\n1. veithen.github.io: [How TCP backlog works in Linux](http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html)","slug":"qa-of-unp","published":1,"updated":"2022-08-09T15:02:00.620Z","photos":[],"link":"","_id":"cl6mbc13e001jigu8bpsmot7n","content":"<p>《Unix Network Programing》的一些问题。</p>\n<a id=\"more\"></a>\n<h2 id=\"Q-amp-A\"><a href=\"#Q-amp-A\" class=\"headerlink\" title=\"Q&amp;A\"></a>Q&amp;A</h2><p>Q: TIME_WAIT能否去除？能否简化？</p>\n<p>A: TIME_WAIT的原理图如下，</p>\n<p><img src=\"/images/pics/time_wait.jpg\" alt=\"time_wait\"></p>\n<ul>\n<li>如果C端不维持TIME_WAIT状态，而是FIN_WAIT2后直接进入CLOSED状态，那么C端将响应RST分节，S端收到后将此分节解释成一个错误，因此若想实现正常关闭，此环节必不可少；</li>\n<li>MSL是一个IP数据报能在互联网上存在的最长时间，而TIME_WAIT持续的时间是两个MSL，这实际上是对路由器异常的容错，防止程序收到脏数据；</li>\n</ul>\n<hr>\n<p>Q: Linux下listen()的backlog的真实含义是什么？有何问题？</p>\n<p>A: <a href=\"http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html\" target=\"_blank\" rel=\"noopener\">How TCP backlog works in Linux</a>给出的解释如下，</p>\n<blockquote>\n<p>The behavior of the backlog argument on TCP sockets changed with Linux 2.2. Now it <strong>specifies the queue length for completely established sockets waiting to be accepted</strong>, instead of the number of incomplete connection requests. The maximum length of the queue for <strong>incomplete sockets can be set using /proc/sys/net/ipv4/tcp_max_syn_backlog</strong>.</p>\n</blockquote>\n<p>即backlog指示的是ESTABLISHED Queue的大小，而SYN RECV Queue的大小则需要在系统配置。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ol>\n<li>veithen.github.io: <a href=\"http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html\" target=\"_blank\" rel=\"noopener\">How TCP backlog works in Linux</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>《Unix Network Programing》的一些问题。</p>","more":"<h2 id=\"Q-amp-A\"><a href=\"#Q-amp-A\" class=\"headerlink\" title=\"Q&amp;A\"></a>Q&amp;A</h2><p>Q: TIME_WAIT能否去除？能否简化？</p>\n<p>A: TIME_WAIT的原理图如下，</p>\n<p><img src=\"/images/pics/time_wait.jpg\" alt=\"time_wait\"></p>\n<ul>\n<li>如果C端不维持TIME_WAIT状态，而是FIN_WAIT2后直接进入CLOSED状态，那么C端将响应RST分节，S端收到后将此分节解释成一个错误，因此若想实现正常关闭，此环节必不可少；</li>\n<li>MSL是一个IP数据报能在互联网上存在的最长时间，而TIME_WAIT持续的时间是两个MSL，这实际上是对路由器异常的容错，防止程序收到脏数据；</li>\n</ul>\n<hr>\n<p>Q: Linux下listen()的backlog的真实含义是什么？有何问题？</p>\n<p>A: <a href=\"http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html\" target=\"_blank\" rel=\"noopener\">How TCP backlog works in Linux</a>给出的解释如下，</p>\n<blockquote>\n<p>The behavior of the backlog argument on TCP sockets changed with Linux 2.2. Now it <strong>specifies the queue length for completely established sockets waiting to be accepted</strong>, instead of the number of incomplete connection requests. The maximum length of the queue for <strong>incomplete sockets can be set using /proc/sys/net/ipv4/tcp_max_syn_backlog</strong>.</p>\n</blockquote>\n<p>即backlog指示的是ESTABLISHED Queue的大小，而SYN RECV Queue的大小则需要在系统配置。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ol>\n<li>veithen.github.io: <a href=\"http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html\" target=\"_blank\" rel=\"noopener\">How TCP backlog works in Linux</a></li>\n</ol>"},{"title":"C语言指针与数组","date":"2017-05-04T09:09:07.000Z","comments":1,"_content":"\nC语言数组下标`[]`符号竟是个语法糖？\n\n<!--more-->\n\n```c\n#include <stdio.h>\n\nstruct node {\n    int a[100];\n    int b[100];\n};\n\nint main() {\n    struct node ins;\n    int i = 0;\n    for(; i<200; i++) {\n        ins.a[i] = 1;\n    }\n    return 0;\n}\n```\n\n问：上述程序在运行时是否会产生数组越限？\n\n答：不会。\n\n> 《C程序设计语言》（第2版·新版）P84写到：\n> 对数组元素a[i]的引用也可以写成*(a+i)这种形式，在计算数组元素a[i]的值时，C语言实际上先将其转换为*(a+i)的形式，然后再进行求值。\n\n如果你没注意到此特性，将有可能导致灾难。","source":"_posts/2017-05-04-puzzle-of-c-pointer.md","raw":"---\ntitle: C语言指针与数组\ndate: 2017-05-04 17:09:07\ncomments: true\ncategories: ['编程语言'] \ntags: ['C/C++']\n---\n\nC语言数组下标`[]`符号竟是个语法糖？\n\n<!--more-->\n\n```c\n#include <stdio.h>\n\nstruct node {\n    int a[100];\n    int b[100];\n};\n\nint main() {\n    struct node ins;\n    int i = 0;\n    for(; i<200; i++) {\n        ins.a[i] = 1;\n    }\n    return 0;\n}\n```\n\n问：上述程序在运行时是否会产生数组越限？\n\n答：不会。\n\n> 《C程序设计语言》（第2版·新版）P84写到：\n> 对数组元素a[i]的引用也可以写成*(a+i)这种形式，在计算数组元素a[i]的值时，C语言实际上先将其转换为*(a+i)的形式，然后再进行求值。\n\n如果你没注意到此特性，将有可能导致灾难。","slug":"puzzle-of-c-pointer","published":1,"updated":"2022-08-09T15:02:00.628Z","layout":"post","photos":[],"link":"","_id":"cl6mbc13f001nigu82z7yf3yd","content":"<p>C语言数组下标<code>[]</code>符号竟是个语法糖？</p>\n<a id=\"more\"></a>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">node</span> &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> a[<span class=\"number\">100</span>];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> b[<span class=\"number\">100</span>];</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">node</span> <span class=\"title\">ins</span>;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(; i&lt;<span class=\"number\">200</span>; i++) &#123;</span><br><span class=\"line\">        ins.a[i] = <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>问：上述程序在运行时是否会产生数组越限？</p>\n<p>答：不会。</p>\n<blockquote>\n<p>《C程序设计语言》（第2版·新版）P84写到：<br>对数组元素a[i]的引用也可以写成<em>(a+i)这种形式，在计算数组元素a[i]的值时，C语言实际上先将其转换为</em>(a+i)的形式，然后再进行求值。</p>\n</blockquote>\n<p>如果你没注意到此特性，将有可能导致灾难。</p>\n","site":{"data":{}},"excerpt":"<p>C语言数组下标<code>[]</code>符号竟是个语法糖？</p>","more":"<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">node</span> &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> a[<span class=\"number\">100</span>];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> b[<span class=\"number\">100</span>];</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">node</span> <span class=\"title\">ins</span>;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(; i&lt;<span class=\"number\">200</span>; i++) &#123;</span><br><span class=\"line\">        ins.a[i] = <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>问：上述程序在运行时是否会产生数组越限？</p>\n<p>答：不会。</p>\n<blockquote>\n<p>《C程序设计语言》（第2版·新版）P84写到：<br>对数组元素a[i]的引用也可以写成<em>(a+i)这种形式，在计算数组元素a[i]的值时，C语言实际上先将其转换为</em>(a+i)的形式，然后再进行求值。</p>\n</blockquote>\n<p>如果你没注意到此特性，将有可能导致灾难。</p>"},{"title":"关于C语言的fread函数","date":"2017-07-07T09:14:16.000Z","comments":1,"_content":"\n关于C函数fread的一道小小题目。\n\n<!--more-->\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n// text.txt的内容只有一行，该行的内容为一个数值：7\n\nint main() {\n    char *file = \"text.txt\";\n    FILE *fp = fopen(file, \"r\");\n    if(fp) {\n        char str[128];\n        int rc = fread(str, 5, 1, fp);\n        printf(\"size is : %d\\n\", rc);\n        if(rc) \n            printf(\"content is : %d\\n\", atoi(str));\n        fclose(fp);\n    }\n    return 0;\n}\n```\n\n你猜运行上面的结果会输出什么？答案是：\n> size is : 0\n\n但我期望的结果是：\n> size is : 2\n> content is : 7\n\n问题出在哪里？且看看fread的定义：\n> ```size_t fread(void *restrict ptr, size_t size, size_t nitems, FILE *restrict stream);```\n\n这里的`size`表示读取的步长大小（字节数），`nitems`为读取多少步，返回结果是实际读取了多少步。上面的代码问题在于，读取的步长大小为5字节，但文件内容并没有5个字节这么多，于是返回结果`rc`为0，自然得不到期望输出了。将上述代码的第11行修改如下即可：\n\n    int rc = fread(str, 1, 5, fp);\n\n即步长为1，预期可以读到5步，实际上只读了两步就结束了（其中一个字节为换行符），因为遇到了文件结束符。","source":"_posts/2017-07-07-sth-about-fread.md","raw":"---\ntitle: 关于C语言的fread函数\ndate: 2017-07-07 17:14:16\ntags: ['C/C++']\ncomments: true\ncategories: ['编程语言']\n---\n\n关于C函数fread的一道小小题目。\n\n<!--more-->\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n// text.txt的内容只有一行，该行的内容为一个数值：7\n\nint main() {\n    char *file = \"text.txt\";\n    FILE *fp = fopen(file, \"r\");\n    if(fp) {\n        char str[128];\n        int rc = fread(str, 5, 1, fp);\n        printf(\"size is : %d\\n\", rc);\n        if(rc) \n            printf(\"content is : %d\\n\", atoi(str));\n        fclose(fp);\n    }\n    return 0;\n}\n```\n\n你猜运行上面的结果会输出什么？答案是：\n> size is : 0\n\n但我期望的结果是：\n> size is : 2\n> content is : 7\n\n问题出在哪里？且看看fread的定义：\n> ```size_t fread(void *restrict ptr, size_t size, size_t nitems, FILE *restrict stream);```\n\n这里的`size`表示读取的步长大小（字节数），`nitems`为读取多少步，返回结果是实际读取了多少步。上面的代码问题在于，读取的步长大小为5字节，但文件内容并没有5个字节这么多，于是返回结果`rc`为0，自然得不到期望输出了。将上述代码的第11行修改如下即可：\n\n    int rc = fread(str, 1, 5, fp);\n\n即步长为1，预期可以读到5步，实际上只读了两步就结束了（其中一个字节为换行符），因为遇到了文件结束符。","slug":"sth-about-fread","published":1,"updated":"2022-08-09T15:02:00.631Z","layout":"post","photos":[],"link":"","_id":"cl6mbc13h001rigu8n29rgkoq","content":"<p>关于C函数fread的一道小小题目。</p>\n<a id=\"more\"></a>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// text.txt的内容只有一行，该行的内容为一个数值：7</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *file = <span class=\"string\">\"text.txt\"</span>;</span><br><span class=\"line\">    FILE *fp = fopen(file, <span class=\"string\">\"r\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(fp) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">char</span> str[<span class=\"number\">128</span>];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rc = fread(str, <span class=\"number\">5</span>, <span class=\"number\">1</span>, fp);</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"size is : %d\\n\"</span>, rc);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rc) </span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"content is : %d\\n\"</span>, atoi(str));</span><br><span class=\"line\">        fclose(fp);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>你猜运行上面的结果会输出什么？答案是：</p>\n<blockquote>\n<p>size is : 0</p>\n</blockquote>\n<p>但我期望的结果是：</p>\n<blockquote>\n<p>size is : 2<br>content is : 7</p>\n</blockquote>\n<p>问题出在哪里？且看看fread的定义：</p>\n<blockquote>\n<p><code>size_t fread(void *restrict ptr, size_t size, size_t nitems, FILE *restrict stream);</code></p>\n</blockquote>\n<p>这里的<code>size</code>表示读取的步长大小（字节数），<code>nitems</code>为读取多少步，返回结果是实际读取了多少步。上面的代码问题在于，读取的步长大小为5字节，但文件内容并没有5个字节这么多，于是返回结果<code>rc</code>为0，自然得不到期望输出了。将上述代码的第11行修改如下即可：</p>\n<pre><code>int rc = fread(str, 1, 5, fp);\n</code></pre><p>即步长为1，预期可以读到5步，实际上只读了两步就结束了（其中一个字节为换行符），因为遇到了文件结束符。</p>\n","site":{"data":{}},"excerpt":"<p>关于C函数fread的一道小小题目。</p>","more":"<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// text.txt的内容只有一行，该行的内容为一个数值：7</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> *file = <span class=\"string\">\"text.txt\"</span>;</span><br><span class=\"line\">    FILE *fp = fopen(file, <span class=\"string\">\"r\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(fp) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">char</span> str[<span class=\"number\">128</span>];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rc = fread(str, <span class=\"number\">5</span>, <span class=\"number\">1</span>, fp);</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"size is : %d\\n\"</span>, rc);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rc) </span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"content is : %d\\n\"</span>, atoi(str));</span><br><span class=\"line\">        fclose(fp);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>你猜运行上面的结果会输出什么？答案是：</p>\n<blockquote>\n<p>size is : 0</p>\n</blockquote>\n<p>但我期望的结果是：</p>\n<blockquote>\n<p>size is : 2<br>content is : 7</p>\n</blockquote>\n<p>问题出在哪里？且看看fread的定义：</p>\n<blockquote>\n<p><code>size_t fread(void *restrict ptr, size_t size, size_t nitems, FILE *restrict stream);</code></p>\n</blockquote>\n<p>这里的<code>size</code>表示读取的步长大小（字节数），<code>nitems</code>为读取多少步，返回结果是实际读取了多少步。上面的代码问题在于，读取的步长大小为5字节，但文件内容并没有5个字节这么多，于是返回结果<code>rc</code>为0，自然得不到期望输出了。将上述代码的第11行修改如下即可：</p>\n<pre><code>int rc = fread(str, 1, 5, fp);\n</code></pre><p>即步长为1，预期可以读到5步，实际上只读了两步就结束了（其中一个字节为换行符），因为遇到了文件结束符。</p>"},{"title":"在Beaglebone Black/bbblack上使用i2c读取rx8025硬件时钟","date":"2017-04-20T10:42:49.000Z","comments":1,"_content":"\n简绍如何在Beaglebone Black/bbblack上使用i2c设置和读取外置的rx8025硬件时钟。\n\n<!--more-->\n\n## 如何使用\n\n注意，\n\n- 目前仅支持rx8025t和rx8025sa；\n- 目前仅支持i2c1（P9_17和P9_18，默认未启用）；\n\n```bash\ngit clone https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025.git\ncd beaglebone_black_bbblack_rx8025\ngcc rtc-8025.c -o rtc-8025\n## set bbblack os time to rx8025\n./rtc-8025 set\n## get rx8025time and set to os\n./rtc-8025 get\n```\n\n## 原理简介\n\n### beaglebone的准备\n\n1. 搭配好rx8025外电路，笔者选用的是i2c1口；\n2. 参考[BeagleBone Black I2C References][1]设置i2c1（即bash下执行`echo BB-I2C1 > /sys/devices/bone_capemgr.9/slots`）\n\n通过文章可知rx8025芯片的默认slave address是0x32，在代码[rtc-8025.c](https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/rtc-8025.c)可见。\n\n### i2c-dev\n\n笔者使用i2c-dev工具操作i2c设备与rx8025芯片进行通信。关于i2c-dev的详细实现见[i2c-dev-interface][2]的**Implementation details**章节。简要描述下：操作i2c设备的驱动由内核负责，通过上文的设置将i2c设备映射为一个系统文件，就能在用户空间下对i2c设备进行读写编程，实质是内核操作i2c设备的系统调用，SCL和SDL的控制完全由内核驱动接管。\n\n### rx8025t和rx8025sa的差别\n\nrx8025t的说明书见[rx8025_cn](https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/rx8025_cn.pdf)，rx8025sa的说明书见[RX8025SA](https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/RX8025SA.pdf)。下面从编程的角度列举其不同点，\n\n- **EEPROM**：rx8025t的寄存器为EEPROM，这意味着每次读写rx8025t后，其PC指针将增加1，越限时回到0，rx8025sa则不是；\n- **read操作结果不同**：rx8025sa在使用`read`函数读取时，属于情况`Read method from address Fh, with no specified start address for read opreation`（说明书第26页），因此`read`函数返回结果的第一个字节其实是0x0F寄存器的内容，而rx8025t的第一个字节是秒寄存器；\n- **未就绪位不同**：未就绪位为1表征芯片处于初始化状态或需要程序初始化芯片，此状态下寄存器的内容无意义，rx8025t的未就绪位为VLF，而rx8025sa为PON；\n- **小时表示不同**：rx8025t默认使用24小时制，rx8025sa支持12/24小时制；\n- **写操作的不同**：根据说明书时序图章节，rx8025t通过`write`函数写的第一个字节是寄存器的开始地址，而rx8025sa则是寄存器的开始地址加上传输模式。\n\n### TODO\n\n为什么读取rx8025t时，通过`read`函数读取到的第一个字节是秒寄存器，从时序图的角度如何解释？\n\n## reference\n\n1. [BeagleBone Black I2C References][1]\n2. [i2c-dev-interface][2]\n\n[1]: https://datko.net/2013/11/03/bbb_i2c/\n[2]: https://www.kernel.org/doc/Documentation/i2c/dev-interface","source":"_posts/2017-04-20-rx-8025.md","raw":"---\ntitle: 在Beaglebone Black/bbblack上使用i2c读取rx8025硬件时钟\ndate: 2017-04-20 18:42:49\ncomments: true\ncategories: ['编程实践'] \ntags: ['Beaglebone']\n---\n\n简绍如何在Beaglebone Black/bbblack上使用i2c设置和读取外置的rx8025硬件时钟。\n\n<!--more-->\n\n## 如何使用\n\n注意，\n\n- 目前仅支持rx8025t和rx8025sa；\n- 目前仅支持i2c1（P9_17和P9_18，默认未启用）；\n\n```bash\ngit clone https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025.git\ncd beaglebone_black_bbblack_rx8025\ngcc rtc-8025.c -o rtc-8025\n## set bbblack os time to rx8025\n./rtc-8025 set\n## get rx8025time and set to os\n./rtc-8025 get\n```\n\n## 原理简介\n\n### beaglebone的准备\n\n1. 搭配好rx8025外电路，笔者选用的是i2c1口；\n2. 参考[BeagleBone Black I2C References][1]设置i2c1（即bash下执行`echo BB-I2C1 > /sys/devices/bone_capemgr.9/slots`）\n\n通过文章可知rx8025芯片的默认slave address是0x32，在代码[rtc-8025.c](https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/rtc-8025.c)可见。\n\n### i2c-dev\n\n笔者使用i2c-dev工具操作i2c设备与rx8025芯片进行通信。关于i2c-dev的详细实现见[i2c-dev-interface][2]的**Implementation details**章节。简要描述下：操作i2c设备的驱动由内核负责，通过上文的设置将i2c设备映射为一个系统文件，就能在用户空间下对i2c设备进行读写编程，实质是内核操作i2c设备的系统调用，SCL和SDL的控制完全由内核驱动接管。\n\n### rx8025t和rx8025sa的差别\n\nrx8025t的说明书见[rx8025_cn](https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/rx8025_cn.pdf)，rx8025sa的说明书见[RX8025SA](https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/RX8025SA.pdf)。下面从编程的角度列举其不同点，\n\n- **EEPROM**：rx8025t的寄存器为EEPROM，这意味着每次读写rx8025t后，其PC指针将增加1，越限时回到0，rx8025sa则不是；\n- **read操作结果不同**：rx8025sa在使用`read`函数读取时，属于情况`Read method from address Fh, with no specified start address for read opreation`（说明书第26页），因此`read`函数返回结果的第一个字节其实是0x0F寄存器的内容，而rx8025t的第一个字节是秒寄存器；\n- **未就绪位不同**：未就绪位为1表征芯片处于初始化状态或需要程序初始化芯片，此状态下寄存器的内容无意义，rx8025t的未就绪位为VLF，而rx8025sa为PON；\n- **小时表示不同**：rx8025t默认使用24小时制，rx8025sa支持12/24小时制；\n- **写操作的不同**：根据说明书时序图章节，rx8025t通过`write`函数写的第一个字节是寄存器的开始地址，而rx8025sa则是寄存器的开始地址加上传输模式。\n\n### TODO\n\n为什么读取rx8025t时，通过`read`函数读取到的第一个字节是秒寄存器，从时序图的角度如何解释？\n\n## reference\n\n1. [BeagleBone Black I2C References][1]\n2. [i2c-dev-interface][2]\n\n[1]: https://datko.net/2013/11/03/bbb_i2c/\n[2]: https://www.kernel.org/doc/Documentation/i2c/dev-interface","slug":"rx-8025","published":1,"updated":"2022-08-09T15:02:00.627Z","layout":"post","photos":[],"link":"","_id":"cl6mbc13j001uigu8pbclxga8","content":"<p>简绍如何在Beaglebone Black/bbblack上使用i2c设置和读取外置的rx8025硬件时钟。</p>\n<a id=\"more\"></a>\n<h2 id=\"如何使用\"><a href=\"#如何使用\" class=\"headerlink\" title=\"如何使用\"></a>如何使用</h2><p>注意，</p>\n<ul>\n<li>目前仅支持rx8025t和rx8025sa；</li>\n<li>目前仅支持i2c1（P9_17和P9_18，默认未启用）；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025.git</span><br><span class=\"line\"><span class=\"built_in\">cd</span> beaglebone_black_bbblack_rx8025</span><br><span class=\"line\">gcc rtc-8025.c -o rtc-8025</span><br><span class=\"line\"><span class=\"comment\">## set bbblack os time to rx8025</span></span><br><span class=\"line\">./rtc-8025 <span class=\"built_in\">set</span></span><br><span class=\"line\"><span class=\"comment\">## get rx8025time and set to os</span></span><br><span class=\"line\">./rtc-8025 get</span><br></pre></td></tr></table></figure>\n<h2 id=\"原理简介\"><a href=\"#原理简介\" class=\"headerlink\" title=\"原理简介\"></a>原理简介</h2><h3 id=\"beaglebone的准备\"><a href=\"#beaglebone的准备\" class=\"headerlink\" title=\"beaglebone的准备\"></a>beaglebone的准备</h3><ol>\n<li>搭配好rx8025外电路，笔者选用的是i2c1口；</li>\n<li>参考<a href=\"https://datko.net/2013/11/03/bbb_i2c/\" target=\"_blank\" rel=\"noopener\">BeagleBone Black I2C References</a>设置i2c1（即bash下执行<code>echo BB-I2C1 &gt; /sys/devices/bone_capemgr.9/slots</code>）</li>\n</ol>\n<p>通过文章可知rx8025芯片的默认slave address是0x32，在代码<a href=\"https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/rtc-8025.c\" target=\"_blank\" rel=\"noopener\">rtc-8025.c</a>可见。</p>\n<h3 id=\"i2c-dev\"><a href=\"#i2c-dev\" class=\"headerlink\" title=\"i2c-dev\"></a>i2c-dev</h3><p>笔者使用i2c-dev工具操作i2c设备与rx8025芯片进行通信。关于i2c-dev的详细实现见<a href=\"https://www.kernel.org/doc/Documentation/i2c/dev-interface\" target=\"_blank\" rel=\"noopener\">i2c-dev-interface</a>的<strong>Implementation details</strong>章节。简要描述下：操作i2c设备的驱动由内核负责，通过上文的设置将i2c设备映射为一个系统文件，就能在用户空间下对i2c设备进行读写编程，实质是内核操作i2c设备的系统调用，SCL和SDL的控制完全由内核驱动接管。</p>\n<h3 id=\"rx8025t和rx8025sa的差别\"><a href=\"#rx8025t和rx8025sa的差别\" class=\"headerlink\" title=\"rx8025t和rx8025sa的差别\"></a>rx8025t和rx8025sa的差别</h3><p>rx8025t的说明书见<a href=\"https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/rx8025_cn.pdf\" target=\"_blank\" rel=\"noopener\">rx8025_cn</a>，rx8025sa的说明书见<a href=\"https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/RX8025SA.pdf\" target=\"_blank\" rel=\"noopener\">RX8025SA</a>。下面从编程的角度列举其不同点，</p>\n<ul>\n<li><strong>EEPROM</strong>：rx8025t的寄存器为EEPROM，这意味着每次读写rx8025t后，其PC指针将增加1，越限时回到0，rx8025sa则不是；</li>\n<li><strong>read操作结果不同</strong>：rx8025sa在使用<code>read</code>函数读取时，属于情况<code>Read method from address Fh, with no specified start address for read opreation</code>（说明书第26页），因此<code>read</code>函数返回结果的第一个字节其实是0x0F寄存器的内容，而rx8025t的第一个字节是秒寄存器；</li>\n<li><strong>未就绪位不同</strong>：未就绪位为1表征芯片处于初始化状态或需要程序初始化芯片，此状态下寄存器的内容无意义，rx8025t的未就绪位为VLF，而rx8025sa为PON；</li>\n<li><strong>小时表示不同</strong>：rx8025t默认使用24小时制，rx8025sa支持12/24小时制；</li>\n<li><strong>写操作的不同</strong>：根据说明书时序图章节，rx8025t通过<code>write</code>函数写的第一个字节是寄存器的开始地址，而rx8025sa则是寄存器的开始地址加上传输模式。</li>\n</ul>\n<h3 id=\"TODO\"><a href=\"#TODO\" class=\"headerlink\" title=\"TODO\"></a>TODO</h3><p>为什么读取rx8025t时，通过<code>read</code>函数读取到的第一个字节是秒寄存器，从时序图的角度如何解释？</p>\n<h2 id=\"reference\"><a href=\"#reference\" class=\"headerlink\" title=\"reference\"></a>reference</h2><ol>\n<li><a href=\"https://datko.net/2013/11/03/bbb_i2c/\" target=\"_blank\" rel=\"noopener\">BeagleBone Black I2C References</a></li>\n<li><a href=\"https://www.kernel.org/doc/Documentation/i2c/dev-interface\" target=\"_blank\" rel=\"noopener\">i2c-dev-interface</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>简绍如何在Beaglebone Black/bbblack上使用i2c设置和读取外置的rx8025硬件时钟。</p>","more":"<h2 id=\"如何使用\"><a href=\"#如何使用\" class=\"headerlink\" title=\"如何使用\"></a>如何使用</h2><p>注意，</p>\n<ul>\n<li>目前仅支持rx8025t和rx8025sa；</li>\n<li>目前仅支持i2c1（P9_17和P9_18，默认未启用）；</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025.git</span><br><span class=\"line\"><span class=\"built_in\">cd</span> beaglebone_black_bbblack_rx8025</span><br><span class=\"line\">gcc rtc-8025.c -o rtc-8025</span><br><span class=\"line\"><span class=\"comment\">## set bbblack os time to rx8025</span></span><br><span class=\"line\">./rtc-8025 <span class=\"built_in\">set</span></span><br><span class=\"line\"><span class=\"comment\">## get rx8025time and set to os</span></span><br><span class=\"line\">./rtc-8025 get</span><br></pre></td></tr></table></figure>\n<h2 id=\"原理简介\"><a href=\"#原理简介\" class=\"headerlink\" title=\"原理简介\"></a>原理简介</h2><h3 id=\"beaglebone的准备\"><a href=\"#beaglebone的准备\" class=\"headerlink\" title=\"beaglebone的准备\"></a>beaglebone的准备</h3><ol>\n<li>搭配好rx8025外电路，笔者选用的是i2c1口；</li>\n<li>参考<a href=\"https://datko.net/2013/11/03/bbb_i2c/\" target=\"_blank\" rel=\"noopener\">BeagleBone Black I2C References</a>设置i2c1（即bash下执行<code>echo BB-I2C1 &gt; /sys/devices/bone_capemgr.9/slots</code>）</li>\n</ol>\n<p>通过文章可知rx8025芯片的默认slave address是0x32，在代码<a href=\"https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/rtc-8025.c\" target=\"_blank\" rel=\"noopener\">rtc-8025.c</a>可见。</p>\n<h3 id=\"i2c-dev\"><a href=\"#i2c-dev\" class=\"headerlink\" title=\"i2c-dev\"></a>i2c-dev</h3><p>笔者使用i2c-dev工具操作i2c设备与rx8025芯片进行通信。关于i2c-dev的详细实现见<a href=\"https://www.kernel.org/doc/Documentation/i2c/dev-interface\" target=\"_blank\" rel=\"noopener\">i2c-dev-interface</a>的<strong>Implementation details</strong>章节。简要描述下：操作i2c设备的驱动由内核负责，通过上文的设置将i2c设备映射为一个系统文件，就能在用户空间下对i2c设备进行读写编程，实质是内核操作i2c设备的系统调用，SCL和SDL的控制完全由内核驱动接管。</p>\n<h3 id=\"rx8025t和rx8025sa的差别\"><a href=\"#rx8025t和rx8025sa的差别\" class=\"headerlink\" title=\"rx8025t和rx8025sa的差别\"></a>rx8025t和rx8025sa的差别</h3><p>rx8025t的说明书见<a href=\"https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/rx8025_cn.pdf\" target=\"_blank\" rel=\"noopener\">rx8025_cn</a>，rx8025sa的说明书见<a href=\"https://github.com/zhangjunjia/beaglebone_black_bbblack_rx8025/blob/master/RX8025SA.pdf\" target=\"_blank\" rel=\"noopener\">RX8025SA</a>。下面从编程的角度列举其不同点，</p>\n<ul>\n<li><strong>EEPROM</strong>：rx8025t的寄存器为EEPROM，这意味着每次读写rx8025t后，其PC指针将增加1，越限时回到0，rx8025sa则不是；</li>\n<li><strong>read操作结果不同</strong>：rx8025sa在使用<code>read</code>函数读取时，属于情况<code>Read method from address Fh, with no specified start address for read opreation</code>（说明书第26页），因此<code>read</code>函数返回结果的第一个字节其实是0x0F寄存器的内容，而rx8025t的第一个字节是秒寄存器；</li>\n<li><strong>未就绪位不同</strong>：未就绪位为1表征芯片处于初始化状态或需要程序初始化芯片，此状态下寄存器的内容无意义，rx8025t的未就绪位为VLF，而rx8025sa为PON；</li>\n<li><strong>小时表示不同</strong>：rx8025t默认使用24小时制，rx8025sa支持12/24小时制；</li>\n<li><strong>写操作的不同</strong>：根据说明书时序图章节，rx8025t通过<code>write</code>函数写的第一个字节是寄存器的开始地址，而rx8025sa则是寄存器的开始地址加上传输模式。</li>\n</ul>\n<h3 id=\"TODO\"><a href=\"#TODO\" class=\"headerlink\" title=\"TODO\"></a>TODO</h3><p>为什么读取rx8025t时，通过<code>read</code>函数读取到的第一个字节是秒寄存器，从时序图的角度如何解释？</p>\n<h2 id=\"reference\"><a href=\"#reference\" class=\"headerlink\" title=\"reference\"></a>reference</h2><ol>\n<li><a href=\"https://datko.net/2013/11/03/bbb_i2c/\" target=\"_blank\" rel=\"noopener\">BeagleBone Black I2C References</a></li>\n<li><a href=\"https://www.kernel.org/doc/Documentation/i2c/dev-interface\" target=\"_blank\" rel=\"noopener\">i2c-dev-interface</a></li>\n</ol>"},{"title":"最优生产计划","date":"2017-05-09T09:25:16.000Z","comments":1,"_content":"\n## 目标\n\n已知各类生产产品的生产时间及负荷曲线（负荷曲线对时间的积分即电量），输入「目标生产计划」，计算后输出「最优生产计划」，使得按该计划进行生产成本最优。\n\n<!--more-->\n\n目标生产计划的构成为，\n\n- 计划开始时间\n- 计划结束时间\n- 生产哪些产品，如：A20件，B30件，C20件，D100件\n\n最优生产计划的构成为，\n\n- t1：开始生产产品P1\n- t2：开始生产产品P2\n- t3：开始生产产品P3\n- ……\n\n## 如何求解\n\n> 成本 = 峰期电费单价 * 峰期电量 + 平期电费单价 * 平期电量 + 谷期电费单价 * 谷期电量\n> \n> 注：这里的峰平谷指的是一天的不同时段，高峰期和低谷期的电费单价是不一样的。\n\n最优生产计划即成本最小的生产计划，安排生产计划需要考虑的约束有，\n\n`各产品生产时间+换料时间+下班/休息时间 <= (计划结束时间 - 计划开始时间)` \n\n这个问题实质是一个动态规划问题，\n\n1. 将「下班/休息时间」从计划时间挖去，得「N段」可用的时间槽；\n2. 将生产的总件数看成「M张」选票，投给上述的「N段」时间槽（候选人），假设共有「X种」投票结果；\n3. 对计划生产的产品序列进行全排列，假设共有「Y种」排列；\n4. 问题转变为从X*Y种排班方式选取最优排班，\n\t1. 判断该排班方式是否满足时间槽的时间约束，不满足则剔除；\n\t2. 安排「产品+换料时间」到时间槽，将时间槽内剩余时间切块，以投票的方式填充到时间槽内产品与产品间的间隔，求该时间槽最优解；\n\t3. 求解每个时间槽的最优解，累加得一次生产安排的最优解，再从多次生产安排选取成本最小的，即为所求。","source":"_posts/2017-05-09-power-adjustment.md","raw":"---\ntitle: 最优生产计划\ndate: 2017-05-09 17:25:16\ncomments: true\ncategories: ['算法'] \ntags: ['动态规划']\n---\n\n## 目标\n\n已知各类生产产品的生产时间及负荷曲线（负荷曲线对时间的积分即电量），输入「目标生产计划」，计算后输出「最优生产计划」，使得按该计划进行生产成本最优。\n\n<!--more-->\n\n目标生产计划的构成为，\n\n- 计划开始时间\n- 计划结束时间\n- 生产哪些产品，如：A20件，B30件，C20件，D100件\n\n最优生产计划的构成为，\n\n- t1：开始生产产品P1\n- t2：开始生产产品P2\n- t3：开始生产产品P3\n- ……\n\n## 如何求解\n\n> 成本 = 峰期电费单价 * 峰期电量 + 平期电费单价 * 平期电量 + 谷期电费单价 * 谷期电量\n> \n> 注：这里的峰平谷指的是一天的不同时段，高峰期和低谷期的电费单价是不一样的。\n\n最优生产计划即成本最小的生产计划，安排生产计划需要考虑的约束有，\n\n`各产品生产时间+换料时间+下班/休息时间 <= (计划结束时间 - 计划开始时间)` \n\n这个问题实质是一个动态规划问题，\n\n1. 将「下班/休息时间」从计划时间挖去，得「N段」可用的时间槽；\n2. 将生产的总件数看成「M张」选票，投给上述的「N段」时间槽（候选人），假设共有「X种」投票结果；\n3. 对计划生产的产品序列进行全排列，假设共有「Y种」排列；\n4. 问题转变为从X*Y种排班方式选取最优排班，\n\t1. 判断该排班方式是否满足时间槽的时间约束，不满足则剔除；\n\t2. 安排「产品+换料时间」到时间槽，将时间槽内剩余时间切块，以投票的方式填充到时间槽内产品与产品间的间隔，求该时间槽最优解；\n\t3. 求解每个时间槽的最优解，累加得一次生产安排的最优解，再从多次生产安排选取成本最小的，即为所求。","slug":"power-adjustment","published":1,"updated":"2022-08-09T15:02:00.629Z","layout":"post","photos":[],"link":"","_id":"cl6mbc13l001yigu81qn2dp05","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>已知各类生产产品的生产时间及负荷曲线（负荷曲线对时间的积分即电量），输入「目标生产计划」，计算后输出「最优生产计划」，使得按该计划进行生产成本最优。</p>\n<a id=\"more\"></a>\n<p>目标生产计划的构成为，</p>\n<ul>\n<li>计划开始时间</li>\n<li>计划结束时间</li>\n<li>生产哪些产品，如：A20件，B30件，C20件，D100件</li>\n</ul>\n<p>最优生产计划的构成为，</p>\n<ul>\n<li>t1：开始生产产品P1</li>\n<li>t2：开始生产产品P2</li>\n<li>t3：开始生产产品P3</li>\n<li>……</li>\n</ul>\n<h2 id=\"如何求解\"><a href=\"#如何求解\" class=\"headerlink\" title=\"如何求解\"></a>如何求解</h2><blockquote>\n<p>成本 = 峰期电费单价 <em> 峰期电量 + 平期电费单价 </em> 平期电量 + 谷期电费单价 * 谷期电量</p>\n<p>注：这里的峰平谷指的是一天的不同时段，高峰期和低谷期的电费单价是不一样的。</p>\n</blockquote>\n<p>最优生产计划即成本最小的生产计划，安排生产计划需要考虑的约束有，</p>\n<p><code>各产品生产时间+换料时间+下班/休息时间 &lt;= (计划结束时间 - 计划开始时间)</code> </p>\n<p>这个问题实质是一个动态规划问题，</p>\n<ol>\n<li>将「下班/休息时间」从计划时间挖去，得「N段」可用的时间槽；</li>\n<li>将生产的总件数看成「M张」选票，投给上述的「N段」时间槽（候选人），假设共有「X种」投票结果；</li>\n<li>对计划生产的产品序列进行全排列，假设共有「Y种」排列；</li>\n<li>问题转变为从X*Y种排班方式选取最优排班，<ol>\n<li>判断该排班方式是否满足时间槽的时间约束，不满足则剔除；</li>\n<li>安排「产品+换料时间」到时间槽，将时间槽内剩余时间切块，以投票的方式填充到时间槽内产品与产品间的间隔，求该时间槽最优解；</li>\n<li>求解每个时间槽的最优解，累加得一次生产安排的最优解，再从多次生产安排选取成本最小的，即为所求。</li>\n</ol>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>已知各类生产产品的生产时间及负荷曲线（负荷曲线对时间的积分即电量），输入「目标生产计划」，计算后输出「最优生产计划」，使得按该计划进行生产成本最优。</p>","more":"<p>目标生产计划的构成为，</p>\n<ul>\n<li>计划开始时间</li>\n<li>计划结束时间</li>\n<li>生产哪些产品，如：A20件，B30件，C20件，D100件</li>\n</ul>\n<p>最优生产计划的构成为，</p>\n<ul>\n<li>t1：开始生产产品P1</li>\n<li>t2：开始生产产品P2</li>\n<li>t3：开始生产产品P3</li>\n<li>……</li>\n</ul>\n<h2 id=\"如何求解\"><a href=\"#如何求解\" class=\"headerlink\" title=\"如何求解\"></a>如何求解</h2><blockquote>\n<p>成本 = 峰期电费单价 <em> 峰期电量 + 平期电费单价 </em> 平期电量 + 谷期电费单价 * 谷期电量</p>\n<p>注：这里的峰平谷指的是一天的不同时段，高峰期和低谷期的电费单价是不一样的。</p>\n</blockquote>\n<p>最优生产计划即成本最小的生产计划，安排生产计划需要考虑的约束有，</p>\n<p><code>各产品生产时间+换料时间+下班/休息时间 &lt;= (计划结束时间 - 计划开始时间)</code> </p>\n<p>这个问题实质是一个动态规划问题，</p>\n<ol>\n<li>将「下班/休息时间」从计划时间挖去，得「N段」可用的时间槽；</li>\n<li>将生产的总件数看成「M张」选票，投给上述的「N段」时间槽（候选人），假设共有「X种」投票结果；</li>\n<li>对计划生产的产品序列进行全排列，假设共有「Y种」排列；</li>\n<li>问题转变为从X*Y种排班方式选取最优排班，<ol>\n<li>判断该排班方式是否满足时间槽的时间约束，不满足则剔除；</li>\n<li>安排「产品+换料时间」到时间槽，将时间槽内剩余时间切块，以投票的方式填充到时间槽内产品与产品间的间隔，求该时间槽最优解；</li>\n<li>求解每个时间槽的最优解，累加得一次生产安排的最优解，再从多次生产安排选取成本最小的，即为所求。</li>\n</ol>\n</li>\n</ol>"},{"layout":"post","title":"Multi virtual HOST of Tomcat","date":"2016-08-17T09:51:00.000Z","comments":1,"_content":"\n本文介绍tomcat如何设置multi vitual host。\n\n<!--more-->\n\n## why and how does it work\n\n注：以下的全部域名是为了举例虚构，出于一些考虑，笔者不打算公布真实域名。\n\n笔者有个域名为[gx.com](http://www.gx.com)，指向个人主页。同时，该域名下有个资源[gx.com/product](http://gx.com/product)，指向笔者的产品界面。某天从同事那了解到还可以设置二级域名，于是，我想把我的产品界面链接[gx.com/product](http://gx.com/product)改为[product.gx.com](http://product.gx.com)，用二级域名的方式来指向（如何创建二级域名请自行搜索）。\n\n笔者的个人主页和产品界面都部署在同一主机的同一个Tomcat容器下（80端口），查了下资料，通过配置Tomcat就可以实现我的上述要求。且先不说如何配置，其工作原理是什么呢？Tomcat在80端口监听HTTP连接，它是如何判断一个HTTP请求到底是要请求[gx.com](http://www.gx.com)的资源，还是要请求[product.gx.com](http://product.gx.com)的资源呢？\n\n```\nGET / HTTP/1.1\nHost: www.gx.com\nProxy-Connection: keep-alive\nUser-Agent: Mozilla/5.0 (Windows NT 6.2) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\nAccept-Encoding: gzip,deflate,sdch\nAccept-Language: en-US,en;q=0.8\n```\n\n原来是通过报文的Header来区分的。至于请求转发的原理，请参考[Tomcat 系统架构与设计模式，第 1 部分: 工作原理](http://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/)。\n\n## how\n\n下面讲解如何配置，先贴上笔者的最终配置。\n\n```xml\n<Engine defaultHost=\"www.gx.com\" name=\"Catalina\">\n\n      <!--For clustering, please take a look at documentation at:\n          /docs/cluster-howto.html  (simple how to)\n          /docs/config/cluster.html (reference documentation) -->\n      <!--\n      <Cluster className=\"org.apache.catalina.ha.tcp.SimpleTcpCluster\"/>\n      -->\n\n      <!-- Use the LockOutRealm to prevent attempts to guess user passwords\n           via a brute-force attack -->\n      <Realm className=\"org.apache.catalina.realm.LockOutRealm\">\n        <!-- This Realm uses the UserDatabase configured in the global JNDI\n             resources under the key \"UserDatabase\".  Any edits\n             that are performed against this UserDatabase are immediately\n             available for use by the Realm.  -->\n        <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/>\n      </Realm>\n\n      <Host appBase=\"primaryapps\" autoDeploy=\"true\" name=\"product.gx.com\" unpackWARs=\"true\">\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" pattern=\"%h %l %u %t &quot;%r&quot; %s %b\" prefix=\"cloud_access_log\" suffix=\".txt\"/>\n      </Host>\n\n      <Host appBase=\"webapps\" autoDeploy=\"true\" name=\"www.gx.com\" unpackWARs=\"true\">\n        <Context path=\"\" docBase=\"guanxing\" debug=\"0\"/>\n        <!-- Access log processes all example.\n             Documentation at: /docs/config/valve.html\n             Note: The pattern used is equivalent to using pattern=\"common\" -->\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" pattern=\"%h %l %u %t &quot;%r&quot; %s %b\" prefix=\"localhost_access_log\" suffix=\".txt\"/>\n\n      </Host>\n      ......\n</Engine>\n```\n\n- 第01行：`defaultHost`必须指向其中一个Host的name，即为域名；\n- 第20行：域名[product.gx.com](http://product.gx.com)的配置，这里我没有配置Context标签，按照官网的说明，它会自动去寻找`<tomcat_home>/<appBase>/ROOT`（见附件1）作为此域名的容器应用（本文为`<tomcat_home>/primaryapps/ROOT`）；\n- 第24行：域名[gx.com](http://www.gx.com)的配置；\n- 第25行：域名[gx.com](http://www.gx.com)的容器应用为`<tomcat_home>/webapps/guanxing`；\n\n------\n\n**附件1**\n>\nWhen autoDeploy or deployOnStartup operations are performed by a Host, the name and context path of the web application are derived from the name(s) of the file(s) that define(s) the web application. Consequently, the context path may not be defined in a META-INF/context.xml embedded in the application and there is a close relationship between the context name, context path, context version and the base file name (the name minus any .war or .xml extension) of the file.\n>\nIf no version is specified then the context name is always the same as the context path. **If the context path is the empty string them the base name will be ROOT (always in upper case) ** otherwise the base name will be the context path with the leading '/' removed and any remaining '/' characters replaced with '#'.\n>\nIf a version is specified then the context path remains unchanged and both the context name and the base name have the string '##' appended to them followed by the version identifier.\n>\nSome examples of these naming conventions are given below.\n>\nhttp://tomcat.apache.org/tomcat-7.0-doc/config/context.html\n","source":"_posts/2016-08-17-tomcat-multi-virtual-host.markdown","raw":"---\nlayout: post\ntitle: Multi virtual HOST of Tomcat\ndate: '2016-08-17 17:51'\ncomments: true\ncategories: ['工具篇'] \ntags: ['Tomcat']\n---\n\n本文介绍tomcat如何设置multi vitual host。\n\n<!--more-->\n\n## why and how does it work\n\n注：以下的全部域名是为了举例虚构，出于一些考虑，笔者不打算公布真实域名。\n\n笔者有个域名为[gx.com](http://www.gx.com)，指向个人主页。同时，该域名下有个资源[gx.com/product](http://gx.com/product)，指向笔者的产品界面。某天从同事那了解到还可以设置二级域名，于是，我想把我的产品界面链接[gx.com/product](http://gx.com/product)改为[product.gx.com](http://product.gx.com)，用二级域名的方式来指向（如何创建二级域名请自行搜索）。\n\n笔者的个人主页和产品界面都部署在同一主机的同一个Tomcat容器下（80端口），查了下资料，通过配置Tomcat就可以实现我的上述要求。且先不说如何配置，其工作原理是什么呢？Tomcat在80端口监听HTTP连接，它是如何判断一个HTTP请求到底是要请求[gx.com](http://www.gx.com)的资源，还是要请求[product.gx.com](http://product.gx.com)的资源呢？\n\n```\nGET / HTTP/1.1\nHost: www.gx.com\nProxy-Connection: keep-alive\nUser-Agent: Mozilla/5.0 (Windows NT 6.2) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\nAccept-Encoding: gzip,deflate,sdch\nAccept-Language: en-US,en;q=0.8\n```\n\n原来是通过报文的Header来区分的。至于请求转发的原理，请参考[Tomcat 系统架构与设计模式，第 1 部分: 工作原理](http://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/)。\n\n## how\n\n下面讲解如何配置，先贴上笔者的最终配置。\n\n```xml\n<Engine defaultHost=\"www.gx.com\" name=\"Catalina\">\n\n      <!--For clustering, please take a look at documentation at:\n          /docs/cluster-howto.html  (simple how to)\n          /docs/config/cluster.html (reference documentation) -->\n      <!--\n      <Cluster className=\"org.apache.catalina.ha.tcp.SimpleTcpCluster\"/>\n      -->\n\n      <!-- Use the LockOutRealm to prevent attempts to guess user passwords\n           via a brute-force attack -->\n      <Realm className=\"org.apache.catalina.realm.LockOutRealm\">\n        <!-- This Realm uses the UserDatabase configured in the global JNDI\n             resources under the key \"UserDatabase\".  Any edits\n             that are performed against this UserDatabase are immediately\n             available for use by the Realm.  -->\n        <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/>\n      </Realm>\n\n      <Host appBase=\"primaryapps\" autoDeploy=\"true\" name=\"product.gx.com\" unpackWARs=\"true\">\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" pattern=\"%h %l %u %t &quot;%r&quot; %s %b\" prefix=\"cloud_access_log\" suffix=\".txt\"/>\n      </Host>\n\n      <Host appBase=\"webapps\" autoDeploy=\"true\" name=\"www.gx.com\" unpackWARs=\"true\">\n        <Context path=\"\" docBase=\"guanxing\" debug=\"0\"/>\n        <!-- Access log processes all example.\n             Documentation at: /docs/config/valve.html\n             Note: The pattern used is equivalent to using pattern=\"common\" -->\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" pattern=\"%h %l %u %t &quot;%r&quot; %s %b\" prefix=\"localhost_access_log\" suffix=\".txt\"/>\n\n      </Host>\n      ......\n</Engine>\n```\n\n- 第01行：`defaultHost`必须指向其中一个Host的name，即为域名；\n- 第20行：域名[product.gx.com](http://product.gx.com)的配置，这里我没有配置Context标签，按照官网的说明，它会自动去寻找`<tomcat_home>/<appBase>/ROOT`（见附件1）作为此域名的容器应用（本文为`<tomcat_home>/primaryapps/ROOT`）；\n- 第24行：域名[gx.com](http://www.gx.com)的配置；\n- 第25行：域名[gx.com](http://www.gx.com)的容器应用为`<tomcat_home>/webapps/guanxing`；\n\n------\n\n**附件1**\n>\nWhen autoDeploy or deployOnStartup operations are performed by a Host, the name and context path of the web application are derived from the name(s) of the file(s) that define(s) the web application. Consequently, the context path may not be defined in a META-INF/context.xml embedded in the application and there is a close relationship between the context name, context path, context version and the base file name (the name minus any .war or .xml extension) of the file.\n>\nIf no version is specified then the context name is always the same as the context path. **If the context path is the empty string them the base name will be ROOT (always in upper case) ** otherwise the base name will be the context path with the leading '/' removed and any remaining '/' characters replaced with '#'.\n>\nIf a version is specified then the context path remains unchanged and both the context name and the base name have the string '##' appended to them followed by the version identifier.\n>\nSome examples of these naming conventions are given below.\n>\nhttp://tomcat.apache.org/tomcat-7.0-doc/config/context.html\n","slug":"tomcat-multi-virtual-host","published":1,"updated":"2022-08-09T15:02:00.625Z","photos":[],"link":"","_id":"cl6mbc13n0021igu80fw84f00","content":"<p>本文介绍tomcat如何设置multi vitual host。</p>\n<a id=\"more\"></a>\n<h2 id=\"why-and-how-does-it-work\"><a href=\"#why-and-how-does-it-work\" class=\"headerlink\" title=\"why and how does it work\"></a>why and how does it work</h2><p>注：以下的全部域名是为了举例虚构，出于一些考虑，笔者不打算公布真实域名。</p>\n<p>笔者有个域名为<a href=\"http://www.gx.com\" target=\"_blank\" rel=\"noopener\">gx.com</a>，指向个人主页。同时，该域名下有个资源<a href=\"http://gx.com/product\" target=\"_blank\" rel=\"noopener\">gx.com/product</a>，指向笔者的产品界面。某天从同事那了解到还可以设置二级域名，于是，我想把我的产品界面链接<a href=\"http://gx.com/product\" target=\"_blank\" rel=\"noopener\">gx.com/product</a>改为<a href=\"http://product.gx.com\" target=\"_blank\" rel=\"noopener\">product.gx.com</a>，用二级域名的方式来指向（如何创建二级域名请自行搜索）。</p>\n<p>笔者的个人主页和产品界面都部署在同一主机的同一个Tomcat容器下（80端口），查了下资料，通过配置Tomcat就可以实现我的上述要求。且先不说如何配置，其工作原理是什么呢？Tomcat在80端口监听HTTP连接，它是如何判断一个HTTP请求到底是要请求<a href=\"http://www.gx.com\" target=\"_blank\" rel=\"noopener\">gx.com</a>的资源，还是要请求<a href=\"http://product.gx.com\" target=\"_blank\" rel=\"noopener\">product.gx.com</a>的资源呢？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GET / HTTP/1.1</span><br><span class=\"line\">Host: www.gx.com</span><br><span class=\"line\">Proxy-Connection: keep-alive</span><br><span class=\"line\">User-Agent: Mozilla/5.0 (Windows NT 6.2) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11</span><br><span class=\"line\">Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8</span><br><span class=\"line\">Accept-Encoding: gzip,deflate,sdch</span><br><span class=\"line\">Accept-Language: en-US,en;q=0.8</span><br></pre></td></tr></table></figure>\n<p>原来是通过报文的Header来区分的。至于请求转发的原理，请参考<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/\" target=\"_blank\" rel=\"noopener\">Tomcat 系统架构与设计模式，第 1 部分: 工作原理</a>。</p>\n<h2 id=\"how\"><a href=\"#how\" class=\"headerlink\" title=\"how\"></a>how</h2><p>下面讲解如何配置，先贴上笔者的最终配置。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Engine</span> <span class=\"attr\">defaultHost</span>=<span class=\"string\">\"www.gx.com\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"Catalina\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">&lt;!--For clustering, please take a look at documentation at:</span></span><br><span class=\"line\"><span class=\"comment\">          /docs/cluster-howto.html  (simple how to)</span></span><br><span class=\"line\"><span class=\"comment\">          /docs/config/cluster.html (reference documentation) --&gt;</span></span><br><span class=\"line\">      <span class=\"comment\">&lt;!--</span></span><br><span class=\"line\"><span class=\"comment\">      &lt;Cluster className=\"org.apache.catalina.ha.tcp.SimpleTcpCluster\"/&gt;</span></span><br><span class=\"line\"><span class=\"comment\">      --&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">&lt;!-- Use the LockOutRealm to prevent attempts to guess user passwords</span></span><br><span class=\"line\"><span class=\"comment\">           via a brute-force attack --&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">Realm</span> <span class=\"attr\">className</span>=<span class=\"string\">\"org.apache.catalina.realm.LockOutRealm\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- This Realm uses the UserDatabase configured in the global JNDI</span></span><br><span class=\"line\"><span class=\"comment\">             resources under the key \"UserDatabase\".  Any edits</span></span><br><span class=\"line\"><span class=\"comment\">             that are performed against this UserDatabase are immediately</span></span><br><span class=\"line\"><span class=\"comment\">             available for use by the Realm.  --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Realm</span> <span class=\"attr\">className</span>=<span class=\"string\">\"org.apache.catalina.realm.UserDatabaseRealm\"</span> <span class=\"attr\">resourceName</span>=<span class=\"string\">\"UserDatabase\"</span>/&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">Realm</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">Host</span> <span class=\"attr\">appBase</span>=<span class=\"string\">\"primaryapps\"</span> <span class=\"attr\">autoDeploy</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"product.gx.com\"</span> <span class=\"attr\">unpackWARs</span>=<span class=\"string\">\"true\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"org.apache.catalina.valves.AccessLogValve\"</span> <span class=\"attr\">directory</span>=<span class=\"string\">\"logs\"</span> <span class=\"attr\">pattern</span>=<span class=\"string\">\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\"</span> <span class=\"attr\">prefix</span>=<span class=\"string\">\"cloud_access_log\"</span> <span class=\"attr\">suffix</span>=<span class=\"string\">\".txt\"</span>/&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">Host</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">Host</span> <span class=\"attr\">appBase</span>=<span class=\"string\">\"webapps\"</span> <span class=\"attr\">autoDeploy</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"www.gx.com\"</span> <span class=\"attr\">unpackWARs</span>=<span class=\"string\">\"true\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Context</span> <span class=\"attr\">path</span>=<span class=\"string\">\"\"</span> <span class=\"attr\">docBase</span>=<span class=\"string\">\"guanxing\"</span> <span class=\"attr\">debug</span>=<span class=\"string\">\"0\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- Access log processes all example.</span></span><br><span class=\"line\"><span class=\"comment\">             Documentation at: /docs/config/valve.html</span></span><br><span class=\"line\"><span class=\"comment\">             <span class=\"doctag\">Note:</span> The pattern used is equivalent to using pattern=\"common\" --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"org.apache.catalina.valves.AccessLogValve\"</span> <span class=\"attr\">directory</span>=<span class=\"string\">\"logs\"</span> <span class=\"attr\">pattern</span>=<span class=\"string\">\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\"</span> <span class=\"attr\">prefix</span>=<span class=\"string\">\"localhost_access_log\"</span> <span class=\"attr\">suffix</span>=<span class=\"string\">\".txt\"</span>/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">Host</span>&gt;</span></span><br><span class=\"line\">      ......</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">Engine</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>第01行：<code>defaultHost</code>必须指向其中一个Host的name，即为域名；</li>\n<li>第20行：域名<a href=\"http://product.gx.com\" target=\"_blank\" rel=\"noopener\">product.gx.com</a>的配置，这里我没有配置Context标签，按照官网的说明，它会自动去寻找<code>&lt;tomcat_home&gt;/&lt;appBase&gt;/ROOT</code>（见附件1）作为此域名的容器应用（本文为<code>&lt;tomcat_home&gt;/primaryapps/ROOT</code>）；</li>\n<li>第24行：域名<a href=\"http://www.gx.com\" target=\"_blank\" rel=\"noopener\">gx.com</a>的配置；</li>\n<li>第25行：域名<a href=\"http://www.gx.com\" target=\"_blank\" rel=\"noopener\">gx.com</a>的容器应用为<code>&lt;tomcat_home&gt;/webapps/guanxing</code>；</li>\n</ul>\n<hr>\n<p><strong>附件1</strong></p>\n<blockquote>\n</blockquote>\n<p>When autoDeploy or deployOnStartup operations are performed by a Host, the name and context path of the web application are derived from the name(s) of the file(s) that define(s) the web application. Consequently, the context path may not be defined in a META-INF/context.xml embedded in the application and there is a close relationship between the context name, context path, context version and the base file name (the name minus any .war or .xml extension) of the file.</p>\n<blockquote>\n</blockquote>\n<p>If no version is specified then the context name is always the same as the context path. <strong>If the context path is the empty string them the base name will be ROOT (always in upper case) </strong> otherwise the base name will be the context path with the leading ‘/‘ removed and any remaining ‘/‘ characters replaced with ‘#’.</p>\n<blockquote>\n</blockquote>\n<p>If a version is specified then the context path remains unchanged and both the context name and the base name have the string ‘##’ appended to them followed by the version identifier.</p>\n<blockquote>\n</blockquote>\n<p>Some examples of these naming conventions are given below.</p>\n<blockquote>\n</blockquote>\n<p><a href=\"http://tomcat.apache.org/tomcat-7.0-doc/config/context.html\" target=\"_blank\" rel=\"noopener\">http://tomcat.apache.org/tomcat-7.0-doc/config/context.html</a></p>\n","site":{"data":{}},"excerpt":"<p>本文介绍tomcat如何设置multi vitual host。</p>","more":"<h2 id=\"why-and-how-does-it-work\"><a href=\"#why-and-how-does-it-work\" class=\"headerlink\" title=\"why and how does it work\"></a>why and how does it work</h2><p>注：以下的全部域名是为了举例虚构，出于一些考虑，笔者不打算公布真实域名。</p>\n<p>笔者有个域名为<a href=\"http://www.gx.com\" target=\"_blank\" rel=\"noopener\">gx.com</a>，指向个人主页。同时，该域名下有个资源<a href=\"http://gx.com/product\" target=\"_blank\" rel=\"noopener\">gx.com/product</a>，指向笔者的产品界面。某天从同事那了解到还可以设置二级域名，于是，我想把我的产品界面链接<a href=\"http://gx.com/product\" target=\"_blank\" rel=\"noopener\">gx.com/product</a>改为<a href=\"http://product.gx.com\" target=\"_blank\" rel=\"noopener\">product.gx.com</a>，用二级域名的方式来指向（如何创建二级域名请自行搜索）。</p>\n<p>笔者的个人主页和产品界面都部署在同一主机的同一个Tomcat容器下（80端口），查了下资料，通过配置Tomcat就可以实现我的上述要求。且先不说如何配置，其工作原理是什么呢？Tomcat在80端口监听HTTP连接，它是如何判断一个HTTP请求到底是要请求<a href=\"http://www.gx.com\" target=\"_blank\" rel=\"noopener\">gx.com</a>的资源，还是要请求<a href=\"http://product.gx.com\" target=\"_blank\" rel=\"noopener\">product.gx.com</a>的资源呢？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GET / HTTP/1.1</span><br><span class=\"line\">Host: www.gx.com</span><br><span class=\"line\">Proxy-Connection: keep-alive</span><br><span class=\"line\">User-Agent: Mozilla/5.0 (Windows NT 6.2) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11</span><br><span class=\"line\">Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8</span><br><span class=\"line\">Accept-Encoding: gzip,deflate,sdch</span><br><span class=\"line\">Accept-Language: en-US,en;q=0.8</span><br></pre></td></tr></table></figure>\n<p>原来是通过报文的Header来区分的。至于请求转发的原理，请参考<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/\" target=\"_blank\" rel=\"noopener\">Tomcat 系统架构与设计模式，第 1 部分: 工作原理</a>。</p>\n<h2 id=\"how\"><a href=\"#how\" class=\"headerlink\" title=\"how\"></a>how</h2><p>下面讲解如何配置，先贴上笔者的最终配置。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Engine</span> <span class=\"attr\">defaultHost</span>=<span class=\"string\">\"www.gx.com\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"Catalina\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">&lt;!--For clustering, please take a look at documentation at:</span></span><br><span class=\"line\"><span class=\"comment\">          /docs/cluster-howto.html  (simple how to)</span></span><br><span class=\"line\"><span class=\"comment\">          /docs/config/cluster.html (reference documentation) --&gt;</span></span><br><span class=\"line\">      <span class=\"comment\">&lt;!--</span></span><br><span class=\"line\"><span class=\"comment\">      &lt;Cluster className=\"org.apache.catalina.ha.tcp.SimpleTcpCluster\"/&gt;</span></span><br><span class=\"line\"><span class=\"comment\">      --&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">&lt;!-- Use the LockOutRealm to prevent attempts to guess user passwords</span></span><br><span class=\"line\"><span class=\"comment\">           via a brute-force attack --&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">Realm</span> <span class=\"attr\">className</span>=<span class=\"string\">\"org.apache.catalina.realm.LockOutRealm\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- This Realm uses the UserDatabase configured in the global JNDI</span></span><br><span class=\"line\"><span class=\"comment\">             resources under the key \"UserDatabase\".  Any edits</span></span><br><span class=\"line\"><span class=\"comment\">             that are performed against this UserDatabase are immediately</span></span><br><span class=\"line\"><span class=\"comment\">             available for use by the Realm.  --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Realm</span> <span class=\"attr\">className</span>=<span class=\"string\">\"org.apache.catalina.realm.UserDatabaseRealm\"</span> <span class=\"attr\">resourceName</span>=<span class=\"string\">\"UserDatabase\"</span>/&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">Realm</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">Host</span> <span class=\"attr\">appBase</span>=<span class=\"string\">\"primaryapps\"</span> <span class=\"attr\">autoDeploy</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"product.gx.com\"</span> <span class=\"attr\">unpackWARs</span>=<span class=\"string\">\"true\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"org.apache.catalina.valves.AccessLogValve\"</span> <span class=\"attr\">directory</span>=<span class=\"string\">\"logs\"</span> <span class=\"attr\">pattern</span>=<span class=\"string\">\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\"</span> <span class=\"attr\">prefix</span>=<span class=\"string\">\"cloud_access_log\"</span> <span class=\"attr\">suffix</span>=<span class=\"string\">\".txt\"</span>/&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">Host</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">Host</span> <span class=\"attr\">appBase</span>=<span class=\"string\">\"webapps\"</span> <span class=\"attr\">autoDeploy</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"www.gx.com\"</span> <span class=\"attr\">unpackWARs</span>=<span class=\"string\">\"true\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Context</span> <span class=\"attr\">path</span>=<span class=\"string\">\"\"</span> <span class=\"attr\">docBase</span>=<span class=\"string\">\"guanxing\"</span> <span class=\"attr\">debug</span>=<span class=\"string\">\"0\"</span>/&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- Access log processes all example.</span></span><br><span class=\"line\"><span class=\"comment\">             Documentation at: /docs/config/valve.html</span></span><br><span class=\"line\"><span class=\"comment\">             <span class=\"doctag\">Note:</span> The pattern used is equivalent to using pattern=\"common\" --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"org.apache.catalina.valves.AccessLogValve\"</span> <span class=\"attr\">directory</span>=<span class=\"string\">\"logs\"</span> <span class=\"attr\">pattern</span>=<span class=\"string\">\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\"</span> <span class=\"attr\">prefix</span>=<span class=\"string\">\"localhost_access_log\"</span> <span class=\"attr\">suffix</span>=<span class=\"string\">\".txt\"</span>/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">Host</span>&gt;</span></span><br><span class=\"line\">      ......</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">Engine</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>第01行：<code>defaultHost</code>必须指向其中一个Host的name，即为域名；</li>\n<li>第20行：域名<a href=\"http://product.gx.com\" target=\"_blank\" rel=\"noopener\">product.gx.com</a>的配置，这里我没有配置Context标签，按照官网的说明，它会自动去寻找<code>&lt;tomcat_home&gt;/&lt;appBase&gt;/ROOT</code>（见附件1）作为此域名的容器应用（本文为<code>&lt;tomcat_home&gt;/primaryapps/ROOT</code>）；</li>\n<li>第24行：域名<a href=\"http://www.gx.com\" target=\"_blank\" rel=\"noopener\">gx.com</a>的配置；</li>\n<li>第25行：域名<a href=\"http://www.gx.com\" target=\"_blank\" rel=\"noopener\">gx.com</a>的容器应用为<code>&lt;tomcat_home&gt;/webapps/guanxing</code>；</li>\n</ul>\n<hr>\n<p><strong>附件1</strong></p>\n<blockquote>\n</blockquote>\n<p>When autoDeploy or deployOnStartup operations are performed by a Host, the name and context path of the web application are derived from the name(s) of the file(s) that define(s) the web application. Consequently, the context path may not be defined in a META-INF/context.xml embedded in the application and there is a close relationship between the context name, context path, context version and the base file name (the name minus any .war or .xml extension) of the file.</p>\n<blockquote>\n</blockquote>\n<p>If no version is specified then the context name is always the same as the context path. <strong>If the context path is the empty string them the base name will be ROOT (always in upper case) </strong> otherwise the base name will be the context path with the leading ‘/‘ removed and any remaining ‘/‘ characters replaced with ‘#’.</p>\n<blockquote>\n</blockquote>\n<p>If a version is specified then the context path remains unchanged and both the context name and the base name have the string ‘##’ appended to them followed by the version identifier.</p>\n<blockquote>\n</blockquote>\n<p>Some examples of these naming conventions are given below.</p>\n<blockquote>\n</blockquote>\n<p><a href=\"http://tomcat.apache.org/tomcat-7.0-doc/config/context.html\" target=\"_blank\" rel=\"noopener\">http://tomcat.apache.org/tomcat-7.0-doc/config/context.html</a></p>"},{"title":"Java Mina close_wait issue","date":"2018-06-14T03:02:06.000Z","comments":1,"_content":"\n在Linux下使用Java Mina编写TCP/IP通信程序时，发现TCP Server出现了大量的CLOSE_WAIT，why？\n\n<!--more-->\n\nclose_wait状态出现在TCP四次挥手，「被动关闭的TCP端」才会出现此状态，详见下图。\n\n![TCP四次挥手](https://img-blog.csdn.net/20170606084851272?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXpjc3U=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n从图片可以得到以下信息，\n\n- 主动关闭端主动发送FIN报文\n- 被动关闭端接收到FIN报文后，协议栈一般会自动回复ACK报文，此时被动关闭端进入了**close_wait**状态。再次强调下，一旦被动关闭端收到了FIN报文并回复ACK，它便进入了close_wait状态\n- 直到被动关闭端发送了FIN报文后，close_wait状态才解除，被动关闭端进入last_ack的状态\n\n这里有两个问题，\n\n- 被动关闭端如何发送FIN报文？\n- 如果被动关闭端不主动close()会有什么后果？\n\n相应的答案是，\n\n- 主动close()已建立的socket连接，放在mina便是`session.closeNow()`\n- 被动关闭端会一直处在close_wait状态，直到达到一个超时时间才释放socket。这个时间默认是2小时，可通过修改系统配置缩短（搜索tcp keepalive setup）\n\n强调一点，**在close_wait状态解除前，除非tcp端口发生变化，否则主动关闭端将无法再次与被动关闭端建立tcp连接，这放在生产环境便是灾难。为什么会这样呢？因为TCP连接是一个4元标识，本地IP+本地端口+远端IP+远端端口唯一标识一个TCP连接，处于close_wait状态相当于keep住了一个4元标识，任何与此标识相同的连接请求（三次握手）将被TCP拒绝。**\n\n\n最重要的结论来了：**如果你遇到这类问题，说明你的程序存在BUG，没有正常close()掉失效的TCP连接**。若使用mina编程，可在sessionIdle()关闭失效的连接避免此错误。\n\n注：使用`lsof`命令可查看进程是否有socket处于close_wait状态。\n\n\n## 参考文献\n\nhttps://blog.csdn.net/qzcsu/article/details/72861891\n","source":"_posts/2018-06-14-close-wait-issue.md","raw":"---\ntitle: Java Mina close_wait issue\ndate: 2018-06-14 11:02:06\ntags: ['Java', 'Mina', 'TCP/IP']\ncomments: true\ncategories: ['计算机网络']\n---\n\n在Linux下使用Java Mina编写TCP/IP通信程序时，发现TCP Server出现了大量的CLOSE_WAIT，why？\n\n<!--more-->\n\nclose_wait状态出现在TCP四次挥手，「被动关闭的TCP端」才会出现此状态，详见下图。\n\n![TCP四次挥手](https://img-blog.csdn.net/20170606084851272?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXpjc3U=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n从图片可以得到以下信息，\n\n- 主动关闭端主动发送FIN报文\n- 被动关闭端接收到FIN报文后，协议栈一般会自动回复ACK报文，此时被动关闭端进入了**close_wait**状态。再次强调下，一旦被动关闭端收到了FIN报文并回复ACK，它便进入了close_wait状态\n- 直到被动关闭端发送了FIN报文后，close_wait状态才解除，被动关闭端进入last_ack的状态\n\n这里有两个问题，\n\n- 被动关闭端如何发送FIN报文？\n- 如果被动关闭端不主动close()会有什么后果？\n\n相应的答案是，\n\n- 主动close()已建立的socket连接，放在mina便是`session.closeNow()`\n- 被动关闭端会一直处在close_wait状态，直到达到一个超时时间才释放socket。这个时间默认是2小时，可通过修改系统配置缩短（搜索tcp keepalive setup）\n\n强调一点，**在close_wait状态解除前，除非tcp端口发生变化，否则主动关闭端将无法再次与被动关闭端建立tcp连接，这放在生产环境便是灾难。为什么会这样呢？因为TCP连接是一个4元标识，本地IP+本地端口+远端IP+远端端口唯一标识一个TCP连接，处于close_wait状态相当于keep住了一个4元标识，任何与此标识相同的连接请求（三次握手）将被TCP拒绝。**\n\n\n最重要的结论来了：**如果你遇到这类问题，说明你的程序存在BUG，没有正常close()掉失效的TCP连接**。若使用mina编程，可在sessionIdle()关闭失效的连接避免此错误。\n\n注：使用`lsof`命令可查看进程是否有socket处于close_wait状态。\n\n\n## 参考文献\n\nhttps://blog.csdn.net/qzcsu/article/details/72861891\n","slug":"close-wait-issue","published":1,"updated":"2022-08-09T15:02:00.636Z","layout":"post","photos":[],"link":"","_id":"cl6mbc13r0026igu801rp59dp","content":"<p>在Linux下使用Java Mina编写TCP/IP通信程序时，发现TCP Server出现了大量的CLOSE_WAIT，why？</p>\n<a id=\"more\"></a>\n<p>close_wait状态出现在TCP四次挥手，「被动关闭的TCP端」才会出现此状态，详见下图。</p>\n<p><img src=\"https://img-blog.csdn.net/20170606084851272?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXpjc3U=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"TCP四次挥手\"></p>\n<p>从图片可以得到以下信息，</p>\n<ul>\n<li>主动关闭端主动发送FIN报文</li>\n<li>被动关闭端接收到FIN报文后，协议栈一般会自动回复ACK报文，此时被动关闭端进入了<strong>close_wait</strong>状态。再次强调下，一旦被动关闭端收到了FIN报文并回复ACK，它便进入了close_wait状态</li>\n<li>直到被动关闭端发送了FIN报文后，close_wait状态才解除，被动关闭端进入last_ack的状态</li>\n</ul>\n<p>这里有两个问题，</p>\n<ul>\n<li>被动关闭端如何发送FIN报文？</li>\n<li>如果被动关闭端不主动close()会有什么后果？</li>\n</ul>\n<p>相应的答案是，</p>\n<ul>\n<li>主动close()已建立的socket连接，放在mina便是<code>session.closeNow()</code></li>\n<li>被动关闭端会一直处在close_wait状态，直到达到一个超时时间才释放socket。这个时间默认是2小时，可通过修改系统配置缩短（搜索tcp keepalive setup）</li>\n</ul>\n<p>强调一点，<strong>在close_wait状态解除前，除非tcp端口发生变化，否则主动关闭端将无法再次与被动关闭端建立tcp连接，这放在生产环境便是灾难。为什么会这样呢？因为TCP连接是一个4元标识，本地IP+本地端口+远端IP+远端端口唯一标识一个TCP连接，处于close_wait状态相当于keep住了一个4元标识，任何与此标识相同的连接请求（三次握手）将被TCP拒绝。</strong></p>\n<p>最重要的结论来了：<strong>如果你遇到这类问题，说明你的程序存在BUG，没有正常close()掉失效的TCP连接</strong>。若使用mina编程，可在sessionIdle()关闭失效的连接避免此错误。</p>\n<p>注：使用<code>lsof</code>命令可查看进程是否有socket处于close_wait状态。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p><a href=\"https://blog.csdn.net/qzcsu/article/details/72861891\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qzcsu/article/details/72861891</a></p>\n","site":{"data":{}},"excerpt":"<p>在Linux下使用Java Mina编写TCP/IP通信程序时，发现TCP Server出现了大量的CLOSE_WAIT，why？</p>","more":"<p>close_wait状态出现在TCP四次挥手，「被动关闭的TCP端」才会出现此状态，详见下图。</p>\n<p><img src=\"https://img-blog.csdn.net/20170606084851272?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXpjc3U=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"TCP四次挥手\"></p>\n<p>从图片可以得到以下信息，</p>\n<ul>\n<li>主动关闭端主动发送FIN报文</li>\n<li>被动关闭端接收到FIN报文后，协议栈一般会自动回复ACK报文，此时被动关闭端进入了<strong>close_wait</strong>状态。再次强调下，一旦被动关闭端收到了FIN报文并回复ACK，它便进入了close_wait状态</li>\n<li>直到被动关闭端发送了FIN报文后，close_wait状态才解除，被动关闭端进入last_ack的状态</li>\n</ul>\n<p>这里有两个问题，</p>\n<ul>\n<li>被动关闭端如何发送FIN报文？</li>\n<li>如果被动关闭端不主动close()会有什么后果？</li>\n</ul>\n<p>相应的答案是，</p>\n<ul>\n<li>主动close()已建立的socket连接，放在mina便是<code>session.closeNow()</code></li>\n<li>被动关闭端会一直处在close_wait状态，直到达到一个超时时间才释放socket。这个时间默认是2小时，可通过修改系统配置缩短（搜索tcp keepalive setup）</li>\n</ul>\n<p>强调一点，<strong>在close_wait状态解除前，除非tcp端口发生变化，否则主动关闭端将无法再次与被动关闭端建立tcp连接，这放在生产环境便是灾难。为什么会这样呢？因为TCP连接是一个4元标识，本地IP+本地端口+远端IP+远端端口唯一标识一个TCP连接，处于close_wait状态相当于keep住了一个4元标识，任何与此标识相同的连接请求（三次握手）将被TCP拒绝。</strong></p>\n<p>最重要的结论来了：<strong>如果你遇到这类问题，说明你的程序存在BUG，没有正常close()掉失效的TCP连接</strong>。若使用mina编程，可在sessionIdle()关闭失效的连接避免此错误。</p>\n<p>注：使用<code>lsof</code>命令可查看进程是否有socket处于close_wait状态。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p><a href=\"https://blog.csdn.net/qzcsu/article/details/72861891\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qzcsu/article/details/72861891</a></p>"},{"title":"Core Java 01 | equals vs ==","date":"2018-06-07T04:22:29.000Z","comments":1,"_content":"\nJava中，equals和==有何区别？\n\n<!-- more -->\n\n`==`是什么？\n\n- `==`是二元运算符；\n- 对于基本数据类型，`==`比较的是值是否相等；\n- 对于对象，`==`比较的是两个引用是否指向同一个内存地址；\n\n`equals`是什么？\n\n- `equals`是顶层父类`java.lang.Object`的成员方法，此方法需通过非空对象调用，其源码如下：\n```java\npublic boolean equals(Object obj) {\n    return (this == obj);\n}\n```\n- 在子类没有重写`equals`方法的情况下，比较的是两个引用是否指向同一个内存地址；\n- 在子类重写了`equals`的情况下，比较的结果视其具体实现而定。例如：8大基本数据的包装数据类型、String类重写了equals方法，比较的是值是否相等。\n\n对于equals，Java有个规定：\n\n> Note that it is generally necessary to override the hashCode method whenever this method is overridden, so as to maintain the general contract for the hashCode method, which states that equal objects must have equal hash codes.\n\n> 长话短说：若两个对象使用equals比较返回true，它们的hashCode方法返回的值必须相等。\n\nWhy？下回详解。\n","source":"_posts/2018-06-07-core-java-equals.md","raw":"---\ntitle: \"Core Java 01 | equals vs ==\"\ndate: 2018-06-07 12:22:29\ntags: ['Java']\ncomments: true\ncategories: ['编程语言']\n---\n\nJava中，equals和==有何区别？\n\n<!-- more -->\n\n`==`是什么？\n\n- `==`是二元运算符；\n- 对于基本数据类型，`==`比较的是值是否相等；\n- 对于对象，`==`比较的是两个引用是否指向同一个内存地址；\n\n`equals`是什么？\n\n- `equals`是顶层父类`java.lang.Object`的成员方法，此方法需通过非空对象调用，其源码如下：\n```java\npublic boolean equals(Object obj) {\n    return (this == obj);\n}\n```\n- 在子类没有重写`equals`方法的情况下，比较的是两个引用是否指向同一个内存地址；\n- 在子类重写了`equals`的情况下，比较的结果视其具体实现而定。例如：8大基本数据的包装数据类型、String类重写了equals方法，比较的是值是否相等。\n\n对于equals，Java有个规定：\n\n> Note that it is generally necessary to override the hashCode method whenever this method is overridden, so as to maintain the general contract for the hashCode method, which states that equal objects must have equal hash codes.\n\n> 长话短说：若两个对象使用equals比较返回true，它们的hashCode方法返回的值必须相等。\n\nWhy？下回详解。\n","slug":"core-java-equals","published":1,"updated":"2022-08-09T15:02:00.634Z","layout":"post","photos":[],"link":"","_id":"cl6mbc13u0029igu8m62yhoxg","content":"<p>Java中，equals和==有何区别？</p>\n<a id=\"more\"></a>\n<p><code>==</code>是什么？</p>\n<ul>\n<li><code>==</code>是二元运算符；</li>\n<li>对于基本数据类型，<code>==</code>比较的是值是否相等；</li>\n<li>对于对象，<code>==</code>比较的是两个引用是否指向同一个内存地址；</li>\n</ul>\n<p><code>equals</code>是什么？</p>\n<ul>\n<li><p><code>equals</code>是顶层父类<code>java.lang.Object</code>的成员方法，此方法需通过非空对象调用，其源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">equals</span><span class=\"params\">(Object obj)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"keyword\">this</span> == obj);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在子类没有重写<code>equals</code>方法的情况下，比较的是两个引用是否指向同一个内存地址；</p>\n</li>\n<li>在子类重写了<code>equals</code>的情况下，比较的结果视其具体实现而定。例如：8大基本数据的包装数据类型、String类重写了equals方法，比较的是值是否相等。</li>\n</ul>\n<p>对于equals，Java有个规定：</p>\n<blockquote>\n<p>Note that it is generally necessary to override the hashCode method whenever this method is overridden, so as to maintain the general contract for the hashCode method, which states that equal objects must have equal hash codes.</p>\n</blockquote>\n<blockquote>\n<p>长话短说：若两个对象使用equals比较返回true，它们的hashCode方法返回的值必须相等。</p>\n</blockquote>\n<p>Why？下回详解。</p>\n","site":{"data":{}},"excerpt":"<p>Java中，equals和==有何区别？</p>","more":"<p><code>==</code>是什么？</p>\n<ul>\n<li><code>==</code>是二元运算符；</li>\n<li>对于基本数据类型，<code>==</code>比较的是值是否相等；</li>\n<li>对于对象，<code>==</code>比较的是两个引用是否指向同一个内存地址；</li>\n</ul>\n<p><code>equals</code>是什么？</p>\n<ul>\n<li><p><code>equals</code>是顶层父类<code>java.lang.Object</code>的成员方法，此方法需通过非空对象调用，其源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">equals</span><span class=\"params\">(Object obj)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"keyword\">this</span> == obj);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在子类没有重写<code>equals</code>方法的情况下，比较的是两个引用是否指向同一个内存地址；</p>\n</li>\n<li>在子类重写了<code>equals</code>的情况下，比较的结果视其具体实现而定。例如：8大基本数据的包装数据类型、String类重写了equals方法，比较的是值是否相等。</li>\n</ul>\n<p>对于equals，Java有个规定：</p>\n<blockquote>\n<p>Note that it is generally necessary to override the hashCode method whenever this method is overridden, so as to maintain the general contract for the hashCode method, which states that equal objects must have equal hash codes.</p>\n</blockquote>\n<blockquote>\n<p>长话短说：若两个对象使用equals比较返回true，它们的hashCode方法返回的值必须相等。</p>\n</blockquote>\n<p>Why？下回详解。</p>"},{"title":"浅谈左移算法","date":"2017-07-28T04:29:39.000Z","comments":1,"_content":"\n假设有一个字符串\"abcdefgh\"，循环左移3位后得到\"defghabc\"，本文讲解其中的一种左移算法。\n\n<!--more-->\n\n已知条件如下：\n\n- 目标字符串（x）：abcdefgh\n- 字符串长度（n）：8\n- 循环左移位数（l）：3\n- 预期结果（y）：defghabc\n\n先考虑左移一位的情况，这个算法可以这样设计：\n\n- 将第一个字符x[0]暂存到变量t，然后x[1]赋给x[0]，x[2]赋给x[1]，以此类推\n- 结束条件为：x[i]的i等于n（即8），将t赋给x[n-1]（即x[7]）\n\n结束条件的特点是：x[i]的i对n做模运算等于缓存t时的字符数组下标（即0），继续归纳左移二位的情况：\n\n- x[0]赋给t，x[2]赋给x[0]，以此类推，结束条件同上，结束时t赋给x[6]\n- 然而x[1]，x[3]，x[5]，x[7]的位置是错的，按照上述规则执行一次移位，左移二位的工作全部完成\n\n这里的特点是n（即8）是l（即2）的倍数。第一次执行移位时，有4个字符的位置正确；第二次移位时，另外4个字符的位置也正确了，移位完成。这里可以归纳出来的结论是：**移位的次数为n与l的最大公约数**。\n\n因此，对于上文已知条件的求解，只需要按照上述算法执行一趟即可完成移位。算法的伪代码如下：\n\n```\n# gcd为最大公约数计算\nfor i in [0, gcd(n, l)):\n    t = x[i]\n    j = i\n    while true:\n        k = (j + l) % n\n\tif k == i:\n\t    break\n\tx[j] = x[k]\n\tj = k\n    x[j] = t\n```\n\n注：\n\n1. 算法整理自《编程珠玑2》\n2. 还有一种思路是：将字符串存储在一个循环链表中，然后偏移index指针到开始位置，按顺序进行读取即可，但比上述算法耗费空间（每个字符需要持有两个指针，一个指向前，一个指向后）\n","source":"_posts/2017-07-28-left-shift.md","raw":"---\ntitle: 浅谈左移算法\ndate: 2017-07-28 12:29:39\ntags: ['C/C++']\ncomments: true\ncategories: ['算法']\n---\n\n假设有一个字符串\"abcdefgh\"，循环左移3位后得到\"defghabc\"，本文讲解其中的一种左移算法。\n\n<!--more-->\n\n已知条件如下：\n\n- 目标字符串（x）：abcdefgh\n- 字符串长度（n）：8\n- 循环左移位数（l）：3\n- 预期结果（y）：defghabc\n\n先考虑左移一位的情况，这个算法可以这样设计：\n\n- 将第一个字符x[0]暂存到变量t，然后x[1]赋给x[0]，x[2]赋给x[1]，以此类推\n- 结束条件为：x[i]的i等于n（即8），将t赋给x[n-1]（即x[7]）\n\n结束条件的特点是：x[i]的i对n做模运算等于缓存t时的字符数组下标（即0），继续归纳左移二位的情况：\n\n- x[0]赋给t，x[2]赋给x[0]，以此类推，结束条件同上，结束时t赋给x[6]\n- 然而x[1]，x[3]，x[5]，x[7]的位置是错的，按照上述规则执行一次移位，左移二位的工作全部完成\n\n这里的特点是n（即8）是l（即2）的倍数。第一次执行移位时，有4个字符的位置正确；第二次移位时，另外4个字符的位置也正确了，移位完成。这里可以归纳出来的结论是：**移位的次数为n与l的最大公约数**。\n\n因此，对于上文已知条件的求解，只需要按照上述算法执行一趟即可完成移位。算法的伪代码如下：\n\n```\n# gcd为最大公约数计算\nfor i in [0, gcd(n, l)):\n    t = x[i]\n    j = i\n    while true:\n        k = (j + l) % n\n\tif k == i:\n\t    break\n\tx[j] = x[k]\n\tj = k\n    x[j] = t\n```\n\n注：\n\n1. 算法整理自《编程珠玑2》\n2. 还有一种思路是：将字符串存储在一个循环链表中，然后偏移index指针到开始位置，按顺序进行读取即可，但比上述算法耗费空间（每个字符需要持有两个指针，一个指向前，一个指向后）\n","slug":"left-shift","published":1,"updated":"2022-08-09T15:02:00.632Z","layout":"post","photos":[],"link":"","_id":"cl6mbc13w002digu82xugx110","content":"<p>假设有一个字符串”abcdefgh”，循环左移3位后得到”defghabc”，本文讲解其中的一种左移算法。</p>\n<a id=\"more\"></a>\n<p>已知条件如下：</p>\n<ul>\n<li>目标字符串（x）：abcdefgh</li>\n<li>字符串长度（n）：8</li>\n<li>循环左移位数（l）：3</li>\n<li>预期结果（y）：defghabc</li>\n</ul>\n<p>先考虑左移一位的情况，这个算法可以这样设计：</p>\n<ul>\n<li>将第一个字符x[0]暂存到变量t，然后x[1]赋给x[0]，x[2]赋给x[1]，以此类推</li>\n<li>结束条件为：x[i]的i等于n（即8），将t赋给x[n-1]（即x[7]）</li>\n</ul>\n<p>结束条件的特点是：x[i]的i对n做模运算等于缓存t时的字符数组下标（即0），继续归纳左移二位的情况：</p>\n<ul>\n<li>x[0]赋给t，x[2]赋给x[0]，以此类推，结束条件同上，结束时t赋给x[6]</li>\n<li>然而x[1]，x[3]，x[5]，x[7]的位置是错的，按照上述规则执行一次移位，左移二位的工作全部完成</li>\n</ul>\n<p>这里的特点是n（即8）是l（即2）的倍数。第一次执行移位时，有4个字符的位置正确；第二次移位时，另外4个字符的位置也正确了，移位完成。这里可以归纳出来的结论是：<strong>移位的次数为n与l的最大公约数</strong>。</p>\n<p>因此，对于上文已知条件的求解，只需要按照上述算法执行一趟即可完成移位。算法的伪代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># gcd为最大公约数计算</span><br><span class=\"line\">for i in [0, gcd(n, l)):</span><br><span class=\"line\">    t = x[i]</span><br><span class=\"line\">    j = i</span><br><span class=\"line\">    while true:</span><br><span class=\"line\">        k = (j + l) % n</span><br><span class=\"line\">\tif k == i:</span><br><span class=\"line\">\t    break</span><br><span class=\"line\">\tx[j] = x[k]</span><br><span class=\"line\">\tj = k</span><br><span class=\"line\">    x[j] = t</span><br></pre></td></tr></table></figure>\n<p>注：</p>\n<ol>\n<li>算法整理自《编程珠玑2》</li>\n<li>还有一种思路是：将字符串存储在一个循环链表中，然后偏移index指针到开始位置，按顺序进行读取即可，但比上述算法耗费空间（每个字符需要持有两个指针，一个指向前，一个指向后）</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>假设有一个字符串”abcdefgh”，循环左移3位后得到”defghabc”，本文讲解其中的一种左移算法。</p>","more":"<p>已知条件如下：</p>\n<ul>\n<li>目标字符串（x）：abcdefgh</li>\n<li>字符串长度（n）：8</li>\n<li>循环左移位数（l）：3</li>\n<li>预期结果（y）：defghabc</li>\n</ul>\n<p>先考虑左移一位的情况，这个算法可以这样设计：</p>\n<ul>\n<li>将第一个字符x[0]暂存到变量t，然后x[1]赋给x[0]，x[2]赋给x[1]，以此类推</li>\n<li>结束条件为：x[i]的i等于n（即8），将t赋给x[n-1]（即x[7]）</li>\n</ul>\n<p>结束条件的特点是：x[i]的i对n做模运算等于缓存t时的字符数组下标（即0），继续归纳左移二位的情况：</p>\n<ul>\n<li>x[0]赋给t，x[2]赋给x[0]，以此类推，结束条件同上，结束时t赋给x[6]</li>\n<li>然而x[1]，x[3]，x[5]，x[7]的位置是错的，按照上述规则执行一次移位，左移二位的工作全部完成</li>\n</ul>\n<p>这里的特点是n（即8）是l（即2）的倍数。第一次执行移位时，有4个字符的位置正确；第二次移位时，另外4个字符的位置也正确了，移位完成。这里可以归纳出来的结论是：<strong>移位的次数为n与l的最大公约数</strong>。</p>\n<p>因此，对于上文已知条件的求解，只需要按照上述算法执行一趟即可完成移位。算法的伪代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># gcd为最大公约数计算</span><br><span class=\"line\">for i in [0, gcd(n, l)):</span><br><span class=\"line\">    t = x[i]</span><br><span class=\"line\">    j = i</span><br><span class=\"line\">    while true:</span><br><span class=\"line\">        k = (j + l) % n</span><br><span class=\"line\">\tif k == i:</span><br><span class=\"line\">\t    break</span><br><span class=\"line\">\tx[j] = x[k]</span><br><span class=\"line\">\tj = k</span><br><span class=\"line\">    x[j] = t</span><br></pre></td></tr></table></figure>\n<p>注：</p>\n<ol>\n<li>算法整理自《编程珠玑2》</li>\n<li>还有一种思路是：将字符串存储在一个循环链表中，然后偏移index指针到开始位置，按顺序进行读取即可，但比上述算法耗费空间（每个字符需要持有两个指针，一个指向前，一个指向后）</li>\n</ol>"},{"title":"Too many open files in java","date":"2018-06-16T09:00:05.000Z","comments":1,"_content":"\nLinux平台下，每个进程能打开的文件描述符是有上限的，这个参数可以通过`ulimit`命令查看和在运行时设置，但若想持久化该配置，需配置到`sysctl.conf`，具体如何\n配置请自行百度。本文记录Java进程「too many open files」的错误，其原因便是打开的文件描述符超过了OS的上限。\n\n<!--more-->\n\n## Linux平台下如何诊断可能存在「too many open files」错误\n\n- 首先，通过`ps`命令查找到进程ID，如`2343`\n- 然后，使用`ls -l /proc/2343/fd`命令可以查看到具体打开了什么类型的文件描述符，如常见的pipe和socket。使用`ls -l /proc/2343/fd|wc -l`可对进程打开的文件描述符进行计数，如果这个数值不断在增大，说明程序存在文件描述符未正常关闭的BUG。注：这里的`2343`请替换为实际进程ID。\n\n## 常见原因是什么\n\n- 一种常见原因是文件流没有正常关闭，解决办法是使用try-finally或try-with-resources确保流的正常关闭。特殊的是，对于`new BufferedReader(new InputStreamReader(process.getInputStream()))`这类代码，在关闭`BufferedReader`时会自动关闭`InputStreamReader`\n- 另一种常见原因是`Runtime.getRuntime().exec()`所导致的问题，[StackOverFlow](https://stackoverflow.com/questions/15956452/troubleshooting-too-many-files-open-with-lsof)上有详细的介绍，示例如下：\n\n```java\n    try\n    {\n        // exec()常用来做操作系统调用\n        p = Runtime.getRuntime().exec(\"something\");\n    }\n    finally\n    {\n        if (p != null)\n        {\n            // 调用完毕后，必须显示关闭标准输出流、错误输出流和输入流，否则会导致文件描述符没有正常释放\n            // 可直接p.getOutputStream().close()关闭\n            IOUtils.closeQuietly(p.getOutputStream());\n            IOUtils.closeQuietly(p.getInputStream());\n            IOUtils.closeQuietly(p.getErrorStream());\n            // 注意，destroy()方法并不负责流的关闭，这是一个非常隐晦的错误\n            p.destroy();\n        }\n    }\n```\n\n","source":"_posts/2018-06-16-too-many-open-files.md","raw":"---\ntitle: Too many open files in java\ndate: 2018-06-16 17:00:05\ntags: ['Java']\ncomments: true\ncategories: ['操作系统']\n---\n\nLinux平台下，每个进程能打开的文件描述符是有上限的，这个参数可以通过`ulimit`命令查看和在运行时设置，但若想持久化该配置，需配置到`sysctl.conf`，具体如何\n配置请自行百度。本文记录Java进程「too many open files」的错误，其原因便是打开的文件描述符超过了OS的上限。\n\n<!--more-->\n\n## Linux平台下如何诊断可能存在「too many open files」错误\n\n- 首先，通过`ps`命令查找到进程ID，如`2343`\n- 然后，使用`ls -l /proc/2343/fd`命令可以查看到具体打开了什么类型的文件描述符，如常见的pipe和socket。使用`ls -l /proc/2343/fd|wc -l`可对进程打开的文件描述符进行计数，如果这个数值不断在增大，说明程序存在文件描述符未正常关闭的BUG。注：这里的`2343`请替换为实际进程ID。\n\n## 常见原因是什么\n\n- 一种常见原因是文件流没有正常关闭，解决办法是使用try-finally或try-with-resources确保流的正常关闭。特殊的是，对于`new BufferedReader(new InputStreamReader(process.getInputStream()))`这类代码，在关闭`BufferedReader`时会自动关闭`InputStreamReader`\n- 另一种常见原因是`Runtime.getRuntime().exec()`所导致的问题，[StackOverFlow](https://stackoverflow.com/questions/15956452/troubleshooting-too-many-files-open-with-lsof)上有详细的介绍，示例如下：\n\n```java\n    try\n    {\n        // exec()常用来做操作系统调用\n        p = Runtime.getRuntime().exec(\"something\");\n    }\n    finally\n    {\n        if (p != null)\n        {\n            // 调用完毕后，必须显示关闭标准输出流、错误输出流和输入流，否则会导致文件描述符没有正常释放\n            // 可直接p.getOutputStream().close()关闭\n            IOUtils.closeQuietly(p.getOutputStream());\n            IOUtils.closeQuietly(p.getInputStream());\n            IOUtils.closeQuietly(p.getErrorStream());\n            // 注意，destroy()方法并不负责流的关闭，这是一个非常隐晦的错误\n            p.destroy();\n        }\n    }\n```\n\n","slug":"too-many-open-files","published":1,"updated":"2022-08-09T15:02:00.639Z","layout":"post","photos":[],"link":"","_id":"cl6mbc13x002gigu82p77vda1","content":"<p>Linux平台下，每个进程能打开的文件描述符是有上限的，这个参数可以通过<code>ulimit</code>命令查看和在运行时设置，但若想持久化该配置，需配置到<code>sysctl.conf</code>，具体如何<br>配置请自行百度。本文记录Java进程「too many open files」的错误，其原因便是打开的文件描述符超过了OS的上限。</p>\n<a id=\"more\"></a>\n<h2 id=\"Linux平台下如何诊断可能存在「too-many-open-files」错误\"><a href=\"#Linux平台下如何诊断可能存在「too-many-open-files」错误\" class=\"headerlink\" title=\"Linux平台下如何诊断可能存在「too many open files」错误\"></a>Linux平台下如何诊断可能存在「too many open files」错误</h2><ul>\n<li>首先，通过<code>ps</code>命令查找到进程ID，如<code>2343</code></li>\n<li>然后，使用<code>ls -l /proc/2343/fd</code>命令可以查看到具体打开了什么类型的文件描述符，如常见的pipe和socket。使用<code>ls -l /proc/2343/fd|wc -l</code>可对进程打开的文件描述符进行计数，如果这个数值不断在增大，说明程序存在文件描述符未正常关闭的BUG。注：这里的<code>2343</code>请替换为实际进程ID。</li>\n</ul>\n<h2 id=\"常见原因是什么\"><a href=\"#常见原因是什么\" class=\"headerlink\" title=\"常见原因是什么\"></a>常见原因是什么</h2><ul>\n<li>一种常见原因是文件流没有正常关闭，解决办法是使用try-finally或try-with-resources确保流的正常关闭。特殊的是，对于<code>new BufferedReader(new InputStreamReader(process.getInputStream()))</code>这类代码，在关闭<code>BufferedReader</code>时会自动关闭<code>InputStreamReader</code></li>\n<li>另一种常见原因是<code>Runtime.getRuntime().exec()</code>所导致的问题，<a href=\"https://stackoverflow.com/questions/15956452/troubleshooting-too-many-files-open-with-lsof\" target=\"_blank\" rel=\"noopener\">StackOverFlow</a>上有详细的介绍，示例如下：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">try</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// exec()常用来做操作系统调用</span></span><br><span class=\"line\">    p = Runtime.getRuntime().exec(<span class=\"string\">\"something\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">finally</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p != <span class=\"keyword\">null</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 调用完毕后，必须显示关闭标准输出流、错误输出流和输入流，否则会导致文件描述符没有正常释放</span></span><br><span class=\"line\">        <span class=\"comment\">// 可直接p.getOutputStream().close()关闭</span></span><br><span class=\"line\">        IOUtils.closeQuietly(p.getOutputStream());</span><br><span class=\"line\">        IOUtils.closeQuietly(p.getInputStream());</span><br><span class=\"line\">        IOUtils.closeQuietly(p.getErrorStream());</span><br><span class=\"line\">        <span class=\"comment\">// 注意，destroy()方法并不负责流的关闭，这是一个非常隐晦的错误</span></span><br><span class=\"line\">        p.destroy();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>Linux平台下，每个进程能打开的文件描述符是有上限的，这个参数可以通过<code>ulimit</code>命令查看和在运行时设置，但若想持久化该配置，需配置到<code>sysctl.conf</code>，具体如何<br>配置请自行百度。本文记录Java进程「too many open files」的错误，其原因便是打开的文件描述符超过了OS的上限。</p>","more":"<h2 id=\"Linux平台下如何诊断可能存在「too-many-open-files」错误\"><a href=\"#Linux平台下如何诊断可能存在「too-many-open-files」错误\" class=\"headerlink\" title=\"Linux平台下如何诊断可能存在「too many open files」错误\"></a>Linux平台下如何诊断可能存在「too many open files」错误</h2><ul>\n<li>首先，通过<code>ps</code>命令查找到进程ID，如<code>2343</code></li>\n<li>然后，使用<code>ls -l /proc/2343/fd</code>命令可以查看到具体打开了什么类型的文件描述符，如常见的pipe和socket。使用<code>ls -l /proc/2343/fd|wc -l</code>可对进程打开的文件描述符进行计数，如果这个数值不断在增大，说明程序存在文件描述符未正常关闭的BUG。注：这里的<code>2343</code>请替换为实际进程ID。</li>\n</ul>\n<h2 id=\"常见原因是什么\"><a href=\"#常见原因是什么\" class=\"headerlink\" title=\"常见原因是什么\"></a>常见原因是什么</h2><ul>\n<li>一种常见原因是文件流没有正常关闭，解决办法是使用try-finally或try-with-resources确保流的正常关闭。特殊的是，对于<code>new BufferedReader(new InputStreamReader(process.getInputStream()))</code>这类代码，在关闭<code>BufferedReader</code>时会自动关闭<code>InputStreamReader</code></li>\n<li>另一种常见原因是<code>Runtime.getRuntime().exec()</code>所导致的问题，<a href=\"https://stackoverflow.com/questions/15956452/troubleshooting-too-many-files-open-with-lsof\" target=\"_blank\" rel=\"noopener\">StackOverFlow</a>上有详细的介绍，示例如下：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">try</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// exec()常用来做操作系统调用</span></span><br><span class=\"line\">    p = Runtime.getRuntime().exec(<span class=\"string\">\"something\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">finally</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p != <span class=\"keyword\">null</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 调用完毕后，必须显示关闭标准输出流、错误输出流和输入流，否则会导致文件描述符没有正常释放</span></span><br><span class=\"line\">        <span class=\"comment\">// 可直接p.getOutputStream().close()关闭</span></span><br><span class=\"line\">        IOUtils.closeQuietly(p.getOutputStream());</span><br><span class=\"line\">        IOUtils.closeQuietly(p.getInputStream());</span><br><span class=\"line\">        IOUtils.closeQuietly(p.getErrorStream());</span><br><span class=\"line\">        <span class=\"comment\">// 注意，destroy()方法并不负责流的关闭，这是一个非常隐晦的错误</span></span><br><span class=\"line\">        p.destroy();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"如何诊断java程序CPU占用率过高","date":"2018-07-07T15:13:53.000Z","comments":1,"_content":"\n在最近一次编程时，我的一个Java应用在嵌入式设备bbblack上的CPU占用率高达60%至70%，简单记录我是如何诊断这个问题的。\n\n<!--more-->\n\nGitHub上有一个项目[jvmtop](https://github.com/patric-r/jvmtop)，借助于jvmtop这个工具，我们可以指定Java进程的pid进行profile，命令如下：\n\n```java\njvmtop <pid>\n```\n\n产生的输出大概如下：\n```\nJvmTop 0.4.1 alpha   amd64,  4 cpus, Linux 2.6.18-34\n https://github.com/patric-r/jvmtop\n\n PID 3539: org.apache.catalina.startup.Bootstrap\n ARGS: start\n VMARGS: -Djava.util.logging.config.file=/home/webserver/apache-tomcat-5.5[...]\n VM: Sun Microsystems Inc. Java HotSpot(TM) 64-Bit Server VM 1.6.0_25\n UP: 869:33m #THR: 106  #THRPEAK: 143  #THRCREATED: 128020 USER: webserver\n CPU:  4.55% GC:  3.25% HEAP: 137m / 227m NONHEAP:  75m / 304m\n Note: Only top 10 threads (according cpu load) are shown!\n\n  TID   NAME                                    STATE    CPU  TOTALCPU BLOCKEDBY\n     25 http-8080-Processor13                RUNNABLE  4.55%     1.60%\n 128022 RMI TCP Connection(18)-10.101.       RUNNABLE  1.82%     0.02%\n  36578 http-8080-Processor164               RUNNABLE  0.91%     2.35%\n  36453 http-8080-Processor94                RUNNABLE  0.91%     1.52%\n     27 http-8080-Processor15                RUNNABLE  0.91%     1.81%\n     14 http-8080-Processor2                 RUNNABLE  0.91%     3.17%\n 128026 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%\n 128025 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%\n 128024 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%\n 128023 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%\n```\n\n通过其输出，我们可以判断出是哪个线程占用较高CPU，以及线程出于什么样的状态。使用`jvmtop -e <pid>`还可以具体确定是哪个方法占用CPU时间片最多。通过这些信息，我定位到了异常：**我的某个循环体出现了死循环**。\n","source":"_posts/2018-07-07-jvmtop-profile.md","raw":"---\ntitle: 如何诊断java程序CPU占用率过高\ndate: 2018-07-07 23:13:53\ntags: ['Java']\ncomments: true\ncategories: ['编程实践']\n---\n\n在最近一次编程时，我的一个Java应用在嵌入式设备bbblack上的CPU占用率高达60%至70%，简单记录我是如何诊断这个问题的。\n\n<!--more-->\n\nGitHub上有一个项目[jvmtop](https://github.com/patric-r/jvmtop)，借助于jvmtop这个工具，我们可以指定Java进程的pid进行profile，命令如下：\n\n```java\njvmtop <pid>\n```\n\n产生的输出大概如下：\n```\nJvmTop 0.4.1 alpha   amd64,  4 cpus, Linux 2.6.18-34\n https://github.com/patric-r/jvmtop\n\n PID 3539: org.apache.catalina.startup.Bootstrap\n ARGS: start\n VMARGS: -Djava.util.logging.config.file=/home/webserver/apache-tomcat-5.5[...]\n VM: Sun Microsystems Inc. Java HotSpot(TM) 64-Bit Server VM 1.6.0_25\n UP: 869:33m #THR: 106  #THRPEAK: 143  #THRCREATED: 128020 USER: webserver\n CPU:  4.55% GC:  3.25% HEAP: 137m / 227m NONHEAP:  75m / 304m\n Note: Only top 10 threads (according cpu load) are shown!\n\n  TID   NAME                                    STATE    CPU  TOTALCPU BLOCKEDBY\n     25 http-8080-Processor13                RUNNABLE  4.55%     1.60%\n 128022 RMI TCP Connection(18)-10.101.       RUNNABLE  1.82%     0.02%\n  36578 http-8080-Processor164               RUNNABLE  0.91%     2.35%\n  36453 http-8080-Processor94                RUNNABLE  0.91%     1.52%\n     27 http-8080-Processor15                RUNNABLE  0.91%     1.81%\n     14 http-8080-Processor2                 RUNNABLE  0.91%     3.17%\n 128026 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%\n 128025 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%\n 128024 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%\n 128023 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%\n```\n\n通过其输出，我们可以判断出是哪个线程占用较高CPU，以及线程出于什么样的状态。使用`jvmtop -e <pid>`还可以具体确定是哪个方法占用CPU时间片最多。通过这些信息，我定位到了异常：**我的某个循环体出现了死循环**。\n","slug":"jvmtop-profile","published":1,"updated":"2022-08-09T15:02:00.639Z","layout":"post","photos":[],"link":"","_id":"cl6mbc141002kigu8x8as7cg0","content":"<p>在最近一次编程时，我的一个Java应用在嵌入式设备bbblack上的CPU占用率高达60%至70%，简单记录我是如何诊断这个问题的。</p>\n<a id=\"more\"></a>\n<p>GitHub上有一个项目<a href=\"https://github.com/patric-r/jvmtop\" target=\"_blank\" rel=\"noopener\">jvmtop</a>，借助于jvmtop这个工具，我们可以指定Java进程的pid进行profile，命令如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jvmtop &lt;pid&gt;</span><br></pre></td></tr></table></figure>\n<p>产生的输出大概如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JvmTop 0.4.1 alpha   amd64,  4 cpus, Linux 2.6.18-34</span><br><span class=\"line\"> https://github.com/patric-r/jvmtop</span><br><span class=\"line\"></span><br><span class=\"line\"> PID 3539: org.apache.catalina.startup.Bootstrap</span><br><span class=\"line\"> ARGS: start</span><br><span class=\"line\"> VMARGS: -Djava.util.logging.config.file=/home/webserver/apache-tomcat-5.5[...]</span><br><span class=\"line\"> VM: Sun Microsystems Inc. Java HotSpot(TM) 64-Bit Server VM 1.6.0_25</span><br><span class=\"line\"> UP: 869:33m #THR: 106  #THRPEAK: 143  #THRCREATED: 128020 USER: webserver</span><br><span class=\"line\"> CPU:  4.55% GC:  3.25% HEAP: 137m / 227m NONHEAP:  75m / 304m</span><br><span class=\"line\"> Note: Only top 10 threads (according cpu load) are shown!</span><br><span class=\"line\"></span><br><span class=\"line\">  TID   NAME                                    STATE    CPU  TOTALCPU BLOCKEDBY</span><br><span class=\"line\">     25 http-8080-Processor13                RUNNABLE  4.55%     1.60%</span><br><span class=\"line\"> 128022 RMI TCP Connection(18)-10.101.       RUNNABLE  1.82%     0.02%</span><br><span class=\"line\">  36578 http-8080-Processor164               RUNNABLE  0.91%     2.35%</span><br><span class=\"line\">  36453 http-8080-Processor94                RUNNABLE  0.91%     1.52%</span><br><span class=\"line\">     27 http-8080-Processor15                RUNNABLE  0.91%     1.81%</span><br><span class=\"line\">     14 http-8080-Processor2                 RUNNABLE  0.91%     3.17%</span><br><span class=\"line\"> 128026 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%</span><br><span class=\"line\"> 128025 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%</span><br><span class=\"line\"> 128024 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%</span><br><span class=\"line\"> 128023 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%</span><br></pre></td></tr></table></figure></p>\n<p>通过其输出，我们可以判断出是哪个线程占用较高CPU，以及线程出于什么样的状态。使用<code>jvmtop -e &lt;pid&gt;</code>还可以具体确定是哪个方法占用CPU时间片最多。通过这些信息，我定位到了异常：<strong>我的某个循环体出现了死循环</strong>。</p>\n","site":{"data":{}},"excerpt":"<p>在最近一次编程时，我的一个Java应用在嵌入式设备bbblack上的CPU占用率高达60%至70%，简单记录我是如何诊断这个问题的。</p>","more":"<p>GitHub上有一个项目<a href=\"https://github.com/patric-r/jvmtop\" target=\"_blank\" rel=\"noopener\">jvmtop</a>，借助于jvmtop这个工具，我们可以指定Java进程的pid进行profile，命令如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jvmtop &lt;pid&gt;</span><br></pre></td></tr></table></figure>\n<p>产生的输出大概如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JvmTop 0.4.1 alpha   amd64,  4 cpus, Linux 2.6.18-34</span><br><span class=\"line\"> https://github.com/patric-r/jvmtop</span><br><span class=\"line\"></span><br><span class=\"line\"> PID 3539: org.apache.catalina.startup.Bootstrap</span><br><span class=\"line\"> ARGS: start</span><br><span class=\"line\"> VMARGS: -Djava.util.logging.config.file=/home/webserver/apache-tomcat-5.5[...]</span><br><span class=\"line\"> VM: Sun Microsystems Inc. Java HotSpot(TM) 64-Bit Server VM 1.6.0_25</span><br><span class=\"line\"> UP: 869:33m #THR: 106  #THRPEAK: 143  #THRCREATED: 128020 USER: webserver</span><br><span class=\"line\"> CPU:  4.55% GC:  3.25% HEAP: 137m / 227m NONHEAP:  75m / 304m</span><br><span class=\"line\"> Note: Only top 10 threads (according cpu load) are shown!</span><br><span class=\"line\"></span><br><span class=\"line\">  TID   NAME                                    STATE    CPU  TOTALCPU BLOCKEDBY</span><br><span class=\"line\">     25 http-8080-Processor13                RUNNABLE  4.55%     1.60%</span><br><span class=\"line\"> 128022 RMI TCP Connection(18)-10.101.       RUNNABLE  1.82%     0.02%</span><br><span class=\"line\">  36578 http-8080-Processor164               RUNNABLE  0.91%     2.35%</span><br><span class=\"line\">  36453 http-8080-Processor94                RUNNABLE  0.91%     1.52%</span><br><span class=\"line\">     27 http-8080-Processor15                RUNNABLE  0.91%     1.81%</span><br><span class=\"line\">     14 http-8080-Processor2                 RUNNABLE  0.91%     3.17%</span><br><span class=\"line\"> 128026 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%</span><br><span class=\"line\"> 128025 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%</span><br><span class=\"line\"> 128024 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%</span><br><span class=\"line\"> 128023 JMX server connection timeout   TIMED_WAITING  0.00%     0.00%</span><br></pre></td></tr></table></figure></p>\n<p>通过其输出，我们可以判断出是哪个线程占用较高CPU，以及线程出于什么样的状态。使用<code>jvmtop -e &lt;pid&gt;</code>还可以具体确定是哪个方法占用CPU时间片最多。通过这些信息，我定位到了异常：<strong>我的某个循环体出现了死循环</strong>。</p>"},{"title":"使用JMC+JFR+JProfile检测Java程序异常","date":"2018-09-12T15:03:39.000Z","comments":1,"_content":"\n本文记录使用JMC（Java Mission Controll）、JFR（Java Flight Record）以及JProfile诊断Java应用不可用（OutOfMemroy）的过程。\n\n<!--more-->\n\n# 术语说明\n\n- **搜计程序**：搜索与计算引擎服务程序。\n- **接口服务（function）**：搜计程序通过dubbo和http暴露出来的服务，调用此接口服务可获取相关数据，搜计程序有多个接口服务，接口服务的别名为function。接口服务的名称及调用入参，由客户通过搜计程序的管理界面设定。\n- **调用者**：调用搜计程序接口服务的进程，如Web系统。\n- **调用请求**：调用者对搜计程序提供的接口服务进行一次RPC调用称为一次调用请求。\n- **执行步骤（procedure）**：接口服务被调用后，通常需要在后台执行一次或多次计算过程，每个计算过程称为一个执行步骤，别名为procedure。接口服务最终返回的结果，依赖于各执行步骤结果的聚合。执行步骤的内部细节（查询的字段、是否联表等），由客户通过搜计程序的管理界面设定。\n- **Limit参数**：当数据无限多时，理论上来讲function以及procedure返回的数据可能无限多，因此必须对返回结果的行数进行限定。此限定参数称为limit参数，格式一般为limit offset, number。Offset表示前多少条结果需要被忽略，number表示忽略了offset条结果后需要取的结果数量。\n\n# 现象描述\n\n搜计程序出现了OutOfMemoryError、调用者请求无响应以及调用请求耗时较长等问题。\n\n## JVM表现\n\n8月29至9月1，搜计程序部署在192.168.8.181服务器用于自定义项目自测时，发生了多次的OutOfMemoryError，截取部分信息如下：\n\n> java.lang.OutOfMemoryError: GC overhead limit exceeded\n> ![OutOfMemoryError](https://user-images.githubusercontent.com/4915189/71431495-1c3c6680-270d-11ea-90d1-363a669926ad.png)\n\n\n## OS表现\n\n搜计程序在181服务器的最大堆内存（Xmx）为8G，通过监测发现，程序在濒临OutOfMemoryError时，实用memory为8G，实用+swap的memory为9G。程序在OutOfMemoryError前，有接近1G的内存被swap到了硬盘，表明程序本身所需内存不断增大，同时OS可用内存不足。\n\n## 调用者表现\n\nWeb系统等调用搜计程序接口服务的进程，出现了调用接口服务无返回数据，以及调用接口服务后需要等待长时间才有返回数据的情况。\n\n# 原因分析\n\n通过Java Flight Recoder对181服务器的搜计程序进行1小时的采样，得到以下信息，基于这些信息可推测出搜计程序OutOfMemoryError以及无响应的原因。\n\n## CPU及分析\n\n![图01 程序OutOfMemoryError前的CPU使用率](https://user-images.githubusercontent.com/4915189/71431503-20688400-270d-11ea-9daa-25778fbe457c.png)\n\n通过图01分析发现，程序OutOfMemoryError前，有一段时间CPU使用率急剧上升，随后下降一段时间，然后又急剧上升。且CPU使用率的急剧上升，是由JVM用户线程导致的（图01蓝色部分）。\n\n![图02 程序OutOfMemoryError前的热点线程和热点方法分析](https://user-images.githubusercontent.com/4915189/71431506-23fc0b00-270d-11ea-9cde-f38238128793.png)\n\n通过图02分析发现，程序OutOfMemoryError前，存在大量的上下文切换，CPU时间主要分配给了调用请求响应线程（dubbo）。\n\n基于以上信息，推测搜计程序的OutOfMemoryError可能和大量的调用请求有关。\n\n## 内存分析\n\n![图03 程序OutOfMemoryError前的内存使用情况](https://user-images.githubusercontent.com/4915189/71431507-28c0bf00-270d-11ea-8279-1079cb2c8039.png)\n\n如图03所示，堆内存的低谷节节攀升。在程序退出前（红框处），即使是GC后，也接近有3G的大小。通过dump内存分析后发现，搜计程序大部分内存基本分布在程序的mergeData方法，而mergeData是由调用请求触发的。\n\n基于以上信息以及**3.4 内存泄漏分析**，可以断定搜计程序的OutOfMemoryError是由调用请求导致的。\n\n## GC分析\n\n![图04 程序OutOfMemoryError前young gc和full gc监控](https://user-images.githubusercontent.com/4915189/71431509-2bbbaf80-270d-11ea-922d-2be36cd1c0a1.png)\n\n如果04所示，通过监控搜计程序的gc次数和时间发现：程序full gc的次数（252），远大于young gc的次数（9）；同时full gc的时间（750秒），远大于young gc的时间（3.2秒）。当程序长时间处于GC状态时，调用请求对应的用户线程将长时间处于阻塞状态，得不到响应，这是程序变慢最直接的原因。大部分用户线程处于阻塞状态如图05所示。\n\n![图 05 Park表示线程处于阻塞状态](https://user-images.githubusercontent.com/4915189/71431511-2eb6a000-270d-11ea-93ee-2ea28c6759d1.png)\n\n![图06 程序OutOfMemoryError前发生了一次时间特别长的FULL GC](https://user-images.githubusercontent.com/4915189/71431514-3413ea80-270d-11ea-8f82-040fe8cbb8cc.png)\n\n图06所示，程序OutOfMemoryError前发生了一次时间特别长的FULL GC，且仅回收了400M的内存。这是JVM出现“GC overhead limit exceeded”的根本原因。表明了GC时间太长，但回收的内存太少。\n\n当Full GC后，JVM依然没有足够内存提供给应用线程时，JVM就会抛出OutOfMemoryError。基于以上信息，可得出程序OutOfMemoryError的根本原因是大量调用请求导致的JVM内存不足。而大量请求之所以会导致JVM内存不足，**主要原因在于部分调用请求在每个执行步骤申请了大量的堆内存，如日志查询等调用请求**。如果频繁的、并发的调用日志查询请求，搜计程序短时间内就会产生OutOfMemoryError。\n\n## 内存泄漏分析\n\n![图07 搜计程序0ld gen长时间监控](https://user-images.githubusercontent.com/4915189/71431518-370edb00-270d-11ea-8da0-368182699273.png)\n\n使用3个调用者线程，对搜计程序进行长达三天的不间断调用，但限定每次调用请求仅获取少量数据。图07为这期间的old gen内存使用情况，经历gc后old gen的内存基本持稳在0.07GB。这表明搜计程序在请求不多、请求数据量不大的情况下，JVM内存回收正常，程序本身没有存在内存泄漏。\n\n# 解决方案\n\n基于以上分析，归结得出程序OutOfMemoryError的主要原因：部分调用请求的执行步骤，申请了大量内存耗尽JVM可用内存导致的程序问题。\n\n![图08 一次调用请求](https://user-images.githubusercontent.com/4915189/71431520-3c6c2580-270d-11ea-96a7-600262a7dedb.png)\n\n如图08所示，为一次导致OutOfMemoryError调用请求的示例。S1和S2表示执行步骤，S1和S2汇总后得到最终结果返回给调用者。且S1和S2所需的内存较多，超过了JVM的可用内存，Full GC后便会导致OutOfMemoryError。\n\n针对此问题，大致整理有以下解决方案。\n\n## 重新审视产品需求\n\n从新审视产品需求，为何有请求大量数据的调用请求，需考虑：\n\n1） 这些调用请求是否是必要的，如果不必要则去除；\n\n2） 减少调用请求的执行步骤数量（尽可能不要联表查询，减少执行步骤的滞留内存）；\n\n3） 减少执行步骤命中的结果数量（多加一些查询参数的制约）。\n\n以上，需要和产品需求制定者和调用者进行沟通讨论。\n\n## 在现有程序进行维护\n\n### 常规策略\n\n**1）废除全连接**\n\n左连接和内连接已经足以应对业务需要，是否还需要有全连接的支持。\n\n**2）查询结果重用（带超时）**\n\n- 对于查询大量数据的调用请求，应将接口服务产生的结果缓存到硬盘（带过期时间，过期自动清除），下次若请求相同数据，则直接查询缓存结果并返回；\n\n- 对于查询大量数据的调用请求，若有两个调用请求同时请求相同的数据，则后到的连接等待先到的连接查询完成，复用先到的连接产生的结果返回给调用者。\n\n（这种做法的代价是一定程度上牺牲了数据的实时性，即命中缓存时，可能某些真实数据已经产生了变化）\n\n**3）限定请求数量**\n\n限定调用请求的最大并发数量，防止调用请求过多，超出搜计程序的负载能力。\n\n**4）调用请求必须要有默认limit参数**\n\n假设数据库的数据有无限多行，调用请求不允许一次请求超过一定行数（假设是10000行）。首先，搜计程序一次提供太多行的数据作为返回结果，会导致堆内存暴增；其次，调用者获取这么多行的数据，也会导致内存暴增。正确的做法应该是调用者分多次调用，每次仅获取一定量的数据。\n\n**5）及时释放执行步骤申请的内存若未被后续执行步骤引用**\n\n假设一次调用请求需经历15个执行步骤，部分较前的执行步骤到了第10个执行步骤时，可能已经没有后续执行步骤对其有引用关系，此时应将该未被引用的执行步骤的内容置为null，告知JVM这块内存是可以回收的。\n\n### 用IO换取内存的策略\n\n![图09 将S1步骤的数据获取转为链式IO](https://user-images.githubusercontent.com/4915189/71431522-40984300-270d-11ea-8fb8-9a3b79ec213a.png)\n\n\n如图09所示，S1为一个需用到大量堆内存的执行步骤。原有的做法是一次性将S1需要用到的全部数据都从数据库查出，并加载到内存。一种改进措施是，**分多次查询数据，逐次将部分结果加载入内存**。\n\n例如，如上图所示，先加载n1到内存中，进行必要计算后，将n1计算产生的结果缓存到硬盘，并在内存记录n1计算产生的结果的相关索引信息。\n\n紧接着，加载n2到内存中，重复前述步骤，直至全部数据查询完毕。此时，便将S1的全部计算执行完毕，且在内存中记录了少量的、必要的关于各个分步骤的索引信息，这些索引信息包括了结果缓存在硬盘什么位置、有多少行等。\n\n这个做法的代价是：\n\n1） 若有大量数据的调用请求时，将产生大量的顺序读和顺序写IO，给硬盘带来巨大负载，因此必须使用独立的硬盘，而不是和其他应用程序公用。另外，出于性能考虑，独立的硬盘最好是固态硬盘。\n\n2） 由于存在频繁的写，硬盘的寿命将比普通用途缩短很多；\n\n3） 由于采用了分小步骤执行，一定程度丧失了数据的实时性，如执行n2的计算时，很可能n1的数据在数据库中已经被修改了；\n\n4） **开发的复杂度难以预估**。聚合函数、计算函数、其他高级函数，以及两个执行步骤产生的结果的联表和分组，全部受到影响，这些逻辑基本都需要修改，以支持这种IO换取内存的策略。\n\n5）**如若查询命中的数据量是与日俱增的，此方案将造成长时间写IO，最终能为程序新的性能瓶颈。**\n\n## 彻底重构\n\n目前搜计程序执行多个执行步骤，并汇总得到最终结果的过程无比复杂，相当于实现了一个自用的SQL的执行引擎。同事建议可以引入Kylin，以替代现有的执行引擎。\n\nKylin是一套旨在对Hadoop环境下分析流程进行加速、且能够与SQL兼容性工具顺利协作的解决方案，Kylin成功将SQL接口与多维分析机制（OLAP）引入Hadoop，旨在对规模极为庞大的数据集加以支持。\n\n对于Kylin能否替代现有解决方案，还需要做进一步的研究。代价是，若此方案可行，原执行引擎需要全部推翻重写。\n\n## 增大内存\n\n物理上，增大机器内存，搜计程序所需内存远大于8G。至于具体需要增大到多少，需根据并发量、请求数据量进行制定。建议大小是32G。\n\n","source":"_posts/2018-09-12-use-jmc-jfr-jprofile.md","raw":"---\ntitle: 使用JMC+JFR+JProfile检测Java程序异常\ndate: 2018-09-12 23:03:39\ntags: ['Java']\ncomments: true\ncategories: ['编程实践']\n---\n\n本文记录使用JMC（Java Mission Controll）、JFR（Java Flight Record）以及JProfile诊断Java应用不可用（OutOfMemroy）的过程。\n\n<!--more-->\n\n# 术语说明\n\n- **搜计程序**：搜索与计算引擎服务程序。\n- **接口服务（function）**：搜计程序通过dubbo和http暴露出来的服务，调用此接口服务可获取相关数据，搜计程序有多个接口服务，接口服务的别名为function。接口服务的名称及调用入参，由客户通过搜计程序的管理界面设定。\n- **调用者**：调用搜计程序接口服务的进程，如Web系统。\n- **调用请求**：调用者对搜计程序提供的接口服务进行一次RPC调用称为一次调用请求。\n- **执行步骤（procedure）**：接口服务被调用后，通常需要在后台执行一次或多次计算过程，每个计算过程称为一个执行步骤，别名为procedure。接口服务最终返回的结果，依赖于各执行步骤结果的聚合。执行步骤的内部细节（查询的字段、是否联表等），由客户通过搜计程序的管理界面设定。\n- **Limit参数**：当数据无限多时，理论上来讲function以及procedure返回的数据可能无限多，因此必须对返回结果的行数进行限定。此限定参数称为limit参数，格式一般为limit offset, number。Offset表示前多少条结果需要被忽略，number表示忽略了offset条结果后需要取的结果数量。\n\n# 现象描述\n\n搜计程序出现了OutOfMemoryError、调用者请求无响应以及调用请求耗时较长等问题。\n\n## JVM表现\n\n8月29至9月1，搜计程序部署在192.168.8.181服务器用于自定义项目自测时，发生了多次的OutOfMemoryError，截取部分信息如下：\n\n> java.lang.OutOfMemoryError: GC overhead limit exceeded\n> ![OutOfMemoryError](https://user-images.githubusercontent.com/4915189/71431495-1c3c6680-270d-11ea-90d1-363a669926ad.png)\n\n\n## OS表现\n\n搜计程序在181服务器的最大堆内存（Xmx）为8G，通过监测发现，程序在濒临OutOfMemoryError时，实用memory为8G，实用+swap的memory为9G。程序在OutOfMemoryError前，有接近1G的内存被swap到了硬盘，表明程序本身所需内存不断增大，同时OS可用内存不足。\n\n## 调用者表现\n\nWeb系统等调用搜计程序接口服务的进程，出现了调用接口服务无返回数据，以及调用接口服务后需要等待长时间才有返回数据的情况。\n\n# 原因分析\n\n通过Java Flight Recoder对181服务器的搜计程序进行1小时的采样，得到以下信息，基于这些信息可推测出搜计程序OutOfMemoryError以及无响应的原因。\n\n## CPU及分析\n\n![图01 程序OutOfMemoryError前的CPU使用率](https://user-images.githubusercontent.com/4915189/71431503-20688400-270d-11ea-9daa-25778fbe457c.png)\n\n通过图01分析发现，程序OutOfMemoryError前，有一段时间CPU使用率急剧上升，随后下降一段时间，然后又急剧上升。且CPU使用率的急剧上升，是由JVM用户线程导致的（图01蓝色部分）。\n\n![图02 程序OutOfMemoryError前的热点线程和热点方法分析](https://user-images.githubusercontent.com/4915189/71431506-23fc0b00-270d-11ea-9cde-f38238128793.png)\n\n通过图02分析发现，程序OutOfMemoryError前，存在大量的上下文切换，CPU时间主要分配给了调用请求响应线程（dubbo）。\n\n基于以上信息，推测搜计程序的OutOfMemoryError可能和大量的调用请求有关。\n\n## 内存分析\n\n![图03 程序OutOfMemoryError前的内存使用情况](https://user-images.githubusercontent.com/4915189/71431507-28c0bf00-270d-11ea-8279-1079cb2c8039.png)\n\n如图03所示，堆内存的低谷节节攀升。在程序退出前（红框处），即使是GC后，也接近有3G的大小。通过dump内存分析后发现，搜计程序大部分内存基本分布在程序的mergeData方法，而mergeData是由调用请求触发的。\n\n基于以上信息以及**3.4 内存泄漏分析**，可以断定搜计程序的OutOfMemoryError是由调用请求导致的。\n\n## GC分析\n\n![图04 程序OutOfMemoryError前young gc和full gc监控](https://user-images.githubusercontent.com/4915189/71431509-2bbbaf80-270d-11ea-922d-2be36cd1c0a1.png)\n\n如果04所示，通过监控搜计程序的gc次数和时间发现：程序full gc的次数（252），远大于young gc的次数（9）；同时full gc的时间（750秒），远大于young gc的时间（3.2秒）。当程序长时间处于GC状态时，调用请求对应的用户线程将长时间处于阻塞状态，得不到响应，这是程序变慢最直接的原因。大部分用户线程处于阻塞状态如图05所示。\n\n![图 05 Park表示线程处于阻塞状态](https://user-images.githubusercontent.com/4915189/71431511-2eb6a000-270d-11ea-93ee-2ea28c6759d1.png)\n\n![图06 程序OutOfMemoryError前发生了一次时间特别长的FULL GC](https://user-images.githubusercontent.com/4915189/71431514-3413ea80-270d-11ea-8f82-040fe8cbb8cc.png)\n\n图06所示，程序OutOfMemoryError前发生了一次时间特别长的FULL GC，且仅回收了400M的内存。这是JVM出现“GC overhead limit exceeded”的根本原因。表明了GC时间太长，但回收的内存太少。\n\n当Full GC后，JVM依然没有足够内存提供给应用线程时，JVM就会抛出OutOfMemoryError。基于以上信息，可得出程序OutOfMemoryError的根本原因是大量调用请求导致的JVM内存不足。而大量请求之所以会导致JVM内存不足，**主要原因在于部分调用请求在每个执行步骤申请了大量的堆内存，如日志查询等调用请求**。如果频繁的、并发的调用日志查询请求，搜计程序短时间内就会产生OutOfMemoryError。\n\n## 内存泄漏分析\n\n![图07 搜计程序0ld gen长时间监控](https://user-images.githubusercontent.com/4915189/71431518-370edb00-270d-11ea-8da0-368182699273.png)\n\n使用3个调用者线程，对搜计程序进行长达三天的不间断调用，但限定每次调用请求仅获取少量数据。图07为这期间的old gen内存使用情况，经历gc后old gen的内存基本持稳在0.07GB。这表明搜计程序在请求不多、请求数据量不大的情况下，JVM内存回收正常，程序本身没有存在内存泄漏。\n\n# 解决方案\n\n基于以上分析，归结得出程序OutOfMemoryError的主要原因：部分调用请求的执行步骤，申请了大量内存耗尽JVM可用内存导致的程序问题。\n\n![图08 一次调用请求](https://user-images.githubusercontent.com/4915189/71431520-3c6c2580-270d-11ea-96a7-600262a7dedb.png)\n\n如图08所示，为一次导致OutOfMemoryError调用请求的示例。S1和S2表示执行步骤，S1和S2汇总后得到最终结果返回给调用者。且S1和S2所需的内存较多，超过了JVM的可用内存，Full GC后便会导致OutOfMemoryError。\n\n针对此问题，大致整理有以下解决方案。\n\n## 重新审视产品需求\n\n从新审视产品需求，为何有请求大量数据的调用请求，需考虑：\n\n1） 这些调用请求是否是必要的，如果不必要则去除；\n\n2） 减少调用请求的执行步骤数量（尽可能不要联表查询，减少执行步骤的滞留内存）；\n\n3） 减少执行步骤命中的结果数量（多加一些查询参数的制约）。\n\n以上，需要和产品需求制定者和调用者进行沟通讨论。\n\n## 在现有程序进行维护\n\n### 常规策略\n\n**1）废除全连接**\n\n左连接和内连接已经足以应对业务需要，是否还需要有全连接的支持。\n\n**2）查询结果重用（带超时）**\n\n- 对于查询大量数据的调用请求，应将接口服务产生的结果缓存到硬盘（带过期时间，过期自动清除），下次若请求相同数据，则直接查询缓存结果并返回；\n\n- 对于查询大量数据的调用请求，若有两个调用请求同时请求相同的数据，则后到的连接等待先到的连接查询完成，复用先到的连接产生的结果返回给调用者。\n\n（这种做法的代价是一定程度上牺牲了数据的实时性，即命中缓存时，可能某些真实数据已经产生了变化）\n\n**3）限定请求数量**\n\n限定调用请求的最大并发数量，防止调用请求过多，超出搜计程序的负载能力。\n\n**4）调用请求必须要有默认limit参数**\n\n假设数据库的数据有无限多行，调用请求不允许一次请求超过一定行数（假设是10000行）。首先，搜计程序一次提供太多行的数据作为返回结果，会导致堆内存暴增；其次，调用者获取这么多行的数据，也会导致内存暴增。正确的做法应该是调用者分多次调用，每次仅获取一定量的数据。\n\n**5）及时释放执行步骤申请的内存若未被后续执行步骤引用**\n\n假设一次调用请求需经历15个执行步骤，部分较前的执行步骤到了第10个执行步骤时，可能已经没有后续执行步骤对其有引用关系，此时应将该未被引用的执行步骤的内容置为null，告知JVM这块内存是可以回收的。\n\n### 用IO换取内存的策略\n\n![图09 将S1步骤的数据获取转为链式IO](https://user-images.githubusercontent.com/4915189/71431522-40984300-270d-11ea-8fb8-9a3b79ec213a.png)\n\n\n如图09所示，S1为一个需用到大量堆内存的执行步骤。原有的做法是一次性将S1需要用到的全部数据都从数据库查出，并加载到内存。一种改进措施是，**分多次查询数据，逐次将部分结果加载入内存**。\n\n例如，如上图所示，先加载n1到内存中，进行必要计算后，将n1计算产生的结果缓存到硬盘，并在内存记录n1计算产生的结果的相关索引信息。\n\n紧接着，加载n2到内存中，重复前述步骤，直至全部数据查询完毕。此时，便将S1的全部计算执行完毕，且在内存中记录了少量的、必要的关于各个分步骤的索引信息，这些索引信息包括了结果缓存在硬盘什么位置、有多少行等。\n\n这个做法的代价是：\n\n1） 若有大量数据的调用请求时，将产生大量的顺序读和顺序写IO，给硬盘带来巨大负载，因此必须使用独立的硬盘，而不是和其他应用程序公用。另外，出于性能考虑，独立的硬盘最好是固态硬盘。\n\n2） 由于存在频繁的写，硬盘的寿命将比普通用途缩短很多；\n\n3） 由于采用了分小步骤执行，一定程度丧失了数据的实时性，如执行n2的计算时，很可能n1的数据在数据库中已经被修改了；\n\n4） **开发的复杂度难以预估**。聚合函数、计算函数、其他高级函数，以及两个执行步骤产生的结果的联表和分组，全部受到影响，这些逻辑基本都需要修改，以支持这种IO换取内存的策略。\n\n5）**如若查询命中的数据量是与日俱增的，此方案将造成长时间写IO，最终能为程序新的性能瓶颈。**\n\n## 彻底重构\n\n目前搜计程序执行多个执行步骤，并汇总得到最终结果的过程无比复杂，相当于实现了一个自用的SQL的执行引擎。同事建议可以引入Kylin，以替代现有的执行引擎。\n\nKylin是一套旨在对Hadoop环境下分析流程进行加速、且能够与SQL兼容性工具顺利协作的解决方案，Kylin成功将SQL接口与多维分析机制（OLAP）引入Hadoop，旨在对规模极为庞大的数据集加以支持。\n\n对于Kylin能否替代现有解决方案，还需要做进一步的研究。代价是，若此方案可行，原执行引擎需要全部推翻重写。\n\n## 增大内存\n\n物理上，增大机器内存，搜计程序所需内存远大于8G。至于具体需要增大到多少，需根据并发量、请求数据量进行制定。建议大小是32G。\n\n","slug":"use-jmc-jfr-jprofile","published":1,"updated":"2022-08-09T15:02:00.640Z","layout":"post","photos":[],"link":"","_id":"cl6mbc142002nigu8oe0tskr5","content":"<p>本文记录使用JMC（Java Mission Controll）、JFR（Java Flight Record）以及JProfile诊断Java应用不可用（OutOfMemroy）的过程。</p>\n<a id=\"more\"></a>\n<h1 id=\"术语说明\"><a href=\"#术语说明\" class=\"headerlink\" title=\"术语说明\"></a>术语说明</h1><ul>\n<li><strong>搜计程序</strong>：搜索与计算引擎服务程序。</li>\n<li><strong>接口服务（function）</strong>：搜计程序通过dubbo和http暴露出来的服务，调用此接口服务可获取相关数据，搜计程序有多个接口服务，接口服务的别名为function。接口服务的名称及调用入参，由客户通过搜计程序的管理界面设定。</li>\n<li><strong>调用者</strong>：调用搜计程序接口服务的进程，如Web系统。</li>\n<li><strong>调用请求</strong>：调用者对搜计程序提供的接口服务进行一次RPC调用称为一次调用请求。</li>\n<li><strong>执行步骤（procedure）</strong>：接口服务被调用后，通常需要在后台执行一次或多次计算过程，每个计算过程称为一个执行步骤，别名为procedure。接口服务最终返回的结果，依赖于各执行步骤结果的聚合。执行步骤的内部细节（查询的字段、是否联表等），由客户通过搜计程序的管理界面设定。</li>\n<li><strong>Limit参数</strong>：当数据无限多时，理论上来讲function以及procedure返回的数据可能无限多，因此必须对返回结果的行数进行限定。此限定参数称为limit参数，格式一般为limit offset, number。Offset表示前多少条结果需要被忽略，number表示忽略了offset条结果后需要取的结果数量。</li>\n</ul>\n<h1 id=\"现象描述\"><a href=\"#现象描述\" class=\"headerlink\" title=\"现象描述\"></a>现象描述</h1><p>搜计程序出现了OutOfMemoryError、调用者请求无响应以及调用请求耗时较长等问题。</p>\n<h2 id=\"JVM表现\"><a href=\"#JVM表现\" class=\"headerlink\" title=\"JVM表现\"></a>JVM表现</h2><p>8月29至9月1，搜计程序部署在192.168.8.181服务器用于自定义项目自测时，发生了多次的OutOfMemoryError，截取部分信息如下：</p>\n<blockquote>\n<p>java.lang.OutOfMemoryError: GC overhead limit exceeded<br><img src=\"https://user-images.githubusercontent.com/4915189/71431495-1c3c6680-270d-11ea-90d1-363a669926ad.png\" alt=\"OutOfMemoryError\"></p>\n</blockquote>\n<h2 id=\"OS表现\"><a href=\"#OS表现\" class=\"headerlink\" title=\"OS表现\"></a>OS表现</h2><p>搜计程序在181服务器的最大堆内存（Xmx）为8G，通过监测发现，程序在濒临OutOfMemoryError时，实用memory为8G，实用+swap的memory为9G。程序在OutOfMemoryError前，有接近1G的内存被swap到了硬盘，表明程序本身所需内存不断增大，同时OS可用内存不足。</p>\n<h2 id=\"调用者表现\"><a href=\"#调用者表现\" class=\"headerlink\" title=\"调用者表现\"></a>调用者表现</h2><p>Web系统等调用搜计程序接口服务的进程，出现了调用接口服务无返回数据，以及调用接口服务后需要等待长时间才有返回数据的情况。</p>\n<h1 id=\"原因分析\"><a href=\"#原因分析\" class=\"headerlink\" title=\"原因分析\"></a>原因分析</h1><p>通过Java Flight Recoder对181服务器的搜计程序进行1小时的采样，得到以下信息，基于这些信息可推测出搜计程序OutOfMemoryError以及无响应的原因。</p>\n<h2 id=\"CPU及分析\"><a href=\"#CPU及分析\" class=\"headerlink\" title=\"CPU及分析\"></a>CPU及分析</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431503-20688400-270d-11ea-9daa-25778fbe457c.png\" alt=\"图01 程序OutOfMemoryError前的CPU使用率\"></p>\n<p>通过图01分析发现，程序OutOfMemoryError前，有一段时间CPU使用率急剧上升，随后下降一段时间，然后又急剧上升。且CPU使用率的急剧上升，是由JVM用户线程导致的（图01蓝色部分）。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431506-23fc0b00-270d-11ea-9cde-f38238128793.png\" alt=\"图02 程序OutOfMemoryError前的热点线程和热点方法分析\"></p>\n<p>通过图02分析发现，程序OutOfMemoryError前，存在大量的上下文切换，CPU时间主要分配给了调用请求响应线程（dubbo）。</p>\n<p>基于以上信息，推测搜计程序的OutOfMemoryError可能和大量的调用请求有关。</p>\n<h2 id=\"内存分析\"><a href=\"#内存分析\" class=\"headerlink\" title=\"内存分析\"></a>内存分析</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431507-28c0bf00-270d-11ea-8279-1079cb2c8039.png\" alt=\"图03 程序OutOfMemoryError前的内存使用情况\"></p>\n<p>如图03所示，堆内存的低谷节节攀升。在程序退出前（红框处），即使是GC后，也接近有3G的大小。通过dump内存分析后发现，搜计程序大部分内存基本分布在程序的mergeData方法，而mergeData是由调用请求触发的。</p>\n<p>基于以上信息以及<strong>3.4 内存泄漏分析</strong>，可以断定搜计程序的OutOfMemoryError是由调用请求导致的。</p>\n<h2 id=\"GC分析\"><a href=\"#GC分析\" class=\"headerlink\" title=\"GC分析\"></a>GC分析</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431509-2bbbaf80-270d-11ea-922d-2be36cd1c0a1.png\" alt=\"图04 程序OutOfMemoryError前young gc和full gc监控\"></p>\n<p>如果04所示，通过监控搜计程序的gc次数和时间发现：程序full gc的次数（252），远大于young gc的次数（9）；同时full gc的时间（750秒），远大于young gc的时间（3.2秒）。当程序长时间处于GC状态时，调用请求对应的用户线程将长时间处于阻塞状态，得不到响应，这是程序变慢最直接的原因。大部分用户线程处于阻塞状态如图05所示。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431511-2eb6a000-270d-11ea-93ee-2ea28c6759d1.png\" alt=\"图 05 Park表示线程处于阻塞状态\"></p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431514-3413ea80-270d-11ea-8f82-040fe8cbb8cc.png\" alt=\"图06 程序OutOfMemoryError前发生了一次时间特别长的FULL GC\"></p>\n<p>图06所示，程序OutOfMemoryError前发生了一次时间特别长的FULL GC，且仅回收了400M的内存。这是JVM出现“GC overhead limit exceeded”的根本原因。表明了GC时间太长，但回收的内存太少。</p>\n<p>当Full GC后，JVM依然没有足够内存提供给应用线程时，JVM就会抛出OutOfMemoryError。基于以上信息，可得出程序OutOfMemoryError的根本原因是大量调用请求导致的JVM内存不足。而大量请求之所以会导致JVM内存不足，<strong>主要原因在于部分调用请求在每个执行步骤申请了大量的堆内存，如日志查询等调用请求</strong>。如果频繁的、并发的调用日志查询请求，搜计程序短时间内就会产生OutOfMemoryError。</p>\n<h2 id=\"内存泄漏分析\"><a href=\"#内存泄漏分析\" class=\"headerlink\" title=\"内存泄漏分析\"></a>内存泄漏分析</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431518-370edb00-270d-11ea-8da0-368182699273.png\" alt=\"图07 搜计程序0ld gen长时间监控\"></p>\n<p>使用3个调用者线程，对搜计程序进行长达三天的不间断调用，但限定每次调用请求仅获取少量数据。图07为这期间的old gen内存使用情况，经历gc后old gen的内存基本持稳在0.07GB。这表明搜计程序在请求不多、请求数据量不大的情况下，JVM内存回收正常，程序本身没有存在内存泄漏。</p>\n<h1 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h1><p>基于以上分析，归结得出程序OutOfMemoryError的主要原因：部分调用请求的执行步骤，申请了大量内存耗尽JVM可用内存导致的程序问题。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431520-3c6c2580-270d-11ea-96a7-600262a7dedb.png\" alt=\"图08 一次调用请求\"></p>\n<p>如图08所示，为一次导致OutOfMemoryError调用请求的示例。S1和S2表示执行步骤，S1和S2汇总后得到最终结果返回给调用者。且S1和S2所需的内存较多，超过了JVM的可用内存，Full GC后便会导致OutOfMemoryError。</p>\n<p>针对此问题，大致整理有以下解决方案。</p>\n<h2 id=\"重新审视产品需求\"><a href=\"#重新审视产品需求\" class=\"headerlink\" title=\"重新审视产品需求\"></a>重新审视产品需求</h2><p>从新审视产品需求，为何有请求大量数据的调用请求，需考虑：</p>\n<p>1） 这些调用请求是否是必要的，如果不必要则去除；</p>\n<p>2） 减少调用请求的执行步骤数量（尽可能不要联表查询，减少执行步骤的滞留内存）；</p>\n<p>3） 减少执行步骤命中的结果数量（多加一些查询参数的制约）。</p>\n<p>以上，需要和产品需求制定者和调用者进行沟通讨论。</p>\n<h2 id=\"在现有程序进行维护\"><a href=\"#在现有程序进行维护\" class=\"headerlink\" title=\"在现有程序进行维护\"></a>在现有程序进行维护</h2><h3 id=\"常规策略\"><a href=\"#常规策略\" class=\"headerlink\" title=\"常规策略\"></a>常规策略</h3><p><strong>1）废除全连接</strong></p>\n<p>左连接和内连接已经足以应对业务需要，是否还需要有全连接的支持。</p>\n<p><strong>2）查询结果重用（带超时）</strong></p>\n<ul>\n<li><p>对于查询大量数据的调用请求，应将接口服务产生的结果缓存到硬盘（带过期时间，过期自动清除），下次若请求相同数据，则直接查询缓存结果并返回；</p>\n</li>\n<li><p>对于查询大量数据的调用请求，若有两个调用请求同时请求相同的数据，则后到的连接等待先到的连接查询完成，复用先到的连接产生的结果返回给调用者。</p>\n</li>\n</ul>\n<p>（这种做法的代价是一定程度上牺牲了数据的实时性，即命中缓存时，可能某些真实数据已经产生了变化）</p>\n<p><strong>3）限定请求数量</strong></p>\n<p>限定调用请求的最大并发数量，防止调用请求过多，超出搜计程序的负载能力。</p>\n<p><strong>4）调用请求必须要有默认limit参数</strong></p>\n<p>假设数据库的数据有无限多行，调用请求不允许一次请求超过一定行数（假设是10000行）。首先，搜计程序一次提供太多行的数据作为返回结果，会导致堆内存暴增；其次，调用者获取这么多行的数据，也会导致内存暴增。正确的做法应该是调用者分多次调用，每次仅获取一定量的数据。</p>\n<p><strong>5）及时释放执行步骤申请的内存若未被后续执行步骤引用</strong></p>\n<p>假设一次调用请求需经历15个执行步骤，部分较前的执行步骤到了第10个执行步骤时，可能已经没有后续执行步骤对其有引用关系，此时应将该未被引用的执行步骤的内容置为null，告知JVM这块内存是可以回收的。</p>\n<h3 id=\"用IO换取内存的策略\"><a href=\"#用IO换取内存的策略\" class=\"headerlink\" title=\"用IO换取内存的策略\"></a>用IO换取内存的策略</h3><p><img src=\"https://user-images.githubusercontent.com/4915189/71431522-40984300-270d-11ea-8fb8-9a3b79ec213a.png\" alt=\"图09 将S1步骤的数据获取转为链式IO\"></p>\n<p>如图09所示，S1为一个需用到大量堆内存的执行步骤。原有的做法是一次性将S1需要用到的全部数据都从数据库查出，并加载到内存。一种改进措施是，<strong>分多次查询数据，逐次将部分结果加载入内存</strong>。</p>\n<p>例如，如上图所示，先加载n1到内存中，进行必要计算后，将n1计算产生的结果缓存到硬盘，并在内存记录n1计算产生的结果的相关索引信息。</p>\n<p>紧接着，加载n2到内存中，重复前述步骤，直至全部数据查询完毕。此时，便将S1的全部计算执行完毕，且在内存中记录了少量的、必要的关于各个分步骤的索引信息，这些索引信息包括了结果缓存在硬盘什么位置、有多少行等。</p>\n<p>这个做法的代价是：</p>\n<p>1） 若有大量数据的调用请求时，将产生大量的顺序读和顺序写IO，给硬盘带来巨大负载，因此必须使用独立的硬盘，而不是和其他应用程序公用。另外，出于性能考虑，独立的硬盘最好是固态硬盘。</p>\n<p>2） 由于存在频繁的写，硬盘的寿命将比普通用途缩短很多；</p>\n<p>3） 由于采用了分小步骤执行，一定程度丧失了数据的实时性，如执行n2的计算时，很可能n1的数据在数据库中已经被修改了；</p>\n<p>4） <strong>开发的复杂度难以预估</strong>。聚合函数、计算函数、其他高级函数，以及两个执行步骤产生的结果的联表和分组，全部受到影响，这些逻辑基本都需要修改，以支持这种IO换取内存的策略。</p>\n<p>5）<strong>如若查询命中的数据量是与日俱增的，此方案将造成长时间写IO，最终能为程序新的性能瓶颈。</strong></p>\n<h2 id=\"彻底重构\"><a href=\"#彻底重构\" class=\"headerlink\" title=\"彻底重构\"></a>彻底重构</h2><p>目前搜计程序执行多个执行步骤，并汇总得到最终结果的过程无比复杂，相当于实现了一个自用的SQL的执行引擎。同事建议可以引入Kylin，以替代现有的执行引擎。</p>\n<p>Kylin是一套旨在对Hadoop环境下分析流程进行加速、且能够与SQL兼容性工具顺利协作的解决方案，Kylin成功将SQL接口与多维分析机制（OLAP）引入Hadoop，旨在对规模极为庞大的数据集加以支持。</p>\n<p>对于Kylin能否替代现有解决方案，还需要做进一步的研究。代价是，若此方案可行，原执行引擎需要全部推翻重写。</p>\n<h2 id=\"增大内存\"><a href=\"#增大内存\" class=\"headerlink\" title=\"增大内存\"></a>增大内存</h2><p>物理上，增大机器内存，搜计程序所需内存远大于8G。至于具体需要增大到多少，需根据并发量、请求数据量进行制定。建议大小是32G。</p>\n","site":{"data":{}},"excerpt":"<p>本文记录使用JMC（Java Mission Controll）、JFR（Java Flight Record）以及JProfile诊断Java应用不可用（OutOfMemroy）的过程。</p>","more":"<h1 id=\"术语说明\"><a href=\"#术语说明\" class=\"headerlink\" title=\"术语说明\"></a>术语说明</h1><ul>\n<li><strong>搜计程序</strong>：搜索与计算引擎服务程序。</li>\n<li><strong>接口服务（function）</strong>：搜计程序通过dubbo和http暴露出来的服务，调用此接口服务可获取相关数据，搜计程序有多个接口服务，接口服务的别名为function。接口服务的名称及调用入参，由客户通过搜计程序的管理界面设定。</li>\n<li><strong>调用者</strong>：调用搜计程序接口服务的进程，如Web系统。</li>\n<li><strong>调用请求</strong>：调用者对搜计程序提供的接口服务进行一次RPC调用称为一次调用请求。</li>\n<li><strong>执行步骤（procedure）</strong>：接口服务被调用后，通常需要在后台执行一次或多次计算过程，每个计算过程称为一个执行步骤，别名为procedure。接口服务最终返回的结果，依赖于各执行步骤结果的聚合。执行步骤的内部细节（查询的字段、是否联表等），由客户通过搜计程序的管理界面设定。</li>\n<li><strong>Limit参数</strong>：当数据无限多时，理论上来讲function以及procedure返回的数据可能无限多，因此必须对返回结果的行数进行限定。此限定参数称为limit参数，格式一般为limit offset, number。Offset表示前多少条结果需要被忽略，number表示忽略了offset条结果后需要取的结果数量。</li>\n</ul>\n<h1 id=\"现象描述\"><a href=\"#现象描述\" class=\"headerlink\" title=\"现象描述\"></a>现象描述</h1><p>搜计程序出现了OutOfMemoryError、调用者请求无响应以及调用请求耗时较长等问题。</p>\n<h2 id=\"JVM表现\"><a href=\"#JVM表现\" class=\"headerlink\" title=\"JVM表现\"></a>JVM表现</h2><p>8月29至9月1，搜计程序部署在192.168.8.181服务器用于自定义项目自测时，发生了多次的OutOfMemoryError，截取部分信息如下：</p>\n<blockquote>\n<p>java.lang.OutOfMemoryError: GC overhead limit exceeded<br><img src=\"https://user-images.githubusercontent.com/4915189/71431495-1c3c6680-270d-11ea-90d1-363a669926ad.png\" alt=\"OutOfMemoryError\"></p>\n</blockquote>\n<h2 id=\"OS表现\"><a href=\"#OS表现\" class=\"headerlink\" title=\"OS表现\"></a>OS表现</h2><p>搜计程序在181服务器的最大堆内存（Xmx）为8G，通过监测发现，程序在濒临OutOfMemoryError时，实用memory为8G，实用+swap的memory为9G。程序在OutOfMemoryError前，有接近1G的内存被swap到了硬盘，表明程序本身所需内存不断增大，同时OS可用内存不足。</p>\n<h2 id=\"调用者表现\"><a href=\"#调用者表现\" class=\"headerlink\" title=\"调用者表现\"></a>调用者表现</h2><p>Web系统等调用搜计程序接口服务的进程，出现了调用接口服务无返回数据，以及调用接口服务后需要等待长时间才有返回数据的情况。</p>\n<h1 id=\"原因分析\"><a href=\"#原因分析\" class=\"headerlink\" title=\"原因分析\"></a>原因分析</h1><p>通过Java Flight Recoder对181服务器的搜计程序进行1小时的采样，得到以下信息，基于这些信息可推测出搜计程序OutOfMemoryError以及无响应的原因。</p>\n<h2 id=\"CPU及分析\"><a href=\"#CPU及分析\" class=\"headerlink\" title=\"CPU及分析\"></a>CPU及分析</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431503-20688400-270d-11ea-9daa-25778fbe457c.png\" alt=\"图01 程序OutOfMemoryError前的CPU使用率\"></p>\n<p>通过图01分析发现，程序OutOfMemoryError前，有一段时间CPU使用率急剧上升，随后下降一段时间，然后又急剧上升。且CPU使用率的急剧上升，是由JVM用户线程导致的（图01蓝色部分）。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431506-23fc0b00-270d-11ea-9cde-f38238128793.png\" alt=\"图02 程序OutOfMemoryError前的热点线程和热点方法分析\"></p>\n<p>通过图02分析发现，程序OutOfMemoryError前，存在大量的上下文切换，CPU时间主要分配给了调用请求响应线程（dubbo）。</p>\n<p>基于以上信息，推测搜计程序的OutOfMemoryError可能和大量的调用请求有关。</p>\n<h2 id=\"内存分析\"><a href=\"#内存分析\" class=\"headerlink\" title=\"内存分析\"></a>内存分析</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431507-28c0bf00-270d-11ea-8279-1079cb2c8039.png\" alt=\"图03 程序OutOfMemoryError前的内存使用情况\"></p>\n<p>如图03所示，堆内存的低谷节节攀升。在程序退出前（红框处），即使是GC后，也接近有3G的大小。通过dump内存分析后发现，搜计程序大部分内存基本分布在程序的mergeData方法，而mergeData是由调用请求触发的。</p>\n<p>基于以上信息以及<strong>3.4 内存泄漏分析</strong>，可以断定搜计程序的OutOfMemoryError是由调用请求导致的。</p>\n<h2 id=\"GC分析\"><a href=\"#GC分析\" class=\"headerlink\" title=\"GC分析\"></a>GC分析</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431509-2bbbaf80-270d-11ea-922d-2be36cd1c0a1.png\" alt=\"图04 程序OutOfMemoryError前young gc和full gc监控\"></p>\n<p>如果04所示，通过监控搜计程序的gc次数和时间发现：程序full gc的次数（252），远大于young gc的次数（9）；同时full gc的时间（750秒），远大于young gc的时间（3.2秒）。当程序长时间处于GC状态时，调用请求对应的用户线程将长时间处于阻塞状态，得不到响应，这是程序变慢最直接的原因。大部分用户线程处于阻塞状态如图05所示。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431511-2eb6a000-270d-11ea-93ee-2ea28c6759d1.png\" alt=\"图 05 Park表示线程处于阻塞状态\"></p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431514-3413ea80-270d-11ea-8f82-040fe8cbb8cc.png\" alt=\"图06 程序OutOfMemoryError前发生了一次时间特别长的FULL GC\"></p>\n<p>图06所示，程序OutOfMemoryError前发生了一次时间特别长的FULL GC，且仅回收了400M的内存。这是JVM出现“GC overhead limit exceeded”的根本原因。表明了GC时间太长，但回收的内存太少。</p>\n<p>当Full GC后，JVM依然没有足够内存提供给应用线程时，JVM就会抛出OutOfMemoryError。基于以上信息，可得出程序OutOfMemoryError的根本原因是大量调用请求导致的JVM内存不足。而大量请求之所以会导致JVM内存不足，<strong>主要原因在于部分调用请求在每个执行步骤申请了大量的堆内存，如日志查询等调用请求</strong>。如果频繁的、并发的调用日志查询请求，搜计程序短时间内就会产生OutOfMemoryError。</p>\n<h2 id=\"内存泄漏分析\"><a href=\"#内存泄漏分析\" class=\"headerlink\" title=\"内存泄漏分析\"></a>内存泄漏分析</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431518-370edb00-270d-11ea-8da0-368182699273.png\" alt=\"图07 搜计程序0ld gen长时间监控\"></p>\n<p>使用3个调用者线程，对搜计程序进行长达三天的不间断调用，但限定每次调用请求仅获取少量数据。图07为这期间的old gen内存使用情况，经历gc后old gen的内存基本持稳在0.07GB。这表明搜计程序在请求不多、请求数据量不大的情况下，JVM内存回收正常，程序本身没有存在内存泄漏。</p>\n<h1 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h1><p>基于以上分析，归结得出程序OutOfMemoryError的主要原因：部分调用请求的执行步骤，申请了大量内存耗尽JVM可用内存导致的程序问题。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431520-3c6c2580-270d-11ea-96a7-600262a7dedb.png\" alt=\"图08 一次调用请求\"></p>\n<p>如图08所示，为一次导致OutOfMemoryError调用请求的示例。S1和S2表示执行步骤，S1和S2汇总后得到最终结果返回给调用者。且S1和S2所需的内存较多，超过了JVM的可用内存，Full GC后便会导致OutOfMemoryError。</p>\n<p>针对此问题，大致整理有以下解决方案。</p>\n<h2 id=\"重新审视产品需求\"><a href=\"#重新审视产品需求\" class=\"headerlink\" title=\"重新审视产品需求\"></a>重新审视产品需求</h2><p>从新审视产品需求，为何有请求大量数据的调用请求，需考虑：</p>\n<p>1） 这些调用请求是否是必要的，如果不必要则去除；</p>\n<p>2） 减少调用请求的执行步骤数量（尽可能不要联表查询，减少执行步骤的滞留内存）；</p>\n<p>3） 减少执行步骤命中的结果数量（多加一些查询参数的制约）。</p>\n<p>以上，需要和产品需求制定者和调用者进行沟通讨论。</p>\n<h2 id=\"在现有程序进行维护\"><a href=\"#在现有程序进行维护\" class=\"headerlink\" title=\"在现有程序进行维护\"></a>在现有程序进行维护</h2><h3 id=\"常规策略\"><a href=\"#常规策略\" class=\"headerlink\" title=\"常规策略\"></a>常规策略</h3><p><strong>1）废除全连接</strong></p>\n<p>左连接和内连接已经足以应对业务需要，是否还需要有全连接的支持。</p>\n<p><strong>2）查询结果重用（带超时）</strong></p>\n<ul>\n<li><p>对于查询大量数据的调用请求，应将接口服务产生的结果缓存到硬盘（带过期时间，过期自动清除），下次若请求相同数据，则直接查询缓存结果并返回；</p>\n</li>\n<li><p>对于查询大量数据的调用请求，若有两个调用请求同时请求相同的数据，则后到的连接等待先到的连接查询完成，复用先到的连接产生的结果返回给调用者。</p>\n</li>\n</ul>\n<p>（这种做法的代价是一定程度上牺牲了数据的实时性，即命中缓存时，可能某些真实数据已经产生了变化）</p>\n<p><strong>3）限定请求数量</strong></p>\n<p>限定调用请求的最大并发数量，防止调用请求过多，超出搜计程序的负载能力。</p>\n<p><strong>4）调用请求必须要有默认limit参数</strong></p>\n<p>假设数据库的数据有无限多行，调用请求不允许一次请求超过一定行数（假设是10000行）。首先，搜计程序一次提供太多行的数据作为返回结果，会导致堆内存暴增；其次，调用者获取这么多行的数据，也会导致内存暴增。正确的做法应该是调用者分多次调用，每次仅获取一定量的数据。</p>\n<p><strong>5）及时释放执行步骤申请的内存若未被后续执行步骤引用</strong></p>\n<p>假设一次调用请求需经历15个执行步骤，部分较前的执行步骤到了第10个执行步骤时，可能已经没有后续执行步骤对其有引用关系，此时应将该未被引用的执行步骤的内容置为null，告知JVM这块内存是可以回收的。</p>\n<h3 id=\"用IO换取内存的策略\"><a href=\"#用IO换取内存的策略\" class=\"headerlink\" title=\"用IO换取内存的策略\"></a>用IO换取内存的策略</h3><p><img src=\"https://user-images.githubusercontent.com/4915189/71431522-40984300-270d-11ea-8fb8-9a3b79ec213a.png\" alt=\"图09 将S1步骤的数据获取转为链式IO\"></p>\n<p>如图09所示，S1为一个需用到大量堆内存的执行步骤。原有的做法是一次性将S1需要用到的全部数据都从数据库查出，并加载到内存。一种改进措施是，<strong>分多次查询数据，逐次将部分结果加载入内存</strong>。</p>\n<p>例如，如上图所示，先加载n1到内存中，进行必要计算后，将n1计算产生的结果缓存到硬盘，并在内存记录n1计算产生的结果的相关索引信息。</p>\n<p>紧接着，加载n2到内存中，重复前述步骤，直至全部数据查询完毕。此时，便将S1的全部计算执行完毕，且在内存中记录了少量的、必要的关于各个分步骤的索引信息，这些索引信息包括了结果缓存在硬盘什么位置、有多少行等。</p>\n<p>这个做法的代价是：</p>\n<p>1） 若有大量数据的调用请求时，将产生大量的顺序读和顺序写IO，给硬盘带来巨大负载，因此必须使用独立的硬盘，而不是和其他应用程序公用。另外，出于性能考虑，独立的硬盘最好是固态硬盘。</p>\n<p>2） 由于存在频繁的写，硬盘的寿命将比普通用途缩短很多；</p>\n<p>3） 由于采用了分小步骤执行，一定程度丧失了数据的实时性，如执行n2的计算时，很可能n1的数据在数据库中已经被修改了；</p>\n<p>4） <strong>开发的复杂度难以预估</strong>。聚合函数、计算函数、其他高级函数，以及两个执行步骤产生的结果的联表和分组，全部受到影响，这些逻辑基本都需要修改，以支持这种IO换取内存的策略。</p>\n<p>5）<strong>如若查询命中的数据量是与日俱增的，此方案将造成长时间写IO，最终能为程序新的性能瓶颈。</strong></p>\n<h2 id=\"彻底重构\"><a href=\"#彻底重构\" class=\"headerlink\" title=\"彻底重构\"></a>彻底重构</h2><p>目前搜计程序执行多个执行步骤，并汇总得到最终结果的过程无比复杂，相当于实现了一个自用的SQL的执行引擎。同事建议可以引入Kylin，以替代现有的执行引擎。</p>\n<p>Kylin是一套旨在对Hadoop环境下分析流程进行加速、且能够与SQL兼容性工具顺利协作的解决方案，Kylin成功将SQL接口与多维分析机制（OLAP）引入Hadoop，旨在对规模极为庞大的数据集加以支持。</p>\n<p>对于Kylin能否替代现有解决方案，还需要做进一步的研究。代价是，若此方案可行，原执行引擎需要全部推翻重写。</p>\n<h2 id=\"增大内存\"><a href=\"#增大内存\" class=\"headerlink\" title=\"增大内存\"></a>增大内存</h2><p>物理上，增大机器内存，搜计程序所需内存远大于8G。至于具体需要增大到多少，需根据并发量、请求数据量进行制定。建议大小是32G。</p>"},{"title":"mysql mmm和mha对比","date":"2019-03-16T08:50:39.000Z","comments":1,"_content":"\n本文简单介绍MySQL的两个high availability方案，MMM和MHA。\n\n<!--more-->\n\n## MMM\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431448-e5fee700-270c-11ea-8139-12d41a02f4b4.png)\n\nMMM(Master-Master replication managerfor Mysql)的基本组成如下，\n- 主节点master1：承载写流量\n- 备主节点master2：replicate主节点master1的写流量，在主节点故障时被monitor提升为主节点，出于与master1数据强一致的考虑，replicate模式一般配置为semi-sync\n- 从节点slave1：replicate主节点master1的写流量，为使得master1的写足够快，一般将replicate模式设为异步\n- 从节点salve2：类似于slave1\n- mmm-agent：以上3个节点都需部署的代理，与monitor进行通信\n- mmm-mon：即monitor，与各mmm-agent通信探测其健康情况，并决策是否要切换主节点或从节点\n- wvip：提供写的虚拟IP，映射到当前活跃的主节点master1\n- rvip：提供读的虚拟IP，至少有一个，映射到slave1或slave2\n\nMMM的主节点切换过程如下：\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431454-eac39b00-270c-11ea-9899-b51b6260851f.png)\n\n- master1的mmm-agent与mmm-mon长期通信失败\n- mmm-mon请求master1的agent，移除VIP\n- mmm-mon请求master2的agent，绑定VIP\n- mmm-mon请求slave节点的agent，连接到新master进行replicate\n\n从节点的故障切换类似于上面的过程。\n\n优点如下，\n\n- 读写分离\n- fail自动切换\n\n缺点如下，\n\n- mmm-mon存在单点故障\n- mmm-agent对网络抖动敏感，可能引起频繁切换\n- 可能引起master脑裂（见下文解释）\n- 多了一个冗余的master节点\n- 需要比较多的VIP数量\n- 方案基于VIP，VIP是基于ARP协议，因此所有节点必须处于同一局域网\n- 主节点提升需要一定时间\n- 写后即时读难以保持一致性（master同步过来的数据可能还在relay log未被应用）\n\n## MHA\n\nMHA(Master High Availability)不同于MMM，它主要保障的是master的高可用。官方的MHA建议至少要有1主2从，淘宝TMHA则支持1主1从。其基本组成如下，\n\n- master：主节点，承载写流量\n- slave：从节点，replicate主节点数据，承载读流量\n- wvip：提供写的虚拟IP，映射到主节点\n- rvip：提供读的虚拟IP，如果只有一个从节点不需要\n- manager：与master、slave通信，负责切换主节点。注意，manager通过ssh的方式远程执行主、从节点上的脚本，需要提前将manager节点的ssh公钥放置到主、从节点；另外，manager通过mysql-client的方式去探测主、从节点的可用性，因此主、从库上也要预先为manager节点分配账户与授权\n\nmaster提升主节点的流程如下，\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431458-ee572200-270c-11ea-846c-bcf25ff79b5a.png)\n\n\n- 从宕机崩溃的master保存二进制日志事件（binlog events）;\n- 识别含有最新更新的slave；\n- 应用差异的中继日志（relay log）到其他的slave；\n- 应用从master保存的二进制日志事件（binlog events）；\n- 移除旧master的VIP地址，提升一个slave为新的master；\n- 使其他的slave连接新的master进行复制；\n- 在新的master启动vip地址，保证前端请求可以发送到新的master\n\n优点如下，\n\n- 相比MMM不需要冗余的master节点\n- 读写分离\n- 自动提升主节点\n\n缺点如下，\n\n- manager节点单点故障\n- 可能引起master脑裂（见下文解释）\n- 使用了VIP，同样有内网限制\n- 主节点切换需要一定时间\n- 写后即时读难以保持一致性\n- 需要支持SSH私钥验证的方式登录\n\n## 扩展知识：VIP与脑裂\n\nVIP的工作原理是，\n\n- 为当期主机配置一个虚拟网卡，如eth0:0，该网卡绑定了唯一的MAC地址和虚拟IP地址VIP\n- 局域网内的主机欲与该VIP通信时，先通过ARP协议取到该VIP对应的MAC地址，再将VIP与MAC地址的对应关系缓存在其主机上\n- 后续通信时，使用上一步骤取到的MAC作为报文的MAC地址\n\nVIP切换的原理是，\n\n- 将旧master绑定的虚拟网卡注销掉\n- 在新的master注册新的虚拟网卡（产生了新的MAC地址）\n- 通知局域网节点更新VIP与MAC的对应关系，后续通信采用新MAC地址\n\n脑裂的原因，在于旧master节点没有正常将VIP摘掉，这时局域网机器通过ARP获取VIP的MAC时，就可能取到旧的MAC地址，导致与旧master通信。什么情况会出现这种情况呢？旧master由于上层交换机故障，未与manager节点正常通信，此时VIP是没有摘除掉的，过了一段时间上层交换机恢复了就会导致此问题。\n\n参考文献\n- https://github.blog/2018-06-20-mysql-high-availability-at-github/\n- https://dzone.com/articles/choosing-mysql-high-availability-solutions\n- https://cloud.tencent.com/developer/article/1056162\n- http://www.fblinux.com/?p=1044\n","source":"_posts/2019-03-16-mysql-mmm-mha.md","raw":"---\ntitle: mysql mmm和mha对比\ndate: 2019-03-16 16:50:39\ntags: ['MySQL']\ncomments: true\ncategories: ['数据库']\n---\n\n本文简单介绍MySQL的两个high availability方案，MMM和MHA。\n\n<!--more-->\n\n## MMM\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431448-e5fee700-270c-11ea-8139-12d41a02f4b4.png)\n\nMMM(Master-Master replication managerfor Mysql)的基本组成如下，\n- 主节点master1：承载写流量\n- 备主节点master2：replicate主节点master1的写流量，在主节点故障时被monitor提升为主节点，出于与master1数据强一致的考虑，replicate模式一般配置为semi-sync\n- 从节点slave1：replicate主节点master1的写流量，为使得master1的写足够快，一般将replicate模式设为异步\n- 从节点salve2：类似于slave1\n- mmm-agent：以上3个节点都需部署的代理，与monitor进行通信\n- mmm-mon：即monitor，与各mmm-agent通信探测其健康情况，并决策是否要切换主节点或从节点\n- wvip：提供写的虚拟IP，映射到当前活跃的主节点master1\n- rvip：提供读的虚拟IP，至少有一个，映射到slave1或slave2\n\nMMM的主节点切换过程如下：\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431454-eac39b00-270c-11ea-9899-b51b6260851f.png)\n\n- master1的mmm-agent与mmm-mon长期通信失败\n- mmm-mon请求master1的agent，移除VIP\n- mmm-mon请求master2的agent，绑定VIP\n- mmm-mon请求slave节点的agent，连接到新master进行replicate\n\n从节点的故障切换类似于上面的过程。\n\n优点如下，\n\n- 读写分离\n- fail自动切换\n\n缺点如下，\n\n- mmm-mon存在单点故障\n- mmm-agent对网络抖动敏感，可能引起频繁切换\n- 可能引起master脑裂（见下文解释）\n- 多了一个冗余的master节点\n- 需要比较多的VIP数量\n- 方案基于VIP，VIP是基于ARP协议，因此所有节点必须处于同一局域网\n- 主节点提升需要一定时间\n- 写后即时读难以保持一致性（master同步过来的数据可能还在relay log未被应用）\n\n## MHA\n\nMHA(Master High Availability)不同于MMM，它主要保障的是master的高可用。官方的MHA建议至少要有1主2从，淘宝TMHA则支持1主1从。其基本组成如下，\n\n- master：主节点，承载写流量\n- slave：从节点，replicate主节点数据，承载读流量\n- wvip：提供写的虚拟IP，映射到主节点\n- rvip：提供读的虚拟IP，如果只有一个从节点不需要\n- manager：与master、slave通信，负责切换主节点。注意，manager通过ssh的方式远程执行主、从节点上的脚本，需要提前将manager节点的ssh公钥放置到主、从节点；另外，manager通过mysql-client的方式去探测主、从节点的可用性，因此主、从库上也要预先为manager节点分配账户与授权\n\nmaster提升主节点的流程如下，\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431458-ee572200-270c-11ea-846c-bcf25ff79b5a.png)\n\n\n- 从宕机崩溃的master保存二进制日志事件（binlog events）;\n- 识别含有最新更新的slave；\n- 应用差异的中继日志（relay log）到其他的slave；\n- 应用从master保存的二进制日志事件（binlog events）；\n- 移除旧master的VIP地址，提升一个slave为新的master；\n- 使其他的slave连接新的master进行复制；\n- 在新的master启动vip地址，保证前端请求可以发送到新的master\n\n优点如下，\n\n- 相比MMM不需要冗余的master节点\n- 读写分离\n- 自动提升主节点\n\n缺点如下，\n\n- manager节点单点故障\n- 可能引起master脑裂（见下文解释）\n- 使用了VIP，同样有内网限制\n- 主节点切换需要一定时间\n- 写后即时读难以保持一致性\n- 需要支持SSH私钥验证的方式登录\n\n## 扩展知识：VIP与脑裂\n\nVIP的工作原理是，\n\n- 为当期主机配置一个虚拟网卡，如eth0:0，该网卡绑定了唯一的MAC地址和虚拟IP地址VIP\n- 局域网内的主机欲与该VIP通信时，先通过ARP协议取到该VIP对应的MAC地址，再将VIP与MAC地址的对应关系缓存在其主机上\n- 后续通信时，使用上一步骤取到的MAC作为报文的MAC地址\n\nVIP切换的原理是，\n\n- 将旧master绑定的虚拟网卡注销掉\n- 在新的master注册新的虚拟网卡（产生了新的MAC地址）\n- 通知局域网节点更新VIP与MAC的对应关系，后续通信采用新MAC地址\n\n脑裂的原因，在于旧master节点没有正常将VIP摘掉，这时局域网机器通过ARP获取VIP的MAC时，就可能取到旧的MAC地址，导致与旧master通信。什么情况会出现这种情况呢？旧master由于上层交换机故障，未与manager节点正常通信，此时VIP是没有摘除掉的，过了一段时间上层交换机恢复了就会导致此问题。\n\n参考文献\n- https://github.blog/2018-06-20-mysql-high-availability-at-github/\n- https://dzone.com/articles/choosing-mysql-high-availability-solutions\n- https://cloud.tencent.com/developer/article/1056162\n- http://www.fblinux.com/?p=1044\n","slug":"mysql-mmm-mha","published":1,"updated":"2022-08-09T15:02:00.647Z","layout":"post","photos":[],"link":"","_id":"cl6mbc144002rigu8xoy42hcd","content":"<p>本文简单介绍MySQL的两个high availability方案，MMM和MHA。</p>\n<a id=\"more\"></a>\n<h2 id=\"MMM\"><a href=\"#MMM\" class=\"headerlink\" title=\"MMM\"></a>MMM</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431448-e5fee700-270c-11ea-8139-12d41a02f4b4.png\" alt=\"image.png\"></p>\n<p>MMM(Master-Master replication managerfor Mysql)的基本组成如下，</p>\n<ul>\n<li>主节点master1：承载写流量</li>\n<li>备主节点master2：replicate主节点master1的写流量，在主节点故障时被monitor提升为主节点，出于与master1数据强一致的考虑，replicate模式一般配置为semi-sync</li>\n<li>从节点slave1：replicate主节点master1的写流量，为使得master1的写足够快，一般将replicate模式设为异步</li>\n<li>从节点salve2：类似于slave1</li>\n<li>mmm-agent：以上3个节点都需部署的代理，与monitor进行通信</li>\n<li>mmm-mon：即monitor，与各mmm-agent通信探测其健康情况，并决策是否要切换主节点或从节点</li>\n<li>wvip：提供写的虚拟IP，映射到当前活跃的主节点master1</li>\n<li>rvip：提供读的虚拟IP，至少有一个，映射到slave1或slave2</li>\n</ul>\n<p>MMM的主节点切换过程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431454-eac39b00-270c-11ea-9899-b51b6260851f.png\" alt=\"image.png\"></p>\n<ul>\n<li>master1的mmm-agent与mmm-mon长期通信失败</li>\n<li>mmm-mon请求master1的agent，移除VIP</li>\n<li>mmm-mon请求master2的agent，绑定VIP</li>\n<li>mmm-mon请求slave节点的agent，连接到新master进行replicate</li>\n</ul>\n<p>从节点的故障切换类似于上面的过程。</p>\n<p>优点如下，</p>\n<ul>\n<li>读写分离</li>\n<li>fail自动切换</li>\n</ul>\n<p>缺点如下，</p>\n<ul>\n<li>mmm-mon存在单点故障</li>\n<li>mmm-agent对网络抖动敏感，可能引起频繁切换</li>\n<li>可能引起master脑裂（见下文解释）</li>\n<li>多了一个冗余的master节点</li>\n<li>需要比较多的VIP数量</li>\n<li>方案基于VIP，VIP是基于ARP协议，因此所有节点必须处于同一局域网</li>\n<li>主节点提升需要一定时间</li>\n<li>写后即时读难以保持一致性（master同步过来的数据可能还在relay log未被应用）</li>\n</ul>\n<h2 id=\"MHA\"><a href=\"#MHA\" class=\"headerlink\" title=\"MHA\"></a>MHA</h2><p>MHA(Master High Availability)不同于MMM，它主要保障的是master的高可用。官方的MHA建议至少要有1主2从，淘宝TMHA则支持1主1从。其基本组成如下，</p>\n<ul>\n<li>master：主节点，承载写流量</li>\n<li>slave：从节点，replicate主节点数据，承载读流量</li>\n<li>wvip：提供写的虚拟IP，映射到主节点</li>\n<li>rvip：提供读的虚拟IP，如果只有一个从节点不需要</li>\n<li>manager：与master、slave通信，负责切换主节点。注意，manager通过ssh的方式远程执行主、从节点上的脚本，需要提前将manager节点的ssh公钥放置到主、从节点；另外，manager通过mysql-client的方式去探测主、从节点的可用性，因此主、从库上也要预先为manager节点分配账户与授权</li>\n</ul>\n<p>master提升主节点的流程如下，</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431458-ee572200-270c-11ea-846c-bcf25ff79b5a.png\" alt=\"image.png\"></p>\n<ul>\n<li>从宕机崩溃的master保存二进制日志事件（binlog events）;</li>\n<li>识别含有最新更新的slave；</li>\n<li>应用差异的中继日志（relay log）到其他的slave；</li>\n<li>应用从master保存的二进制日志事件（binlog events）；</li>\n<li>移除旧master的VIP地址，提升一个slave为新的master；</li>\n<li>使其他的slave连接新的master进行复制；</li>\n<li>在新的master启动vip地址，保证前端请求可以发送到新的master</li>\n</ul>\n<p>优点如下，</p>\n<ul>\n<li>相比MMM不需要冗余的master节点</li>\n<li>读写分离</li>\n<li>自动提升主节点</li>\n</ul>\n<p>缺点如下，</p>\n<ul>\n<li>manager节点单点故障</li>\n<li>可能引起master脑裂（见下文解释）</li>\n<li>使用了VIP，同样有内网限制</li>\n<li>主节点切换需要一定时间</li>\n<li>写后即时读难以保持一致性</li>\n<li>需要支持SSH私钥验证的方式登录</li>\n</ul>\n<h2 id=\"扩展知识：VIP与脑裂\"><a href=\"#扩展知识：VIP与脑裂\" class=\"headerlink\" title=\"扩展知识：VIP与脑裂\"></a>扩展知识：VIP与脑裂</h2><p>VIP的工作原理是，</p>\n<ul>\n<li>为当期主机配置一个虚拟网卡，如eth0:0，该网卡绑定了唯一的MAC地址和虚拟IP地址VIP</li>\n<li>局域网内的主机欲与该VIP通信时，先通过ARP协议取到该VIP对应的MAC地址，再将VIP与MAC地址的对应关系缓存在其主机上</li>\n<li>后续通信时，使用上一步骤取到的MAC作为报文的MAC地址</li>\n</ul>\n<p>VIP切换的原理是，</p>\n<ul>\n<li>将旧master绑定的虚拟网卡注销掉</li>\n<li>在新的master注册新的虚拟网卡（产生了新的MAC地址）</li>\n<li>通知局域网节点更新VIP与MAC的对应关系，后续通信采用新MAC地址</li>\n</ul>\n<p>脑裂的原因，在于旧master节点没有正常将VIP摘掉，这时局域网机器通过ARP获取VIP的MAC时，就可能取到旧的MAC地址，导致与旧master通信。什么情况会出现这种情况呢？旧master由于上层交换机故障，未与manager节点正常通信，此时VIP是没有摘除掉的，过了一段时间上层交换机恢复了就会导致此问题。</p>\n<p>参考文献</p>\n<ul>\n<li><a href=\"https://github.blog/2018-06-20-mysql-high-availability-at-github/\" target=\"_blank\" rel=\"noopener\">https://github.blog/2018-06-20-mysql-high-availability-at-github/</a></li>\n<li><a href=\"https://dzone.com/articles/choosing-mysql-high-availability-solutions\" target=\"_blank\" rel=\"noopener\">https://dzone.com/articles/choosing-mysql-high-availability-solutions</a></li>\n<li><a href=\"https://cloud.tencent.com/developer/article/1056162\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/developer/article/1056162</a></li>\n<li><a href=\"http://www.fblinux.com/?p=1044\" target=\"_blank\" rel=\"noopener\">http://www.fblinux.com/?p=1044</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>本文简单介绍MySQL的两个high availability方案，MMM和MHA。</p>","more":"<h2 id=\"MMM\"><a href=\"#MMM\" class=\"headerlink\" title=\"MMM\"></a>MMM</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71431448-e5fee700-270c-11ea-8139-12d41a02f4b4.png\" alt=\"image.png\"></p>\n<p>MMM(Master-Master replication managerfor Mysql)的基本组成如下，</p>\n<ul>\n<li>主节点master1：承载写流量</li>\n<li>备主节点master2：replicate主节点master1的写流量，在主节点故障时被monitor提升为主节点，出于与master1数据强一致的考虑，replicate模式一般配置为semi-sync</li>\n<li>从节点slave1：replicate主节点master1的写流量，为使得master1的写足够快，一般将replicate模式设为异步</li>\n<li>从节点salve2：类似于slave1</li>\n<li>mmm-agent：以上3个节点都需部署的代理，与monitor进行通信</li>\n<li>mmm-mon：即monitor，与各mmm-agent通信探测其健康情况，并决策是否要切换主节点或从节点</li>\n<li>wvip：提供写的虚拟IP，映射到当前活跃的主节点master1</li>\n<li>rvip：提供读的虚拟IP，至少有一个，映射到slave1或slave2</li>\n</ul>\n<p>MMM的主节点切换过程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431454-eac39b00-270c-11ea-9899-b51b6260851f.png\" alt=\"image.png\"></p>\n<ul>\n<li>master1的mmm-agent与mmm-mon长期通信失败</li>\n<li>mmm-mon请求master1的agent，移除VIP</li>\n<li>mmm-mon请求master2的agent，绑定VIP</li>\n<li>mmm-mon请求slave节点的agent，连接到新master进行replicate</li>\n</ul>\n<p>从节点的故障切换类似于上面的过程。</p>\n<p>优点如下，</p>\n<ul>\n<li>读写分离</li>\n<li>fail自动切换</li>\n</ul>\n<p>缺点如下，</p>\n<ul>\n<li>mmm-mon存在单点故障</li>\n<li>mmm-agent对网络抖动敏感，可能引起频繁切换</li>\n<li>可能引起master脑裂（见下文解释）</li>\n<li>多了一个冗余的master节点</li>\n<li>需要比较多的VIP数量</li>\n<li>方案基于VIP，VIP是基于ARP协议，因此所有节点必须处于同一局域网</li>\n<li>主节点提升需要一定时间</li>\n<li>写后即时读难以保持一致性（master同步过来的数据可能还在relay log未被应用）</li>\n</ul>\n<h2 id=\"MHA\"><a href=\"#MHA\" class=\"headerlink\" title=\"MHA\"></a>MHA</h2><p>MHA(Master High Availability)不同于MMM，它主要保障的是master的高可用。官方的MHA建议至少要有1主2从，淘宝TMHA则支持1主1从。其基本组成如下，</p>\n<ul>\n<li>master：主节点，承载写流量</li>\n<li>slave：从节点，replicate主节点数据，承载读流量</li>\n<li>wvip：提供写的虚拟IP，映射到主节点</li>\n<li>rvip：提供读的虚拟IP，如果只有一个从节点不需要</li>\n<li>manager：与master、slave通信，负责切换主节点。注意，manager通过ssh的方式远程执行主、从节点上的脚本，需要提前将manager节点的ssh公钥放置到主、从节点；另外，manager通过mysql-client的方式去探测主、从节点的可用性，因此主、从库上也要预先为manager节点分配账户与授权</li>\n</ul>\n<p>master提升主节点的流程如下，</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431458-ee572200-270c-11ea-846c-bcf25ff79b5a.png\" alt=\"image.png\"></p>\n<ul>\n<li>从宕机崩溃的master保存二进制日志事件（binlog events）;</li>\n<li>识别含有最新更新的slave；</li>\n<li>应用差异的中继日志（relay log）到其他的slave；</li>\n<li>应用从master保存的二进制日志事件（binlog events）；</li>\n<li>移除旧master的VIP地址，提升一个slave为新的master；</li>\n<li>使其他的slave连接新的master进行复制；</li>\n<li>在新的master启动vip地址，保证前端请求可以发送到新的master</li>\n</ul>\n<p>优点如下，</p>\n<ul>\n<li>相比MMM不需要冗余的master节点</li>\n<li>读写分离</li>\n<li>自动提升主节点</li>\n</ul>\n<p>缺点如下，</p>\n<ul>\n<li>manager节点单点故障</li>\n<li>可能引起master脑裂（见下文解释）</li>\n<li>使用了VIP，同样有内网限制</li>\n<li>主节点切换需要一定时间</li>\n<li>写后即时读难以保持一致性</li>\n<li>需要支持SSH私钥验证的方式登录</li>\n</ul>\n<h2 id=\"扩展知识：VIP与脑裂\"><a href=\"#扩展知识：VIP与脑裂\" class=\"headerlink\" title=\"扩展知识：VIP与脑裂\"></a>扩展知识：VIP与脑裂</h2><p>VIP的工作原理是，</p>\n<ul>\n<li>为当期主机配置一个虚拟网卡，如eth0:0，该网卡绑定了唯一的MAC地址和虚拟IP地址VIP</li>\n<li>局域网内的主机欲与该VIP通信时，先通过ARP协议取到该VIP对应的MAC地址，再将VIP与MAC地址的对应关系缓存在其主机上</li>\n<li>后续通信时，使用上一步骤取到的MAC作为报文的MAC地址</li>\n</ul>\n<p>VIP切换的原理是，</p>\n<ul>\n<li>将旧master绑定的虚拟网卡注销掉</li>\n<li>在新的master注册新的虚拟网卡（产生了新的MAC地址）</li>\n<li>通知局域网节点更新VIP与MAC的对应关系，后续通信采用新MAC地址</li>\n</ul>\n<p>脑裂的原因，在于旧master节点没有正常将VIP摘掉，这时局域网机器通过ARP获取VIP的MAC时，就可能取到旧的MAC地址，导致与旧master通信。什么情况会出现这种情况呢？旧master由于上层交换机故障，未与manager节点正常通信，此时VIP是没有摘除掉的，过了一段时间上层交换机恢复了就会导致此问题。</p>\n<p>参考文献</p>\n<ul>\n<li><a href=\"https://github.blog/2018-06-20-mysql-high-availability-at-github/\" target=\"_blank\" rel=\"noopener\">https://github.blog/2018-06-20-mysql-high-availability-at-github/</a></li>\n<li><a href=\"https://dzone.com/articles/choosing-mysql-high-availability-solutions\" target=\"_blank\" rel=\"noopener\">https://dzone.com/articles/choosing-mysql-high-availability-solutions</a></li>\n<li><a href=\"https://cloud.tencent.com/developer/article/1056162\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/developer/article/1056162</a></li>\n<li><a href=\"http://www.fblinux.com/?p=1044\" target=\"_blank\" rel=\"noopener\">http://www.fblinux.com/?p=1044</a></li>\n</ul>"},{"title":"RDMS Sharding的一些总结","date":"2019-03-31T14:13:22.000Z","comments":1,"_content":"\n本文简单总结RDMS对数据进行shard的一些套路。\n\n<!--more-->\n\n## Why sharding\n\n早期的RDMS（Relational Database Management System）是单物理机单实例。随着用户量、访问量的急剧上升，20%的表可能占据了80%的数据量（二八法则），这时你可能会考虑将大数据表拆到机器A和机器B，小数据表拆到机器C。好处是显而易见的，原先压在一部机器的负载分散到多部机器，坏处是以前的一些SQL可能需要改写，因为我们无法跨库做join，尽可能把需要join的表分在一部机器的同一个库内可以暂时规避这个问题。\n\n很快的，用户量和数据继续蹭蹭蹭的往上涨，有些表已经是百万行级别了，很快又要撑不住了。这时，你把目光聚焦在那些大表上，发现有些表的某些列是BLOB型数据（图片或文件等）。这些数据一般不需要范围查询，基本都是指定主键查出来的，于是你把这些列分离出去，单独存在文件或图片服务器上，你的一些糟糕的`select * from xxx`的语句从此性能得到提升，新增的insert因为不需要写BLOB也比以前快了一丢丢，数据表的总体数据量大小也大大减少，代价是你需要根据主键到图片或文件服务器获取你要的BLOB数据。\n（知识扩展：`select *`语句需要查聚簇索引——主键索引，因为BLOB数据一般不建立索引，需要在主键索引才能拿到没建立索引的列的数据）\n\n但是，把部分列分离出去，行数还是那么多啊！按照业务规模发展下去，行数分分钟就要破千万了啊！所有读写负载都打在了单表单服务器上，想想都是噩梦，怎么破？\n\n这时候只能把一张大表水平切几刀（表结构不变），切成多张小表了。这便是本文讨论的范围，主要是一些思路上的总结。\n\n- 怎么切：sharding strategy\n- 切完后怎么扩容：resharding\n- 切完有什么好处，又有何副作用以及业界是怎么解决这些问题的：side effect\n\n\n## Sharding strategy compare\n\n### Case 1 静态算式规则切分\n\n![id % 4](https://user-images.githubusercontent.com/4915189/71431441-d97a8e80-270c-11ea-9b72-ed3ec0e921a2.png)\n\n上图的`id`是主键，4是结点总数，`id % 4`即静态算术规则。输入主键计算出数值下标，由数值到LOOKUP表就可以确定数据在哪台服务器上。\n（注：LOOKUP表维护下标与真实服务器信息的对应关系，简单实现可以考虑配置在服务器，复杂的可以考虑引入Zookeeper）\n\n**1、如何扩容？**\n\n对于`id % 4`的规则，扩容类似于[Java HashMap的rebash的过程](https://www.geeksforgeeks.org/load-factor-and-rehashing/)。如果id不是一个整型数值，规则需要改写成`hash(id) % 4`，hash函数用于将id转为int。假如新增一个节点，此时需要经历以下过程：\n\n- 将第0结点上的id做`id % 5`，如果值不为0，则将该行记录移动到其他服务器上；\n- 其他结点以此类推。\n\n这里有两个显而易见的坏处，\n\n- 几乎每个结点的数据都需要重新打散，分发到其他服务器。这需要大量的磁盘IO，可谓伤筋动骨，改进办法见下文；\n- 在扩容未完成时，该从哪个结点读？该从哪个结点写？如果要做到动态扩容不影响读写，那么就需要做非常非常多的额外工作。一个可以考虑的策略是，挂个升级公告，停止对外服务，扩容期间数据库无任何读写，这应该算是一般游戏公司的做法了。\n\n**2、好处是什么？**\n\n读和写能够比较均匀的打到各个节点。\n\n- 对于自增主键式的写入，不会出现负载都打在一个结点的情况；\n- 对于频繁读最近新增的数据的case，也不会出现负载都打在一个结点的情况。\n\n**3、代价是什么？是否有解决思路？**\n\n对于上面的`id % 4`问题，其实可以换一个思路。虽然我们只有4台物理机，但我们可以把规则定为`id % 1024`，即逻辑上有1024台机。然后通过配置上面说的LOOKUP表，实现4台物理机均摊这1024台逻辑机器的角色，这样可以规避上面的新增结点需要全部数据打散的问题，这也是[一致性哈希](https://en.wikipedia.org/wiki/Consistent_hashing)\n的思想。1024这数值必须是公司业务理论上不能达到的上限（除了顶尖的那几家互联网公司，一般公司也不会超过这个值了），否则还是会出现上面的痛点。\n\n主键被打散，对按主键范围查询不友好，范围查询基本退化成了全表查询。如果主键范围查询时还带`order by`，那还得在查询完后自行对数据进行排序。\n\n解决思路是，数据在单节点是有序的，将查询分发给每个结点，并行去查数据，最后对返回结果做合并。如果要求`order by`，则在合并结果集时进行两两的归并排序。\n\n### Case 2 范围规则切分\n\n![dynamic range](https://user-images.githubusercontent.com/4915189/71431444-dd0e1580-270c-11ea-8d7d-c801dd1df161.png)\n\n与上面的算式规则不同的是，这里需要一个range函数，输入主键后得到一个range数值，然后再去查LOOKUP表确定数据落在哪个结点。range函数一般有两种，有序型和无序性。输入[1,2,3,4]这一组数据后，输出的数据依然是有序的称为有序型（一般应用在数据类型），输出无序的称为无序型（比如hash函数）。\n\n**1、如何扩容？**\n\n相比“静态算式规则”，“范围规则”的扩容较为简单。以将范围[10, 30]拆成[10,20]和[21,30]为例，大概需要以下过程，\n\n- 新增物理节点；\n- 标记旧节点[10,30]当前binlog的ID为A；\n- 利用MySQL的可重复读（repeatable read）的特性，将数据copy到新节点；\n- 完成copy后，新节点从上文binlog的ID为A的位置，同步旧节点的binlog数据，仅应用对[21,30]范围有影响的语句；\n- binlog同步完成后，修改LOOKUP表，使得后续对[21,30]范围的读写路由到新节点，清除旧节点[21,30]这个范围的数据；\n\n这里有几个挑战，1）数据表太大一次性拷贝将导致[长事务](https://www.simononsoftware.com/are-long-running-transactions-bad/)\n怎么办，2）如何确保数据已全部同步到新节点，3）修改LOOKUP表前已经有读写数据的请求被路由到旧节点该怎么办？\n\n对于第1点，可以考虑，\n- 先拷贝[21至25]的数据，然后读取旧节点的最新binlog的ID为B；\n- 紧接着拷贝[26至30]的数据；\n- 将binlog的id为A至B的改动应用在[21至25]这个数据范围；\n- 将binlog的id为B至最新binlog的ID的全部数据应用到[21至30]这个范围；\n\n对于第2点，可以考虑通过新、旧节点间的lag来判断，并产生一个触发信号。\n\n对于第3点，需要有某个仲裁节点，在收到前述触发信号后，阻塞后续所有对于[20,30]的读写请求，直到旧节点对于[20,30]已发起的SQL语句已经全部处理返回后，修改LOOKUP表再让被阻塞的读写请求通行。\n\n**2、好处是什么？**\n\n相较于“静态算式规则”，“范围规则”的扩容更为简单，且不存在预设的最大节点数的影响。\n\n对于上文的range函数，如果是有序型的，\n\n- 则对范围查询较为友好；\n- 但却对自增主键式写入不友好（负载都压在最后一个结点），以及可能会导致hotspot（最近新增数据的读都压在最后一个结点），除非更换range函数为无序型的否则没有解决方案。\n\n如果是无序型的，\n\n- 则对范围查询不友好，解决思路同上文；\n- 但却能很好的将读写负载分散到各节点。\n\n**3、代价是什么？是否有解决思路？**\n\n上文已提及。\n\n## Common issue\n\n上面提到的两种sharding的case，有一些共同问题如下。\n\n一、都需要解决跨节点join的问题。业界解决思路是通过应用层代码去处理join，即先查小表A，再用小表A的结果作为参数去查询需要join的大表B（这里的大、小是相对的含义）；另外一种则是通过代理层去解决。\n\n二、都需要解决跨节点transaction的问题。业界的解决思路一般是改进式的2PC([Two-phase commit protocol](https://en.wikipedia.org/wiki/Two-phase_commit_protocol))。\n\n三、如果主键有多个列应该如何sharding。假如主键是id和time，可以先通过id来定位到机器组0（假设有A、B、C、D四部机器组成），然后再由time来定位到A、B、C、D的其中一部机器。如果有超过2个主键呢？你确定你需要这么多主键吗？\n\n四、如何支持非聚簇索引。RDMS中，表除了聚簇索引，还有非聚簇索引。在已经sharding的前提下，如果要以非聚簇索引的列作为查询条件去查询数据，此时查询便退化成了全节点扫描。一个解决思路是，将非聚簇索引和聚簇索引单独建一张表（冗余表），然后以非聚簇索引去sharding，查询时先查冗余表，然后再回表到主表，以此避免全节点扫描。\n\n## Conclusion\n\n本文介绍了两种sharding方式。一种是算术规则式，需要先预估逻辑节点的最大值，以避免代价昂贵的全节点rehash；另一种是范围规则式，其关键在于range函数的选取——有顺序型和无序型两种。\n\n## Reference\n\n[How Sharding Works](https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6)\n[ClustrixDB Data Distribution](http://docs.clustrix.com/display/CLXDOC/Data+Distribution)\n[Challenges of Sharding MySQL](https://www.clustrix.com/bettersql/challenges-sharding-mysql/)\n","source":"_posts/2019-03-31-beyond-sharding.md","raw":"---\ntitle: RDMS Sharding的一些总结\ndate: 2019-03-31 22:13:22\ntags: ['MySQL', '数据库']\ncomments: true\ncategories: ['系统设计']\n---\n\n本文简单总结RDMS对数据进行shard的一些套路。\n\n<!--more-->\n\n## Why sharding\n\n早期的RDMS（Relational Database Management System）是单物理机单实例。随着用户量、访问量的急剧上升，20%的表可能占据了80%的数据量（二八法则），这时你可能会考虑将大数据表拆到机器A和机器B，小数据表拆到机器C。好处是显而易见的，原先压在一部机器的负载分散到多部机器，坏处是以前的一些SQL可能需要改写，因为我们无法跨库做join，尽可能把需要join的表分在一部机器的同一个库内可以暂时规避这个问题。\n\n很快的，用户量和数据继续蹭蹭蹭的往上涨，有些表已经是百万行级别了，很快又要撑不住了。这时，你把目光聚焦在那些大表上，发现有些表的某些列是BLOB型数据（图片或文件等）。这些数据一般不需要范围查询，基本都是指定主键查出来的，于是你把这些列分离出去，单独存在文件或图片服务器上，你的一些糟糕的`select * from xxx`的语句从此性能得到提升，新增的insert因为不需要写BLOB也比以前快了一丢丢，数据表的总体数据量大小也大大减少，代价是你需要根据主键到图片或文件服务器获取你要的BLOB数据。\n（知识扩展：`select *`语句需要查聚簇索引——主键索引，因为BLOB数据一般不建立索引，需要在主键索引才能拿到没建立索引的列的数据）\n\n但是，把部分列分离出去，行数还是那么多啊！按照业务规模发展下去，行数分分钟就要破千万了啊！所有读写负载都打在了单表单服务器上，想想都是噩梦，怎么破？\n\n这时候只能把一张大表水平切几刀（表结构不变），切成多张小表了。这便是本文讨论的范围，主要是一些思路上的总结。\n\n- 怎么切：sharding strategy\n- 切完后怎么扩容：resharding\n- 切完有什么好处，又有何副作用以及业界是怎么解决这些问题的：side effect\n\n\n## Sharding strategy compare\n\n### Case 1 静态算式规则切分\n\n![id % 4](https://user-images.githubusercontent.com/4915189/71431441-d97a8e80-270c-11ea-9b72-ed3ec0e921a2.png)\n\n上图的`id`是主键，4是结点总数，`id % 4`即静态算术规则。输入主键计算出数值下标，由数值到LOOKUP表就可以确定数据在哪台服务器上。\n（注：LOOKUP表维护下标与真实服务器信息的对应关系，简单实现可以考虑配置在服务器，复杂的可以考虑引入Zookeeper）\n\n**1、如何扩容？**\n\n对于`id % 4`的规则，扩容类似于[Java HashMap的rebash的过程](https://www.geeksforgeeks.org/load-factor-and-rehashing/)。如果id不是一个整型数值，规则需要改写成`hash(id) % 4`，hash函数用于将id转为int。假如新增一个节点，此时需要经历以下过程：\n\n- 将第0结点上的id做`id % 5`，如果值不为0，则将该行记录移动到其他服务器上；\n- 其他结点以此类推。\n\n这里有两个显而易见的坏处，\n\n- 几乎每个结点的数据都需要重新打散，分发到其他服务器。这需要大量的磁盘IO，可谓伤筋动骨，改进办法见下文；\n- 在扩容未完成时，该从哪个结点读？该从哪个结点写？如果要做到动态扩容不影响读写，那么就需要做非常非常多的额外工作。一个可以考虑的策略是，挂个升级公告，停止对外服务，扩容期间数据库无任何读写，这应该算是一般游戏公司的做法了。\n\n**2、好处是什么？**\n\n读和写能够比较均匀的打到各个节点。\n\n- 对于自增主键式的写入，不会出现负载都打在一个结点的情况；\n- 对于频繁读最近新增的数据的case，也不会出现负载都打在一个结点的情况。\n\n**3、代价是什么？是否有解决思路？**\n\n对于上面的`id % 4`问题，其实可以换一个思路。虽然我们只有4台物理机，但我们可以把规则定为`id % 1024`，即逻辑上有1024台机。然后通过配置上面说的LOOKUP表，实现4台物理机均摊这1024台逻辑机器的角色，这样可以规避上面的新增结点需要全部数据打散的问题，这也是[一致性哈希](https://en.wikipedia.org/wiki/Consistent_hashing)\n的思想。1024这数值必须是公司业务理论上不能达到的上限（除了顶尖的那几家互联网公司，一般公司也不会超过这个值了），否则还是会出现上面的痛点。\n\n主键被打散，对按主键范围查询不友好，范围查询基本退化成了全表查询。如果主键范围查询时还带`order by`，那还得在查询完后自行对数据进行排序。\n\n解决思路是，数据在单节点是有序的，将查询分发给每个结点，并行去查数据，最后对返回结果做合并。如果要求`order by`，则在合并结果集时进行两两的归并排序。\n\n### Case 2 范围规则切分\n\n![dynamic range](https://user-images.githubusercontent.com/4915189/71431444-dd0e1580-270c-11ea-8d7d-c801dd1df161.png)\n\n与上面的算式规则不同的是，这里需要一个range函数，输入主键后得到一个range数值，然后再去查LOOKUP表确定数据落在哪个结点。range函数一般有两种，有序型和无序性。输入[1,2,3,4]这一组数据后，输出的数据依然是有序的称为有序型（一般应用在数据类型），输出无序的称为无序型（比如hash函数）。\n\n**1、如何扩容？**\n\n相比“静态算式规则”，“范围规则”的扩容较为简单。以将范围[10, 30]拆成[10,20]和[21,30]为例，大概需要以下过程，\n\n- 新增物理节点；\n- 标记旧节点[10,30]当前binlog的ID为A；\n- 利用MySQL的可重复读（repeatable read）的特性，将数据copy到新节点；\n- 完成copy后，新节点从上文binlog的ID为A的位置，同步旧节点的binlog数据，仅应用对[21,30]范围有影响的语句；\n- binlog同步完成后，修改LOOKUP表，使得后续对[21,30]范围的读写路由到新节点，清除旧节点[21,30]这个范围的数据；\n\n这里有几个挑战，1）数据表太大一次性拷贝将导致[长事务](https://www.simononsoftware.com/are-long-running-transactions-bad/)\n怎么办，2）如何确保数据已全部同步到新节点，3）修改LOOKUP表前已经有读写数据的请求被路由到旧节点该怎么办？\n\n对于第1点，可以考虑，\n- 先拷贝[21至25]的数据，然后读取旧节点的最新binlog的ID为B；\n- 紧接着拷贝[26至30]的数据；\n- 将binlog的id为A至B的改动应用在[21至25]这个数据范围；\n- 将binlog的id为B至最新binlog的ID的全部数据应用到[21至30]这个范围；\n\n对于第2点，可以考虑通过新、旧节点间的lag来判断，并产生一个触发信号。\n\n对于第3点，需要有某个仲裁节点，在收到前述触发信号后，阻塞后续所有对于[20,30]的读写请求，直到旧节点对于[20,30]已发起的SQL语句已经全部处理返回后，修改LOOKUP表再让被阻塞的读写请求通行。\n\n**2、好处是什么？**\n\n相较于“静态算式规则”，“范围规则”的扩容更为简单，且不存在预设的最大节点数的影响。\n\n对于上文的range函数，如果是有序型的，\n\n- 则对范围查询较为友好；\n- 但却对自增主键式写入不友好（负载都压在最后一个结点），以及可能会导致hotspot（最近新增数据的读都压在最后一个结点），除非更换range函数为无序型的否则没有解决方案。\n\n如果是无序型的，\n\n- 则对范围查询不友好，解决思路同上文；\n- 但却能很好的将读写负载分散到各节点。\n\n**3、代价是什么？是否有解决思路？**\n\n上文已提及。\n\n## Common issue\n\n上面提到的两种sharding的case，有一些共同问题如下。\n\n一、都需要解决跨节点join的问题。业界解决思路是通过应用层代码去处理join，即先查小表A，再用小表A的结果作为参数去查询需要join的大表B（这里的大、小是相对的含义）；另外一种则是通过代理层去解决。\n\n二、都需要解决跨节点transaction的问题。业界的解决思路一般是改进式的2PC([Two-phase commit protocol](https://en.wikipedia.org/wiki/Two-phase_commit_protocol))。\n\n三、如果主键有多个列应该如何sharding。假如主键是id和time，可以先通过id来定位到机器组0（假设有A、B、C、D四部机器组成），然后再由time来定位到A、B、C、D的其中一部机器。如果有超过2个主键呢？你确定你需要这么多主键吗？\n\n四、如何支持非聚簇索引。RDMS中，表除了聚簇索引，还有非聚簇索引。在已经sharding的前提下，如果要以非聚簇索引的列作为查询条件去查询数据，此时查询便退化成了全节点扫描。一个解决思路是，将非聚簇索引和聚簇索引单独建一张表（冗余表），然后以非聚簇索引去sharding，查询时先查冗余表，然后再回表到主表，以此避免全节点扫描。\n\n## Conclusion\n\n本文介绍了两种sharding方式。一种是算术规则式，需要先预估逻辑节点的最大值，以避免代价昂贵的全节点rehash；另一种是范围规则式，其关键在于range函数的选取——有顺序型和无序型两种。\n\n## Reference\n\n[How Sharding Works](https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6)\n[ClustrixDB Data Distribution](http://docs.clustrix.com/display/CLXDOC/Data+Distribution)\n[Challenges of Sharding MySQL](https://www.clustrix.com/bettersql/challenges-sharding-mysql/)\n","slug":"beyond-sharding","published":1,"updated":"2022-08-09T15:02:00.648Z","layout":"post","photos":[],"link":"","_id":"cl6mbc146002uigu8v3jlcu0a","content":"<p>本文简单总结RDMS对数据进行shard的一些套路。</p>\n<a id=\"more\"></a>\n<h2 id=\"Why-sharding\"><a href=\"#Why-sharding\" class=\"headerlink\" title=\"Why sharding\"></a>Why sharding</h2><p>早期的RDMS（Relational Database Management System）是单物理机单实例。随着用户量、访问量的急剧上升，20%的表可能占据了80%的数据量（二八法则），这时你可能会考虑将大数据表拆到机器A和机器B，小数据表拆到机器C。好处是显而易见的，原先压在一部机器的负载分散到多部机器，坏处是以前的一些SQL可能需要改写，因为我们无法跨库做join，尽可能把需要join的表分在一部机器的同一个库内可以暂时规避这个问题。</p>\n<p>很快的，用户量和数据继续蹭蹭蹭的往上涨，有些表已经是百万行级别了，很快又要撑不住了。这时，你把目光聚焦在那些大表上，发现有些表的某些列是BLOB型数据（图片或文件等）。这些数据一般不需要范围查询，基本都是指定主键查出来的，于是你把这些列分离出去，单独存在文件或图片服务器上，你的一些糟糕的<code>select * from xxx</code>的语句从此性能得到提升，新增的insert因为不需要写BLOB也比以前快了一丢丢，数据表的总体数据量大小也大大减少，代价是你需要根据主键到图片或文件服务器获取你要的BLOB数据。<br>（知识扩展：<code>select *</code>语句需要查聚簇索引——主键索引，因为BLOB数据一般不建立索引，需要在主键索引才能拿到没建立索引的列的数据）</p>\n<p>但是，把部分列分离出去，行数还是那么多啊！按照业务规模发展下去，行数分分钟就要破千万了啊！所有读写负载都打在了单表单服务器上，想想都是噩梦，怎么破？</p>\n<p>这时候只能把一张大表水平切几刀（表结构不变），切成多张小表了。这便是本文讨论的范围，主要是一些思路上的总结。</p>\n<ul>\n<li>怎么切：sharding strategy</li>\n<li>切完后怎么扩容：resharding</li>\n<li>切完有什么好处，又有何副作用以及业界是怎么解决这些问题的：side effect</li>\n</ul>\n<h2 id=\"Sharding-strategy-compare\"><a href=\"#Sharding-strategy-compare\" class=\"headerlink\" title=\"Sharding strategy compare\"></a>Sharding strategy compare</h2><h3 id=\"Case-1-静态算式规则切分\"><a href=\"#Case-1-静态算式规则切分\" class=\"headerlink\" title=\"Case 1 静态算式规则切分\"></a>Case 1 静态算式规则切分</h3><p><img src=\"https://user-images.githubusercontent.com/4915189/71431441-d97a8e80-270c-11ea-9b72-ed3ec0e921a2.png\" alt=\"id % 4\"></p>\n<p>上图的<code>id</code>是主键，4是结点总数，<code>id % 4</code>即静态算术规则。输入主键计算出数值下标，由数值到LOOKUP表就可以确定数据在哪台服务器上。<br>（注：LOOKUP表维护下标与真实服务器信息的对应关系，简单实现可以考虑配置在服务器，复杂的可以考虑引入Zookeeper）</p>\n<p><strong>1、如何扩容？</strong></p>\n<p>对于<code>id % 4</code>的规则，扩容类似于<a href=\"https://www.geeksforgeeks.org/load-factor-and-rehashing/\" target=\"_blank\" rel=\"noopener\">Java HashMap的rebash的过程</a>。如果id不是一个整型数值，规则需要改写成<code>hash(id) % 4</code>，hash函数用于将id转为int。假如新增一个节点，此时需要经历以下过程：</p>\n<ul>\n<li>将第0结点上的id做<code>id % 5</code>，如果值不为0，则将该行记录移动到其他服务器上；</li>\n<li>其他结点以此类推。</li>\n</ul>\n<p>这里有两个显而易见的坏处，</p>\n<ul>\n<li>几乎每个结点的数据都需要重新打散，分发到其他服务器。这需要大量的磁盘IO，可谓伤筋动骨，改进办法见下文；</li>\n<li>在扩容未完成时，该从哪个结点读？该从哪个结点写？如果要做到动态扩容不影响读写，那么就需要做非常非常多的额外工作。一个可以考虑的策略是，挂个升级公告，停止对外服务，扩容期间数据库无任何读写，这应该算是一般游戏公司的做法了。</li>\n</ul>\n<p><strong>2、好处是什么？</strong></p>\n<p>读和写能够比较均匀的打到各个节点。</p>\n<ul>\n<li>对于自增主键式的写入，不会出现负载都打在一个结点的情况；</li>\n<li>对于频繁读最近新增的数据的case，也不会出现负载都打在一个结点的情况。</li>\n</ul>\n<p><strong>3、代价是什么？是否有解决思路？</strong></p>\n<p>对于上面的<code>id % 4</code>问题，其实可以换一个思路。虽然我们只有4台物理机，但我们可以把规则定为<code>id % 1024</code>，即逻辑上有1024台机。然后通过配置上面说的LOOKUP表，实现4台物理机均摊这1024台逻辑机器的角色，这样可以规避上面的新增结点需要全部数据打散的问题，这也是<a href=\"https://en.wikipedia.org/wiki/Consistent_hashing\" target=\"_blank\" rel=\"noopener\">一致性哈希</a><br>的思想。1024这数值必须是公司业务理论上不能达到的上限（除了顶尖的那几家互联网公司，一般公司也不会超过这个值了），否则还是会出现上面的痛点。</p>\n<p>主键被打散，对按主键范围查询不友好，范围查询基本退化成了全表查询。如果主键范围查询时还带<code>order by</code>，那还得在查询完后自行对数据进行排序。</p>\n<p>解决思路是，数据在单节点是有序的，将查询分发给每个结点，并行去查数据，最后对返回结果做合并。如果要求<code>order by</code>，则在合并结果集时进行两两的归并排序。</p>\n<h3 id=\"Case-2-范围规则切分\"><a href=\"#Case-2-范围规则切分\" class=\"headerlink\" title=\"Case 2 范围规则切分\"></a>Case 2 范围规则切分</h3><p><img src=\"https://user-images.githubusercontent.com/4915189/71431444-dd0e1580-270c-11ea-8d7d-c801dd1df161.png\" alt=\"dynamic range\"></p>\n<p>与上面的算式规则不同的是，这里需要一个range函数，输入主键后得到一个range数值，然后再去查LOOKUP表确定数据落在哪个结点。range函数一般有两种，有序型和无序性。输入[1,2,3,4]这一组数据后，输出的数据依然是有序的称为有序型（一般应用在数据类型），输出无序的称为无序型（比如hash函数）。</p>\n<p><strong>1、如何扩容？</strong></p>\n<p>相比“静态算式规则”，“范围规则”的扩容较为简单。以将范围[10, 30]拆成[10,20]和[21,30]为例，大概需要以下过程，</p>\n<ul>\n<li>新增物理节点；</li>\n<li>标记旧节点[10,30]当前binlog的ID为A；</li>\n<li>利用MySQL的可重复读（repeatable read）的特性，将数据copy到新节点；</li>\n<li>完成copy后，新节点从上文binlog的ID为A的位置，同步旧节点的binlog数据，仅应用对[21,30]范围有影响的语句；</li>\n<li>binlog同步完成后，修改LOOKUP表，使得后续对[21,30]范围的读写路由到新节点，清除旧节点[21,30]这个范围的数据；</li>\n</ul>\n<p>这里有几个挑战，1）数据表太大一次性拷贝将导致<a href=\"https://www.simononsoftware.com/are-long-running-transactions-bad/\" target=\"_blank\" rel=\"noopener\">长事务</a><br>怎么办，2）如何确保数据已全部同步到新节点，3）修改LOOKUP表前已经有读写数据的请求被路由到旧节点该怎么办？</p>\n<p>对于第1点，可以考虑，</p>\n<ul>\n<li>先拷贝[21至25]的数据，然后读取旧节点的最新binlog的ID为B；</li>\n<li>紧接着拷贝[26至30]的数据；</li>\n<li>将binlog的id为A至B的改动应用在[21至25]这个数据范围；</li>\n<li>将binlog的id为B至最新binlog的ID的全部数据应用到[21至30]这个范围；</li>\n</ul>\n<p>对于第2点，可以考虑通过新、旧节点间的lag来判断，并产生一个触发信号。</p>\n<p>对于第3点，需要有某个仲裁节点，在收到前述触发信号后，阻塞后续所有对于[20,30]的读写请求，直到旧节点对于[20,30]已发起的SQL语句已经全部处理返回后，修改LOOKUP表再让被阻塞的读写请求通行。</p>\n<p><strong>2、好处是什么？</strong></p>\n<p>相较于“静态算式规则”，“范围规则”的扩容更为简单，且不存在预设的最大节点数的影响。</p>\n<p>对于上文的range函数，如果是有序型的，</p>\n<ul>\n<li>则对范围查询较为友好；</li>\n<li>但却对自增主键式写入不友好（负载都压在最后一个结点），以及可能会导致hotspot（最近新增数据的读都压在最后一个结点），除非更换range函数为无序型的否则没有解决方案。</li>\n</ul>\n<p>如果是无序型的，</p>\n<ul>\n<li>则对范围查询不友好，解决思路同上文；</li>\n<li>但却能很好的将读写负载分散到各节点。</li>\n</ul>\n<p><strong>3、代价是什么？是否有解决思路？</strong></p>\n<p>上文已提及。</p>\n<h2 id=\"Common-issue\"><a href=\"#Common-issue\" class=\"headerlink\" title=\"Common issue\"></a>Common issue</h2><p>上面提到的两种sharding的case，有一些共同问题如下。</p>\n<p>一、都需要解决跨节点join的问题。业界解决思路是通过应用层代码去处理join，即先查小表A，再用小表A的结果作为参数去查询需要join的大表B（这里的大、小是相对的含义）；另外一种则是通过代理层去解决。</p>\n<p>二、都需要解决跨节点transaction的问题。业界的解决思路一般是改进式的2PC(<a href=\"https://en.wikipedia.org/wiki/Two-phase_commit_protocol\" target=\"_blank\" rel=\"noopener\">Two-phase commit protocol</a>)。</p>\n<p>三、如果主键有多个列应该如何sharding。假如主键是id和time，可以先通过id来定位到机器组0（假设有A、B、C、D四部机器组成），然后再由time来定位到A、B、C、D的其中一部机器。如果有超过2个主键呢？你确定你需要这么多主键吗？</p>\n<p>四、如何支持非聚簇索引。RDMS中，表除了聚簇索引，还有非聚簇索引。在已经sharding的前提下，如果要以非聚簇索引的列作为查询条件去查询数据，此时查询便退化成了全节点扫描。一个解决思路是，将非聚簇索引和聚簇索引单独建一张表（冗余表），然后以非聚簇索引去sharding，查询时先查冗余表，然后再回表到主表，以此避免全节点扫描。</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>本文介绍了两种sharding方式。一种是算术规则式，需要先预估逻辑节点的最大值，以避免代价昂贵的全节点rehash；另一种是范围规则式，其关键在于range函数的选取——有顺序型和无序型两种。</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6\" target=\"_blank\" rel=\"noopener\">How Sharding Works</a><br><a href=\"http://docs.clustrix.com/display/CLXDOC/Data+Distribution\" target=\"_blank\" rel=\"noopener\">ClustrixDB Data Distribution</a><br><a href=\"https://www.clustrix.com/bettersql/challenges-sharding-mysql/\" target=\"_blank\" rel=\"noopener\">Challenges of Sharding MySQL</a></p>\n","site":{"data":{}},"excerpt":"<p>本文简单总结RDMS对数据进行shard的一些套路。</p>","more":"<h2 id=\"Why-sharding\"><a href=\"#Why-sharding\" class=\"headerlink\" title=\"Why sharding\"></a>Why sharding</h2><p>早期的RDMS（Relational Database Management System）是单物理机单实例。随着用户量、访问量的急剧上升，20%的表可能占据了80%的数据量（二八法则），这时你可能会考虑将大数据表拆到机器A和机器B，小数据表拆到机器C。好处是显而易见的，原先压在一部机器的负载分散到多部机器，坏处是以前的一些SQL可能需要改写，因为我们无法跨库做join，尽可能把需要join的表分在一部机器的同一个库内可以暂时规避这个问题。</p>\n<p>很快的，用户量和数据继续蹭蹭蹭的往上涨，有些表已经是百万行级别了，很快又要撑不住了。这时，你把目光聚焦在那些大表上，发现有些表的某些列是BLOB型数据（图片或文件等）。这些数据一般不需要范围查询，基本都是指定主键查出来的，于是你把这些列分离出去，单独存在文件或图片服务器上，你的一些糟糕的<code>select * from xxx</code>的语句从此性能得到提升，新增的insert因为不需要写BLOB也比以前快了一丢丢，数据表的总体数据量大小也大大减少，代价是你需要根据主键到图片或文件服务器获取你要的BLOB数据。<br>（知识扩展：<code>select *</code>语句需要查聚簇索引——主键索引，因为BLOB数据一般不建立索引，需要在主键索引才能拿到没建立索引的列的数据）</p>\n<p>但是，把部分列分离出去，行数还是那么多啊！按照业务规模发展下去，行数分分钟就要破千万了啊！所有读写负载都打在了单表单服务器上，想想都是噩梦，怎么破？</p>\n<p>这时候只能把一张大表水平切几刀（表结构不变），切成多张小表了。这便是本文讨论的范围，主要是一些思路上的总结。</p>\n<ul>\n<li>怎么切：sharding strategy</li>\n<li>切完后怎么扩容：resharding</li>\n<li>切完有什么好处，又有何副作用以及业界是怎么解决这些问题的：side effect</li>\n</ul>\n<h2 id=\"Sharding-strategy-compare\"><a href=\"#Sharding-strategy-compare\" class=\"headerlink\" title=\"Sharding strategy compare\"></a>Sharding strategy compare</h2><h3 id=\"Case-1-静态算式规则切分\"><a href=\"#Case-1-静态算式规则切分\" class=\"headerlink\" title=\"Case 1 静态算式规则切分\"></a>Case 1 静态算式规则切分</h3><p><img src=\"https://user-images.githubusercontent.com/4915189/71431441-d97a8e80-270c-11ea-9b72-ed3ec0e921a2.png\" alt=\"id % 4\"></p>\n<p>上图的<code>id</code>是主键，4是结点总数，<code>id % 4</code>即静态算术规则。输入主键计算出数值下标，由数值到LOOKUP表就可以确定数据在哪台服务器上。<br>（注：LOOKUP表维护下标与真实服务器信息的对应关系，简单实现可以考虑配置在服务器，复杂的可以考虑引入Zookeeper）</p>\n<p><strong>1、如何扩容？</strong></p>\n<p>对于<code>id % 4</code>的规则，扩容类似于<a href=\"https://www.geeksforgeeks.org/load-factor-and-rehashing/\" target=\"_blank\" rel=\"noopener\">Java HashMap的rebash的过程</a>。如果id不是一个整型数值，规则需要改写成<code>hash(id) % 4</code>，hash函数用于将id转为int。假如新增一个节点，此时需要经历以下过程：</p>\n<ul>\n<li>将第0结点上的id做<code>id % 5</code>，如果值不为0，则将该行记录移动到其他服务器上；</li>\n<li>其他结点以此类推。</li>\n</ul>\n<p>这里有两个显而易见的坏处，</p>\n<ul>\n<li>几乎每个结点的数据都需要重新打散，分发到其他服务器。这需要大量的磁盘IO，可谓伤筋动骨，改进办法见下文；</li>\n<li>在扩容未完成时，该从哪个结点读？该从哪个结点写？如果要做到动态扩容不影响读写，那么就需要做非常非常多的额外工作。一个可以考虑的策略是，挂个升级公告，停止对外服务，扩容期间数据库无任何读写，这应该算是一般游戏公司的做法了。</li>\n</ul>\n<p><strong>2、好处是什么？</strong></p>\n<p>读和写能够比较均匀的打到各个节点。</p>\n<ul>\n<li>对于自增主键式的写入，不会出现负载都打在一个结点的情况；</li>\n<li>对于频繁读最近新增的数据的case，也不会出现负载都打在一个结点的情况。</li>\n</ul>\n<p><strong>3、代价是什么？是否有解决思路？</strong></p>\n<p>对于上面的<code>id % 4</code>问题，其实可以换一个思路。虽然我们只有4台物理机，但我们可以把规则定为<code>id % 1024</code>，即逻辑上有1024台机。然后通过配置上面说的LOOKUP表，实现4台物理机均摊这1024台逻辑机器的角色，这样可以规避上面的新增结点需要全部数据打散的问题，这也是<a href=\"https://en.wikipedia.org/wiki/Consistent_hashing\" target=\"_blank\" rel=\"noopener\">一致性哈希</a><br>的思想。1024这数值必须是公司业务理论上不能达到的上限（除了顶尖的那几家互联网公司，一般公司也不会超过这个值了），否则还是会出现上面的痛点。</p>\n<p>主键被打散，对按主键范围查询不友好，范围查询基本退化成了全表查询。如果主键范围查询时还带<code>order by</code>，那还得在查询完后自行对数据进行排序。</p>\n<p>解决思路是，数据在单节点是有序的，将查询分发给每个结点，并行去查数据，最后对返回结果做合并。如果要求<code>order by</code>，则在合并结果集时进行两两的归并排序。</p>\n<h3 id=\"Case-2-范围规则切分\"><a href=\"#Case-2-范围规则切分\" class=\"headerlink\" title=\"Case 2 范围规则切分\"></a>Case 2 范围规则切分</h3><p><img src=\"https://user-images.githubusercontent.com/4915189/71431444-dd0e1580-270c-11ea-8d7d-c801dd1df161.png\" alt=\"dynamic range\"></p>\n<p>与上面的算式规则不同的是，这里需要一个range函数，输入主键后得到一个range数值，然后再去查LOOKUP表确定数据落在哪个结点。range函数一般有两种，有序型和无序性。输入[1,2,3,4]这一组数据后，输出的数据依然是有序的称为有序型（一般应用在数据类型），输出无序的称为无序型（比如hash函数）。</p>\n<p><strong>1、如何扩容？</strong></p>\n<p>相比“静态算式规则”，“范围规则”的扩容较为简单。以将范围[10, 30]拆成[10,20]和[21,30]为例，大概需要以下过程，</p>\n<ul>\n<li>新增物理节点；</li>\n<li>标记旧节点[10,30]当前binlog的ID为A；</li>\n<li>利用MySQL的可重复读（repeatable read）的特性，将数据copy到新节点；</li>\n<li>完成copy后，新节点从上文binlog的ID为A的位置，同步旧节点的binlog数据，仅应用对[21,30]范围有影响的语句；</li>\n<li>binlog同步完成后，修改LOOKUP表，使得后续对[21,30]范围的读写路由到新节点，清除旧节点[21,30]这个范围的数据；</li>\n</ul>\n<p>这里有几个挑战，1）数据表太大一次性拷贝将导致<a href=\"https://www.simononsoftware.com/are-long-running-transactions-bad/\" target=\"_blank\" rel=\"noopener\">长事务</a><br>怎么办，2）如何确保数据已全部同步到新节点，3）修改LOOKUP表前已经有读写数据的请求被路由到旧节点该怎么办？</p>\n<p>对于第1点，可以考虑，</p>\n<ul>\n<li>先拷贝[21至25]的数据，然后读取旧节点的最新binlog的ID为B；</li>\n<li>紧接着拷贝[26至30]的数据；</li>\n<li>将binlog的id为A至B的改动应用在[21至25]这个数据范围；</li>\n<li>将binlog的id为B至最新binlog的ID的全部数据应用到[21至30]这个范围；</li>\n</ul>\n<p>对于第2点，可以考虑通过新、旧节点间的lag来判断，并产生一个触发信号。</p>\n<p>对于第3点，需要有某个仲裁节点，在收到前述触发信号后，阻塞后续所有对于[20,30]的读写请求，直到旧节点对于[20,30]已发起的SQL语句已经全部处理返回后，修改LOOKUP表再让被阻塞的读写请求通行。</p>\n<p><strong>2、好处是什么？</strong></p>\n<p>相较于“静态算式规则”，“范围规则”的扩容更为简单，且不存在预设的最大节点数的影响。</p>\n<p>对于上文的range函数，如果是有序型的，</p>\n<ul>\n<li>则对范围查询较为友好；</li>\n<li>但却对自增主键式写入不友好（负载都压在最后一个结点），以及可能会导致hotspot（最近新增数据的读都压在最后一个结点），除非更换range函数为无序型的否则没有解决方案。</li>\n</ul>\n<p>如果是无序型的，</p>\n<ul>\n<li>则对范围查询不友好，解决思路同上文；</li>\n<li>但却能很好的将读写负载分散到各节点。</li>\n</ul>\n<p><strong>3、代价是什么？是否有解决思路？</strong></p>\n<p>上文已提及。</p>\n<h2 id=\"Common-issue\"><a href=\"#Common-issue\" class=\"headerlink\" title=\"Common issue\"></a>Common issue</h2><p>上面提到的两种sharding的case，有一些共同问题如下。</p>\n<p>一、都需要解决跨节点join的问题。业界解决思路是通过应用层代码去处理join，即先查小表A，再用小表A的结果作为参数去查询需要join的大表B（这里的大、小是相对的含义）；另外一种则是通过代理层去解决。</p>\n<p>二、都需要解决跨节点transaction的问题。业界的解决思路一般是改进式的2PC(<a href=\"https://en.wikipedia.org/wiki/Two-phase_commit_protocol\" target=\"_blank\" rel=\"noopener\">Two-phase commit protocol</a>)。</p>\n<p>三、如果主键有多个列应该如何sharding。假如主键是id和time，可以先通过id来定位到机器组0（假设有A、B、C、D四部机器组成），然后再由time来定位到A、B、C、D的其中一部机器。如果有超过2个主键呢？你确定你需要这么多主键吗？</p>\n<p>四、如何支持非聚簇索引。RDMS中，表除了聚簇索引，还有非聚簇索引。在已经sharding的前提下，如果要以非聚簇索引的列作为查询条件去查询数据，此时查询便退化成了全节点扫描。一个解决思路是，将非聚簇索引和聚簇索引单独建一张表（冗余表），然后以非聚簇索引去sharding，查询时先查冗余表，然后再回表到主表，以此避免全节点扫描。</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>本文介绍了两种sharding方式。一种是算术规则式，需要先预估逻辑节点的最大值，以避免代价昂贵的全节点rehash；另一种是范围规则式，其关键在于range函数的选取——有顺序型和无序型两种。</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6\" target=\"_blank\" rel=\"noopener\">How Sharding Works</a><br><a href=\"http://docs.clustrix.com/display/CLXDOC/Data+Distribution\" target=\"_blank\" rel=\"noopener\">ClustrixDB Data Distribution</a><br><a href=\"https://www.clustrix.com/bettersql/challenges-sharding-mysql/\" target=\"_blank\" rel=\"noopener\">Challenges of Sharding MySQL</a></p>"},{"title":"TCP状态转移总结","date":"2018-09-20T15:57:43.000Z","comments":1,"_content":"\n简单总结几个个人觉得较为重要的TCP状态。\n\n<!--more-->\n\n![20170120191710076.png](https://user-images.githubusercontent.com/4915189/71431467-f7e08a00-270c-11ea-922b-0f1638cb8b61.png)\n\n名词定义：\n\n- 客户端：发起connect操作的端\n- 服务端：发起bind操作的端\n- 主动关闭端：主动发起四次挥手端\n- 被动关闭端：被动接收四次挥手FIN报文端\n\n\n## CLOSED\n\n- 客户端发送SYN后进入SYN_SENT，若超时未收到ACK，则进入CLOSED\n- 被动关闭端接收到FIN后，发送ACK后进入CLOSE_WAIT，等待应用可进入CLOSED状态后，发送FIN后进入LAST_ACK状态，等待并接收到主动关闭端的ACK后进入CLOSED状态\n- 主动关闭端接收到FIN后，进入TIME_WAIT，等待2MSL时间后，进入CLOSED状态\n- 通过设置SO_LINGER可干预内核对于socket close动作的静默处理\n\n## CLOSE_WAIT\n\n若程序有大量socket进入此状态，则意味着被动关闭端大量的连接在收到FIN后，程序没有主动将socket close掉。对应到Java的Mina或Netty框架，应该在IDLE或者EXCEPTION_CAUGHT时，主动将socket进行close。\n\n## FIN_WAIT\n\n- FIN_WAIT-1是主动关闭端发送FIN后进入的状态\n- 主动关闭端若收到被动关闭端ACK，则进入FIN_WAIT-2\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431469-fca53e00-270c-11ea-97ce-e684f88792d6.png)\n\n## 服务端的SYN_RCVD与ESTABLISHED\n\n- 服务端处于SYN_RCVD的Socket存在于服务端的半连接队列中，队列数量配置内核参数tcp_max_syn_backlog。臭名昭著的SYN Flood攻击便是利用TCP服务端的SYN_RCVD状态进行攻击的（服务端静默重发ACK五次），半连接队列满了之后，静默处理是拒绝接受新的SYN，攻击者由此达到了拒绝服务攻击的目的，可通过Linux的SYNcookie防范此攻击（此时tcp_max_syn_backlog值无效）\n- 服务端处于ESTABLISHED的Socket存在于服务端的全连接队列，队列数量配置内核参数backlog，队列满了将拒绝接受accept新连接，可配置内核参数设置队列满之后静默丢弃客户端的ACK还是发送回一个RST\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431473-029b1f00-270d-11ea-9acf-cd848b9705b7.png)\n\n## TIME_WAIT\n\n如果C端不维持TIME_WAIT状态，而是FIN_WAIT2后直接进入CLOSED状态，那么C端将响应RST分节，S端收到后将此分节解释成一个错误，因此若想实现正常关闭，此环节必不可少；\nMSL是一个IP数据报能在互联网上存在的最长时间，而TIME_WAIT持续的时间是两个MSL，这实际上是对路由器异常的容错，防止程序收到脏数据；\n\n","source":"_posts/2018-09-20-tcp-state.md","raw":"---\ntitle: TCP状态转移总结\ndate: 2018-09-20 23:57:43\ntags: 'TCP/IP'\ncomments: true\ncategories: ['计算机网络']\n---\n\n简单总结几个个人觉得较为重要的TCP状态。\n\n<!--more-->\n\n![20170120191710076.png](https://user-images.githubusercontent.com/4915189/71431467-f7e08a00-270c-11ea-922b-0f1638cb8b61.png)\n\n名词定义：\n\n- 客户端：发起connect操作的端\n- 服务端：发起bind操作的端\n- 主动关闭端：主动发起四次挥手端\n- 被动关闭端：被动接收四次挥手FIN报文端\n\n\n## CLOSED\n\n- 客户端发送SYN后进入SYN_SENT，若超时未收到ACK，则进入CLOSED\n- 被动关闭端接收到FIN后，发送ACK后进入CLOSE_WAIT，等待应用可进入CLOSED状态后，发送FIN后进入LAST_ACK状态，等待并接收到主动关闭端的ACK后进入CLOSED状态\n- 主动关闭端接收到FIN后，进入TIME_WAIT，等待2MSL时间后，进入CLOSED状态\n- 通过设置SO_LINGER可干预内核对于socket close动作的静默处理\n\n## CLOSE_WAIT\n\n若程序有大量socket进入此状态，则意味着被动关闭端大量的连接在收到FIN后，程序没有主动将socket close掉。对应到Java的Mina或Netty框架，应该在IDLE或者EXCEPTION_CAUGHT时，主动将socket进行close。\n\n## FIN_WAIT\n\n- FIN_WAIT-1是主动关闭端发送FIN后进入的状态\n- 主动关闭端若收到被动关闭端ACK，则进入FIN_WAIT-2\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431469-fca53e00-270c-11ea-97ce-e684f88792d6.png)\n\n## 服务端的SYN_RCVD与ESTABLISHED\n\n- 服务端处于SYN_RCVD的Socket存在于服务端的半连接队列中，队列数量配置内核参数tcp_max_syn_backlog。臭名昭著的SYN Flood攻击便是利用TCP服务端的SYN_RCVD状态进行攻击的（服务端静默重发ACK五次），半连接队列满了之后，静默处理是拒绝接受新的SYN，攻击者由此达到了拒绝服务攻击的目的，可通过Linux的SYNcookie防范此攻击（此时tcp_max_syn_backlog值无效）\n- 服务端处于ESTABLISHED的Socket存在于服务端的全连接队列，队列数量配置内核参数backlog，队列满了将拒绝接受accept新连接，可配置内核参数设置队列满之后静默丢弃客户端的ACK还是发送回一个RST\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431473-029b1f00-270d-11ea-9acf-cd848b9705b7.png)\n\n## TIME_WAIT\n\n如果C端不维持TIME_WAIT状态，而是FIN_WAIT2后直接进入CLOSED状态，那么C端将响应RST分节，S端收到后将此分节解释成一个错误，因此若想实现正常关闭，此环节必不可少；\nMSL是一个IP数据报能在互联网上存在的最长时间，而TIME_WAIT持续的时间是两个MSL，这实际上是对路由器异常的容错，防止程序收到脏数据；\n\n","slug":"tcp-state","published":1,"updated":"2022-08-09T15:02:00.645Z","layout":"post","photos":[],"link":"","_id":"cl6mbc148002yigu8fy800kgo","content":"<p>简单总结几个个人觉得较为重要的TCP状态。</p>\n<a id=\"more\"></a>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431467-f7e08a00-270c-11ea-922b-0f1638cb8b61.png\" alt=\"20170120191710076.png\"></p>\n<p>名词定义：</p>\n<ul>\n<li>客户端：发起connect操作的端</li>\n<li>服务端：发起bind操作的端</li>\n<li>主动关闭端：主动发起四次挥手端</li>\n<li>被动关闭端：被动接收四次挥手FIN报文端</li>\n</ul>\n<h2 id=\"CLOSED\"><a href=\"#CLOSED\" class=\"headerlink\" title=\"CLOSED\"></a>CLOSED</h2><ul>\n<li>客户端发送SYN后进入SYN_SENT，若超时未收到ACK，则进入CLOSED</li>\n<li>被动关闭端接收到FIN后，发送ACK后进入CLOSE_WAIT，等待应用可进入CLOSED状态后，发送FIN后进入LAST_ACK状态，等待并接收到主动关闭端的ACK后进入CLOSED状态</li>\n<li>主动关闭端接收到FIN后，进入TIME_WAIT，等待2MSL时间后，进入CLOSED状态</li>\n<li>通过设置SO_LINGER可干预内核对于socket close动作的静默处理</li>\n</ul>\n<h2 id=\"CLOSE-WAIT\"><a href=\"#CLOSE-WAIT\" class=\"headerlink\" title=\"CLOSE_WAIT\"></a>CLOSE_WAIT</h2><p>若程序有大量socket进入此状态，则意味着被动关闭端大量的连接在收到FIN后，程序没有主动将socket close掉。对应到Java的Mina或Netty框架，应该在IDLE或者EXCEPTION_CAUGHT时，主动将socket进行close。</p>\n<h2 id=\"FIN-WAIT\"><a href=\"#FIN-WAIT\" class=\"headerlink\" title=\"FIN_WAIT\"></a>FIN_WAIT</h2><ul>\n<li>FIN_WAIT-1是主动关闭端发送FIN后进入的状态</li>\n<li>主动关闭端若收到被动关闭端ACK，则进入FIN_WAIT-2</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431469-fca53e00-270c-11ea-97ce-e684f88792d6.png\" alt=\"image.png\"></p>\n<h2 id=\"服务端的SYN-RCVD与ESTABLISHED\"><a href=\"#服务端的SYN-RCVD与ESTABLISHED\" class=\"headerlink\" title=\"服务端的SYN_RCVD与ESTABLISHED\"></a>服务端的SYN_RCVD与ESTABLISHED</h2><ul>\n<li>服务端处于SYN_RCVD的Socket存在于服务端的半连接队列中，队列数量配置内核参数tcp_max_syn_backlog。臭名昭著的SYN Flood攻击便是利用TCP服务端的SYN_RCVD状态进行攻击的（服务端静默重发ACK五次），半连接队列满了之后，静默处理是拒绝接受新的SYN，攻击者由此达到了拒绝服务攻击的目的，可通过Linux的SYNcookie防范此攻击（此时tcp_max_syn_backlog值无效）</li>\n<li>服务端处于ESTABLISHED的Socket存在于服务端的全连接队列，队列数量配置内核参数backlog，队列满了将拒绝接受accept新连接，可配置内核参数设置队列满之后静默丢弃客户端的ACK还是发送回一个RST</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431473-029b1f00-270d-11ea-9acf-cd848b9705b7.png\" alt=\"image.png\"></p>\n<h2 id=\"TIME-WAIT\"><a href=\"#TIME-WAIT\" class=\"headerlink\" title=\"TIME_WAIT\"></a>TIME_WAIT</h2><p>如果C端不维持TIME_WAIT状态，而是FIN_WAIT2后直接进入CLOSED状态，那么C端将响应RST分节，S端收到后将此分节解释成一个错误，因此若想实现正常关闭，此环节必不可少；<br>MSL是一个IP数据报能在互联网上存在的最长时间，而TIME_WAIT持续的时间是两个MSL，这实际上是对路由器异常的容错，防止程序收到脏数据；</p>\n","site":{"data":{}},"excerpt":"<p>简单总结几个个人觉得较为重要的TCP状态。</p>","more":"<p><img src=\"https://user-images.githubusercontent.com/4915189/71431467-f7e08a00-270c-11ea-922b-0f1638cb8b61.png\" alt=\"20170120191710076.png\"></p>\n<p>名词定义：</p>\n<ul>\n<li>客户端：发起connect操作的端</li>\n<li>服务端：发起bind操作的端</li>\n<li>主动关闭端：主动发起四次挥手端</li>\n<li>被动关闭端：被动接收四次挥手FIN报文端</li>\n</ul>\n<h2 id=\"CLOSED\"><a href=\"#CLOSED\" class=\"headerlink\" title=\"CLOSED\"></a>CLOSED</h2><ul>\n<li>客户端发送SYN后进入SYN_SENT，若超时未收到ACK，则进入CLOSED</li>\n<li>被动关闭端接收到FIN后，发送ACK后进入CLOSE_WAIT，等待应用可进入CLOSED状态后，发送FIN后进入LAST_ACK状态，等待并接收到主动关闭端的ACK后进入CLOSED状态</li>\n<li>主动关闭端接收到FIN后，进入TIME_WAIT，等待2MSL时间后，进入CLOSED状态</li>\n<li>通过设置SO_LINGER可干预内核对于socket close动作的静默处理</li>\n</ul>\n<h2 id=\"CLOSE-WAIT\"><a href=\"#CLOSE-WAIT\" class=\"headerlink\" title=\"CLOSE_WAIT\"></a>CLOSE_WAIT</h2><p>若程序有大量socket进入此状态，则意味着被动关闭端大量的连接在收到FIN后，程序没有主动将socket close掉。对应到Java的Mina或Netty框架，应该在IDLE或者EXCEPTION_CAUGHT时，主动将socket进行close。</p>\n<h2 id=\"FIN-WAIT\"><a href=\"#FIN-WAIT\" class=\"headerlink\" title=\"FIN_WAIT\"></a>FIN_WAIT</h2><ul>\n<li>FIN_WAIT-1是主动关闭端发送FIN后进入的状态</li>\n<li>主动关闭端若收到被动关闭端ACK，则进入FIN_WAIT-2</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431469-fca53e00-270c-11ea-97ce-e684f88792d6.png\" alt=\"image.png\"></p>\n<h2 id=\"服务端的SYN-RCVD与ESTABLISHED\"><a href=\"#服务端的SYN-RCVD与ESTABLISHED\" class=\"headerlink\" title=\"服务端的SYN_RCVD与ESTABLISHED\"></a>服务端的SYN_RCVD与ESTABLISHED</h2><ul>\n<li>服务端处于SYN_RCVD的Socket存在于服务端的半连接队列中，队列数量配置内核参数tcp_max_syn_backlog。臭名昭著的SYN Flood攻击便是利用TCP服务端的SYN_RCVD状态进行攻击的（服务端静默重发ACK五次），半连接队列满了之后，静默处理是拒绝接受新的SYN，攻击者由此达到了拒绝服务攻击的目的，可通过Linux的SYNcookie防范此攻击（此时tcp_max_syn_backlog值无效）</li>\n<li>服务端处于ESTABLISHED的Socket存在于服务端的全连接队列，队列数量配置内核参数backlog，队列满了将拒绝接受accept新连接，可配置内核参数设置队列满之后静默丢弃客户端的ACK还是发送回一个RST</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431473-029b1f00-270d-11ea-9acf-cd848b9705b7.png\" alt=\"image.png\"></p>\n<h2 id=\"TIME-WAIT\"><a href=\"#TIME-WAIT\" class=\"headerlink\" title=\"TIME_WAIT\"></a>TIME_WAIT</h2><p>如果C端不维持TIME_WAIT状态，而是FIN_WAIT2后直接进入CLOSED状态，那么C端将响应RST分节，S端收到后将此分节解释成一个错误，因此若想实现正常关闭，此环节必不可少；<br>MSL是一个IP数据报能在互联网上存在的最长时间，而TIME_WAIT持续的时间是两个MSL，这实际上是对路由器异常的容错，防止程序收到脏数据；</p>"},{"title":"redis的分布式锁算法redlock","date":"2019-08-21T00:07:44.000Z","comments":1,"_content":"\nRedis单实例用于分布式锁的方案，在对可靠性要求不够高的场景下已经被大量应用，然而此方案存在一些缺陷，其作者提出了一种新的基于redis多实例的改进版算法。\n\n<!-- more -->\n\n**1. Redis单实例作为分布式锁存在什么问题？**\n\n单点故障。假设Redis实例crash了，依赖获取锁后进行相应工作的业务逻辑无法执行。\n\n互斥问题。进程A取锁，进入业务逻辑工作，此时Redis实例恰好crash并快速恢复了。进程B立即取到锁，也进入了业务逻辑。Boom，分布式锁的互斥性得不到保证了。\n\n**2. 新版Redlock算法的思路是什么？**\n\n> 1. It gets the current time in milliseconds.\n客户端获取当前时间（毫秒）\n> 2. It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP.\n用同一个key+随机value顺序向N个redis实例取NX锁，取NX锁的timeout相比redlock锁的release时间要小得多（毫秒级），若某个redis实例crash客户端能快速越过\n> 3. The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired.\n当且仅当获取半数以上redis实例的NX锁，且获取NX锁的总耗时（利用当前时间减去第一步的时间）小于redlock锁的release时间，获取redlock锁成功\n> 4. If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3.\n> 5. If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).\n如果获取redlock锁失败，主动释放各个redis实例已经获取的NX锁\n\n**3. Martin认为以上算法存在什么问题？**\n\n分布式领域的专家在[他的博客](http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)对分布式算法redlock提出质疑，质疑点如下。\n\n互斥性问题。见下图。Client1获取锁后进入STW，STW后锁已经超时，但Client1仍然认为自己持有锁。antirez在[他的博客](http://antirez.com/news/101)回应可以通过时间的double check来规避这个问题，但Martin提出，STW可能在任何情况下发生，更甚的是网络导致的延迟更是程序难以规避的，检查时间根本没用。Martin在他的博客提出了fencing的解决方案，详见他的博客。\n\n![互斥问题](http://martin.kleppmann.com/2016/02/unsafe-lock.png)\n\n时钟依赖问题。Martin提到Redis依赖于系统调用`gettimeofday`来判断NX锁是否超时，`gettimeofday`的可靠性堪忧，某些情况下如NTP校时会导致NX锁的提前或延后超时，Martin在他的博客提出这也会导致互斥问题。\n\n直觉上来讲，redlock算法在上述第3步，获取锁的时间虽然没超时，但获取锁的时间占据了redlock锁release时间的大部分，此时还有进行下去的必要吗？\n\n**4. antirez的回应有哪些亮点？**\n\n为什么NX锁的value要用随机值？可以通过lua脚本原子性的释放锁。\n\n客户端获取redlock锁失败后，应休眠random delay后重试，防止多客户端在同一时间又去竞争锁，竞态得不到缓解。\n\n如果N个redis实例其中某一个crash了，可以为其设置一个delay start，防止它恢复后突然加入打破现有的平衡。也可以考虑设置fsync，这样每次redis数据修改都会落盘。\n","source":"_posts/2019-08-21-redlock-algorithm.md","raw":"---\ntitle: redis的分布式锁算法redlock\ndate: 2019-08-21 08:07:44\ntags: ['Redis']\ncomments: true\ncategories: ['分布式系统']\n---\n\nRedis单实例用于分布式锁的方案，在对可靠性要求不够高的场景下已经被大量应用，然而此方案存在一些缺陷，其作者提出了一种新的基于redis多实例的改进版算法。\n\n<!-- more -->\n\n**1. Redis单实例作为分布式锁存在什么问题？**\n\n单点故障。假设Redis实例crash了，依赖获取锁后进行相应工作的业务逻辑无法执行。\n\n互斥问题。进程A取锁，进入业务逻辑工作，此时Redis实例恰好crash并快速恢复了。进程B立即取到锁，也进入了业务逻辑。Boom，分布式锁的互斥性得不到保证了。\n\n**2. 新版Redlock算法的思路是什么？**\n\n> 1. It gets the current time in milliseconds.\n客户端获取当前时间（毫秒）\n> 2. It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP.\n用同一个key+随机value顺序向N个redis实例取NX锁，取NX锁的timeout相比redlock锁的release时间要小得多（毫秒级），若某个redis实例crash客户端能快速越过\n> 3. The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired.\n当且仅当获取半数以上redis实例的NX锁，且获取NX锁的总耗时（利用当前时间减去第一步的时间）小于redlock锁的release时间，获取redlock锁成功\n> 4. If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3.\n> 5. If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).\n如果获取redlock锁失败，主动释放各个redis实例已经获取的NX锁\n\n**3. Martin认为以上算法存在什么问题？**\n\n分布式领域的专家在[他的博客](http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)对分布式算法redlock提出质疑，质疑点如下。\n\n互斥性问题。见下图。Client1获取锁后进入STW，STW后锁已经超时，但Client1仍然认为自己持有锁。antirez在[他的博客](http://antirez.com/news/101)回应可以通过时间的double check来规避这个问题，但Martin提出，STW可能在任何情况下发生，更甚的是网络导致的延迟更是程序难以规避的，检查时间根本没用。Martin在他的博客提出了fencing的解决方案，详见他的博客。\n\n![互斥问题](http://martin.kleppmann.com/2016/02/unsafe-lock.png)\n\n时钟依赖问题。Martin提到Redis依赖于系统调用`gettimeofday`来判断NX锁是否超时，`gettimeofday`的可靠性堪忧，某些情况下如NTP校时会导致NX锁的提前或延后超时，Martin在他的博客提出这也会导致互斥问题。\n\n直觉上来讲，redlock算法在上述第3步，获取锁的时间虽然没超时，但获取锁的时间占据了redlock锁release时间的大部分，此时还有进行下去的必要吗？\n\n**4. antirez的回应有哪些亮点？**\n\n为什么NX锁的value要用随机值？可以通过lua脚本原子性的释放锁。\n\n客户端获取redlock锁失败后，应休眠random delay后重试，防止多客户端在同一时间又去竞争锁，竞态得不到缓解。\n\n如果N个redis实例其中某一个crash了，可以为其设置一个delay start，防止它恢复后突然加入打破现有的平衡。也可以考虑设置fsync，这样每次redis数据修改都会落盘。\n","slug":"redlock-algorithm","published":1,"updated":"2022-08-09T15:02:00.651Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14b0032igu87qrh5z3u","content":"<p>Redis单实例用于分布式锁的方案，在对可靠性要求不够高的场景下已经被大量应用，然而此方案存在一些缺陷，其作者提出了一种新的基于redis多实例的改进版算法。</p>\n<a id=\"more\"></a>\n<p><strong>1. Redis单实例作为分布式锁存在什么问题？</strong></p>\n<p>单点故障。假设Redis实例crash了，依赖获取锁后进行相应工作的业务逻辑无法执行。</p>\n<p>互斥问题。进程A取锁，进入业务逻辑工作，此时Redis实例恰好crash并快速恢复了。进程B立即取到锁，也进入了业务逻辑。Boom，分布式锁的互斥性得不到保证了。</p>\n<p><strong>2. 新版Redlock算法的思路是什么？</strong></p>\n<blockquote>\n<ol>\n<li>It gets the current time in milliseconds.<br>客户端获取当前时间（毫秒）</li>\n<li>It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP.<br>用同一个key+随机value顺序向N个redis实例取NX锁，取NX锁的timeout相比redlock锁的release时间要小得多（毫秒级），若某个redis实例crash客户端能快速越过</li>\n<li>The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired.<br>当且仅当获取半数以上redis实例的NX锁，且获取NX锁的总耗时（利用当前时间减去第一步的时间）小于redlock锁的release时间，获取redlock锁成功</li>\n<li>If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3.</li>\n<li>If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).<br>如果获取redlock锁失败，主动释放各个redis实例已经获取的NX锁</li>\n</ol>\n</blockquote>\n<p><strong>3. Martin认为以上算法存在什么问题？</strong></p>\n<p>分布式领域的专家在<a href=\"http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\" target=\"_blank\" rel=\"noopener\">他的博客</a>对分布式算法redlock提出质疑，质疑点如下。</p>\n<p>互斥性问题。见下图。Client1获取锁后进入STW，STW后锁已经超时，但Client1仍然认为自己持有锁。antirez在<a href=\"http://antirez.com/news/101\" target=\"_blank\" rel=\"noopener\">他的博客</a>回应可以通过时间的double check来规避这个问题，但Martin提出，STW可能在任何情况下发生，更甚的是网络导致的延迟更是程序难以规避的，检查时间根本没用。Martin在他的博客提出了fencing的解决方案，详见他的博客。</p>\n<p><img src=\"http://martin.kleppmann.com/2016/02/unsafe-lock.png\" alt=\"互斥问题\"></p>\n<p>时钟依赖问题。Martin提到Redis依赖于系统调用<code>gettimeofday</code>来判断NX锁是否超时，<code>gettimeofday</code>的可靠性堪忧，某些情况下如NTP校时会导致NX锁的提前或延后超时，Martin在他的博客提出这也会导致互斥问题。</p>\n<p>直觉上来讲，redlock算法在上述第3步，获取锁的时间虽然没超时，但获取锁的时间占据了redlock锁release时间的大部分，此时还有进行下去的必要吗？</p>\n<p><strong>4. antirez的回应有哪些亮点？</strong></p>\n<p>为什么NX锁的value要用随机值？可以通过lua脚本原子性的释放锁。</p>\n<p>客户端获取redlock锁失败后，应休眠random delay后重试，防止多客户端在同一时间又去竞争锁，竞态得不到缓解。</p>\n<p>如果N个redis实例其中某一个crash了，可以为其设置一个delay start，防止它恢复后突然加入打破现有的平衡。也可以考虑设置fsync，这样每次redis数据修改都会落盘。</p>\n","site":{"data":{}},"excerpt":"<p>Redis单实例用于分布式锁的方案，在对可靠性要求不够高的场景下已经被大量应用，然而此方案存在一些缺陷，其作者提出了一种新的基于redis多实例的改进版算法。</p>","more":"<p><strong>1. Redis单实例作为分布式锁存在什么问题？</strong></p>\n<p>单点故障。假设Redis实例crash了，依赖获取锁后进行相应工作的业务逻辑无法执行。</p>\n<p>互斥问题。进程A取锁，进入业务逻辑工作，此时Redis实例恰好crash并快速恢复了。进程B立即取到锁，也进入了业务逻辑。Boom，分布式锁的互斥性得不到保证了。</p>\n<p><strong>2. 新版Redlock算法的思路是什么？</strong></p>\n<blockquote>\n<ol>\n<li>It gets the current time in milliseconds.<br>客户端获取当前时间（毫秒）</li>\n<li>It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP.<br>用同一个key+随机value顺序向N个redis实例取NX锁，取NX锁的timeout相比redlock锁的release时间要小得多（毫秒级），若某个redis实例crash客户端能快速越过</li>\n<li>The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired.<br>当且仅当获取半数以上redis实例的NX锁，且获取NX锁的总耗时（利用当前时间减去第一步的时间）小于redlock锁的release时间，获取redlock锁成功</li>\n<li>If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3.</li>\n<li>If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).<br>如果获取redlock锁失败，主动释放各个redis实例已经获取的NX锁</li>\n</ol>\n</blockquote>\n<p><strong>3. Martin认为以上算法存在什么问题？</strong></p>\n<p>分布式领域的专家在<a href=\"http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\" target=\"_blank\" rel=\"noopener\">他的博客</a>对分布式算法redlock提出质疑，质疑点如下。</p>\n<p>互斥性问题。见下图。Client1获取锁后进入STW，STW后锁已经超时，但Client1仍然认为自己持有锁。antirez在<a href=\"http://antirez.com/news/101\" target=\"_blank\" rel=\"noopener\">他的博客</a>回应可以通过时间的double check来规避这个问题，但Martin提出，STW可能在任何情况下发生，更甚的是网络导致的延迟更是程序难以规避的，检查时间根本没用。Martin在他的博客提出了fencing的解决方案，详见他的博客。</p>\n<p><img src=\"http://martin.kleppmann.com/2016/02/unsafe-lock.png\" alt=\"互斥问题\"></p>\n<p>时钟依赖问题。Martin提到Redis依赖于系统调用<code>gettimeofday</code>来判断NX锁是否超时，<code>gettimeofday</code>的可靠性堪忧，某些情况下如NTP校时会导致NX锁的提前或延后超时，Martin在他的博客提出这也会导致互斥问题。</p>\n<p>直觉上来讲，redlock算法在上述第3步，获取锁的时间虽然没超时，但获取锁的时间占据了redlock锁release时间的大部分，此时还有进行下去的必要吗？</p>\n<p><strong>4. antirez的回应有哪些亮点？</strong></p>\n<p>为什么NX锁的value要用随机值？可以通过lua脚本原子性的释放锁。</p>\n<p>客户端获取redlock锁失败后，应休眠random delay后重试，防止多客户端在同一时间又去竞争锁，竞态得不到缓解。</p>\n<p>如果N个redis实例其中某一个crash了，可以为其设置一个delay start，防止它恢复后突然加入打破现有的平衡。也可以考虑设置fsync，这样每次redis数据修改都会落盘。</p>"},{"title":"Redis Cluster & HDFS & ClustrixDB Reshard/Rebalance","date":"2019-03-31T14:12:14.000Z","comments":1,"_content":"\n对于分布式存储，在新增或删除节点时，必将存在某些节点的数据“过多”，某些节点的数据“过少”。对节点上的数据进行重新整理使各节点的数据趋于相近的过程，就叫rebalance或reshard。本文简单介绍Redis Cluster、HDFS和ClustrixDB是如何对数据进行重分片的。\n\n<!--more-->\n\n## Redis Cluster Reshard\n\n细节参考自[Redis Cluster Spec](https://redis.io/topics/cluster-spec)的**Redirection and resharding**章节。下图表示数据slot原先在Original节点，被迁移到New节点需要经历的过程。\n（注：slot的介绍见[Redis Cluster Spec](https://redis.io/topics/cluster-spec)）\n\n![redis cluster reshard](https://user-images.githubusercontent.com/4915189/71431424-c23ba100-270c-11ea-91b1-1cafb8aeaef5.png)\n\n- 新增了New节点——Redis Instance（也可能是本来就存在的一个redis实例）；\n- Original上待迁移slot被设置为importing状态，New上欲接受slot被设置为migrating状态。对该slot的读写请求仍然从original节点进来，但是当original不存在请求中包含的key时，请求将被转发给new节点，original已存在该key则请求仍由original受理；\n- 将original节点已有的key逐个迁移到new节点，每个key在迁移过程是原子性的（会对该key进行加锁）；\n- key全部迁移完成后，通过gossip协议通知集群中的其他节点更新metadata，以后该slot节点的请求将由new节点负责。\n\nRedis Cluster可以做到online resharding，代价是迁移旧key的过程会对每个key进行加锁，加锁时间与key的值正相关。另外，其resharding是需要手动触发的。\n\n## HDFS rebalance\n\n细节参考自[hdfs rebalance JIRA需求](https://issues.apache.org/jira/browse/HADOOP-1652)的**RebalanceDesign6.pdf**，大概过程如下图所示。\n\n![hdfs rebalance](https://user-images.githubusercontent.com/4915189/71431431-c9fb4580-270c-11ea-90b9-d851304c514a.png)\n\n- 先向namenode取得各datanode的数据报告，根据规则确定source节点和destination节点；\n- 获取source节点的部分block的metadata（元数据）；\n- 对于每个要迁移的block，找到离destination节点最近的含有该block replica的proxy节点（不一定是source节点），向其发送copy到destination的指令；\n- proxy节点把block数据传到destination；\n- destination接受完block数据后，通知namenode更新block的metadata，并原路返回block已迁移完成的信号；\n- 重复执行上述步骤，将每一个block迁移到destination。\n\nhdfs rebalance同样需要手动触发，相比redis cluster，其整个迁移的过程是offline的——必须在safe mode模式下进行。\n\n## ClustrixDB rebalance\n\nClustrixDB是一个闭源的数据库——目的是解决MySQL难以scale的问题，其中一篇[Rebalancer设计文档](http://docs.clustrix.com/display/CLXDOC/Rebalancer)详细的阐述了数据迁移的过程。这里的迁移场景指的是类似于上文Redis Cluster的slot迁移，是将某个replica从一个结点迁移到另外一个结点，下图描述了replica从Node 4迁移到Node 1的过程。\n\n注：\n- ClustrixDB sharding后的数据分片，由一个slice和多个replica组成（类比一主多备）；\n- 下文的queue可以类比MySQL的binlog，不同的是它除了存储binlog到queue还提供转发binlog和重放的功能；\n\n![ClustrixDB rebalance](https://user-images.githubusercontent.com/4915189/71431435-d1225380-270c-11ea-8a89-657b928f8ded.png)\n\n- Initial State阶段：Node 3和Node 4为含有同一个分片数据的replica；\n- Data Copy阶段：在epoch B开始时间，新增了Node 1作为replica（Building状态）和Node 2作为Queue（Store状态）；epoch A之后对于Node 4的新增修改将以类似于binlog的方式同步到Node 2的queue；Node 4的旧有数据将以一致性视图冻结在该时刻，并逐条传输到Node 1的Building replica；\n- Queue Replay阶段：旧有数据已经同步完毕，此时将Node 2的queue数据进行重放到Node 1，此时queue仍然接受写入；\n- End of Queue阶段：queue的数据重放执行完后，立马转为synchronize queue，即转为store & Forward状态，数据进到queue后同步给Node 1执行，执行完成才返回；\n- Queue Flipped阶段：将旧节点Node 4标记为Retired，新节点Node 1标记为Online，epoch B开始的未提交的事务还是提交到Node 4，由queue直接forward到Node 1；\n- Final state状态：待epoch B时间开始的transaction都提交后，可以将旧节点和queue都下线。\n\nClustrixDB的metadata也是[Multi-Version Concurrency Control (MVCC)](http://docs.clustrix.com/display/CLXDOC/Concurrency+Control)的，从epoch B开始意味着metadata发生了变化。为了防止数据不一致，需要在epoch A开始的事务全部提交后再开始epoch B。另外，如果磁盘和网络容量富余，其实上文的queue可以考虑与Node 1放在一起。最后，上文说到的synchronize queue是一个漂亮的设计，这不就是Java的synchronize queue吗？\n\n","source":"_posts/2019-03-31-beyond-resharding.md","raw":"---\ntitle: Redis Cluster & HDFS & ClustrixDB Reshard/Rebalance\ndate: 2019-03-31 22:12:14\ntags: ['数据库', 'MySQL', 'Redis', 'HDFS']\ncomments: true\ncategories: ['系统设计']\n---\n\n对于分布式存储，在新增或删除节点时，必将存在某些节点的数据“过多”，某些节点的数据“过少”。对节点上的数据进行重新整理使各节点的数据趋于相近的过程，就叫rebalance或reshard。本文简单介绍Redis Cluster、HDFS和ClustrixDB是如何对数据进行重分片的。\n\n<!--more-->\n\n## Redis Cluster Reshard\n\n细节参考自[Redis Cluster Spec](https://redis.io/topics/cluster-spec)的**Redirection and resharding**章节。下图表示数据slot原先在Original节点，被迁移到New节点需要经历的过程。\n（注：slot的介绍见[Redis Cluster Spec](https://redis.io/topics/cluster-spec)）\n\n![redis cluster reshard](https://user-images.githubusercontent.com/4915189/71431424-c23ba100-270c-11ea-91b1-1cafb8aeaef5.png)\n\n- 新增了New节点——Redis Instance（也可能是本来就存在的一个redis实例）；\n- Original上待迁移slot被设置为importing状态，New上欲接受slot被设置为migrating状态。对该slot的读写请求仍然从original节点进来，但是当original不存在请求中包含的key时，请求将被转发给new节点，original已存在该key则请求仍由original受理；\n- 将original节点已有的key逐个迁移到new节点，每个key在迁移过程是原子性的（会对该key进行加锁）；\n- key全部迁移完成后，通过gossip协议通知集群中的其他节点更新metadata，以后该slot节点的请求将由new节点负责。\n\nRedis Cluster可以做到online resharding，代价是迁移旧key的过程会对每个key进行加锁，加锁时间与key的值正相关。另外，其resharding是需要手动触发的。\n\n## HDFS rebalance\n\n细节参考自[hdfs rebalance JIRA需求](https://issues.apache.org/jira/browse/HADOOP-1652)的**RebalanceDesign6.pdf**，大概过程如下图所示。\n\n![hdfs rebalance](https://user-images.githubusercontent.com/4915189/71431431-c9fb4580-270c-11ea-90b9-d851304c514a.png)\n\n- 先向namenode取得各datanode的数据报告，根据规则确定source节点和destination节点；\n- 获取source节点的部分block的metadata（元数据）；\n- 对于每个要迁移的block，找到离destination节点最近的含有该block replica的proxy节点（不一定是source节点），向其发送copy到destination的指令；\n- proxy节点把block数据传到destination；\n- destination接受完block数据后，通知namenode更新block的metadata，并原路返回block已迁移完成的信号；\n- 重复执行上述步骤，将每一个block迁移到destination。\n\nhdfs rebalance同样需要手动触发，相比redis cluster，其整个迁移的过程是offline的——必须在safe mode模式下进行。\n\n## ClustrixDB rebalance\n\nClustrixDB是一个闭源的数据库——目的是解决MySQL难以scale的问题，其中一篇[Rebalancer设计文档](http://docs.clustrix.com/display/CLXDOC/Rebalancer)详细的阐述了数据迁移的过程。这里的迁移场景指的是类似于上文Redis Cluster的slot迁移，是将某个replica从一个结点迁移到另外一个结点，下图描述了replica从Node 4迁移到Node 1的过程。\n\n注：\n- ClustrixDB sharding后的数据分片，由一个slice和多个replica组成（类比一主多备）；\n- 下文的queue可以类比MySQL的binlog，不同的是它除了存储binlog到queue还提供转发binlog和重放的功能；\n\n![ClustrixDB rebalance](https://user-images.githubusercontent.com/4915189/71431435-d1225380-270c-11ea-8a89-657b928f8ded.png)\n\n- Initial State阶段：Node 3和Node 4为含有同一个分片数据的replica；\n- Data Copy阶段：在epoch B开始时间，新增了Node 1作为replica（Building状态）和Node 2作为Queue（Store状态）；epoch A之后对于Node 4的新增修改将以类似于binlog的方式同步到Node 2的queue；Node 4的旧有数据将以一致性视图冻结在该时刻，并逐条传输到Node 1的Building replica；\n- Queue Replay阶段：旧有数据已经同步完毕，此时将Node 2的queue数据进行重放到Node 1，此时queue仍然接受写入；\n- End of Queue阶段：queue的数据重放执行完后，立马转为synchronize queue，即转为store & Forward状态，数据进到queue后同步给Node 1执行，执行完成才返回；\n- Queue Flipped阶段：将旧节点Node 4标记为Retired，新节点Node 1标记为Online，epoch B开始的未提交的事务还是提交到Node 4，由queue直接forward到Node 1；\n- Final state状态：待epoch B时间开始的transaction都提交后，可以将旧节点和queue都下线。\n\nClustrixDB的metadata也是[Multi-Version Concurrency Control (MVCC)](http://docs.clustrix.com/display/CLXDOC/Concurrency+Control)的，从epoch B开始意味着metadata发生了变化。为了防止数据不一致，需要在epoch A开始的事务全部提交后再开始epoch B。另外，如果磁盘和网络容量富余，其实上文的queue可以考虑与Node 1放在一起。最后，上文说到的synchronize queue是一个漂亮的设计，这不就是Java的synchronize queue吗？\n\n","slug":"beyond-resharding","published":1,"updated":"2022-08-09T15:02:00.648Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14d0035igu85lypq9v0","content":"<p>对于分布式存储，在新增或删除节点时，必将存在某些节点的数据“过多”，某些节点的数据“过少”。对节点上的数据进行重新整理使各节点的数据趋于相近的过程，就叫rebalance或reshard。本文简单介绍Redis Cluster、HDFS和ClustrixDB是如何对数据进行重分片的。</p>\n<a id=\"more\"></a>\n<h2 id=\"Redis-Cluster-Reshard\"><a href=\"#Redis-Cluster-Reshard\" class=\"headerlink\" title=\"Redis Cluster Reshard\"></a>Redis Cluster Reshard</h2><p>细节参考自<a href=\"https://redis.io/topics/cluster-spec\" target=\"_blank\" rel=\"noopener\">Redis Cluster Spec</a>的<strong>Redirection and resharding</strong>章节。下图表示数据slot原先在Original节点，被迁移到New节点需要经历的过程。<br>（注：slot的介绍见<a href=\"https://redis.io/topics/cluster-spec\" target=\"_blank\" rel=\"noopener\">Redis Cluster Spec</a>）</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431424-c23ba100-270c-11ea-91b1-1cafb8aeaef5.png\" alt=\"redis cluster reshard\"></p>\n<ul>\n<li>新增了New节点——Redis Instance（也可能是本来就存在的一个redis实例）；</li>\n<li>Original上待迁移slot被设置为importing状态，New上欲接受slot被设置为migrating状态。对该slot的读写请求仍然从original节点进来，但是当original不存在请求中包含的key时，请求将被转发给new节点，original已存在该key则请求仍由original受理；</li>\n<li>将original节点已有的key逐个迁移到new节点，每个key在迁移过程是原子性的（会对该key进行加锁）；</li>\n<li>key全部迁移完成后，通过gossip协议通知集群中的其他节点更新metadata，以后该slot节点的请求将由new节点负责。</li>\n</ul>\n<p>Redis Cluster可以做到online resharding，代价是迁移旧key的过程会对每个key进行加锁，加锁时间与key的值正相关。另外，其resharding是需要手动触发的。</p>\n<h2 id=\"HDFS-rebalance\"><a href=\"#HDFS-rebalance\" class=\"headerlink\" title=\"HDFS rebalance\"></a>HDFS rebalance</h2><p>细节参考自<a href=\"https://issues.apache.org/jira/browse/HADOOP-1652\" target=\"_blank\" rel=\"noopener\">hdfs rebalance JIRA需求</a>的<strong>RebalanceDesign6.pdf</strong>，大概过程如下图所示。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431431-c9fb4580-270c-11ea-90b9-d851304c514a.png\" alt=\"hdfs rebalance\"></p>\n<ul>\n<li>先向namenode取得各datanode的数据报告，根据规则确定source节点和destination节点；</li>\n<li>获取source节点的部分block的metadata（元数据）；</li>\n<li>对于每个要迁移的block，找到离destination节点最近的含有该block replica的proxy节点（不一定是source节点），向其发送copy到destination的指令；</li>\n<li>proxy节点把block数据传到destination；</li>\n<li>destination接受完block数据后，通知namenode更新block的metadata，并原路返回block已迁移完成的信号；</li>\n<li>重复执行上述步骤，将每一个block迁移到destination。</li>\n</ul>\n<p>hdfs rebalance同样需要手动触发，相比redis cluster，其整个迁移的过程是offline的——必须在safe mode模式下进行。</p>\n<h2 id=\"ClustrixDB-rebalance\"><a href=\"#ClustrixDB-rebalance\" class=\"headerlink\" title=\"ClustrixDB rebalance\"></a>ClustrixDB rebalance</h2><p>ClustrixDB是一个闭源的数据库——目的是解决MySQL难以scale的问题，其中一篇<a href=\"http://docs.clustrix.com/display/CLXDOC/Rebalancer\" target=\"_blank\" rel=\"noopener\">Rebalancer设计文档</a>详细的阐述了数据迁移的过程。这里的迁移场景指的是类似于上文Redis Cluster的slot迁移，是将某个replica从一个结点迁移到另外一个结点，下图描述了replica从Node 4迁移到Node 1的过程。</p>\n<p>注：</p>\n<ul>\n<li>ClustrixDB sharding后的数据分片，由一个slice和多个replica组成（类比一主多备）；</li>\n<li>下文的queue可以类比MySQL的binlog，不同的是它除了存储binlog到queue还提供转发binlog和重放的功能；</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431435-d1225380-270c-11ea-8a89-657b928f8ded.png\" alt=\"ClustrixDB rebalance\"></p>\n<ul>\n<li>Initial State阶段：Node 3和Node 4为含有同一个分片数据的replica；</li>\n<li>Data Copy阶段：在epoch B开始时间，新增了Node 1作为replica（Building状态）和Node 2作为Queue（Store状态）；epoch A之后对于Node 4的新增修改将以类似于binlog的方式同步到Node 2的queue；Node 4的旧有数据将以一致性视图冻结在该时刻，并逐条传输到Node 1的Building replica；</li>\n<li>Queue Replay阶段：旧有数据已经同步完毕，此时将Node 2的queue数据进行重放到Node 1，此时queue仍然接受写入；</li>\n<li>End of Queue阶段：queue的数据重放执行完后，立马转为synchronize queue，即转为store &amp; Forward状态，数据进到queue后同步给Node 1执行，执行完成才返回；</li>\n<li>Queue Flipped阶段：将旧节点Node 4标记为Retired，新节点Node 1标记为Online，epoch B开始的未提交的事务还是提交到Node 4，由queue直接forward到Node 1；</li>\n<li>Final state状态：待epoch B时间开始的transaction都提交后，可以将旧节点和queue都下线。</li>\n</ul>\n<p>ClustrixDB的metadata也是<a href=\"http://docs.clustrix.com/display/CLXDOC/Concurrency+Control\" target=\"_blank\" rel=\"noopener\">Multi-Version Concurrency Control (MVCC)</a>的，从epoch B开始意味着metadata发生了变化。为了防止数据不一致，需要在epoch A开始的事务全部提交后再开始epoch B。另外，如果磁盘和网络容量富余，其实上文的queue可以考虑与Node 1放在一起。最后，上文说到的synchronize queue是一个漂亮的设计，这不就是Java的synchronize queue吗？</p>\n","site":{"data":{}},"excerpt":"<p>对于分布式存储，在新增或删除节点时，必将存在某些节点的数据“过多”，某些节点的数据“过少”。对节点上的数据进行重新整理使各节点的数据趋于相近的过程，就叫rebalance或reshard。本文简单介绍Redis Cluster、HDFS和ClustrixDB是如何对数据进行重分片的。</p>","more":"<h2 id=\"Redis-Cluster-Reshard\"><a href=\"#Redis-Cluster-Reshard\" class=\"headerlink\" title=\"Redis Cluster Reshard\"></a>Redis Cluster Reshard</h2><p>细节参考自<a href=\"https://redis.io/topics/cluster-spec\" target=\"_blank\" rel=\"noopener\">Redis Cluster Spec</a>的<strong>Redirection and resharding</strong>章节。下图表示数据slot原先在Original节点，被迁移到New节点需要经历的过程。<br>（注：slot的介绍见<a href=\"https://redis.io/topics/cluster-spec\" target=\"_blank\" rel=\"noopener\">Redis Cluster Spec</a>）</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431424-c23ba100-270c-11ea-91b1-1cafb8aeaef5.png\" alt=\"redis cluster reshard\"></p>\n<ul>\n<li>新增了New节点——Redis Instance（也可能是本来就存在的一个redis实例）；</li>\n<li>Original上待迁移slot被设置为importing状态，New上欲接受slot被设置为migrating状态。对该slot的读写请求仍然从original节点进来，但是当original不存在请求中包含的key时，请求将被转发给new节点，original已存在该key则请求仍由original受理；</li>\n<li>将original节点已有的key逐个迁移到new节点，每个key在迁移过程是原子性的（会对该key进行加锁）；</li>\n<li>key全部迁移完成后，通过gossip协议通知集群中的其他节点更新metadata，以后该slot节点的请求将由new节点负责。</li>\n</ul>\n<p>Redis Cluster可以做到online resharding，代价是迁移旧key的过程会对每个key进行加锁，加锁时间与key的值正相关。另外，其resharding是需要手动触发的。</p>\n<h2 id=\"HDFS-rebalance\"><a href=\"#HDFS-rebalance\" class=\"headerlink\" title=\"HDFS rebalance\"></a>HDFS rebalance</h2><p>细节参考自<a href=\"https://issues.apache.org/jira/browse/HADOOP-1652\" target=\"_blank\" rel=\"noopener\">hdfs rebalance JIRA需求</a>的<strong>RebalanceDesign6.pdf</strong>，大概过程如下图所示。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431431-c9fb4580-270c-11ea-90b9-d851304c514a.png\" alt=\"hdfs rebalance\"></p>\n<ul>\n<li>先向namenode取得各datanode的数据报告，根据规则确定source节点和destination节点；</li>\n<li>获取source节点的部分block的metadata（元数据）；</li>\n<li>对于每个要迁移的block，找到离destination节点最近的含有该block replica的proxy节点（不一定是source节点），向其发送copy到destination的指令；</li>\n<li>proxy节点把block数据传到destination；</li>\n<li>destination接受完block数据后，通知namenode更新block的metadata，并原路返回block已迁移完成的信号；</li>\n<li>重复执行上述步骤，将每一个block迁移到destination。</li>\n</ul>\n<p>hdfs rebalance同样需要手动触发，相比redis cluster，其整个迁移的过程是offline的——必须在safe mode模式下进行。</p>\n<h2 id=\"ClustrixDB-rebalance\"><a href=\"#ClustrixDB-rebalance\" class=\"headerlink\" title=\"ClustrixDB rebalance\"></a>ClustrixDB rebalance</h2><p>ClustrixDB是一个闭源的数据库——目的是解决MySQL难以scale的问题，其中一篇<a href=\"http://docs.clustrix.com/display/CLXDOC/Rebalancer\" target=\"_blank\" rel=\"noopener\">Rebalancer设计文档</a>详细的阐述了数据迁移的过程。这里的迁移场景指的是类似于上文Redis Cluster的slot迁移，是将某个replica从一个结点迁移到另外一个结点，下图描述了replica从Node 4迁移到Node 1的过程。</p>\n<p>注：</p>\n<ul>\n<li>ClustrixDB sharding后的数据分片，由一个slice和多个replica组成（类比一主多备）；</li>\n<li>下文的queue可以类比MySQL的binlog，不同的是它除了存储binlog到queue还提供转发binlog和重放的功能；</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431435-d1225380-270c-11ea-8a89-657b928f8ded.png\" alt=\"ClustrixDB rebalance\"></p>\n<ul>\n<li>Initial State阶段：Node 3和Node 4为含有同一个分片数据的replica；</li>\n<li>Data Copy阶段：在epoch B开始时间，新增了Node 1作为replica（Building状态）和Node 2作为Queue（Store状态）；epoch A之后对于Node 4的新增修改将以类似于binlog的方式同步到Node 2的queue；Node 4的旧有数据将以一致性视图冻结在该时刻，并逐条传输到Node 1的Building replica；</li>\n<li>Queue Replay阶段：旧有数据已经同步完毕，此时将Node 2的queue数据进行重放到Node 1，此时queue仍然接受写入；</li>\n<li>End of Queue阶段：queue的数据重放执行完后，立马转为synchronize queue，即转为store &amp; Forward状态，数据进到queue后同步给Node 1执行，执行完成才返回；</li>\n<li>Queue Flipped阶段：将旧节点Node 4标记为Retired，新节点Node 1标记为Online，epoch B开始的未提交的事务还是提交到Node 4，由queue直接forward到Node 1；</li>\n<li>Final state状态：待epoch B时间开始的transaction都提交后，可以将旧节点和queue都下线。</li>\n</ul>\n<p>ClustrixDB的metadata也是<a href=\"http://docs.clustrix.com/display/CLXDOC/Concurrency+Control\" target=\"_blank\" rel=\"noopener\">Multi-Version Concurrency Control (MVCC)</a>的，从epoch B开始意味着metadata发生了变化。为了防止数据不一致，需要在epoch A开始的事务全部提交后再开始epoch B。另外，如果磁盘和网络容量富余，其实上文的queue可以考虑与Node 1放在一起。最后，上文说到的synchronize queue是一个漂亮的设计，这不就是Java的synchronize queue吗？</p>"},{"title":"算法训练营毕业总结","date":"2019-12-27T14:18:05.000Z","comments":1,"_content":"\n参加即可时间算法训练营的总结。\n\n<!--more-->\n\n# 数据结构篇\n\nhttps://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c\n\n## 数组\n\n按索引查找快，O(1)；非尾端插入、非尾端删除慢，平均O(n)\n\n## 链表\n\n按索引查找慢，平均O(n)；定位到元素后，插入、删除快，平均O(1)\n\n## 跳表\n\n元素有序，可以理解为多层的单链表，形状类似于金字塔，解决单链表查询慢的问题。通俗理解：\n- 最底下一层，第n层：原始数据单链表\n- n-1层：节点数相比第n层减半的单链表，其第i个元素（i>=0）指向并等于第n层的2i个元素\n- n-2层：类似上面以此类推\n- 第1层：类似上面以此类推\n\n定位元素层第1层往下找，每次查找都能将目标值所在空间折半。单链表是一维，跳表是二维，属于一种升维的思想解决问题\n\n## 栈\n\n先进后出，FILO。n个元素入栈1，将栈1元素逐一出栈放到栈2，将栈2元素逐一出栈可以达到FIFO\n\n## 队列\n\n先进先出，FIFO\n\n## 双端队列\n\n头尾两端都可以入、出元素的特殊队列\n\n## 优先队列\n\n插入为O(1)，取出元素为O(nlogn)的特殊队列，每次取元素都会导致重平衡，顶层一般用堆实现\n\n## 哈希表\n\nJDK8的HashMap的源码分析\n\nget操作\n\n- 通过hash方法计算hash\n- 通过hash去getNode，先由hash定位到所在通，取桶的第一个节点进行hash值compare，相等则返回。否则遍历桶的所有结点去匹配，桶的数据结构即可能是平衡二叉树，也可能是单链表\n\nput操作\n\n- 计算key的hash\n- 检测table是否为空，如果是调用resize进行实例化\n- 计算value需要存储到哪个slot，如果该slot为空，直接新建一个slot（单链表），并将value作为头结点，然后返回\n- 否则，取出value所在slot，命名其为s\n  - 判断value的hash值和s的头结点的hash值是否相同，若相同则覆盖返回\n  - 否则判断s是否是一个平衡二叉树，若是则调用putTreeVal将value放到树中，putTreeVal会使得树进入平衡状态\n  - 再否则，遍历单链表，若找到hash值相同的结点，覆盖之；否则，将value加在s的尾部，此时需要判断s是否需要进行树化（单个slot的节点数大于等于8需要树化），因为攻击者可能设计一些key使得他们落在同一个slot，此时slot单链表会拉的很长，同时由于负载因子设置不合理此时并未发生重平衡，那对slot的访问就变成了O(N)的复杂度\n- 最后，判断总size是否超出threhold（根据capacity和负载因子计算出来的值），是的话调用resize()将size翻倍并重新放置各个Node\n\n注：hashmap之所以设计负载因子，是为了防止结点都落在了一个slot上，threhold=capacity x 负载因子。每个slot的元素都接近threhold是理想的平衡状态，一旦有某个slot超了将导致重平衡。\n\n# 算法篇\n\n## 树的遍历\n\n```python\n# 前中后序遍历模板\ndef preorder(root):\n    traverse_path.append(root.val)\n    preorder(root.left)\n    preorder(root.right)\ndef inorder(root):\n    inorder(root.left)\n    traverse_path.append(root.val)\n    inorder(root.right)\ndef postorder(root):\n    postorder(root.left)\n    postorder(root.right)\n    traverse_path.append(root.val)\n```\n\n## 递归模板\n\n```python\n# 递归模板\ndef recursie(level, p1, p2, ...):\n    if level > MAX_LEVEL:\n        # process result\n        return\n    # process current level logic\n    process(level, p1, p2, ...)\n    # drill down\n    recurse(level + 1, p1, p2, ...)\n    # reverse current level logic if needed\n```\n\n## 分治模板\n\n```python\n# 分治模板\ndef divide_conquer(problem, p1, p2, ...):\n    if not problem:\n        return\n\n    # prepare\n    subproblems = split_problem(problem, p1, p2, ...)\n\n    # divide\n    subresults = [divide_conquer(subproblems[i], p1, p2, ...) for i in range(len(subproblems))]\n\n    # combine\n    result = process_result(subresults)\n\n    # reverse\n```\n\n## DFS深度优先模板\n\n```python\n# depth-first search\n# 深度优先（DFS）遍历代码模板\n# 递归调用\nvisited = set()\ndef dfs(root):\n    if root in visited:\n        return # terminator\n    visited.add(root)\n    # process logic here\n    for node in root.children():\n        if not node in visited:\n            dfs(node)\n```\n\n```python\n# depth-first search\n# 深度优先（DFS）遍历代码模板\n# 非递归（手动维护栈）\ndef dfs(root):\n    visited, stack = set(), [root]\n    while stack:\n        node = stack.pop()\n        if not node in visited:\n            visited.add(node)\n            process(node)\n            for child in reversed(node.children()): # add from right to left\n                stack.append(child)\n```\n\n## 广度优先模板\n\n```python\n# breadth-first search\n# 广度优先遍历（BFS）代码模板\n# 非递归，自己的理解\ndef bfs():\n    visited, deque = set(), [root]\n    while deque:\n        node = queue.popleft() # 从左到右一层层遍历\n        if node not in visited:\n            visited.add(node)\n            deque.append(node.childrens) # 下一层加到最右端\n\n# breadth-first search\n# 广度优先遍历（BFS）代码模板\n# 非递归，打印层次信息\ndef bfs():\n    visited, deque = set(), [root]\n    level = 0\n    while deque:\n        size, level = len(deque), level+1\n        for _ in range(size): # 第level层\n            node = queue.popleft() # 从左到右一层层遍历\n            if node not in visited:\n                visited.add(node)\n                deque.append(node.childrens) # 下一层加到最右端\n```\n\n## 二分查找模板\n\n```python\n# binary search代码模板\nleft, right = 0, len(array) - 1\nwhile left <= right:\n    mid = (left + right) / 2\n    if array[mid] == target:\n        return or break\n    elif array[mid] < target:\n        left = mid + 1\n    else:\n        right = mid - 1\n```\n\n## 动态规划总结\n\ndynamic programing = simplifying a complicated problem by breaking it down into simpler problems(in a recursive manner)\n\n动态规划与分治没有本质区别\n- 共性：找重复子问题\n- 差异：找最优子结构、中途可淘汰次优解\n\ndynamic program三要素\n- subproblem(recursive manner)最优子结构\n- memorize记忆中间状态\n- 找递推公式\n\n## Trie树\n\nTrie树（字典树、字符查找树、键树）\n- 多叉树\n- 每个节点不存储单词本身，只存储指向到下n个节点的n个不同字母\n- 从根节点到某一节点的路径的所有字母组合起来，即为表示的单词（字符串），每个节点的数值即为该单词在文本中出现的频次\n- 常用于搜索引擎的词频统计，能最大程度减少无谓的字符串比较，这方面的效率优于哈希表\n\n## 并查集\n\n并查集\n- makeSet(s)：用s个单元素新建并查集\n- unionSet(x, y)：若x和y所在并查集不相交，进行合并\n- find(x)：找出x所在并查集的代表（群主），可用来快速判断两个元素是否在同一个并查集（比较代表）\n\n朋友圈数量解题思路\n- N个人：N个只有一个元素的独立集合\n- 关系M[i][j]为1：将两个并查集进行合并\n- 结果：最后剩多少个独立的集合\n\nfind函数需要考虑路径压缩，防止拉链太长：\n```python\ndef find(x):\n    if f[x] != x:\n        f[x] = find(f[x]) # 路径压缩，防止拉链太长\n    return f[x]\n```\n\n## 双向BFS\n\n双向BFS总结\n```python\n# breadth-first search\n# 广度优先遍历（BFS）代码模板\n# 非递归，自己的理解\ndef bfs():\n    forward, backward = set(start_node), set(target_node)\n    while forward:\n        temp = set()\n        for node in forward:\n            for child in node.childrens:\n                if child in backward: # 前后相交则结束\n                    return\n                temp.add(child) # 记录下一层\n        forward = temp\n        if len(backward) < len(forward): # 从元素小的那一层开始遍历\n            forward, backward = forward, backward\n```\n\n## 启发式搜索A*\n\n```python\n# A*代码模板\ndef AstartSearch():\n    visited = set(root)\n    pq = collections.priority_queue() # 优先级 —> 估价函数\n    pq.append(root)\n    while pq:\n        node = pq.pop()\n        process(node)\n        next = [node for node in node.children if node not in visited]\n        pq.push(next)\n```\n\n## 位运算\n\n位运算实战技巧\n```\n判断奇偶\nx % 2 == 0 => (x & 1) == 0\nx % 2 == 1 => (x & 1) == 1\n\n除以2\nx/2 => x >> 1\n\n清零最低位的1\nx & (x-1)\n\n取到最低位的1\nx & -x\n```\n\n## LRU\n\nlru实现：hashmap+deque(double linked list)\n\n## 布隆过滤器\n\nbloom filter(capacity, k)\n- bit = hash(num, seed) % capacity，seed的范围是1到k\n- 插入：计算k次bit，将bit所在位置1\n- 查找：计算k次bit，如果bit所在位都为1，则数可能存在，否则一定不存在\n\n## 动态规划复习\n\n重温动态规划三要素：dynamic program = subproblem(recursive) + memorize + 递推公式\n\n精简为二要素：状态定义、状态转移方程\n\nLeetCode网友整理的多维DP的代码模板\n```python\nfor 状态1 in 状态1的所有取值：\n    for 状态2 in 状态2的所有取值：\n        for ...\n            dp[状态1][状态2][...] = 择优(选择1，选择2...)\n```\n\n## 字符串匹配算法\n\nRabin-Karp：https://shimo.im/docs/KXDdkT99TVtXvTXP/read\nKMP\n- https://www.bilibili.com/video/av11866460?from=search&seid=17425875345653862171\n- http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\n\n\nhttps://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec\n","source":"_posts/2019-12-27-algorithm-04-summary.md","raw":"---\ntitle: 算法训练营毕业总结\ndate: 2019-12-27 22:18:05\ntags: ['Algorithm']\ncomments: true\ncategories: ['算法']\n---\n\n参加即可时间算法训练营的总结。\n\n<!--more-->\n\n# 数据结构篇\n\nhttps://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c\n\n## 数组\n\n按索引查找快，O(1)；非尾端插入、非尾端删除慢，平均O(n)\n\n## 链表\n\n按索引查找慢，平均O(n)；定位到元素后，插入、删除快，平均O(1)\n\n## 跳表\n\n元素有序，可以理解为多层的单链表，形状类似于金字塔，解决单链表查询慢的问题。通俗理解：\n- 最底下一层，第n层：原始数据单链表\n- n-1层：节点数相比第n层减半的单链表，其第i个元素（i>=0）指向并等于第n层的2i个元素\n- n-2层：类似上面以此类推\n- 第1层：类似上面以此类推\n\n定位元素层第1层往下找，每次查找都能将目标值所在空间折半。单链表是一维，跳表是二维，属于一种升维的思想解决问题\n\n## 栈\n\n先进后出，FILO。n个元素入栈1，将栈1元素逐一出栈放到栈2，将栈2元素逐一出栈可以达到FIFO\n\n## 队列\n\n先进先出，FIFO\n\n## 双端队列\n\n头尾两端都可以入、出元素的特殊队列\n\n## 优先队列\n\n插入为O(1)，取出元素为O(nlogn)的特殊队列，每次取元素都会导致重平衡，顶层一般用堆实现\n\n## 哈希表\n\nJDK8的HashMap的源码分析\n\nget操作\n\n- 通过hash方法计算hash\n- 通过hash去getNode，先由hash定位到所在通，取桶的第一个节点进行hash值compare，相等则返回。否则遍历桶的所有结点去匹配，桶的数据结构即可能是平衡二叉树，也可能是单链表\n\nput操作\n\n- 计算key的hash\n- 检测table是否为空，如果是调用resize进行实例化\n- 计算value需要存储到哪个slot，如果该slot为空，直接新建一个slot（单链表），并将value作为头结点，然后返回\n- 否则，取出value所在slot，命名其为s\n  - 判断value的hash值和s的头结点的hash值是否相同，若相同则覆盖返回\n  - 否则判断s是否是一个平衡二叉树，若是则调用putTreeVal将value放到树中，putTreeVal会使得树进入平衡状态\n  - 再否则，遍历单链表，若找到hash值相同的结点，覆盖之；否则，将value加在s的尾部，此时需要判断s是否需要进行树化（单个slot的节点数大于等于8需要树化），因为攻击者可能设计一些key使得他们落在同一个slot，此时slot单链表会拉的很长，同时由于负载因子设置不合理此时并未发生重平衡，那对slot的访问就变成了O(N)的复杂度\n- 最后，判断总size是否超出threhold（根据capacity和负载因子计算出来的值），是的话调用resize()将size翻倍并重新放置各个Node\n\n注：hashmap之所以设计负载因子，是为了防止结点都落在了一个slot上，threhold=capacity x 负载因子。每个slot的元素都接近threhold是理想的平衡状态，一旦有某个slot超了将导致重平衡。\n\n# 算法篇\n\n## 树的遍历\n\n```python\n# 前中后序遍历模板\ndef preorder(root):\n    traverse_path.append(root.val)\n    preorder(root.left)\n    preorder(root.right)\ndef inorder(root):\n    inorder(root.left)\n    traverse_path.append(root.val)\n    inorder(root.right)\ndef postorder(root):\n    postorder(root.left)\n    postorder(root.right)\n    traverse_path.append(root.val)\n```\n\n## 递归模板\n\n```python\n# 递归模板\ndef recursie(level, p1, p2, ...):\n    if level > MAX_LEVEL:\n        # process result\n        return\n    # process current level logic\n    process(level, p1, p2, ...)\n    # drill down\n    recurse(level + 1, p1, p2, ...)\n    # reverse current level logic if needed\n```\n\n## 分治模板\n\n```python\n# 分治模板\ndef divide_conquer(problem, p1, p2, ...):\n    if not problem:\n        return\n\n    # prepare\n    subproblems = split_problem(problem, p1, p2, ...)\n\n    # divide\n    subresults = [divide_conquer(subproblems[i], p1, p2, ...) for i in range(len(subproblems))]\n\n    # combine\n    result = process_result(subresults)\n\n    # reverse\n```\n\n## DFS深度优先模板\n\n```python\n# depth-first search\n# 深度优先（DFS）遍历代码模板\n# 递归调用\nvisited = set()\ndef dfs(root):\n    if root in visited:\n        return # terminator\n    visited.add(root)\n    # process logic here\n    for node in root.children():\n        if not node in visited:\n            dfs(node)\n```\n\n```python\n# depth-first search\n# 深度优先（DFS）遍历代码模板\n# 非递归（手动维护栈）\ndef dfs(root):\n    visited, stack = set(), [root]\n    while stack:\n        node = stack.pop()\n        if not node in visited:\n            visited.add(node)\n            process(node)\n            for child in reversed(node.children()): # add from right to left\n                stack.append(child)\n```\n\n## 广度优先模板\n\n```python\n# breadth-first search\n# 广度优先遍历（BFS）代码模板\n# 非递归，自己的理解\ndef bfs():\n    visited, deque = set(), [root]\n    while deque:\n        node = queue.popleft() # 从左到右一层层遍历\n        if node not in visited:\n            visited.add(node)\n            deque.append(node.childrens) # 下一层加到最右端\n\n# breadth-first search\n# 广度优先遍历（BFS）代码模板\n# 非递归，打印层次信息\ndef bfs():\n    visited, deque = set(), [root]\n    level = 0\n    while deque:\n        size, level = len(deque), level+1\n        for _ in range(size): # 第level层\n            node = queue.popleft() # 从左到右一层层遍历\n            if node not in visited:\n                visited.add(node)\n                deque.append(node.childrens) # 下一层加到最右端\n```\n\n## 二分查找模板\n\n```python\n# binary search代码模板\nleft, right = 0, len(array) - 1\nwhile left <= right:\n    mid = (left + right) / 2\n    if array[mid] == target:\n        return or break\n    elif array[mid] < target:\n        left = mid + 1\n    else:\n        right = mid - 1\n```\n\n## 动态规划总结\n\ndynamic programing = simplifying a complicated problem by breaking it down into simpler problems(in a recursive manner)\n\n动态规划与分治没有本质区别\n- 共性：找重复子问题\n- 差异：找最优子结构、中途可淘汰次优解\n\ndynamic program三要素\n- subproblem(recursive manner)最优子结构\n- memorize记忆中间状态\n- 找递推公式\n\n## Trie树\n\nTrie树（字典树、字符查找树、键树）\n- 多叉树\n- 每个节点不存储单词本身，只存储指向到下n个节点的n个不同字母\n- 从根节点到某一节点的路径的所有字母组合起来，即为表示的单词（字符串），每个节点的数值即为该单词在文本中出现的频次\n- 常用于搜索引擎的词频统计，能最大程度减少无谓的字符串比较，这方面的效率优于哈希表\n\n## 并查集\n\n并查集\n- makeSet(s)：用s个单元素新建并查集\n- unionSet(x, y)：若x和y所在并查集不相交，进行合并\n- find(x)：找出x所在并查集的代表（群主），可用来快速判断两个元素是否在同一个并查集（比较代表）\n\n朋友圈数量解题思路\n- N个人：N个只有一个元素的独立集合\n- 关系M[i][j]为1：将两个并查集进行合并\n- 结果：最后剩多少个独立的集合\n\nfind函数需要考虑路径压缩，防止拉链太长：\n```python\ndef find(x):\n    if f[x] != x:\n        f[x] = find(f[x]) # 路径压缩，防止拉链太长\n    return f[x]\n```\n\n## 双向BFS\n\n双向BFS总结\n```python\n# breadth-first search\n# 广度优先遍历（BFS）代码模板\n# 非递归，自己的理解\ndef bfs():\n    forward, backward = set(start_node), set(target_node)\n    while forward:\n        temp = set()\n        for node in forward:\n            for child in node.childrens:\n                if child in backward: # 前后相交则结束\n                    return\n                temp.add(child) # 记录下一层\n        forward = temp\n        if len(backward) < len(forward): # 从元素小的那一层开始遍历\n            forward, backward = forward, backward\n```\n\n## 启发式搜索A*\n\n```python\n# A*代码模板\ndef AstartSearch():\n    visited = set(root)\n    pq = collections.priority_queue() # 优先级 —> 估价函数\n    pq.append(root)\n    while pq:\n        node = pq.pop()\n        process(node)\n        next = [node for node in node.children if node not in visited]\n        pq.push(next)\n```\n\n## 位运算\n\n位运算实战技巧\n```\n判断奇偶\nx % 2 == 0 => (x & 1) == 0\nx % 2 == 1 => (x & 1) == 1\n\n除以2\nx/2 => x >> 1\n\n清零最低位的1\nx & (x-1)\n\n取到最低位的1\nx & -x\n```\n\n## LRU\n\nlru实现：hashmap+deque(double linked list)\n\n## 布隆过滤器\n\nbloom filter(capacity, k)\n- bit = hash(num, seed) % capacity，seed的范围是1到k\n- 插入：计算k次bit，将bit所在位置1\n- 查找：计算k次bit，如果bit所在位都为1，则数可能存在，否则一定不存在\n\n## 动态规划复习\n\n重温动态规划三要素：dynamic program = subproblem(recursive) + memorize + 递推公式\n\n精简为二要素：状态定义、状态转移方程\n\nLeetCode网友整理的多维DP的代码模板\n```python\nfor 状态1 in 状态1的所有取值：\n    for 状态2 in 状态2的所有取值：\n        for ...\n            dp[状态1][状态2][...] = 择优(选择1，选择2...)\n```\n\n## 字符串匹配算法\n\nRabin-Karp：https://shimo.im/docs/KXDdkT99TVtXvTXP/read\nKMP\n- https://www.bilibili.com/video/av11866460?from=search&seid=17425875345653862171\n- http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\n\n\nhttps://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec\n","slug":"algorithm-04-summary","published":1,"updated":"2022-08-09T15:02:00.654Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14f003aigu81z0g4d3h","content":"<p>参加即可时间算法训练营的总结。</p>\n<a id=\"more\"></a>\n<h1 id=\"数据结构篇\"><a href=\"#数据结构篇\" class=\"headerlink\" title=\"数据结构篇\"></a>数据结构篇</h1><p><a href=\"https://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c\" target=\"_blank\" rel=\"noopener\">https://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c</a></p>\n<h2 id=\"数组\"><a href=\"#数组\" class=\"headerlink\" title=\"数组\"></a>数组</h2><p>按索引查找快，O(1)；非尾端插入、非尾端删除慢，平均O(n)</p>\n<h2 id=\"链表\"><a href=\"#链表\" class=\"headerlink\" title=\"链表\"></a>链表</h2><p>按索引查找慢，平均O(n)；定位到元素后，插入、删除快，平均O(1)</p>\n<h2 id=\"跳表\"><a href=\"#跳表\" class=\"headerlink\" title=\"跳表\"></a>跳表</h2><p>元素有序，可以理解为多层的单链表，形状类似于金字塔，解决单链表查询慢的问题。通俗理解：</p>\n<ul>\n<li>最底下一层，第n层：原始数据单链表</li>\n<li>n-1层：节点数相比第n层减半的单链表，其第i个元素（i&gt;=0）指向并等于第n层的2i个元素</li>\n<li>n-2层：类似上面以此类推</li>\n<li>第1层：类似上面以此类推</li>\n</ul>\n<p>定位元素层第1层往下找，每次查找都能将目标值所在空间折半。单链表是一维，跳表是二维，属于一种升维的思想解决问题</p>\n<h2 id=\"栈\"><a href=\"#栈\" class=\"headerlink\" title=\"栈\"></a>栈</h2><p>先进后出，FILO。n个元素入栈1，将栈1元素逐一出栈放到栈2，将栈2元素逐一出栈可以达到FIFO</p>\n<h2 id=\"队列\"><a href=\"#队列\" class=\"headerlink\" title=\"队列\"></a>队列</h2><p>先进先出，FIFO</p>\n<h2 id=\"双端队列\"><a href=\"#双端队列\" class=\"headerlink\" title=\"双端队列\"></a>双端队列</h2><p>头尾两端都可以入、出元素的特殊队列</p>\n<h2 id=\"优先队列\"><a href=\"#优先队列\" class=\"headerlink\" title=\"优先队列\"></a>优先队列</h2><p>插入为O(1)，取出元素为O(nlogn)的特殊队列，每次取元素都会导致重平衡，顶层一般用堆实现</p>\n<h2 id=\"哈希表\"><a href=\"#哈希表\" class=\"headerlink\" title=\"哈希表\"></a>哈希表</h2><p>JDK8的HashMap的源码分析</p>\n<p>get操作</p>\n<ul>\n<li>通过hash方法计算hash</li>\n<li>通过hash去getNode，先由hash定位到所在通，取桶的第一个节点进行hash值compare，相等则返回。否则遍历桶的所有结点去匹配，桶的数据结构即可能是平衡二叉树，也可能是单链表</li>\n</ul>\n<p>put操作</p>\n<ul>\n<li>计算key的hash</li>\n<li>检测table是否为空，如果是调用resize进行实例化</li>\n<li>计算value需要存储到哪个slot，如果该slot为空，直接新建一个slot（单链表），并将value作为头结点，然后返回</li>\n<li>否则，取出value所在slot，命名其为s<ul>\n<li>判断value的hash值和s的头结点的hash值是否相同，若相同则覆盖返回</li>\n<li>否则判断s是否是一个平衡二叉树，若是则调用putTreeVal将value放到树中，putTreeVal会使得树进入平衡状态</li>\n<li>再否则，遍历单链表，若找到hash值相同的结点，覆盖之；否则，将value加在s的尾部，此时需要判断s是否需要进行树化（单个slot的节点数大于等于8需要树化），因为攻击者可能设计一些key使得他们落在同一个slot，此时slot单链表会拉的很长，同时由于负载因子设置不合理此时并未发生重平衡，那对slot的访问就变成了O(N)的复杂度</li>\n</ul>\n</li>\n<li>最后，判断总size是否超出threhold（根据capacity和负载因子计算出来的值），是的话调用resize()将size翻倍并重新放置各个Node</li>\n</ul>\n<p>注：hashmap之所以设计负载因子，是为了防止结点都落在了一个slot上，threhold=capacity x 负载因子。每个slot的元素都接近threhold是理想的平衡状态，一旦有某个slot超了将导致重平衡。</p>\n<h1 id=\"算法篇\"><a href=\"#算法篇\" class=\"headerlink\" title=\"算法篇\"></a>算法篇</h1><h2 id=\"树的遍历\"><a href=\"#树的遍历\" class=\"headerlink\" title=\"树的遍历\"></a>树的遍历</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 前中后序遍历模板</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">preorder</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    traverse_path.append(root.val)</span><br><span class=\"line\">    preorder(root.left)</span><br><span class=\"line\">    preorder(root.right)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inorder</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    inorder(root.left)</span><br><span class=\"line\">    traverse_path.append(root.val)</span><br><span class=\"line\">    inorder(root.right)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">postorder</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    postorder(root.left)</span><br><span class=\"line\">    postorder(root.right)</span><br><span class=\"line\">    traverse_path.append(root.val)</span><br></pre></td></tr></table></figure>\n<h2 id=\"递归模板\"><a href=\"#递归模板\" class=\"headerlink\" title=\"递归模板\"></a>递归模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 递归模板</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">recursie</span><span class=\"params\">(level, p1, p2, ...)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> level &gt; MAX_LEVEL:</span><br><span class=\"line\">        <span class=\"comment\"># process result</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\">    <span class=\"comment\"># process current level logic</span></span><br><span class=\"line\">    process(level, p1, p2, ...)</span><br><span class=\"line\">    <span class=\"comment\"># drill down</span></span><br><span class=\"line\">    recurse(level + <span class=\"number\">1</span>, p1, p2, ...)</span><br><span class=\"line\">    <span class=\"comment\"># reverse current level logic if needed</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"分治模板\"><a href=\"#分治模板\" class=\"headerlink\" title=\"分治模板\"></a>分治模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分治模板</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">divide_conquer</span><span class=\"params\">(problem, p1, p2, ...)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> problem:</span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># prepare</span></span><br><span class=\"line\">    subproblems = split_problem(problem, p1, p2, ...)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># divide</span></span><br><span class=\"line\">    subresults = [divide_conquer(subproblems[i], p1, p2, ...) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(subproblems))]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># combine</span></span><br><span class=\"line\">    result = process_result(subresults)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># reverse</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"DFS深度优先模板\"><a href=\"#DFS深度优先模板\" class=\"headerlink\" title=\"DFS深度优先模板\"></a>DFS深度优先模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># depth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 深度优先（DFS）遍历代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 递归调用</span></span><br><span class=\"line\">visited = set()</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">dfs</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> root <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"comment\"># terminator</span></span><br><span class=\"line\">    visited.add(root)</span><br><span class=\"line\">    <span class=\"comment\"># process logic here</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> node <span class=\"keyword\">in</span> root.children():</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> node <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">            dfs(node)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># depth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 深度优先（DFS）遍历代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 非递归（手动维护栈）</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">dfs</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    visited, stack = set(), [root]</span><br><span class=\"line\">    <span class=\"keyword\">while</span> stack:</span><br><span class=\"line\">        node = stack.pop()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> node <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">            visited.add(node)</span><br><span class=\"line\">            process(node)</span><br><span class=\"line\">            <span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> reversed(node.children()): <span class=\"comment\"># add from right to left</span></span><br><span class=\"line\">                stack.append(child)</span><br></pre></td></tr></table></figure>\n<h2 id=\"广度优先模板\"><a href=\"#广度优先模板\" class=\"headerlink\" title=\"广度优先模板\"></a>广度优先模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># breadth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 广度优先遍历（BFS）代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 非递归，自己的理解</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bfs</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    visited, deque = set(), [root]</span><br><span class=\"line\">    <span class=\"keyword\">while</span> deque:</span><br><span class=\"line\">        node = queue.popleft() <span class=\"comment\"># 从左到右一层层遍历</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> node <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">            visited.add(node)</span><br><span class=\"line\">            deque.append(node.childrens) <span class=\"comment\"># 下一层加到最右端</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># breadth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 广度优先遍历（BFS）代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 非递归，打印层次信息</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bfs</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    visited, deque = set(), [root]</span><br><span class=\"line\">    level = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> deque:</span><br><span class=\"line\">        size, level = len(deque), level+<span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(size): <span class=\"comment\"># 第level层</span></span><br><span class=\"line\">            node = queue.popleft() <span class=\"comment\"># 从左到右一层层遍历</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> node <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">                visited.add(node)</span><br><span class=\"line\">                deque.append(node.childrens) <span class=\"comment\"># 下一层加到最右端</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"二分查找模板\"><a href=\"#二分查找模板\" class=\"headerlink\" title=\"二分查找模板\"></a>二分查找模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># binary search代码模板</span></span><br><span class=\"line\">left, right = <span class=\"number\">0</span>, len(array) - <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> left &lt;= right:</span><br><span class=\"line\">    mid = (left + right) / <span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> array[mid] == target:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">or</span> <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> array[mid] &lt; target:</span><br><span class=\"line\">        left = mid + <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        right = mid - <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"动态规划总结\"><a href=\"#动态规划总结\" class=\"headerlink\" title=\"动态规划总结\"></a>动态规划总结</h2><p>dynamic programing = simplifying a complicated problem by breaking it down into simpler problems(in a recursive manner)</p>\n<p>动态规划与分治没有本质区别</p>\n<ul>\n<li>共性：找重复子问题</li>\n<li>差异：找最优子结构、中途可淘汰次优解</li>\n</ul>\n<p>dynamic program三要素</p>\n<ul>\n<li>subproblem(recursive manner)最优子结构</li>\n<li>memorize记忆中间状态</li>\n<li>找递推公式</li>\n</ul>\n<h2 id=\"Trie树\"><a href=\"#Trie树\" class=\"headerlink\" title=\"Trie树\"></a>Trie树</h2><p>Trie树（字典树、字符查找树、键树）</p>\n<ul>\n<li>多叉树</li>\n<li>每个节点不存储单词本身，只存储指向到下n个节点的n个不同字母</li>\n<li>从根节点到某一节点的路径的所有字母组合起来，即为表示的单词（字符串），每个节点的数值即为该单词在文本中出现的频次</li>\n<li>常用于搜索引擎的词频统计，能最大程度减少无谓的字符串比较，这方面的效率优于哈希表</li>\n</ul>\n<h2 id=\"并查集\"><a href=\"#并查集\" class=\"headerlink\" title=\"并查集\"></a>并查集</h2><p>并查集</p>\n<ul>\n<li>makeSet(s)：用s个单元素新建并查集</li>\n<li>unionSet(x, y)：若x和y所在并查集不相交，进行合并</li>\n<li>find(x)：找出x所在并查集的代表（群主），可用来快速判断两个元素是否在同一个并查集（比较代表）</li>\n</ul>\n<p>朋友圈数量解题思路</p>\n<ul>\n<li>N个人：N个只有一个元素的独立集合</li>\n<li>关系M[i][j]为1：将两个并查集进行合并</li>\n<li>结果：最后剩多少个独立的集合</li>\n</ul>\n<p>find函数需要考虑路径压缩，防止拉链太长：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">find</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> f[x] != x:</span><br><span class=\"line\">        f[x] = find(f[x]) <span class=\"comment\"># 路径压缩，防止拉链太长</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> f[x]</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"双向BFS\"><a href=\"#双向BFS\" class=\"headerlink\" title=\"双向BFS\"></a>双向BFS</h2><p>双向BFS总结<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># breadth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 广度优先遍历（BFS）代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 非递归，自己的理解</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bfs</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    forward, backward = set(start_node), set(target_node)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> forward:</span><br><span class=\"line\">        temp = set()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> node <span class=\"keyword\">in</span> forward:</span><br><span class=\"line\">            <span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> node.childrens:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> child <span class=\"keyword\">in</span> backward: <span class=\"comment\"># 前后相交则结束</span></span><br><span class=\"line\">                    <span class=\"keyword\">return</span></span><br><span class=\"line\">                temp.add(child) <span class=\"comment\"># 记录下一层</span></span><br><span class=\"line\">        forward = temp</span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(backward) &lt; len(forward): <span class=\"comment\"># 从元素小的那一层开始遍历</span></span><br><span class=\"line\">            forward, backward = forward, backward</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"启发式搜索A\"><a href=\"#启发式搜索A\" class=\"headerlink\" title=\"启发式搜索A*\"></a>启发式搜索A*</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># A*代码模板</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">AstartSearch</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    visited = set(root)</span><br><span class=\"line\">    pq = collections.priority_queue() <span class=\"comment\"># 优先级 —&gt; 估价函数</span></span><br><span class=\"line\">    pq.append(root)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> pq:</span><br><span class=\"line\">        node = pq.pop()</span><br><span class=\"line\">        process(node)</span><br><span class=\"line\">        next = [node <span class=\"keyword\">for</span> node <span class=\"keyword\">in</span> node.children <span class=\"keyword\">if</span> node <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> visited]</span><br><span class=\"line\">        pq.push(next)</span><br></pre></td></tr></table></figure>\n<h2 id=\"位运算\"><a href=\"#位运算\" class=\"headerlink\" title=\"位运算\"></a>位运算</h2><p>位运算实战技巧<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">判断奇偶</span><br><span class=\"line\">x % 2 == 0 =&gt; (x &amp; 1) == 0</span><br><span class=\"line\">x % 2 == 1 =&gt; (x &amp; 1) == 1</span><br><span class=\"line\"></span><br><span class=\"line\">除以2</span><br><span class=\"line\">x/2 =&gt; x &gt;&gt; 1</span><br><span class=\"line\"></span><br><span class=\"line\">清零最低位的1</span><br><span class=\"line\">x &amp; (x-1)</span><br><span class=\"line\"></span><br><span class=\"line\">取到最低位的1</span><br><span class=\"line\">x &amp; -x</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"LRU\"><a href=\"#LRU\" class=\"headerlink\" title=\"LRU\"></a>LRU</h2><p>lru实现：hashmap+deque(double linked list)</p>\n<h2 id=\"布隆过滤器\"><a href=\"#布隆过滤器\" class=\"headerlink\" title=\"布隆过滤器\"></a>布隆过滤器</h2><p>bloom filter(capacity, k)</p>\n<ul>\n<li>bit = hash(num, seed) % capacity，seed的范围是1到k</li>\n<li>插入：计算k次bit，将bit所在位置1</li>\n<li>查找：计算k次bit，如果bit所在位都为1，则数可能存在，否则一定不存在</li>\n</ul>\n<h2 id=\"动态规划复习\"><a href=\"#动态规划复习\" class=\"headerlink\" title=\"动态规划复习\"></a>动态规划复习</h2><p>重温动态规划三要素：dynamic program = subproblem(recursive) + memorize + 递推公式</p>\n<p>精简为二要素：状态定义、状态转移方程</p>\n<p>LeetCode网友整理的多维DP的代码模板<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> 状态<span class=\"number\">1</span> <span class=\"keyword\">in</span> 状态<span class=\"number\">1</span>的所有取值：</span><br><span class=\"line\">    <span class=\"keyword\">for</span> 状态<span class=\"number\">2</span> <span class=\"keyword\">in</span> 状态<span class=\"number\">2</span>的所有取值：</span><br><span class=\"line\">        <span class=\"keyword\">for</span> ...</span><br><span class=\"line\">            dp[状态<span class=\"number\">1</span>][状态<span class=\"number\">2</span>][...] = 择优(选择<span class=\"number\">1</span>，选择<span class=\"number\">2.</span>..)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"字符串匹配算法\"><a href=\"#字符串匹配算法\" class=\"headerlink\" title=\"字符串匹配算法\"></a>字符串匹配算法</h2><p>Rabin-Karp：<a href=\"https://shimo.im/docs/KXDdkT99TVtXvTXP/read\" target=\"_blank\" rel=\"noopener\">https://shimo.im/docs/KXDdkT99TVtXvTXP/read</a><br>KMP</p>\n<ul>\n<li><a href=\"https://www.bilibili.com/video/av11866460?from=search&amp;seid=17425875345653862171\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/av11866460?from=search&amp;seid=17425875345653862171</a></li>\n<li><a href=\"http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\" target=\"_blank\" rel=\"noopener\">http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html</a></li>\n</ul>\n<p><a href=\"https://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec\" target=\"_blank\" rel=\"noopener\">https://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec</a></p>\n","site":{"data":{}},"excerpt":"<p>参加即可时间算法训练营的总结。</p>","more":"<h1 id=\"数据结构篇\"><a href=\"#数据结构篇\" class=\"headerlink\" title=\"数据结构篇\"></a>数据结构篇</h1><p><a href=\"https://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c\" target=\"_blank\" rel=\"noopener\">https://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c</a></p>\n<h2 id=\"数组\"><a href=\"#数组\" class=\"headerlink\" title=\"数组\"></a>数组</h2><p>按索引查找快，O(1)；非尾端插入、非尾端删除慢，平均O(n)</p>\n<h2 id=\"链表\"><a href=\"#链表\" class=\"headerlink\" title=\"链表\"></a>链表</h2><p>按索引查找慢，平均O(n)；定位到元素后，插入、删除快，平均O(1)</p>\n<h2 id=\"跳表\"><a href=\"#跳表\" class=\"headerlink\" title=\"跳表\"></a>跳表</h2><p>元素有序，可以理解为多层的单链表，形状类似于金字塔，解决单链表查询慢的问题。通俗理解：</p>\n<ul>\n<li>最底下一层，第n层：原始数据单链表</li>\n<li>n-1层：节点数相比第n层减半的单链表，其第i个元素（i&gt;=0）指向并等于第n层的2i个元素</li>\n<li>n-2层：类似上面以此类推</li>\n<li>第1层：类似上面以此类推</li>\n</ul>\n<p>定位元素层第1层往下找，每次查找都能将目标值所在空间折半。单链表是一维，跳表是二维，属于一种升维的思想解决问题</p>\n<h2 id=\"栈\"><a href=\"#栈\" class=\"headerlink\" title=\"栈\"></a>栈</h2><p>先进后出，FILO。n个元素入栈1，将栈1元素逐一出栈放到栈2，将栈2元素逐一出栈可以达到FIFO</p>\n<h2 id=\"队列\"><a href=\"#队列\" class=\"headerlink\" title=\"队列\"></a>队列</h2><p>先进先出，FIFO</p>\n<h2 id=\"双端队列\"><a href=\"#双端队列\" class=\"headerlink\" title=\"双端队列\"></a>双端队列</h2><p>头尾两端都可以入、出元素的特殊队列</p>\n<h2 id=\"优先队列\"><a href=\"#优先队列\" class=\"headerlink\" title=\"优先队列\"></a>优先队列</h2><p>插入为O(1)，取出元素为O(nlogn)的特殊队列，每次取元素都会导致重平衡，顶层一般用堆实现</p>\n<h2 id=\"哈希表\"><a href=\"#哈希表\" class=\"headerlink\" title=\"哈希表\"></a>哈希表</h2><p>JDK8的HashMap的源码分析</p>\n<p>get操作</p>\n<ul>\n<li>通过hash方法计算hash</li>\n<li>通过hash去getNode，先由hash定位到所在通，取桶的第一个节点进行hash值compare，相等则返回。否则遍历桶的所有结点去匹配，桶的数据结构即可能是平衡二叉树，也可能是单链表</li>\n</ul>\n<p>put操作</p>\n<ul>\n<li>计算key的hash</li>\n<li>检测table是否为空，如果是调用resize进行实例化</li>\n<li>计算value需要存储到哪个slot，如果该slot为空，直接新建一个slot（单链表），并将value作为头结点，然后返回</li>\n<li>否则，取出value所在slot，命名其为s<ul>\n<li>判断value的hash值和s的头结点的hash值是否相同，若相同则覆盖返回</li>\n<li>否则判断s是否是一个平衡二叉树，若是则调用putTreeVal将value放到树中，putTreeVal会使得树进入平衡状态</li>\n<li>再否则，遍历单链表，若找到hash值相同的结点，覆盖之；否则，将value加在s的尾部，此时需要判断s是否需要进行树化（单个slot的节点数大于等于8需要树化），因为攻击者可能设计一些key使得他们落在同一个slot，此时slot单链表会拉的很长，同时由于负载因子设置不合理此时并未发生重平衡，那对slot的访问就变成了O(N)的复杂度</li>\n</ul>\n</li>\n<li>最后，判断总size是否超出threhold（根据capacity和负载因子计算出来的值），是的话调用resize()将size翻倍并重新放置各个Node</li>\n</ul>\n<p>注：hashmap之所以设计负载因子，是为了防止结点都落在了一个slot上，threhold=capacity x 负载因子。每个slot的元素都接近threhold是理想的平衡状态，一旦有某个slot超了将导致重平衡。</p>\n<h1 id=\"算法篇\"><a href=\"#算法篇\" class=\"headerlink\" title=\"算法篇\"></a>算法篇</h1><h2 id=\"树的遍历\"><a href=\"#树的遍历\" class=\"headerlink\" title=\"树的遍历\"></a>树的遍历</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 前中后序遍历模板</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">preorder</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    traverse_path.append(root.val)</span><br><span class=\"line\">    preorder(root.left)</span><br><span class=\"line\">    preorder(root.right)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inorder</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    inorder(root.left)</span><br><span class=\"line\">    traverse_path.append(root.val)</span><br><span class=\"line\">    inorder(root.right)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">postorder</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    postorder(root.left)</span><br><span class=\"line\">    postorder(root.right)</span><br><span class=\"line\">    traverse_path.append(root.val)</span><br></pre></td></tr></table></figure>\n<h2 id=\"递归模板\"><a href=\"#递归模板\" class=\"headerlink\" title=\"递归模板\"></a>递归模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 递归模板</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">recursie</span><span class=\"params\">(level, p1, p2, ...)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> level &gt; MAX_LEVEL:</span><br><span class=\"line\">        <span class=\"comment\"># process result</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\">    <span class=\"comment\"># process current level logic</span></span><br><span class=\"line\">    process(level, p1, p2, ...)</span><br><span class=\"line\">    <span class=\"comment\"># drill down</span></span><br><span class=\"line\">    recurse(level + <span class=\"number\">1</span>, p1, p2, ...)</span><br><span class=\"line\">    <span class=\"comment\"># reverse current level logic if needed</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"分治模板\"><a href=\"#分治模板\" class=\"headerlink\" title=\"分治模板\"></a>分治模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分治模板</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">divide_conquer</span><span class=\"params\">(problem, p1, p2, ...)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> problem:</span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># prepare</span></span><br><span class=\"line\">    subproblems = split_problem(problem, p1, p2, ...)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># divide</span></span><br><span class=\"line\">    subresults = [divide_conquer(subproblems[i], p1, p2, ...) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(subproblems))]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># combine</span></span><br><span class=\"line\">    result = process_result(subresults)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># reverse</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"DFS深度优先模板\"><a href=\"#DFS深度优先模板\" class=\"headerlink\" title=\"DFS深度优先模板\"></a>DFS深度优先模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># depth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 深度优先（DFS）遍历代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 递归调用</span></span><br><span class=\"line\">visited = set()</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">dfs</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> root <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"comment\"># terminator</span></span><br><span class=\"line\">    visited.add(root)</span><br><span class=\"line\">    <span class=\"comment\"># process logic here</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> node <span class=\"keyword\">in</span> root.children():</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> node <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">            dfs(node)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># depth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 深度优先（DFS）遍历代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 非递归（手动维护栈）</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">dfs</span><span class=\"params\">(root)</span>:</span></span><br><span class=\"line\">    visited, stack = set(), [root]</span><br><span class=\"line\">    <span class=\"keyword\">while</span> stack:</span><br><span class=\"line\">        node = stack.pop()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> node <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">            visited.add(node)</span><br><span class=\"line\">            process(node)</span><br><span class=\"line\">            <span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> reversed(node.children()): <span class=\"comment\"># add from right to left</span></span><br><span class=\"line\">                stack.append(child)</span><br></pre></td></tr></table></figure>\n<h2 id=\"广度优先模板\"><a href=\"#广度优先模板\" class=\"headerlink\" title=\"广度优先模板\"></a>广度优先模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># breadth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 广度优先遍历（BFS）代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 非递归，自己的理解</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bfs</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    visited, deque = set(), [root]</span><br><span class=\"line\">    <span class=\"keyword\">while</span> deque:</span><br><span class=\"line\">        node = queue.popleft() <span class=\"comment\"># 从左到右一层层遍历</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> node <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">            visited.add(node)</span><br><span class=\"line\">            deque.append(node.childrens) <span class=\"comment\"># 下一层加到最右端</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># breadth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 广度优先遍历（BFS）代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 非递归，打印层次信息</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bfs</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    visited, deque = set(), [root]</span><br><span class=\"line\">    level = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> deque:</span><br><span class=\"line\">        size, level = len(deque), level+<span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(size): <span class=\"comment\"># 第level层</span></span><br><span class=\"line\">            node = queue.popleft() <span class=\"comment\"># 从左到右一层层遍历</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> node <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">                visited.add(node)</span><br><span class=\"line\">                deque.append(node.childrens) <span class=\"comment\"># 下一层加到最右端</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"二分查找模板\"><a href=\"#二分查找模板\" class=\"headerlink\" title=\"二分查找模板\"></a>二分查找模板</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># binary search代码模板</span></span><br><span class=\"line\">left, right = <span class=\"number\">0</span>, len(array) - <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> left &lt;= right:</span><br><span class=\"line\">    mid = (left + right) / <span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> array[mid] == target:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">or</span> <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> array[mid] &lt; target:</span><br><span class=\"line\">        left = mid + <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        right = mid - <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"动态规划总结\"><a href=\"#动态规划总结\" class=\"headerlink\" title=\"动态规划总结\"></a>动态规划总结</h2><p>dynamic programing = simplifying a complicated problem by breaking it down into simpler problems(in a recursive manner)</p>\n<p>动态规划与分治没有本质区别</p>\n<ul>\n<li>共性：找重复子问题</li>\n<li>差异：找最优子结构、中途可淘汰次优解</li>\n</ul>\n<p>dynamic program三要素</p>\n<ul>\n<li>subproblem(recursive manner)最优子结构</li>\n<li>memorize记忆中间状态</li>\n<li>找递推公式</li>\n</ul>\n<h2 id=\"Trie树\"><a href=\"#Trie树\" class=\"headerlink\" title=\"Trie树\"></a>Trie树</h2><p>Trie树（字典树、字符查找树、键树）</p>\n<ul>\n<li>多叉树</li>\n<li>每个节点不存储单词本身，只存储指向到下n个节点的n个不同字母</li>\n<li>从根节点到某一节点的路径的所有字母组合起来，即为表示的单词（字符串），每个节点的数值即为该单词在文本中出现的频次</li>\n<li>常用于搜索引擎的词频统计，能最大程度减少无谓的字符串比较，这方面的效率优于哈希表</li>\n</ul>\n<h2 id=\"并查集\"><a href=\"#并查集\" class=\"headerlink\" title=\"并查集\"></a>并查集</h2><p>并查集</p>\n<ul>\n<li>makeSet(s)：用s个单元素新建并查集</li>\n<li>unionSet(x, y)：若x和y所在并查集不相交，进行合并</li>\n<li>find(x)：找出x所在并查集的代表（群主），可用来快速判断两个元素是否在同一个并查集（比较代表）</li>\n</ul>\n<p>朋友圈数量解题思路</p>\n<ul>\n<li>N个人：N个只有一个元素的独立集合</li>\n<li>关系M[i][j]为1：将两个并查集进行合并</li>\n<li>结果：最后剩多少个独立的集合</li>\n</ul>\n<p>find函数需要考虑路径压缩，防止拉链太长：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">find</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> f[x] != x:</span><br><span class=\"line\">        f[x] = find(f[x]) <span class=\"comment\"># 路径压缩，防止拉链太长</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> f[x]</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"双向BFS\"><a href=\"#双向BFS\" class=\"headerlink\" title=\"双向BFS\"></a>双向BFS</h2><p>双向BFS总结<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># breadth-first search</span></span><br><span class=\"line\"><span class=\"comment\"># 广度优先遍历（BFS）代码模板</span></span><br><span class=\"line\"><span class=\"comment\"># 非递归，自己的理解</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bfs</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    forward, backward = set(start_node), set(target_node)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> forward:</span><br><span class=\"line\">        temp = set()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> node <span class=\"keyword\">in</span> forward:</span><br><span class=\"line\">            <span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> node.childrens:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> child <span class=\"keyword\">in</span> backward: <span class=\"comment\"># 前后相交则结束</span></span><br><span class=\"line\">                    <span class=\"keyword\">return</span></span><br><span class=\"line\">                temp.add(child) <span class=\"comment\"># 记录下一层</span></span><br><span class=\"line\">        forward = temp</span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(backward) &lt; len(forward): <span class=\"comment\"># 从元素小的那一层开始遍历</span></span><br><span class=\"line\">            forward, backward = forward, backward</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"启发式搜索A\"><a href=\"#启发式搜索A\" class=\"headerlink\" title=\"启发式搜索A*\"></a>启发式搜索A*</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># A*代码模板</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">AstartSearch</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    visited = set(root)</span><br><span class=\"line\">    pq = collections.priority_queue() <span class=\"comment\"># 优先级 —&gt; 估价函数</span></span><br><span class=\"line\">    pq.append(root)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> pq:</span><br><span class=\"line\">        node = pq.pop()</span><br><span class=\"line\">        process(node)</span><br><span class=\"line\">        next = [node <span class=\"keyword\">for</span> node <span class=\"keyword\">in</span> node.children <span class=\"keyword\">if</span> node <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> visited]</span><br><span class=\"line\">        pq.push(next)</span><br></pre></td></tr></table></figure>\n<h2 id=\"位运算\"><a href=\"#位运算\" class=\"headerlink\" title=\"位运算\"></a>位运算</h2><p>位运算实战技巧<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">判断奇偶</span><br><span class=\"line\">x % 2 == 0 =&gt; (x &amp; 1) == 0</span><br><span class=\"line\">x % 2 == 1 =&gt; (x &amp; 1) == 1</span><br><span class=\"line\"></span><br><span class=\"line\">除以2</span><br><span class=\"line\">x/2 =&gt; x &gt;&gt; 1</span><br><span class=\"line\"></span><br><span class=\"line\">清零最低位的1</span><br><span class=\"line\">x &amp; (x-1)</span><br><span class=\"line\"></span><br><span class=\"line\">取到最低位的1</span><br><span class=\"line\">x &amp; -x</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"LRU\"><a href=\"#LRU\" class=\"headerlink\" title=\"LRU\"></a>LRU</h2><p>lru实现：hashmap+deque(double linked list)</p>\n<h2 id=\"布隆过滤器\"><a href=\"#布隆过滤器\" class=\"headerlink\" title=\"布隆过滤器\"></a>布隆过滤器</h2><p>bloom filter(capacity, k)</p>\n<ul>\n<li>bit = hash(num, seed) % capacity，seed的范围是1到k</li>\n<li>插入：计算k次bit，将bit所在位置1</li>\n<li>查找：计算k次bit，如果bit所在位都为1，则数可能存在，否则一定不存在</li>\n</ul>\n<h2 id=\"动态规划复习\"><a href=\"#动态规划复习\" class=\"headerlink\" title=\"动态规划复习\"></a>动态规划复习</h2><p>重温动态规划三要素：dynamic program = subproblem(recursive) + memorize + 递推公式</p>\n<p>精简为二要素：状态定义、状态转移方程</p>\n<p>LeetCode网友整理的多维DP的代码模板<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> 状态<span class=\"number\">1</span> <span class=\"keyword\">in</span> 状态<span class=\"number\">1</span>的所有取值：</span><br><span class=\"line\">    <span class=\"keyword\">for</span> 状态<span class=\"number\">2</span> <span class=\"keyword\">in</span> 状态<span class=\"number\">2</span>的所有取值：</span><br><span class=\"line\">        <span class=\"keyword\">for</span> ...</span><br><span class=\"line\">            dp[状态<span class=\"number\">1</span>][状态<span class=\"number\">2</span>][...] = 择优(选择<span class=\"number\">1</span>，选择<span class=\"number\">2.</span>..)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"字符串匹配算法\"><a href=\"#字符串匹配算法\" class=\"headerlink\" title=\"字符串匹配算法\"></a>字符串匹配算法</h2><p>Rabin-Karp：<a href=\"https://shimo.im/docs/KXDdkT99TVtXvTXP/read\" target=\"_blank\" rel=\"noopener\">https://shimo.im/docs/KXDdkT99TVtXvTXP/read</a><br>KMP</p>\n<ul>\n<li><a href=\"https://www.bilibili.com/video/av11866460?from=search&amp;seid=17425875345653862171\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/av11866460?from=search&amp;seid=17425875345653862171</a></li>\n<li><a href=\"http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\" target=\"_blank\" rel=\"noopener\">http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html</a></li>\n</ul>\n<p><a href=\"https://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec\" target=\"_blank\" rel=\"noopener\">https://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec</a></p>"},{"title":"【博客笔记】掘金的knock_小新的Java并发系列","date":"2019-12-27T14:14:52.000Z","comments":1,"_content":"\n博客地址：https://juejin.im/post/5b4f54d66fb9a04f8d6bb44a\n\n<!--more-->\n\n## JMM相关\n\nJMM：cpu、cache、mem为物理层，stack、heap为逻辑层。static修饰的变量、新建的object、object的成员在heap，剩余的在stack。方法参数、object引用、局部变量等在stack。\n\nhappens-before：无论指令如何重排序，JMM需保证几种必要的时序正确：lock、volatile、start()、join()、interrupt()、finalize()、代码执行顺序。\n\nvolatile：通过读写内存屏障，实现了可见性保证。\n\n## Lock相关\n\nsynchronized：偏向锁（单线程）、轻量锁（多线程轻量竞争）、重量锁。CAS需要物理层支持，有ABA问题。\n\nReentrantLock：fair与unfair的差别主要在于tryAcquire时是否排队；AQS是基础抽象类，定义了acquire和release等基础行为，且实现了共有抽象方法。\n\nSemaphore：fair与unfair的差别是tryAcquireShared是否排队；获取失败添加到等待队列，等待队列先进先出（对于队列而言是公平）。\n\nCountDownLatch：CountDownLatch的await等待countDown全部释放，才可以开始下一轮次。\n\nCountDownLatch和Semaphore区别：state每次只减1，为0时才释放所有等待线程；提供了超时acquire的方法，等不到可以去做其他事情。\n\nReentrantReadWriteLock：读锁共享，写锁独占。读锁检测到没有写锁，或写锁是当前线程，且数量未超上限，则获取，读锁与Semaphore的区别如是也。写锁需要全部读锁释放才可获取，会发生写饥饿，与ReentrantLock的区别如是也。\n\nStampedLock：StampedLock写锁获取与rwlock类似，但释放不是减一而是加一，目的是记录获取过写锁，防止乐观读锁出现ABA问题；读锁容量在127内是加一减一，若溢出则用readerOverflow变量加减一，之所以读容量较小是为了腾出更多容量来记录写锁行为，这点个人觉得难以理解。乐观读锁实际没有获取锁，其validate()相当于一个double check，如果此间没有过写锁行为，则验证通过，否则需要考虑升级为悲观读锁。\n\n## 容器相关\n\nConcurrentHashMap：插入时若未初始化CAS实例化，桶未有结点则CAS插入到头，正在扩容协助扩容，hash冲突则使用synchronized加锁当前桶。\n\nArrayBlockingQueue：通过独占锁互斥读写、通过两个conditon阻塞或唤醒生产与消费者、通过takeIndex、putIndex、count维护一个滑动的读写窗口。超时poll和offer则结合awaitNanos实现。\n\nConcurrentSkipListMap：并发下的有序map实现\n\n有界阻塞队列包括：ArrayBlockingQueue、LinkedBlockingQueue以及LinkedBlockingDeque三种，LinkedBlockingDeque应用场景很少，一般用在“工作窃取”模式下。ArrayBlockingQueue和LinkedBlockingQueue基本就是数组和链表的区别。无界队列包括PriorityBlockingQueue、DelayQueue和LinkedTransferQueue。PriorityBlockingQueue用在需要排序的队列中。DelayQueue可以用来做一些定时任务或者缓存过期的场景。LinkedTransferQueue则相比较其他队列多了transfer功能。最后剩下一个不存储元素的队列SynchronousQueue，用来处理一些高效的传递性场景。\n\nLinkedBlockingQueue底层是链表，它使用了两个独占锁来控制头部消费和尾部生产，使用AtomicInteger的count来控制并发更新。\n\n## 线程池相关\n\n1. 举个例子来说明为什么要使用线程池，有什么好处？\n    - 客户端&服务端通信，线程创建销毁开销中，线程池可复用\n1. jdk1.8中提供了哪几种基本的线程池？\n    - 单线程（无界队列）、固定线程（无界队列）、无限线程（同步队列）、定时线程\n1. 线程池几大组件的关系？\n    - Excutor是顶级接口，接受Runnable作为入参\n    - ExcutorService接口扩展了Excutor接口，新增了线程控制和状态判断的方法\n    - Excutors是创建线程池的工厂\n    - ThreadPoolExecutor是具体实现类\n1. ExecutorService的生命周期？\n    - RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED\n1. 线程池中的线程能设置超时吗？\n    - submit得到future后调用get\n1. 怎么取消线程池中的线程？\n    - 同上\n1. 如何设置一个合适的线程池大小？\n    - 视工作负载、CPU核心数而定\n1. 当使用有界队列时，如何设置一个合适的队列大小？\n    - 视平均消费时长、消费线程数而定\n1. 当使用有界队列时，如果队列已满，如何选择合适的拒绝策略？\n    - 直接拒绝、报错拒绝、执行调用方的拒绝策略（阻塞）\n1. 如何统计线程池中的线程执行时间？\n    - ThreadPoolExecutor的beforeExcute和afterExcute方法","source":"_posts/2019-12-27-juejin-juc-blog-note.md","raw":"---\ntitle: 【博客笔记】掘金的knock_小新的Java并发系列\ndate: 2019-12-27 22:14:52\ntags: ['Java']\ncomments: true\ncategories: ['编程语言']\n---\n\n博客地址：https://juejin.im/post/5b4f54d66fb9a04f8d6bb44a\n\n<!--more-->\n\n## JMM相关\n\nJMM：cpu、cache、mem为物理层，stack、heap为逻辑层。static修饰的变量、新建的object、object的成员在heap，剩余的在stack。方法参数、object引用、局部变量等在stack。\n\nhappens-before：无论指令如何重排序，JMM需保证几种必要的时序正确：lock、volatile、start()、join()、interrupt()、finalize()、代码执行顺序。\n\nvolatile：通过读写内存屏障，实现了可见性保证。\n\n## Lock相关\n\nsynchronized：偏向锁（单线程）、轻量锁（多线程轻量竞争）、重量锁。CAS需要物理层支持，有ABA问题。\n\nReentrantLock：fair与unfair的差别主要在于tryAcquire时是否排队；AQS是基础抽象类，定义了acquire和release等基础行为，且实现了共有抽象方法。\n\nSemaphore：fair与unfair的差别是tryAcquireShared是否排队；获取失败添加到等待队列，等待队列先进先出（对于队列而言是公平）。\n\nCountDownLatch：CountDownLatch的await等待countDown全部释放，才可以开始下一轮次。\n\nCountDownLatch和Semaphore区别：state每次只减1，为0时才释放所有等待线程；提供了超时acquire的方法，等不到可以去做其他事情。\n\nReentrantReadWriteLock：读锁共享，写锁独占。读锁检测到没有写锁，或写锁是当前线程，且数量未超上限，则获取，读锁与Semaphore的区别如是也。写锁需要全部读锁释放才可获取，会发生写饥饿，与ReentrantLock的区别如是也。\n\nStampedLock：StampedLock写锁获取与rwlock类似，但释放不是减一而是加一，目的是记录获取过写锁，防止乐观读锁出现ABA问题；读锁容量在127内是加一减一，若溢出则用readerOverflow变量加减一，之所以读容量较小是为了腾出更多容量来记录写锁行为，这点个人觉得难以理解。乐观读锁实际没有获取锁，其validate()相当于一个double check，如果此间没有过写锁行为，则验证通过，否则需要考虑升级为悲观读锁。\n\n## 容器相关\n\nConcurrentHashMap：插入时若未初始化CAS实例化，桶未有结点则CAS插入到头，正在扩容协助扩容，hash冲突则使用synchronized加锁当前桶。\n\nArrayBlockingQueue：通过独占锁互斥读写、通过两个conditon阻塞或唤醒生产与消费者、通过takeIndex、putIndex、count维护一个滑动的读写窗口。超时poll和offer则结合awaitNanos实现。\n\nConcurrentSkipListMap：并发下的有序map实现\n\n有界阻塞队列包括：ArrayBlockingQueue、LinkedBlockingQueue以及LinkedBlockingDeque三种，LinkedBlockingDeque应用场景很少，一般用在“工作窃取”模式下。ArrayBlockingQueue和LinkedBlockingQueue基本就是数组和链表的区别。无界队列包括PriorityBlockingQueue、DelayQueue和LinkedTransferQueue。PriorityBlockingQueue用在需要排序的队列中。DelayQueue可以用来做一些定时任务或者缓存过期的场景。LinkedTransferQueue则相比较其他队列多了transfer功能。最后剩下一个不存储元素的队列SynchronousQueue，用来处理一些高效的传递性场景。\n\nLinkedBlockingQueue底层是链表，它使用了两个独占锁来控制头部消费和尾部生产，使用AtomicInteger的count来控制并发更新。\n\n## 线程池相关\n\n1. 举个例子来说明为什么要使用线程池，有什么好处？\n    - 客户端&服务端通信，线程创建销毁开销中，线程池可复用\n1. jdk1.8中提供了哪几种基本的线程池？\n    - 单线程（无界队列）、固定线程（无界队列）、无限线程（同步队列）、定时线程\n1. 线程池几大组件的关系？\n    - Excutor是顶级接口，接受Runnable作为入参\n    - ExcutorService接口扩展了Excutor接口，新增了线程控制和状态判断的方法\n    - Excutors是创建线程池的工厂\n    - ThreadPoolExecutor是具体实现类\n1. ExecutorService的生命周期？\n    - RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED\n1. 线程池中的线程能设置超时吗？\n    - submit得到future后调用get\n1. 怎么取消线程池中的线程？\n    - 同上\n1. 如何设置一个合适的线程池大小？\n    - 视工作负载、CPU核心数而定\n1. 当使用有界队列时，如何设置一个合适的队列大小？\n    - 视平均消费时长、消费线程数而定\n1. 当使用有界队列时，如果队列已满，如何选择合适的拒绝策略？\n    - 直接拒绝、报错拒绝、执行调用方的拒绝策略（阻塞）\n1. 如何统计线程池中的线程执行时间？\n    - ThreadPoolExecutor的beforeExcute和afterExcute方法","slug":"juejin-juc-blog-note","published":1,"updated":"2022-08-09T15:02:00.655Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14h003digu84v608hkt","content":"<p>博客地址：<a href=\"https://juejin.im/post/5b4f54d66fb9a04f8d6bb44a\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5b4f54d66fb9a04f8d6bb44a</a></p>\n<a id=\"more\"></a>\n<h2 id=\"JMM相关\"><a href=\"#JMM相关\" class=\"headerlink\" title=\"JMM相关\"></a>JMM相关</h2><p>JMM：cpu、cache、mem为物理层，stack、heap为逻辑层。static修饰的变量、新建的object、object的成员在heap，剩余的在stack。方法参数、object引用、局部变量等在stack。</p>\n<p>happens-before：无论指令如何重排序，JMM需保证几种必要的时序正确：lock、volatile、start()、join()、interrupt()、finalize()、代码执行顺序。</p>\n<p>volatile：通过读写内存屏障，实现了可见性保证。</p>\n<h2 id=\"Lock相关\"><a href=\"#Lock相关\" class=\"headerlink\" title=\"Lock相关\"></a>Lock相关</h2><p>synchronized：偏向锁（单线程）、轻量锁（多线程轻量竞争）、重量锁。CAS需要物理层支持，有ABA问题。</p>\n<p>ReentrantLock：fair与unfair的差别主要在于tryAcquire时是否排队；AQS是基础抽象类，定义了acquire和release等基础行为，且实现了共有抽象方法。</p>\n<p>Semaphore：fair与unfair的差别是tryAcquireShared是否排队；获取失败添加到等待队列，等待队列先进先出（对于队列而言是公平）。</p>\n<p>CountDownLatch：CountDownLatch的await等待countDown全部释放，才可以开始下一轮次。</p>\n<p>CountDownLatch和Semaphore区别：state每次只减1，为0时才释放所有等待线程；提供了超时acquire的方法，等不到可以去做其他事情。</p>\n<p>ReentrantReadWriteLock：读锁共享，写锁独占。读锁检测到没有写锁，或写锁是当前线程，且数量未超上限，则获取，读锁与Semaphore的区别如是也。写锁需要全部读锁释放才可获取，会发生写饥饿，与ReentrantLock的区别如是也。</p>\n<p>StampedLock：StampedLock写锁获取与rwlock类似，但释放不是减一而是加一，目的是记录获取过写锁，防止乐观读锁出现ABA问题；读锁容量在127内是加一减一，若溢出则用readerOverflow变量加减一，之所以读容量较小是为了腾出更多容量来记录写锁行为，这点个人觉得难以理解。乐观读锁实际没有获取锁，其validate()相当于一个double check，如果此间没有过写锁行为，则验证通过，否则需要考虑升级为悲观读锁。</p>\n<h2 id=\"容器相关\"><a href=\"#容器相关\" class=\"headerlink\" title=\"容器相关\"></a>容器相关</h2><p>ConcurrentHashMap：插入时若未初始化CAS实例化，桶未有结点则CAS插入到头，正在扩容协助扩容，hash冲突则使用synchronized加锁当前桶。</p>\n<p>ArrayBlockingQueue：通过独占锁互斥读写、通过两个conditon阻塞或唤醒生产与消费者、通过takeIndex、putIndex、count维护一个滑动的读写窗口。超时poll和offer则结合awaitNanos实现。</p>\n<p>ConcurrentSkipListMap：并发下的有序map实现</p>\n<p>有界阻塞队列包括：ArrayBlockingQueue、LinkedBlockingQueue以及LinkedBlockingDeque三种，LinkedBlockingDeque应用场景很少，一般用在“工作窃取”模式下。ArrayBlockingQueue和LinkedBlockingQueue基本就是数组和链表的区别。无界队列包括PriorityBlockingQueue、DelayQueue和LinkedTransferQueue。PriorityBlockingQueue用在需要排序的队列中。DelayQueue可以用来做一些定时任务或者缓存过期的场景。LinkedTransferQueue则相比较其他队列多了transfer功能。最后剩下一个不存储元素的队列SynchronousQueue，用来处理一些高效的传递性场景。</p>\n<p>LinkedBlockingQueue底层是链表，它使用了两个独占锁来控制头部消费和尾部生产，使用AtomicInteger的count来控制并发更新。</p>\n<h2 id=\"线程池相关\"><a href=\"#线程池相关\" class=\"headerlink\" title=\"线程池相关\"></a>线程池相关</h2><ol>\n<li>举个例子来说明为什么要使用线程池，有什么好处？<ul>\n<li>客户端&amp;服务端通信，线程创建销毁开销中，线程池可复用</li>\n</ul>\n</li>\n<li>jdk1.8中提供了哪几种基本的线程池？<ul>\n<li>单线程（无界队列）、固定线程（无界队列）、无限线程（同步队列）、定时线程</li>\n</ul>\n</li>\n<li>线程池几大组件的关系？<ul>\n<li>Excutor是顶级接口，接受Runnable作为入参</li>\n<li>ExcutorService接口扩展了Excutor接口，新增了线程控制和状态判断的方法</li>\n<li>Excutors是创建线程池的工厂</li>\n<li>ThreadPoolExecutor是具体实现类</li>\n</ul>\n</li>\n<li>ExecutorService的生命周期？<ul>\n<li>RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED</li>\n</ul>\n</li>\n<li>线程池中的线程能设置超时吗？<ul>\n<li>submit得到future后调用get</li>\n</ul>\n</li>\n<li>怎么取消线程池中的线程？<ul>\n<li>同上</li>\n</ul>\n</li>\n<li>如何设置一个合适的线程池大小？<ul>\n<li>视工作负载、CPU核心数而定</li>\n</ul>\n</li>\n<li>当使用有界队列时，如何设置一个合适的队列大小？<ul>\n<li>视平均消费时长、消费线程数而定</li>\n</ul>\n</li>\n<li>当使用有界队列时，如果队列已满，如何选择合适的拒绝策略？<ul>\n<li>直接拒绝、报错拒绝、执行调用方的拒绝策略（阻塞）</li>\n</ul>\n</li>\n<li>如何统计线程池中的线程执行时间？<ul>\n<li>ThreadPoolExecutor的beforeExcute和afterExcute方法</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>博客地址：<a href=\"https://juejin.im/post/5b4f54d66fb9a04f8d6bb44a\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5b4f54d66fb9a04f8d6bb44a</a></p>","more":"<h2 id=\"JMM相关\"><a href=\"#JMM相关\" class=\"headerlink\" title=\"JMM相关\"></a>JMM相关</h2><p>JMM：cpu、cache、mem为物理层，stack、heap为逻辑层。static修饰的变量、新建的object、object的成员在heap，剩余的在stack。方法参数、object引用、局部变量等在stack。</p>\n<p>happens-before：无论指令如何重排序，JMM需保证几种必要的时序正确：lock、volatile、start()、join()、interrupt()、finalize()、代码执行顺序。</p>\n<p>volatile：通过读写内存屏障，实现了可见性保证。</p>\n<h2 id=\"Lock相关\"><a href=\"#Lock相关\" class=\"headerlink\" title=\"Lock相关\"></a>Lock相关</h2><p>synchronized：偏向锁（单线程）、轻量锁（多线程轻量竞争）、重量锁。CAS需要物理层支持，有ABA问题。</p>\n<p>ReentrantLock：fair与unfair的差别主要在于tryAcquire时是否排队；AQS是基础抽象类，定义了acquire和release等基础行为，且实现了共有抽象方法。</p>\n<p>Semaphore：fair与unfair的差别是tryAcquireShared是否排队；获取失败添加到等待队列，等待队列先进先出（对于队列而言是公平）。</p>\n<p>CountDownLatch：CountDownLatch的await等待countDown全部释放，才可以开始下一轮次。</p>\n<p>CountDownLatch和Semaphore区别：state每次只减1，为0时才释放所有等待线程；提供了超时acquire的方法，等不到可以去做其他事情。</p>\n<p>ReentrantReadWriteLock：读锁共享，写锁独占。读锁检测到没有写锁，或写锁是当前线程，且数量未超上限，则获取，读锁与Semaphore的区别如是也。写锁需要全部读锁释放才可获取，会发生写饥饿，与ReentrantLock的区别如是也。</p>\n<p>StampedLock：StampedLock写锁获取与rwlock类似，但释放不是减一而是加一，目的是记录获取过写锁，防止乐观读锁出现ABA问题；读锁容量在127内是加一减一，若溢出则用readerOverflow变量加减一，之所以读容量较小是为了腾出更多容量来记录写锁行为，这点个人觉得难以理解。乐观读锁实际没有获取锁，其validate()相当于一个double check，如果此间没有过写锁行为，则验证通过，否则需要考虑升级为悲观读锁。</p>\n<h2 id=\"容器相关\"><a href=\"#容器相关\" class=\"headerlink\" title=\"容器相关\"></a>容器相关</h2><p>ConcurrentHashMap：插入时若未初始化CAS实例化，桶未有结点则CAS插入到头，正在扩容协助扩容，hash冲突则使用synchronized加锁当前桶。</p>\n<p>ArrayBlockingQueue：通过独占锁互斥读写、通过两个conditon阻塞或唤醒生产与消费者、通过takeIndex、putIndex、count维护一个滑动的读写窗口。超时poll和offer则结合awaitNanos实现。</p>\n<p>ConcurrentSkipListMap：并发下的有序map实现</p>\n<p>有界阻塞队列包括：ArrayBlockingQueue、LinkedBlockingQueue以及LinkedBlockingDeque三种，LinkedBlockingDeque应用场景很少，一般用在“工作窃取”模式下。ArrayBlockingQueue和LinkedBlockingQueue基本就是数组和链表的区别。无界队列包括PriorityBlockingQueue、DelayQueue和LinkedTransferQueue。PriorityBlockingQueue用在需要排序的队列中。DelayQueue可以用来做一些定时任务或者缓存过期的场景。LinkedTransferQueue则相比较其他队列多了transfer功能。最后剩下一个不存储元素的队列SynchronousQueue，用来处理一些高效的传递性场景。</p>\n<p>LinkedBlockingQueue底层是链表，它使用了两个独占锁来控制头部消费和尾部生产，使用AtomicInteger的count来控制并发更新。</p>\n<h2 id=\"线程池相关\"><a href=\"#线程池相关\" class=\"headerlink\" title=\"线程池相关\"></a>线程池相关</h2><ol>\n<li>举个例子来说明为什么要使用线程池，有什么好处？<ul>\n<li>客户端&amp;服务端通信，线程创建销毁开销中，线程池可复用</li>\n</ul>\n</li>\n<li>jdk1.8中提供了哪几种基本的线程池？<ul>\n<li>单线程（无界队列）、固定线程（无界队列）、无限线程（同步队列）、定时线程</li>\n</ul>\n</li>\n<li>线程池几大组件的关系？<ul>\n<li>Excutor是顶级接口，接受Runnable作为入参</li>\n<li>ExcutorService接口扩展了Excutor接口，新增了线程控制和状态判断的方法</li>\n<li>Excutors是创建线程池的工厂</li>\n<li>ThreadPoolExecutor是具体实现类</li>\n</ul>\n</li>\n<li>ExecutorService的生命周期？<ul>\n<li>RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED</li>\n</ul>\n</li>\n<li>线程池中的线程能设置超时吗？<ul>\n<li>submit得到future后调用get</li>\n</ul>\n</li>\n<li>怎么取消线程池中的线程？<ul>\n<li>同上</li>\n</ul>\n</li>\n<li>如何设置一个合适的线程池大小？<ul>\n<li>视工作负载、CPU核心数而定</li>\n</ul>\n</li>\n<li>当使用有界队列时，如何设置一个合适的队列大小？<ul>\n<li>视平均消费时长、消费线程数而定</li>\n</ul>\n</li>\n<li>当使用有界队列时，如果队列已满，如何选择合适的拒绝策略？<ul>\n<li>直接拒绝、报错拒绝、执行调用方的拒绝策略（阻塞）</li>\n</ul>\n</li>\n<li>如何统计线程池中的线程执行时间？<ul>\n<li>ThreadPoolExecutor的beforeExcute和afterExcute方法</li>\n</ul>\n</li>\n</ol>"},{"title":"b-tree的由来","date":"2019-12-27T14:31:55.000Z","comments":1,"_content":"\n在YouTube上有个视频将[B树](https://www.youtube.com/watch?v=aZjYr87r1b8)深入浅出讲的十分透彻，简单整理笔记如下。\n\n<!--more-->\n\n## disk structure\n\n![image](https://user-images.githubusercontent.com/4915189/71506681-e8a03e80-28bc-11ea-862d-8e6d7f10eb07.png)\n\n机械磁盘的物理架构，是由多个盘面、中心柱和机械臂组成的。中心柱串起多个盘面，每个盘面上都有机械臂靠伸入、伸出以及旋转盘面实现对整个盘面的访问。盘面的track，指的是一条圆形轨道，盘面有大大小小的多个track。盘面的sector，指的是一个最小单位的扇形面积，所有sector构成了盘面这个圆。track no和sector no唯一标识一个block，它是磁盘分配的最小单位。假设我们要写10条记录到硬盘，他们背后就是写在一系列block。\n\n## indexing\n\n![image](https://user-images.githubusercontent.com/4915189/71506950-d07cef00-28bd-11ea-8ed2-0f5ae150eabd.png)\n\n假设我们在磁盘存储了100个记录，每次要找指定id的记录我们都得从头扫描，代价非常昂贵。其实可以把间隔10个记录存索引，如把指向1、10、20等的地址信息存到索引文件，每次查询指定id记录时先加载索引文件，然后根据地址信息再去扫描实际数据记录。这就是indexing的思想。\n\n## multi-indexing和m-way search tree\n\n假设磁盘的记录是1W、10W和100W个呢？这时上述的索引文件将非常庞大，必须在索引文件之上再建索引，再建一层索引可能还是太大难以一次load到内存，重复这个动作直至最上面一层的索引文件足够小。这就叫multi-indexing，即多层索引。\n\n![image](https://user-images.githubusercontent.com/4915189/71510392-b9dc9500-28c9-11ea-9518-7e4e92b12e49.png)\n\n把上面的多层索引竖着拎起来，它就是一颗m-way search tree。查找记录时一层层索引往下找，直到到达最底下一层的实际记录层。索引的组织之所以不用binary-search tree，是因为同等节点存储在binary-search tree的深度更深，而每向下一层都涉及到磁盘读I/O，读I/O次数较m-tree要多的多。m-way search tree虽然一次读了较多数据到内存，到它减少了较重的I/O操作，也是一种空间（主存）换时间的思想。\n\n## b-tree\n\n上面的记录在实际工程中，是存储在数据库的。b-tree其实就是数据库规定的一种m-way search tree语法，通过规定该语法实现了索引结构的增、删、改自维护，它的目的是使得m-way search tree能自适应。\n\n![image](https://user-images.githubusercontent.com/4915189/71511235-8f400b80-28cc-11ea-9171-ee6ccefb264f.png)\n\nb-tree有以下规定：\n- 每个节点最多有m个孩子，根节点（非叶子）至少有2个孩子，其他非叶子节点至少有Ceil(m/2)个孩子\n- 所有叶子节点都在同一层\n- 每个节点包含n个关键字信息（真实记录数据），关键字的个数n满足ceil(m/2)-1 <= n <= m-1，且关键字呈升序排序，即关键字k1 < k2 < ... < ki < kn\n- 每个非叶子节点有n+1个指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于关键字k(i-1)\n\n更多b-tree细节见[b-tree](https://www.geeksforgeeks.org/introduction-of-b-tree-2/)。\n\n## b+ tree\n\n![image](https://user-images.githubusercontent.com/4915189/71511550-bfd47500-28cd-11ea-90aa-c8589680301f.png)\n\nb-tree的特点是所有数据都存储在节点上。假设我们要发起一个数据库的全表扫描，b-tree的结构将会导致不断上下回溯索引，正因此才有了b+ tree。它和b-tree的不同在于：\n- 非叶子节点只存储指针索引信息，不存真实数据\n- 真实数据记录都存放在叶子节点中\n- 所有叶子节点之间都有一个链指针以便于顺序查找\n\n更多细节参考[b+ tree](https://www.geeksforgeeks.org/introduction-of-b-tree/)\n","source":"_posts/2019-12-27-b-tree.md","raw":"---\ntitle: b-tree的由来\ndate: 2019-12-27 22:31:55\ntags: ['B-Tree']\ncomments: true\ncategories: ['数据结构']\n---\n\n在YouTube上有个视频将[B树](https://www.youtube.com/watch?v=aZjYr87r1b8)深入浅出讲的十分透彻，简单整理笔记如下。\n\n<!--more-->\n\n## disk structure\n\n![image](https://user-images.githubusercontent.com/4915189/71506681-e8a03e80-28bc-11ea-862d-8e6d7f10eb07.png)\n\n机械磁盘的物理架构，是由多个盘面、中心柱和机械臂组成的。中心柱串起多个盘面，每个盘面上都有机械臂靠伸入、伸出以及旋转盘面实现对整个盘面的访问。盘面的track，指的是一条圆形轨道，盘面有大大小小的多个track。盘面的sector，指的是一个最小单位的扇形面积，所有sector构成了盘面这个圆。track no和sector no唯一标识一个block，它是磁盘分配的最小单位。假设我们要写10条记录到硬盘，他们背后就是写在一系列block。\n\n## indexing\n\n![image](https://user-images.githubusercontent.com/4915189/71506950-d07cef00-28bd-11ea-8ed2-0f5ae150eabd.png)\n\n假设我们在磁盘存储了100个记录，每次要找指定id的记录我们都得从头扫描，代价非常昂贵。其实可以把间隔10个记录存索引，如把指向1、10、20等的地址信息存到索引文件，每次查询指定id记录时先加载索引文件，然后根据地址信息再去扫描实际数据记录。这就是indexing的思想。\n\n## multi-indexing和m-way search tree\n\n假设磁盘的记录是1W、10W和100W个呢？这时上述的索引文件将非常庞大，必须在索引文件之上再建索引，再建一层索引可能还是太大难以一次load到内存，重复这个动作直至最上面一层的索引文件足够小。这就叫multi-indexing，即多层索引。\n\n![image](https://user-images.githubusercontent.com/4915189/71510392-b9dc9500-28c9-11ea-9518-7e4e92b12e49.png)\n\n把上面的多层索引竖着拎起来，它就是一颗m-way search tree。查找记录时一层层索引往下找，直到到达最底下一层的实际记录层。索引的组织之所以不用binary-search tree，是因为同等节点存储在binary-search tree的深度更深，而每向下一层都涉及到磁盘读I/O，读I/O次数较m-tree要多的多。m-way search tree虽然一次读了较多数据到内存，到它减少了较重的I/O操作，也是一种空间（主存）换时间的思想。\n\n## b-tree\n\n上面的记录在实际工程中，是存储在数据库的。b-tree其实就是数据库规定的一种m-way search tree语法，通过规定该语法实现了索引结构的增、删、改自维护，它的目的是使得m-way search tree能自适应。\n\n![image](https://user-images.githubusercontent.com/4915189/71511235-8f400b80-28cc-11ea-9171-ee6ccefb264f.png)\n\nb-tree有以下规定：\n- 每个节点最多有m个孩子，根节点（非叶子）至少有2个孩子，其他非叶子节点至少有Ceil(m/2)个孩子\n- 所有叶子节点都在同一层\n- 每个节点包含n个关键字信息（真实记录数据），关键字的个数n满足ceil(m/2)-1 <= n <= m-1，且关键字呈升序排序，即关键字k1 < k2 < ... < ki < kn\n- 每个非叶子节点有n+1个指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于关键字k(i-1)\n\n更多b-tree细节见[b-tree](https://www.geeksforgeeks.org/introduction-of-b-tree-2/)。\n\n## b+ tree\n\n![image](https://user-images.githubusercontent.com/4915189/71511550-bfd47500-28cd-11ea-90aa-c8589680301f.png)\n\nb-tree的特点是所有数据都存储在节点上。假设我们要发起一个数据库的全表扫描，b-tree的结构将会导致不断上下回溯索引，正因此才有了b+ tree。它和b-tree的不同在于：\n- 非叶子节点只存储指针索引信息，不存真实数据\n- 真实数据记录都存放在叶子节点中\n- 所有叶子节点之间都有一个链指针以便于顺序查找\n\n更多细节参考[b+ tree](https://www.geeksforgeeks.org/introduction-of-b-tree/)\n","slug":"b-tree","published":1,"updated":"2022-08-09T15:02:00.655Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14m003iigu8gbdl7xys","content":"<p>在YouTube上有个视频将<a href=\"https://www.youtube.com/watch?v=aZjYr87r1b8\" target=\"_blank\" rel=\"noopener\">B树</a>深入浅出讲的十分透彻，简单整理笔记如下。</p>\n<a id=\"more\"></a>\n<h2 id=\"disk-structure\"><a href=\"#disk-structure\" class=\"headerlink\" title=\"disk structure\"></a>disk structure</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71506681-e8a03e80-28bc-11ea-862d-8e6d7f10eb07.png\" alt=\"image\"></p>\n<p>机械磁盘的物理架构，是由多个盘面、中心柱和机械臂组成的。中心柱串起多个盘面，每个盘面上都有机械臂靠伸入、伸出以及旋转盘面实现对整个盘面的访问。盘面的track，指的是一条圆形轨道，盘面有大大小小的多个track。盘面的sector，指的是一个最小单位的扇形面积，所有sector构成了盘面这个圆。track no和sector no唯一标识一个block，它是磁盘分配的最小单位。假设我们要写10条记录到硬盘，他们背后就是写在一系列block。</p>\n<h2 id=\"indexing\"><a href=\"#indexing\" class=\"headerlink\" title=\"indexing\"></a>indexing</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71506950-d07cef00-28bd-11ea-8ed2-0f5ae150eabd.png\" alt=\"image\"></p>\n<p>假设我们在磁盘存储了100个记录，每次要找指定id的记录我们都得从头扫描，代价非常昂贵。其实可以把间隔10个记录存索引，如把指向1、10、20等的地址信息存到索引文件，每次查询指定id记录时先加载索引文件，然后根据地址信息再去扫描实际数据记录。这就是indexing的思想。</p>\n<h2 id=\"multi-indexing和m-way-search-tree\"><a href=\"#multi-indexing和m-way-search-tree\" class=\"headerlink\" title=\"multi-indexing和m-way search tree\"></a>multi-indexing和m-way search tree</h2><p>假设磁盘的记录是1W、10W和100W个呢？这时上述的索引文件将非常庞大，必须在索引文件之上再建索引，再建一层索引可能还是太大难以一次load到内存，重复这个动作直至最上面一层的索引文件足够小。这就叫multi-indexing，即多层索引。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71510392-b9dc9500-28c9-11ea-9518-7e4e92b12e49.png\" alt=\"image\"></p>\n<p>把上面的多层索引竖着拎起来，它就是一颗m-way search tree。查找记录时一层层索引往下找，直到到达最底下一层的实际记录层。索引的组织之所以不用binary-search tree，是因为同等节点存储在binary-search tree的深度更深，而每向下一层都涉及到磁盘读I/O，读I/O次数较m-tree要多的多。m-way search tree虽然一次读了较多数据到内存，到它减少了较重的I/O操作，也是一种空间（主存）换时间的思想。</p>\n<h2 id=\"b-tree\"><a href=\"#b-tree\" class=\"headerlink\" title=\"b-tree\"></a>b-tree</h2><p>上面的记录在实际工程中，是存储在数据库的。b-tree其实就是数据库规定的一种m-way search tree语法，通过规定该语法实现了索引结构的增、删、改自维护，它的目的是使得m-way search tree能自适应。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71511235-8f400b80-28cc-11ea-9171-ee6ccefb264f.png\" alt=\"image\"></p>\n<p>b-tree有以下规定：</p>\n<ul>\n<li>每个节点最多有m个孩子，根节点（非叶子）至少有2个孩子，其他非叶子节点至少有Ceil(m/2)个孩子</li>\n<li>所有叶子节点都在同一层</li>\n<li>每个节点包含n个关键字信息（真实记录数据），关键字的个数n满足ceil(m/2)-1 &lt;= n &lt;= m-1，且关键字呈升序排序，即关键字k1 &lt; k2 &lt; … &lt; ki &lt; kn</li>\n<li>每个非叶子节点有n+1个指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于关键字k(i-1)</li>\n</ul>\n<p>更多b-tree细节见<a href=\"https://www.geeksforgeeks.org/introduction-of-b-tree-2/\" target=\"_blank\" rel=\"noopener\">b-tree</a>。</p>\n<h2 id=\"b-tree-1\"><a href=\"#b-tree-1\" class=\"headerlink\" title=\"b+ tree\"></a>b+ tree</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71511550-bfd47500-28cd-11ea-90aa-c8589680301f.png\" alt=\"image\"></p>\n<p>b-tree的特点是所有数据都存储在节点上。假设我们要发起一个数据库的全表扫描，b-tree的结构将会导致不断上下回溯索引，正因此才有了b+ tree。它和b-tree的不同在于：</p>\n<ul>\n<li>非叶子节点只存储指针索引信息，不存真实数据</li>\n<li>真实数据记录都存放在叶子节点中</li>\n<li>所有叶子节点之间都有一个链指针以便于顺序查找</li>\n</ul>\n<p>更多细节参考<a href=\"https://www.geeksforgeeks.org/introduction-of-b-tree/\" target=\"_blank\" rel=\"noopener\">b+ tree</a></p>\n","site":{"data":{}},"excerpt":"<p>在YouTube上有个视频将<a href=\"https://www.youtube.com/watch?v=aZjYr87r1b8\" target=\"_blank\" rel=\"noopener\">B树</a>深入浅出讲的十分透彻，简单整理笔记如下。</p>","more":"<h2 id=\"disk-structure\"><a href=\"#disk-structure\" class=\"headerlink\" title=\"disk structure\"></a>disk structure</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71506681-e8a03e80-28bc-11ea-862d-8e6d7f10eb07.png\" alt=\"image\"></p>\n<p>机械磁盘的物理架构，是由多个盘面、中心柱和机械臂组成的。中心柱串起多个盘面，每个盘面上都有机械臂靠伸入、伸出以及旋转盘面实现对整个盘面的访问。盘面的track，指的是一条圆形轨道，盘面有大大小小的多个track。盘面的sector，指的是一个最小单位的扇形面积，所有sector构成了盘面这个圆。track no和sector no唯一标识一个block，它是磁盘分配的最小单位。假设我们要写10条记录到硬盘，他们背后就是写在一系列block。</p>\n<h2 id=\"indexing\"><a href=\"#indexing\" class=\"headerlink\" title=\"indexing\"></a>indexing</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71506950-d07cef00-28bd-11ea-8ed2-0f5ae150eabd.png\" alt=\"image\"></p>\n<p>假设我们在磁盘存储了100个记录，每次要找指定id的记录我们都得从头扫描，代价非常昂贵。其实可以把间隔10个记录存索引，如把指向1、10、20等的地址信息存到索引文件，每次查询指定id记录时先加载索引文件，然后根据地址信息再去扫描实际数据记录。这就是indexing的思想。</p>\n<h2 id=\"multi-indexing和m-way-search-tree\"><a href=\"#multi-indexing和m-way-search-tree\" class=\"headerlink\" title=\"multi-indexing和m-way search tree\"></a>multi-indexing和m-way search tree</h2><p>假设磁盘的记录是1W、10W和100W个呢？这时上述的索引文件将非常庞大，必须在索引文件之上再建索引，再建一层索引可能还是太大难以一次load到内存，重复这个动作直至最上面一层的索引文件足够小。这就叫multi-indexing，即多层索引。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71510392-b9dc9500-28c9-11ea-9518-7e4e92b12e49.png\" alt=\"image\"></p>\n<p>把上面的多层索引竖着拎起来，它就是一颗m-way search tree。查找记录时一层层索引往下找，直到到达最底下一层的实际记录层。索引的组织之所以不用binary-search tree，是因为同等节点存储在binary-search tree的深度更深，而每向下一层都涉及到磁盘读I/O，读I/O次数较m-tree要多的多。m-way search tree虽然一次读了较多数据到内存，到它减少了较重的I/O操作，也是一种空间（主存）换时间的思想。</p>\n<h2 id=\"b-tree\"><a href=\"#b-tree\" class=\"headerlink\" title=\"b-tree\"></a>b-tree</h2><p>上面的记录在实际工程中，是存储在数据库的。b-tree其实就是数据库规定的一种m-way search tree语法，通过规定该语法实现了索引结构的增、删、改自维护，它的目的是使得m-way search tree能自适应。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71511235-8f400b80-28cc-11ea-9171-ee6ccefb264f.png\" alt=\"image\"></p>\n<p>b-tree有以下规定：</p>\n<ul>\n<li>每个节点最多有m个孩子，根节点（非叶子）至少有2个孩子，其他非叶子节点至少有Ceil(m/2)个孩子</li>\n<li>所有叶子节点都在同一层</li>\n<li>每个节点包含n个关键字信息（真实记录数据），关键字的个数n满足ceil(m/2)-1 &lt;= n &lt;= m-1，且关键字呈升序排序，即关键字k1 &lt; k2 &lt; … &lt; ki &lt; kn</li>\n<li>每个非叶子节点有n+1个指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于关键字k(i-1)</li>\n</ul>\n<p>更多b-tree细节见<a href=\"https://www.geeksforgeeks.org/introduction-of-b-tree-2/\" target=\"_blank\" rel=\"noopener\">b-tree</a>。</p>\n<h2 id=\"b-tree-1\"><a href=\"#b-tree-1\" class=\"headerlink\" title=\"b+ tree\"></a>b+ tree</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71511550-bfd47500-28cd-11ea-90aa-c8589680301f.png\" alt=\"image\"></p>\n<p>b-tree的特点是所有数据都存储在节点上。假设我们要发起一个数据库的全表扫描，b-tree的结构将会导致不断上下回溯索引，正因此才有了b+ tree。它和b-tree的不同在于：</p>\n<ul>\n<li>非叶子节点只存储指针索引信息，不存真实数据</li>\n<li>真实数据记录都存放在叶子节点中</li>\n<li>所有叶子节点之间都有一个链指针以便于顺序查找</li>\n</ul>\n<p>更多细节参考<a href=\"https://www.geeksforgeeks.org/introduction-of-b-tree/\" target=\"_blank\" rel=\"noopener\">b+ tree</a></p>"},{"title":"【实战笔记】一个通用方法团灭6道股票问题","date":"2019-12-27T14:29:43.000Z","comments":1,"_content":"\n强烈建议阅读原文：[一个通用方法团灭6道股票问题](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/solution/yi-ge-tong-yong-fang-fa-tuan-mie-6-dao-gu-piao-wen/)。受益于这篇文章的启发，团灭了6道股票问题，下面将我自己的理解整理如下。\n\n<!--more-->\n\n解动态规划类问题有两个套路：一是先定义清楚状态 ，二是定义出状态转移方程。\n\n这6道问题，我们可以抽象出这些状态：第i天的股票价格、最多的交易次数k、每天可能买入或卖出也可能什么都不做的行为j。将行为j进行简化，把它定义成当天持有股票、不持有股票两种状态。我们可以得到以下状态定义：\n```python\n# 状态定义：dp[i][k][1 or 0]\ni表示第i天，0 <= i <= n-1\nk表示第k天，1 <= k <= K，假设在buy时k才加1（你也可以定义在sell时才加1）\n1表示当天持有者股票，0表示当天不持有\n\ndp[i][k][1 or 0]表示第i天交易k次持有或不持有股票的最大利益\n\n最终要求的其实就是dp[i][k][0]（最后一天抛售完股票利益最大化）\n```\n\n进一步递推状态方程，可以如下描述：\n```python\n# 转移方程：\ndp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n              max(昨天就没持有, 昨天持有今天卖出)\ndp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n              max(昨天就持有, 昨天没有今天买入)\n\n在实际编程中，要注意dp[i][k][1 or 0]中的i不能为-1，k不能为0，此为边界条件。按照常识不难得出以下结论：\ndp[0][k][0] = 0 # 第0天不持有股票，无盈亏，最大利益为0\ndp[0][k][1] = 0 - prices[0] # 第0天买入股票，最大利益为负的prices[0]\n```\n\n下面按照上述的递推方程来团灭6道股票问题，代码中含有详尽的日志说明。\n\n[股票问题1](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k = 1（dp[i-1][0][0]为0，k都为1可舍去）\n        # dp[i][1][0] = max(dp[i-1][1][0], dp[i-1][1][1]+prices[i])\n        # dp[i][1][1] = max(dp[i-1][1][1], dp[i-1][0][0]-prices[i])\n        #\n        # dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n        # dp[i][1] = max(dp[i-1][1], -prices[i])\n        if len(prices) < 2:\n            return 0\n        dp = [[0] * 2 for _ in range(len(prices))]\n        dp[0][0] = 0\n        dp[0][1] = 0 - prices[0]\n        for i in range(1, len(prices)):\n            dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n            dp[i][1] = max(dp[i-1][1], -prices[i])\n        return dp[-1][0]\n```\n\n[股票问题2](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        #\n        # k这个状态可摘去，目标是求最大化利益，对k值取多少无要求\n        # dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        if len(prices) < 2:\n            return 0\n        dp = [[0] * 2 for _ in range(len(prices))]\n        dp[0][0] = 0\n        dp[0][1] = 0 - prices[0]\n        for i in range(1, len(prices)):\n            dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n            dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        return dp[-1][0]\n```\n\n[股票问题3](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k = 2\n        if len(prices) < 2:\n            return 0\n        max_k = 2 + 1\n        # 这样定义多维数组有坑啊，[0] * 2为一个list，后面的乘法都是乘的引用数...\n        # dp = [[[0] * 2] * max_k] * len(prices)\n        dp = [[[0] * 2 for _ in range(max_k)] for _ in range(len(prices))]\n        print(dp)\n        for k in range(1, max_k):\n            dp[0][k][0] = 0\n            dp[0][k][1] = 0 - prices[0]\n            for i in range(1, len(prices)):\n                dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n                dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        return dp[-1][-1][0]\n```\n\n[股票问题4](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iv/)\n```python\nclass Solution(object):\n    def maxProfit(self, k, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k = 2\n        if len(prices) < 2:\n            return 0\n        # 等同于k不限次数的情况\n        if k > len(prices) / 2: \n            dp = [[0] * 2 for _ in range(len(prices))]\n            dp[0][0] = 0\n            dp[0][1] = 0 - prices[0]\n            for i in range(1, len(prices)):\n                dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n                dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n            return dp[-1][0]\n        max_k = k + 1\n        # 这样定义多维数组有坑啊，[0] * 2为一个list，后面的乘法都是乘的引用数...\n        # dp = [[[0] * 2] * max_k] * len(prices)\n        dp = [[[0] * 2 for _ in range(max_k)] for _ in range(len(prices))]\n        for _k in range(1, max_k):\n            dp[0][_k][0] = 0\n            dp[0][_k][1] = 0 - prices[0]\n            for i in range(1, len(prices)):\n                dp[i][_k][0] = max(dp[i-1][_k][0], dp[i-1][_k][1]+prices[i])\n                dp[i][_k][1] = max(dp[i-1][_k][1], dp[i-1][_k-1][0]-prices[i])\n        return dp[-1][-1][0]\n```\n\n[股票问题含手续费](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices, fee):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k这个状态可摘去，目标是求最大化利益，对k值取多少无要求\n        # dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # \n        # 新增的限定条件为卖出股票时需要给手续费\n        # dp[i][k][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]-fee)\n        if len(prices) < 2:\n            return 0\n        dp = [[0] * 2 for _ in range(len(prices))]\n        dp[0][0] = 0\n        dp[0][1] = 0 - prices[0]\n        for i in range(1, len(prices)):\n            dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]-fee)\n            dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        return dp[-1][0]\n```\n\n[股票问题含冻结时间](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k这个状态可摘去，目标是求最大化利益，对k值取多少无要求\n        # dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # \n        # 新增的限定条件为卖出股票后无法在第二天买入，更新转移方程\n        # dp[i][k][1] = max(dp[i-1][1], dp[i-2][0]-prices[i])\n        if len(prices) < 2:\n            return 0\n        dp = [[0] * 2 for _ in range(len(prices))]\n        dp[0][0] = 0\n        dp[0][1] = 0 - prices[0]\n        for i in range(1, len(prices)):\n            dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n            dp[i][1] = max(dp[i-1][1], dp[i-2][0]-prices[i]) # i-2表示隔天交易\n        return dp[-1][0]\n```","source":"_posts/2019-12-27-stock-dp.md","raw":"---\ntitle: 【实战笔记】一个通用方法团灭6道股票问题\ndate: 2019-12-27 22:29:43\ntags: ['Algorithm', '动态规划']\ncomments: true\ncategories: ['算法']\n---\n\n强烈建议阅读原文：[一个通用方法团灭6道股票问题](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/solution/yi-ge-tong-yong-fang-fa-tuan-mie-6-dao-gu-piao-wen/)。受益于这篇文章的启发，团灭了6道股票问题，下面将我自己的理解整理如下。\n\n<!--more-->\n\n解动态规划类问题有两个套路：一是先定义清楚状态 ，二是定义出状态转移方程。\n\n这6道问题，我们可以抽象出这些状态：第i天的股票价格、最多的交易次数k、每天可能买入或卖出也可能什么都不做的行为j。将行为j进行简化，把它定义成当天持有股票、不持有股票两种状态。我们可以得到以下状态定义：\n```python\n# 状态定义：dp[i][k][1 or 0]\ni表示第i天，0 <= i <= n-1\nk表示第k天，1 <= k <= K，假设在buy时k才加1（你也可以定义在sell时才加1）\n1表示当天持有者股票，0表示当天不持有\n\ndp[i][k][1 or 0]表示第i天交易k次持有或不持有股票的最大利益\n\n最终要求的其实就是dp[i][k][0]（最后一天抛售完股票利益最大化）\n```\n\n进一步递推状态方程，可以如下描述：\n```python\n# 转移方程：\ndp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n              max(昨天就没持有, 昨天持有今天卖出)\ndp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n              max(昨天就持有, 昨天没有今天买入)\n\n在实际编程中，要注意dp[i][k][1 or 0]中的i不能为-1，k不能为0，此为边界条件。按照常识不难得出以下结论：\ndp[0][k][0] = 0 # 第0天不持有股票，无盈亏，最大利益为0\ndp[0][k][1] = 0 - prices[0] # 第0天买入股票，最大利益为负的prices[0]\n```\n\n下面按照上述的递推方程来团灭6道股票问题，代码中含有详尽的日志说明。\n\n[股票问题1](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k = 1（dp[i-1][0][0]为0，k都为1可舍去）\n        # dp[i][1][0] = max(dp[i-1][1][0], dp[i-1][1][1]+prices[i])\n        # dp[i][1][1] = max(dp[i-1][1][1], dp[i-1][0][0]-prices[i])\n        #\n        # dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n        # dp[i][1] = max(dp[i-1][1], -prices[i])\n        if len(prices) < 2:\n            return 0\n        dp = [[0] * 2 for _ in range(len(prices))]\n        dp[0][0] = 0\n        dp[0][1] = 0 - prices[0]\n        for i in range(1, len(prices)):\n            dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n            dp[i][1] = max(dp[i-1][1], -prices[i])\n        return dp[-1][0]\n```\n\n[股票问题2](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        #\n        # k这个状态可摘去，目标是求最大化利益，对k值取多少无要求\n        # dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        if len(prices) < 2:\n            return 0\n        dp = [[0] * 2 for _ in range(len(prices))]\n        dp[0][0] = 0\n        dp[0][1] = 0 - prices[0]\n        for i in range(1, len(prices)):\n            dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n            dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        return dp[-1][0]\n```\n\n[股票问题3](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k = 2\n        if len(prices) < 2:\n            return 0\n        max_k = 2 + 1\n        # 这样定义多维数组有坑啊，[0] * 2为一个list，后面的乘法都是乘的引用数...\n        # dp = [[[0] * 2] * max_k] * len(prices)\n        dp = [[[0] * 2 for _ in range(max_k)] for _ in range(len(prices))]\n        print(dp)\n        for k in range(1, max_k):\n            dp[0][k][0] = 0\n            dp[0][k][1] = 0 - prices[0]\n            for i in range(1, len(prices)):\n                dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n                dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        return dp[-1][-1][0]\n```\n\n[股票问题4](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iv/)\n```python\nclass Solution(object):\n    def maxProfit(self, k, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k = 2\n        if len(prices) < 2:\n            return 0\n        # 等同于k不限次数的情况\n        if k > len(prices) / 2: \n            dp = [[0] * 2 for _ in range(len(prices))]\n            dp[0][0] = 0\n            dp[0][1] = 0 - prices[0]\n            for i in range(1, len(prices)):\n                dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n                dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n            return dp[-1][0]\n        max_k = k + 1\n        # 这样定义多维数组有坑啊，[0] * 2为一个list，后面的乘法都是乘的引用数...\n        # dp = [[[0] * 2] * max_k] * len(prices)\n        dp = [[[0] * 2 for _ in range(max_k)] for _ in range(len(prices))]\n        for _k in range(1, max_k):\n            dp[0][_k][0] = 0\n            dp[0][_k][1] = 0 - prices[0]\n            for i in range(1, len(prices)):\n                dp[i][_k][0] = max(dp[i-1][_k][0], dp[i-1][_k][1]+prices[i])\n                dp[i][_k][1] = max(dp[i-1][_k][1], dp[i-1][_k-1][0]-prices[i])\n        return dp[-1][-1][0]\n```\n\n[股票问题含手续费](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices, fee):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k这个状态可摘去，目标是求最大化利益，对k值取多少无要求\n        # dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # \n        # 新增的限定条件为卖出股票时需要给手续费\n        # dp[i][k][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]-fee)\n        if len(prices) < 2:\n            return 0\n        dp = [[0] * 2 for _ in range(len(prices))]\n        dp[0][0] = 0\n        dp[0][1] = 0 - prices[0]\n        for i in range(1, len(prices)):\n            dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]-fee)\n            dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        return dp[-1][0]\n```\n\n[股票问题含冻结时间](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/)\n```python\nclass Solution(object):\n    def maxProfit(self, prices):\n        \"\"\"\n        :type prices: List[int]\n        :rtype: int\n        \"\"\"\n        # 状态定义：dp[i][k][1 or 0]\n        # i表示第i天，0 <= i <= n-1\n        # k表示第k天，1 <= k <= K，假设在buy时k才加1\n        # 1表示当天持有者股票，0表示当天不持有\n        # 转移方程：\n        # dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # 边界：i为-1，k为0\n        # dp[-1][k][0] = dp[i][0][0] = 0\n        # dp[-1][k][1] = dp[i][0][1] = -infinite\n        #\n        # k这个状态可摘去，目标是求最大化利益，对k值取多少无要求\n        # dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n        #               max(昨天就没持有, 昨天持有今天卖出)\n        # dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])\n        #               max(昨天就持有, 昨天没有今天买入)\n        # \n        # 新增的限定条件为卖出股票后无法在第二天买入，更新转移方程\n        # dp[i][k][1] = max(dp[i-1][1], dp[i-2][0]-prices[i])\n        if len(prices) < 2:\n            return 0\n        dp = [[0] * 2 for _ in range(len(prices))]\n        dp[0][0] = 0\n        dp[0][1] = 0 - prices[0]\n        for i in range(1, len(prices)):\n            dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])\n            dp[i][1] = max(dp[i-1][1], dp[i-2][0]-prices[i]) # i-2表示隔天交易\n        return dp[-1][0]\n```","slug":"stock-dp","published":1,"updated":"2022-08-09T15:02:00.659Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14o003ligu8mr8fwgs4","content":"<p>强烈建议阅读原文：<a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/solution/yi-ge-tong-yong-fang-fa-tuan-mie-6-dao-gu-piao-wen/\" target=\"_blank\" rel=\"noopener\">一个通用方法团灭6道股票问题</a>。受益于这篇文章的启发，团灭了6道股票问题，下面将我自己的理解整理如下。</p>\n<a id=\"more\"></a>\n<p>解动态规划类问题有两个套路：一是先定义清楚状态 ，二是定义出状态转移方程。</p>\n<p>这6道问题，我们可以抽象出这些状态：第i天的股票价格、最多的交易次数k、每天可能买入或卖出也可能什么都不做的行为j。将行为j进行简化，把它定义成当天持有股票、不持有股票两种状态。我们可以得到以下状态定义：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">i表示第i天，<span class=\"number\">0</span> &lt;= i &lt;= n<span class=\"number\">-1</span></span><br><span class=\"line\">k表示第k天，<span class=\"number\">1</span> &lt;= k &lt;= K，假设在buy时k才加<span class=\"number\">1</span>（你也可以定义在sell时才加<span class=\"number\">1</span>）</span><br><span class=\"line\"><span class=\"number\">1</span>表示当天持有者股票，<span class=\"number\">0</span>表示当天不持有</span><br><span class=\"line\"></span><br><span class=\"line\">dp[i][k][<span class=\"number\">1</span> <span class=\"keyword\">or</span> <span class=\"number\">0</span>]表示第i天交易k次持有或不持有股票的最大利益</span><br><span class=\"line\"></span><br><span class=\"line\">最终要求的其实就是dp[i][k][<span class=\"number\">0</span>]（最后一天抛售完股票利益最大化）</span><br></pre></td></tr></table></figure></p>\n<p>进一步递推状态方程，可以如下描述：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">dp[i][k][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">              max(昨天就没持有, 昨天持有今天卖出)</span><br><span class=\"line\">dp[i][k][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][k<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">              max(昨天就持有, 昨天没有今天买入)</span><br><span class=\"line\"></span><br><span class=\"line\">在实际编程中，要注意dp[i][k][<span class=\"number\">1</span> <span class=\"keyword\">or</span> <span class=\"number\">0</span>]中的i不能为<span class=\"number\">-1</span>，k不能为<span class=\"number\">0</span>，此为边界条件。按照常识不难得出以下结论：</span><br><span class=\"line\">dp[<span class=\"number\">0</span>][k][<span class=\"number\">0</span>] = <span class=\"number\">0</span> <span class=\"comment\"># 第0天不持有股票，无盈亏，最大利益为0</span></span><br><span class=\"line\">dp[<span class=\"number\">0</span>][k][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>] <span class=\"comment\"># 第0天买入股票，最大利益为负的prices[0]</span></span><br></pre></td></tr></table></figure></p>\n<p>下面按照上述的递推方程来团灭6道股票问题，代码中含有详尽的日志说明。</p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/\" target=\"_blank\" rel=\"noopener\">股票问题1</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k = 1（dp[i-1][0][0]为0，k都为1可舍去）</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1][0] = max(dp[i-1][1][0], dp[i-1][1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1][1] = max(dp[i-1][1][1], dp[i-1][0][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1] = max(dp[i-1][1], -prices[i])</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">            dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">            dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], -prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/\" target=\"_blank\" rel=\"noopener\">股票问题2</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k这个状态可摘去，目标是求最大化利益，对k值取多少无要求</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">            dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">            dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/\" target=\"_blank\" rel=\"noopener\">股票问题3</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k = 2</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        max_k = <span class=\"number\">2</span> + <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># 这样定义多维数组有坑啊，[0] * 2为一个list，后面的乘法都是乘的引用数...</span></span><br><span class=\"line\">        <span class=\"comment\"># dp = [[[0] * 2] * max_k] * len(prices)</span></span><br><span class=\"line\">        dp = [[[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(max_k)] <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        print(dp)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, max_k):</span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][k][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][k][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">                dp[i][k][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">                dp[i][k][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][k<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iv/\" target=\"_blank\" rel=\"noopener\">股票问题4</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, k, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k = 2</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"comment\"># 等同于k不限次数的情况</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> k &gt; len(prices) / <span class=\"number\">2</span>: </span><br><span class=\"line\">            dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">                dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">                dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">            <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">        max_k = k + <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># 这样定义多维数组有坑啊，[0] * 2为一个list，后面的乘法都是乘的引用数...</span></span><br><span class=\"line\">        <span class=\"comment\"># dp = [[[0] * 2] * max_k] * len(prices)</span></span><br><span class=\"line\">        dp = [[[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(max_k)] <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> _k <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, max_k):</span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][_k][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][_k][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">                dp[i][_k][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][_k][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][_k][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">                dp[i][_k][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][_k][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][_k<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/\" target=\"_blank\" rel=\"noopener\">股票问题含手续费</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices, fee)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k这个状态可摘去，目标是求最大化利益，对k值取多少无要求</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"comment\"># 新增的限定条件为卖出股票时需要给手续费</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]-fee)</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">            dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i]-fee)</span><br><span class=\"line\">            dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/\" target=\"_blank\" rel=\"noopener\">股票问题含冻结时间</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k这个状态可摘去，目标是求最大化利益，对k值取多少无要求</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"comment\"># 新增的限定条件为卖出股票后无法在第二天买入，更新转移方程</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][1], dp[i-2][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">            dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">            dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], dp[i<span class=\"number\">-2</span>][<span class=\"number\">0</span>]-prices[i]) <span class=\"comment\"># i-2表示隔天交易</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>强烈建议阅读原文：<a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/solution/yi-ge-tong-yong-fang-fa-tuan-mie-6-dao-gu-piao-wen/\" target=\"_blank\" rel=\"noopener\">一个通用方法团灭6道股票问题</a>。受益于这篇文章的启发，团灭了6道股票问题，下面将我自己的理解整理如下。</p>","more":"<p>解动态规划类问题有两个套路：一是先定义清楚状态 ，二是定义出状态转移方程。</p>\n<p>这6道问题，我们可以抽象出这些状态：第i天的股票价格、最多的交易次数k、每天可能买入或卖出也可能什么都不做的行为j。将行为j进行简化，把它定义成当天持有股票、不持有股票两种状态。我们可以得到以下状态定义：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">i表示第i天，<span class=\"number\">0</span> &lt;= i &lt;= n<span class=\"number\">-1</span></span><br><span class=\"line\">k表示第k天，<span class=\"number\">1</span> &lt;= k &lt;= K，假设在buy时k才加<span class=\"number\">1</span>（你也可以定义在sell时才加<span class=\"number\">1</span>）</span><br><span class=\"line\"><span class=\"number\">1</span>表示当天持有者股票，<span class=\"number\">0</span>表示当天不持有</span><br><span class=\"line\"></span><br><span class=\"line\">dp[i][k][<span class=\"number\">1</span> <span class=\"keyword\">or</span> <span class=\"number\">0</span>]表示第i天交易k次持有或不持有股票的最大利益</span><br><span class=\"line\"></span><br><span class=\"line\">最终要求的其实就是dp[i][k][<span class=\"number\">0</span>]（最后一天抛售完股票利益最大化）</span><br></pre></td></tr></table></figure></p>\n<p>进一步递推状态方程，可以如下描述：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">dp[i][k][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">              max(昨天就没持有, 昨天持有今天卖出)</span><br><span class=\"line\">dp[i][k][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][k<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">              max(昨天就持有, 昨天没有今天买入)</span><br><span class=\"line\"></span><br><span class=\"line\">在实际编程中，要注意dp[i][k][<span class=\"number\">1</span> <span class=\"keyword\">or</span> <span class=\"number\">0</span>]中的i不能为<span class=\"number\">-1</span>，k不能为<span class=\"number\">0</span>，此为边界条件。按照常识不难得出以下结论：</span><br><span class=\"line\">dp[<span class=\"number\">0</span>][k][<span class=\"number\">0</span>] = <span class=\"number\">0</span> <span class=\"comment\"># 第0天不持有股票，无盈亏，最大利益为0</span></span><br><span class=\"line\">dp[<span class=\"number\">0</span>][k][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>] <span class=\"comment\"># 第0天买入股票，最大利益为负的prices[0]</span></span><br></pre></td></tr></table></figure></p>\n<p>下面按照上述的递推方程来团灭6道股票问题，代码中含有详尽的日志说明。</p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/\" target=\"_blank\" rel=\"noopener\">股票问题1</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k = 1（dp[i-1][0][0]为0，k都为1可舍去）</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1][0] = max(dp[i-1][1][0], dp[i-1][1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1][1] = max(dp[i-1][1][1], dp[i-1][0][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1] = max(dp[i-1][1], -prices[i])</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">            dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">            dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], -prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/\" target=\"_blank\" rel=\"noopener\">股票问题2</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k这个状态可摘去，目标是求最大化利益，对k值取多少无要求</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">            dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">            dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/\" target=\"_blank\" rel=\"noopener\">股票问题3</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k = 2</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        max_k = <span class=\"number\">2</span> + <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># 这样定义多维数组有坑啊，[0] * 2为一个list，后面的乘法都是乘的引用数...</span></span><br><span class=\"line\">        <span class=\"comment\"># dp = [[[0] * 2] * max_k] * len(prices)</span></span><br><span class=\"line\">        dp = [[[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(max_k)] <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        print(dp)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, max_k):</span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][k][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][k][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">                dp[i][k][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">                dp[i][k][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][k][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][k<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iv/\" target=\"_blank\" rel=\"noopener\">股票问题4</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, k, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k = 2</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"comment\"># 等同于k不限次数的情况</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> k &gt; len(prices) / <span class=\"number\">2</span>: </span><br><span class=\"line\">            dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">                dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">                dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">            <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">        max_k = k + <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># 这样定义多维数组有坑啊，[0] * 2为一个list，后面的乘法都是乘的引用数...</span></span><br><span class=\"line\">        <span class=\"comment\"># dp = [[[0] * 2] * max_k] * len(prices)</span></span><br><span class=\"line\">        dp = [[[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(max_k)] <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> _k <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, max_k):</span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][_k][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">            dp[<span class=\"number\">0</span>][_k][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">                dp[i][_k][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][_k][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][_k][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">                dp[i][_k][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][_k][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][_k<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/\" target=\"_blank\" rel=\"noopener\">股票问题含手续费</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices, fee)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k这个状态可摘去，目标是求最大化利益，对k值取多少无要求</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"comment\"># 新增的限定条件为卖出股票时需要给手续费</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]-fee)</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">            dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i]-fee)</span><br><span class=\"line\">            dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>]-prices[i])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/\" target=\"_blank\" rel=\"noopener\">股票问题含冻结时间</a><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">maxProfit</span><span class=\"params\">(self, prices)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        :type prices: List[int]</span></span><br><span class=\"line\"><span class=\"string\">        :rtype: int</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 状态定义：dp[i][k][1 or 0]</span></span><br><span class=\"line\">        <span class=\"comment\"># i表示第i天，0 &lt;= i &lt;= n-1</span></span><br><span class=\"line\">        <span class=\"comment\"># k表示第k天，1 &lt;= k &lt;= K，假设在buy时k才加1</span></span><br><span class=\"line\">        <span class=\"comment\"># 1表示当天持有者股票，0表示当天不持有</span></span><br><span class=\"line\">        <span class=\"comment\"># 转移方程：</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># 边界：i为-1，k为0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][0] = dp[i][0][0] = 0</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[-1][k][1] = dp[i][0][1] = -infinite</span></span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        <span class=\"comment\"># k这个状态可摘去，目标是求最大化利益，对k值取多少无要求</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就没持有, 昨天持有今天卖出)</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"comment\">#               max(昨天就持有, 昨天没有今天买入)</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"comment\"># 新增的限定条件为卖出股票后无法在第二天买入，更新转移方程</span></span><br><span class=\"line\">        <span class=\"comment\"># dp[i][k][1] = max(dp[i-1][1], dp[i-2][0]-prices[i])</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(prices) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">        dp = [[<span class=\"number\">0</span>] * <span class=\"number\">2</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(len(prices))]</span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">        dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = <span class=\"number\">0</span> - prices[<span class=\"number\">0</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, len(prices)):</span><br><span class=\"line\">            dp[i][<span class=\"number\">0</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">0</span>], dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>]+prices[i])</span><br><span class=\"line\">            dp[i][<span class=\"number\">1</span>] = max(dp[i<span class=\"number\">-1</span>][<span class=\"number\">1</span>], dp[i<span class=\"number\">-2</span>][<span class=\"number\">0</span>]-prices[i]) <span class=\"comment\"># i-2表示隔天交易</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">-1</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></p>"},{"title":"MySQL基础回顾 | 表连接与Group By","date":"2018-09-13T12:00:03.000Z","comments":1,"_content":"\nMySQL基础回顾第一篇，回顾4种表连接的含义、与笛卡尔积的区别以及group by的用途。\n\n<!-- more -->\n\n## 表连接\n\nUser表信息如下：\n\nuserid|username|orgid\n---|---|---\n1|jay|10\n2|tom|11\n3|shelly|12\n\nOrg表信息如下：\n\norgid|orgname\n---|---\n10|gdut\n12|gzut\n15|skj\n\n### 表连接语法\n\n表连接的语法为：`A [left|right|inner|full] join B on A.x = B.y`。`[]`内的选项4选一，不填写时默认表示表示`inner`。4个选项的含义如下：\n\n- inner：内连接\n- left：左连接\n- right：右连接\n- full：全连接\n\n### 表连接解释\n\n下图为表连接的文氏图表示，中间蓝色部分表示`A.x = B.y`的A表与B表的行记录，即A的x字段与B的y字段相等，x与y称为连接字段。习惯上，我们把join左边的表称为左表，其右边的表称为右表，在本例中A是左表，B是右表。\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431479-0dee4a80-270d-11ea-8bdd-da043078410d.png)\n\n对于join，可以理解为把A的所有列和B的所有列并在一起。以上面的表格为例，A表和B表的列并在一起变成了：\n\nuserid|username|orgid(user表)|orgid(org表)|orgname\n---|---|---|---|---\n\n此时由于orgid字段重名，我们需通过select挑出需要的字段。以上面的表格为例，可编写SQL如下挑出所需字段：\n\n```\nSELECT u.userid, u.username, u.orgid, o.orgname FROM user u join org o ON u.orgid = o.orgid\n```\n\nleft join时，A表（左表）的所有行原封不动的保留，B表（右表）的行保留情况如下，\n\n- 上午文氏图的蓝色部分：B表的所有行原封不动的保留；\n- 上午文氏图的右白色部分：B表的所有行的值全部显示为NULL；\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n2|tom|11|NULL\n3|shelly|12|gzut\n\nright join时，与right join刚好相反，B表（右表）的所有行原封不动的保留，A表（左表）仅有与B表orgid重叠的行原封不动的保留。\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n3|shelly|12|gzut\nNULL|NULL|15|skj\n\ninner join，仅保留A表与B表orgid重叠的行。\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n3|shelly|12|gzut\n\nfull join，用集合运算可理解为`(left join) + (right join) - (inner join)`。\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n2|tom|11|NULL\n3|shelly|12|gzut\nNULL|NULL|15|skj\n\n## 笛卡尔积Cross Join\n\n这是一种特殊的Join，以上文的user表cross join org表为例，全连接SQL如下：\n\n```\nSELECT \n    u.userid,\n    u.username,\n    u.orgid,\n    o.orgname\nFROM\n    user u cross join org o -- 注：cross join可用逗号表示\n```\n\n得到的结果如下：\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n1|jay|10|gzut\n1|jay|10|skj\n2|tom|11|gdut\n2|tom|11|gzut\n2|tom|11|skj\n3|shelly|12|gdut\n3|shelly|12|gzut\n3|shelly|12|skj\n\n也就说，在cross join不设定where条件的情况下，得到的结果是一个笛卡尔积，总行数等于左表的行数乘以B表的行数。在指定where条件的情况下，下文的SQL等同于inner join。\n\n```\nSELECT \n    u.userid,\n    u.username,\n    u.orgid,\n    o.orgname\nFROM\n    user u, org o -- 注：cross join可用逗号表示\nWHERE\n    u.orgid = o.orgid\n```\n\n## group by\n\n`group by`的语义是把行进行分组，如：\n\n```\nSELECT \n    u.userid,\n    u.username,\n    u.orgid,\n    o.orgname\nFROM\n    user u cross join org o\nGROUP BY u.userid\n```\n\n以上SQL，会把userid相同的分成一个组，然后仅保留组内的第一条记录，得到的结果为：\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n2|tom|11|gdut\n3|shelly|12|gdut\n\n基于`group by`分组的特性，一般其会配置聚合函数使用，如count()和avg()等函数。修改SQL如下：\n\n```\nSELECT \n    u.userid, count(*)\nFROM\n    user u cross join org o\nGROUP BY u.userid\n```\n\n将得到结果：\n\nuserid|count\n---|---\n1|3\n2|3\n3|3\n\n`group by`后跟一个字段，表示一维分组，如果跟两个字段则为二维分组，三个字段及以上以此类推。以二重`group by`为例，`group by a, b`可以通俗的理解为：**所有a字段值相同，同时b字段值相同的行，会被分到同一组**。\n","source":"_posts/2018-09-13-basic-concept-of-mysql-1.md","raw":"---\ntitle: MySQL基础回顾 | 表连接与Group By\ndate: 2018-09-13 20:00:03\ntags: 'MySQL'\ncomments: true\ncategories: ['数据库']\n---\n\nMySQL基础回顾第一篇，回顾4种表连接的含义、与笛卡尔积的区别以及group by的用途。\n\n<!-- more -->\n\n## 表连接\n\nUser表信息如下：\n\nuserid|username|orgid\n---|---|---\n1|jay|10\n2|tom|11\n3|shelly|12\n\nOrg表信息如下：\n\norgid|orgname\n---|---\n10|gdut\n12|gzut\n15|skj\n\n### 表连接语法\n\n表连接的语法为：`A [left|right|inner|full] join B on A.x = B.y`。`[]`内的选项4选一，不填写时默认表示表示`inner`。4个选项的含义如下：\n\n- inner：内连接\n- left：左连接\n- right：右连接\n- full：全连接\n\n### 表连接解释\n\n下图为表连接的文氏图表示，中间蓝色部分表示`A.x = B.y`的A表与B表的行记录，即A的x字段与B的y字段相等，x与y称为连接字段。习惯上，我们把join左边的表称为左表，其右边的表称为右表，在本例中A是左表，B是右表。\n\n![image.png](https://user-images.githubusercontent.com/4915189/71431479-0dee4a80-270d-11ea-8bdd-da043078410d.png)\n\n对于join，可以理解为把A的所有列和B的所有列并在一起。以上面的表格为例，A表和B表的列并在一起变成了：\n\nuserid|username|orgid(user表)|orgid(org表)|orgname\n---|---|---|---|---\n\n此时由于orgid字段重名，我们需通过select挑出需要的字段。以上面的表格为例，可编写SQL如下挑出所需字段：\n\n```\nSELECT u.userid, u.username, u.orgid, o.orgname FROM user u join org o ON u.orgid = o.orgid\n```\n\nleft join时，A表（左表）的所有行原封不动的保留，B表（右表）的行保留情况如下，\n\n- 上午文氏图的蓝色部分：B表的所有行原封不动的保留；\n- 上午文氏图的右白色部分：B表的所有行的值全部显示为NULL；\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n2|tom|11|NULL\n3|shelly|12|gzut\n\nright join时，与right join刚好相反，B表（右表）的所有行原封不动的保留，A表（左表）仅有与B表orgid重叠的行原封不动的保留。\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n3|shelly|12|gzut\nNULL|NULL|15|skj\n\ninner join，仅保留A表与B表orgid重叠的行。\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n3|shelly|12|gzut\n\nfull join，用集合运算可理解为`(left join) + (right join) - (inner join)`。\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n2|tom|11|NULL\n3|shelly|12|gzut\nNULL|NULL|15|skj\n\n## 笛卡尔积Cross Join\n\n这是一种特殊的Join，以上文的user表cross join org表为例，全连接SQL如下：\n\n```\nSELECT \n    u.userid,\n    u.username,\n    u.orgid,\n    o.orgname\nFROM\n    user u cross join org o -- 注：cross join可用逗号表示\n```\n\n得到的结果如下：\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n1|jay|10|gzut\n1|jay|10|skj\n2|tom|11|gdut\n2|tom|11|gzut\n2|tom|11|skj\n3|shelly|12|gdut\n3|shelly|12|gzut\n3|shelly|12|skj\n\n也就说，在cross join不设定where条件的情况下，得到的结果是一个笛卡尔积，总行数等于左表的行数乘以B表的行数。在指定where条件的情况下，下文的SQL等同于inner join。\n\n```\nSELECT \n    u.userid,\n    u.username,\n    u.orgid,\n    o.orgname\nFROM\n    user u, org o -- 注：cross join可用逗号表示\nWHERE\n    u.orgid = o.orgid\n```\n\n## group by\n\n`group by`的语义是把行进行分组，如：\n\n```\nSELECT \n    u.userid,\n    u.username,\n    u.orgid,\n    o.orgname\nFROM\n    user u cross join org o\nGROUP BY u.userid\n```\n\n以上SQL，会把userid相同的分成一个组，然后仅保留组内的第一条记录，得到的结果为：\n\nuserid|username|orgid|orgname\n---|---|---|---\n1|jay|10|gdut\n2|tom|11|gdut\n3|shelly|12|gdut\n\n基于`group by`分组的特性，一般其会配置聚合函数使用，如count()和avg()等函数。修改SQL如下：\n\n```\nSELECT \n    u.userid, count(*)\nFROM\n    user u cross join org o\nGROUP BY u.userid\n```\n\n将得到结果：\n\nuserid|count\n---|---\n1|3\n2|3\n3|3\n\n`group by`后跟一个字段，表示一维分组，如果跟两个字段则为二维分组，三个字段及以上以此类推。以二重`group by`为例，`group by a, b`可以通俗的理解为：**所有a字段值相同，同时b字段值相同的行，会被分到同一组**。\n","slug":"basic-concept-of-mysql-1","published":1,"updated":"2022-08-09T15:02:00.642Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14r003qigu8m8s7jfy8","content":"<p>MySQL基础回顾第一篇，回顾4种表连接的含义、与笛卡尔积的区别以及group by的用途。</p>\n<a id=\"more\"></a>\n<h2 id=\"表连接\"><a href=\"#表连接\" class=\"headerlink\" title=\"表连接\"></a>表连接</h2><p>User表信息如下：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n</tr>\n</tbody>\n</table>\n<p>Org表信息如下：</p>\n<table>\n<thead>\n<tr>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>12</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>15</td>\n<td>skj</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"表连接语法\"><a href=\"#表连接语法\" class=\"headerlink\" title=\"表连接语法\"></a>表连接语法</h3><p>表连接的语法为：<code>A [left|right|inner|full] join B on A.x = B.y</code>。<code>[]</code>内的选项4选一，不填写时默认表示表示<code>inner</code>。4个选项的含义如下：</p>\n<ul>\n<li>inner：内连接</li>\n<li>left：左连接</li>\n<li>right：右连接</li>\n<li>full：全连接</li>\n</ul>\n<h3 id=\"表连接解释\"><a href=\"#表连接解释\" class=\"headerlink\" title=\"表连接解释\"></a>表连接解释</h3><p>下图为表连接的文氏图表示，中间蓝色部分表示<code>A.x = B.y</code>的A表与B表的行记录，即A的x字段与B的y字段相等，x与y称为连接字段。习惯上，我们把join左边的表称为左表，其右边的表称为右表，在本例中A是左表，B是右表。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431479-0dee4a80-270d-11ea-8bdd-da043078410d.png\" alt=\"image.png\"></p>\n<p>对于join，可以理解为把A的所有列和B的所有列并在一起。以上面的表格为例，A表和B表的列并在一起变成了：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid(user表)</th>\n<th>orgid(org表)</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>此时由于orgid字段重名，我们需通过select挑出需要的字段。以上面的表格为例，可编写SQL如下挑出所需字段：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT u.userid, u.username, u.orgid, o.orgname FROM user u join org o ON u.orgid = o.orgid</span><br></pre></td></tr></table></figure>\n<p>left join时，A表（左表）的所有行原封不动的保留，B表（右表）的行保留情况如下，</p>\n<ul>\n<li>上午文氏图的蓝色部分：B表的所有行原封不动的保留；</li>\n<li>上午文氏图的右白色部分：B表的所有行的值全部显示为NULL；</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n</tbody>\n</table>\n<p>right join时，与right join刚好相反，B表（右表）的所有行原封不动的保留，A表（左表）仅有与B表orgid重叠的行原封不动的保留。</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>NULL</td>\n<td>NULL</td>\n<td>15</td>\n<td>skj</td>\n</tr>\n</tbody>\n</table>\n<p>inner join，仅保留A表与B表orgid重叠的行。</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n</tbody>\n</table>\n<p>full join，用集合运算可理解为<code>(left join) + (right join) - (inner join)</code>。</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>NULL</td>\n<td>NULL</td>\n<td>15</td>\n<td>skj</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"笛卡尔积Cross-Join\"><a href=\"#笛卡尔积Cross-Join\" class=\"headerlink\" title=\"笛卡尔积Cross Join\"></a>笛卡尔积Cross Join</h2><p>这是一种特殊的Join，以上文的user表cross join org表为例，全连接SQL如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT </span><br><span class=\"line\">    u.userid,</span><br><span class=\"line\">    u.username,</span><br><span class=\"line\">    u.orgid,</span><br><span class=\"line\">    o.orgname</span><br><span class=\"line\">FROM</span><br><span class=\"line\">    user u cross join org o -- 注：cross join可用逗号表示</span><br></pre></td></tr></table></figure>\n<p>得到的结果如下：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>skj</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>skj</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>skj</td>\n</tr>\n</tbody>\n</table>\n<p>也就说，在cross join不设定where条件的情况下，得到的结果是一个笛卡尔积，总行数等于左表的行数乘以B表的行数。在指定where条件的情况下，下文的SQL等同于inner join。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT </span><br><span class=\"line\">    u.userid,</span><br><span class=\"line\">    u.username,</span><br><span class=\"line\">    u.orgid,</span><br><span class=\"line\">    o.orgname</span><br><span class=\"line\">FROM</span><br><span class=\"line\">    user u, org o -- 注：cross join可用逗号表示</span><br><span class=\"line\">WHERE</span><br><span class=\"line\">    u.orgid = o.orgid</span><br></pre></td></tr></table></figure>\n<h2 id=\"group-by\"><a href=\"#group-by\" class=\"headerlink\" title=\"group by\"></a>group by</h2><p><code>group by</code>的语义是把行进行分组，如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT </span><br><span class=\"line\">    u.userid,</span><br><span class=\"line\">    u.username,</span><br><span class=\"line\">    u.orgid,</span><br><span class=\"line\">    o.orgname</span><br><span class=\"line\">FROM</span><br><span class=\"line\">    user u cross join org o</span><br><span class=\"line\">GROUP BY u.userid</span><br></pre></td></tr></table></figure>\n<p>以上SQL，会把userid相同的分成一个组，然后仅保留组内的第一条记录，得到的结果为：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gdut</td>\n</tr>\n</tbody>\n</table>\n<p>基于<code>group by</code>分组的特性，一般其会配置聚合函数使用，如count()和avg()等函数。修改SQL如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT </span><br><span class=\"line\">    u.userid, count(*)</span><br><span class=\"line\">FROM</span><br><span class=\"line\">    user u cross join org o</span><br><span class=\"line\">GROUP BY u.userid</span><br></pre></td></tr></table></figure>\n<p>将得到结果：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>count</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>3</td>\n</tr>\n<tr>\n<td>2</td>\n<td>3</td>\n</tr>\n<tr>\n<td>3</td>\n<td>3</td>\n</tr>\n</tbody>\n</table>\n<p><code>group by</code>后跟一个字段，表示一维分组，如果跟两个字段则为二维分组，三个字段及以上以此类推。以二重<code>group by</code>为例，<code>group by a, b</code>可以通俗的理解为：<strong>所有a字段值相同，同时b字段值相同的行，会被分到同一组</strong>。</p>\n","site":{"data":{}},"excerpt":"<p>MySQL基础回顾第一篇，回顾4种表连接的含义、与笛卡尔积的区别以及group by的用途。</p>","more":"<h2 id=\"表连接\"><a href=\"#表连接\" class=\"headerlink\" title=\"表连接\"></a>表连接</h2><p>User表信息如下：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n</tr>\n</tbody>\n</table>\n<p>Org表信息如下：</p>\n<table>\n<thead>\n<tr>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>12</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>15</td>\n<td>skj</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"表连接语法\"><a href=\"#表连接语法\" class=\"headerlink\" title=\"表连接语法\"></a>表连接语法</h3><p>表连接的语法为：<code>A [left|right|inner|full] join B on A.x = B.y</code>。<code>[]</code>内的选项4选一，不填写时默认表示表示<code>inner</code>。4个选项的含义如下：</p>\n<ul>\n<li>inner：内连接</li>\n<li>left：左连接</li>\n<li>right：右连接</li>\n<li>full：全连接</li>\n</ul>\n<h3 id=\"表连接解释\"><a href=\"#表连接解释\" class=\"headerlink\" title=\"表连接解释\"></a>表连接解释</h3><p>下图为表连接的文氏图表示，中间蓝色部分表示<code>A.x = B.y</code>的A表与B表的行记录，即A的x字段与B的y字段相等，x与y称为连接字段。习惯上，我们把join左边的表称为左表，其右边的表称为右表，在本例中A是左表，B是右表。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431479-0dee4a80-270d-11ea-8bdd-da043078410d.png\" alt=\"image.png\"></p>\n<p>对于join，可以理解为把A的所有列和B的所有列并在一起。以上面的表格为例，A表和B表的列并在一起变成了：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid(user表)</th>\n<th>orgid(org表)</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>此时由于orgid字段重名，我们需通过select挑出需要的字段。以上面的表格为例，可编写SQL如下挑出所需字段：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT u.userid, u.username, u.orgid, o.orgname FROM user u join org o ON u.orgid = o.orgid</span><br></pre></td></tr></table></figure>\n<p>left join时，A表（左表）的所有行原封不动的保留，B表（右表）的行保留情况如下，</p>\n<ul>\n<li>上午文氏图的蓝色部分：B表的所有行原封不动的保留；</li>\n<li>上午文氏图的右白色部分：B表的所有行的值全部显示为NULL；</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n</tbody>\n</table>\n<p>right join时，与right join刚好相反，B表（右表）的所有行原封不动的保留，A表（左表）仅有与B表orgid重叠的行原封不动的保留。</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>NULL</td>\n<td>NULL</td>\n<td>15</td>\n<td>skj</td>\n</tr>\n</tbody>\n</table>\n<p>inner join，仅保留A表与B表orgid重叠的行。</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n</tbody>\n</table>\n<p>full join，用集合运算可理解为<code>(left join) + (right join) - (inner join)</code>。</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>NULL</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>NULL</td>\n<td>NULL</td>\n<td>15</td>\n<td>skj</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"笛卡尔积Cross-Join\"><a href=\"#笛卡尔积Cross-Join\" class=\"headerlink\" title=\"笛卡尔积Cross Join\"></a>笛卡尔积Cross Join</h2><p>这是一种特殊的Join，以上文的user表cross join org表为例，全连接SQL如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT </span><br><span class=\"line\">    u.userid,</span><br><span class=\"line\">    u.username,</span><br><span class=\"line\">    u.orgid,</span><br><span class=\"line\">    o.orgname</span><br><span class=\"line\">FROM</span><br><span class=\"line\">    user u cross join org o -- 注：cross join可用逗号表示</span><br></pre></td></tr></table></figure>\n<p>得到的结果如下：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>skj</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>skj</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gzut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>skj</td>\n</tr>\n</tbody>\n</table>\n<p>也就说，在cross join不设定where条件的情况下，得到的结果是一个笛卡尔积，总行数等于左表的行数乘以B表的行数。在指定where条件的情况下，下文的SQL等同于inner join。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT </span><br><span class=\"line\">    u.userid,</span><br><span class=\"line\">    u.username,</span><br><span class=\"line\">    u.orgid,</span><br><span class=\"line\">    o.orgname</span><br><span class=\"line\">FROM</span><br><span class=\"line\">    user u, org o -- 注：cross join可用逗号表示</span><br><span class=\"line\">WHERE</span><br><span class=\"line\">    u.orgid = o.orgid</span><br></pre></td></tr></table></figure>\n<h2 id=\"group-by\"><a href=\"#group-by\" class=\"headerlink\" title=\"group by\"></a>group by</h2><p><code>group by</code>的语义是把行进行分组，如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT </span><br><span class=\"line\">    u.userid,</span><br><span class=\"line\">    u.username,</span><br><span class=\"line\">    u.orgid,</span><br><span class=\"line\">    o.orgname</span><br><span class=\"line\">FROM</span><br><span class=\"line\">    user u cross join org o</span><br><span class=\"line\">GROUP BY u.userid</span><br></pre></td></tr></table></figure>\n<p>以上SQL，会把userid相同的分成一个组，然后仅保留组内的第一条记录，得到的结果为：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>username</th>\n<th>orgid</th>\n<th>orgname</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>jay</td>\n<td>10</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tom</td>\n<td>11</td>\n<td>gdut</td>\n</tr>\n<tr>\n<td>3</td>\n<td>shelly</td>\n<td>12</td>\n<td>gdut</td>\n</tr>\n</tbody>\n</table>\n<p>基于<code>group by</code>分组的特性，一般其会配置聚合函数使用，如count()和avg()等函数。修改SQL如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT </span><br><span class=\"line\">    u.userid, count(*)</span><br><span class=\"line\">FROM</span><br><span class=\"line\">    user u cross join org o</span><br><span class=\"line\">GROUP BY u.userid</span><br></pre></td></tr></table></figure>\n<p>将得到结果：</p>\n<table>\n<thead>\n<tr>\n<th>userid</th>\n<th>count</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>3</td>\n</tr>\n<tr>\n<td>2</td>\n<td>3</td>\n</tr>\n<tr>\n<td>3</td>\n<td>3</td>\n</tr>\n</tbody>\n</table>\n<p><code>group by</code>后跟一个字段，表示一维分组，如果跟两个字段则为二维分组，三个字段及以上以此类推。以二重<code>group by</code>为例，<code>group by a, b</code>可以通俗的理解为：<strong>所有a字段值相同，同时b字段值相同的行，会被分到同一组</strong>。</p>"},{"title":"《Kafka核心技术与实战》专栏笔记","date":"2020-01-03T14:00:32.000Z","comments":1,"_content":"\n本文是极客时间专栏《Kafka核心技术与实战》的阅读笔记。\n\n<!--more-->\n\n## Kafka的三层模型\n\n![image](https://user-images.githubusercontent.com/4915189/70886991-c6363780-2017-11ea-9b16-c455e0daf769.png)\n\n- 第一层：主题Topic。主题是承载消息的逻辑容器，物理上通过多个分区来实现。\n- 第二层：分区Partition。一个主题的消息按规则分散（比如轮询、哈希）存储在多个分区，单个分区内的消息是有序的，分区间的消息没有顺序关系。分区还分为leader和follower，leader才对外提供服务（producer写入、consumer消费）并记录消息位移offset，follower用于灾备。消费者以一个组（consumer group）的方式消费多个分区的数据，分配每个消费者消费哪些分区leader的过程称为rebalance，每个消费者自行记录单个分区的消费位移（consumer offset）。\n- 第三层：消息record。存储在分区内的最小单元信息。\n\n## Kafka的几个重要版本\n\n- 0.9.0.0版本：增加基础安全认证，使用Java重写消费API，引入Kafka Connect\n- 0.11.0.0版本：幂等性Producer API、事务API，对Kafka消息格式做了重构\n\n## kafka的重要参数\n\n![image](https://user-images.githubusercontent.com/4915189/70970163-9b5fe800-20d8-11ea-955d-1949f4889d4f.png)\n![image](https://user-images.githubusercontent.com/4915189/70970212-bc283d80-20d8-11ea-9c1d-1e4bd5772adf.png)\n\n\n## 分区策略\n\n- 轮询策略：轮询写到每个分区\n- 随机策略：随机写到每个分区\n- Key-ordering策略：消息指定了key的，会被放到同一个分区，保障了单分区的有序性\n\n## 压缩、解压策略\n\nProducer压缩、Broker保持、Consumer解压\n\n- 吞吐量：lz4 > snappy > zstd & gzip\n- 压缩比：zstd > lz4 > gzip > snappy\n- 带宽：snappy最多，zstd最少\n- CPU：压缩时snappy多，解压时gzip多\n\n## 丢消息问题\n\n- producer应该使用带回调的producer.send(msg, callback)而不是producer.send(msg)，前者在丢消息可以在callback进行处理\n- 消费者应该在消费消息后再提交位移，且不要开启自动提交，而应该用自动提交；\n- broker端应该设置factor参数，将消息多存几份防止丢失；\n- producer设置acks = all\n- producer设置retries为一个比较大的值防止网络抖动导致的失败\n- 禁用unclean的broker leader选举\n- 关闭consumer的自动提交位移\n\n## producer对TCP连接的管理\n- 创建producer时，它会连接bootstrap.servers的所有Broker\n- producer会定时请求更新元数据，判断到连接未建立则会触发创建\n- 发送数据时，同上\n- 关闭有两种，用户主动关闭，空链路被kafka释放\n\n## 拦截器\n\n- 可用于客户端监控、端到端监控、消息审计等；\n- producer可在send之前、send完收到ack触发拦截方法；\n- 消费者可在消费前、消费后commit触发拦截方法；\n\n## __consumer_offsets\n- 早期版本将消费者位移数据保存在zookeeper，但高频的读写zookeeper使得其成为瓶颈点\n- 保存的记录为key/value，key为`<Group ID, 主题名, 分区号>`，消息体为位移数据\n- 当kafka集群的第一个consumer启动时，kafka会自动创建位移主题\n- kafka使用compact策略定期删除过期的位移数据，防止撑爆硬盘\n\n## consumer group\n- consumer提交位移时，其实是向coordinator所在broker提交位移\n- 消费者组注册、成员管理也是由coordinator管理\n- 如何确定消费者组的coordinator\n  - partitionId=Math.abs(groupId.hashCode() % __consumer_offsets的总分区数)\n  - 找出给分区leader副本所在的broker\n- 大部分重平衡都是由于consumer被认为已经挂掉被kafka剔除组导致的，如何防止？\n  - 延长会话\n    - session.timeout.ms建议设为6秒，延长会话存活时间防止被误认为consumer死亡\n    - heartbeat.interval.ms建议设为2秒，值越小能越快感知进入重平衡\n    - **以上两值，consumer被认为死亡至少经历了3次心跳**\n  - 延长消费时间\n    - max.poll.interval.ms，两次poll的间隔如果大于这个值consumer会主动离开组，这可能是消费逻辑太重导致的，适当延长该值\n  - 排查是否FULL GC\n\n## 消费者端多线程设计（KafkaConsumer为单线程）\n- 主线程负责消费数据提交位移，心跳线程负责探活\n- KafkaConsumer不是线程安全的\n- 方案1：消费者端多个线程，每个线程是一个KafkaConsumer（受限于topic_partition分区数）\n- 方案2：消费者端一个KafkaConsumer线程，poll到的消息丢给线程池消费（可能导致消息重复消费、不利于提交位移）\n\n## CommitFailedException\n- poll之后的消费时间超过max.poll.interval.ms，consumer触发LeaveGroup，此时必然会提交位移失败（0.10.1.0版本之后），解决方案\n    - 优化消费逻辑\n    - 增加max.poll.interval.ms\n    - 减少max.poll.records\n    - 消费者端使用多线程消费（但引入多线程提交位移的负责度）\n- 消费者组和standalone的消费者的groupid冲突，也会导致这个错误\n\n## 消费者管理TCP连接\n- 创建KafkaConsumer时不会创建TCP连接，以下3个时机才会发起TCP连接\n    - 发起 FindCoordinator 请求时（发给负载最小的Broker，使用完后关闭）\n    - 连接协调者时（连接coordinator）=> 心跳、Rebalance相关\n    - 消费数据时（消费要消费的leader副本所在broker）=> 数据消费、元数据相关\n\n## 消费者组位移\n- 自动提交可能会导致重复消费，假设每5秒自动提交一次，在两次提交中间发生重平衡就会导致这个问题\n- commitSync会阻塞消费者，失败时会自动重试\n- commitAsync是异步操作，而且可以带回调，失败了不重试（因为此时位移值已经不是最新的了）\n- 大部分情况用异步提交，在consumer要关闭前用同步提交\n- kafka支持一次取多消息如5000条，每消费100条手动提交一次位移\n\n## consumer group的消费监控\n\nconsumer lag指的是滞后未消费的消息数。假如生产了100W条消息，但当下只消费了80W条，那么lag为20W条。监控方法有三种：kafka的consumers-group脚本、comsumer的java api、自带的jmx监控指标（优选）。\n\n## 副本机制\n\nkafka的replica本质是一个只能追加写（append）的日志。kafka在创建分区时，会根据replica参数创建多个分区副本，分区副本分leader副本和follower副本两种，分布在不同的broker，他们的关系如下图：\n\n![image](https://user-images.githubusercontent.com/4915189/70912772-a02c8980-204f-11ea-8643-b0d48cf9741f.png)\n\n针对具体一分区的读/写，都会定位到leader副本。follower副本并不向外提供读取的功能，它们的作用只会在leader副本crash时进行重新选举用到。kafka的副本，没有类似于其他分布式系统的一些好处：\n- 副本可提供读，读的能力得到扩充；\n- 可根据客户端地理位置分配距离较近的副本提供读，加速读取。\n\n但kafka的副本也规避了不能read-your-writes的问题。如果写到分区A，但读的是分区B，分区A、B是异步同步，此时读B可能读不到最新的数据，如果保证能读到即时更新则为read-your-writes。\n\nkafka维护了一个ISR副本集合，领导副本重新选举时从这个集合中进行选择（normal情况），leader副本必会存在ISR集合中。follower副本与leader副本的时间差若小于replica.lag.time.max.ms则会被加到ISR集合，否则会被从ISR集合中踢出。极端情况下，ISR集合可能为空，这意味着leader副本crash了且所有follower副本都“落后”了replica.lag.time.max.ms时间，这种情况意味着丢失数据较严重。此时进行的领导者选举称作unclean选举，需要unclean.leader.election.enable为true时才开启。\n\n## broker的请求处理模型\n\nbroker的socket模型为[reactor模型](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)，reactor负责accept请求，然后dispatch给不同的worker进行处理，大致如下：\n\n![image](https://user-images.githubusercontent.com/4915189/70974586-0e6e5c00-20e3-11ea-8b6f-061ba7136691.png)\n\n专栏提到更细致的线程模型如下：\n\n![image](https://user-images.githubusercontent.com/4915189/70974621-234aef80-20e3-11ea-9465-ae83e6d74c63.png)\n\n（专栏的这张图片有不严谨之处，最终的响应队列如何能直接返回结果给客户端呢？）\n\n网络线程池read()完数据，生产给共享队列，IO线程池取数据消费。请求分两种：一种是数据类，一种是控制类。数据类比如PRODUCE、FETCH等请求，需要落盘或读盘，比较特殊的是当PRODUCE请求的ack设置为all时，在当前leader副本数据落盘后还需要等待其他follower副本落盘成功的消息才返回给客户端，此类PRODUCE请求会被放置到purgatory队列中（延迟队列）。控制类请求有诸如角色变更、停止replica。\n\n![image](https://user-images.githubusercontent.com/4915189/72348031-69ac6200-3714-11ea-87c9-d445e7349d01.png)\n\n（matt33博客的这张图比较靠谱）\n\n数据类、控制类实质上是两套不同的处理流程（可简单理解为两个抽象队列），他们各自有acceptor、网络线程池、IO线程池，即他们的入端口都是不同的。\n\n## kafka重平衡\n\n什么情况下会触发消费者组(consumer group)的重平衡：\n- 新的消费者通过指定group.id加入组\n- 已有的消费退出组（主动退出、崩溃导致的心跳timeout）\n- 消费者组关联的分区数、主题数发生变化\n\nconsumer group的重平衡，需要broker端的协调者组件协调，kafka内部实现了一个状态机协助状态转移：\n![image](https://user-images.githubusercontent.com/4915189/71159642-fcc2bb00-2280-11ea-83c9-3674506d08aa.png)\n- 进入PreparingRebalance，意味着触发了重平衡，所有消费者都需要重新参与一次重平衡\n- Stable意味着重平衡完成\n- Dead意味着这个组的一些元数据被清除了\n\nkafka内部维护了一个_consumer_offsets的topic，一个consumer group消费的全部主题的offset数据，存在该topic的同一个partition，该partition的leader副本所在broker，即为该group的协调者。\n\n从consumer的视角来看，它们参与重平衡的过程如下：\n- 程序刚启动，或者收到了协调者组件含**REBALANCE_IN_PROGRESS**的心跳response（如果是这种情况需要先把当前未提交的位移数据提交）\n- 向协调者组件发起加入组(JoinGroup)请求，协调者组件会回复ACK信号；特殊的是，一般第一个发起JoinGroup的consumer会被协调者组件选为leader consumer，协调者组件回复的ACK会携带上所有发起JoinGroup的consumer信息\n- 向协调者组件发起SyncGroup请求，leader consumer的请求会带上分区分配方案，其余的consumer则是一个空消息\n- 协调者组件将重平衡分配方案回复给每个consumer\n\n对分区消费的并行度有疑问，查资料后整理如下：\n![image](https://user-images.githubusercontent.com/4915189/71161512-727c5600-2284-11ea-816a-0488b3d93976.png)\n\n一个topic下的一个分区只能由一个consumer消费，但反之并不成立，一个consumer可能分配到多个topic_partition。假设分组订阅的topic下的partition总数为N，消费者组的消费者数最好不要超过N，多出来的消费者不会分配topic_partition是一种浪费。\n\n## kafka的控制器（controller）\n\n在Zookeeper的协助下协调和管理整个Kafka集群。多个Broker竞争创建zookeeper的/controller，第一个创建成功的即为controller；当现有的controller宕机时，各broker监听到该事件触发重新选举（创建/controller）。它主要有以下职责：\n- 主题管理（创建、删除、增加分区）\n- 分区重分配\n- preferred领导者选举（避免部分broker负载过重而提供的一种更换leader的方案）\n- 集群成员管理（新增broker、broker主动关闭、broker宕机，/broker/ids/下的临时节点）\n- 元数据服务（从zookeeper同步最新元数据，同步最新元数据给其他broker）\n\n其内部线程设计如下：\n![image](https://user-images.githubusercontent.com/4915189/71415497-f4122080-2696-11ea-92b9-4060d033b866.png)\n\n- 多个zookeeper事件（异步处理）放到queue，由单线程顺序处理防止竞态；\n- 控制类请求有另外一条通道，将比queue中的事件高优处理，如StopReplica请求；\n\n## 高水位和Leader Epoch\n\n![image](https://user-images.githubusercontent.com/4915189/71415605-769ae000-2697-11ea-92a9-faa2fc36bca0.png)\n\n- 高水位（high water mask，简称HW）：表征已提交消息和未提交消息的分界，这里的未提交是指该message未被全部follower副本replicate——大于等于HW的均未被replicate\n    - leader副本的HW即为分区的HW\n    - follower副本的HW表征其与leader副本的同步情况，其值 = min(收到的leader的HW, follower的LEO)\n- 日志末端位移（log end offset，简称LEO）：表征待写入消息的位置位移，新的消息来临时将写入LEO指向的位置，然后LEO自增1\n    - leader副本同时保存有follower的LEO，用途：leader的HW = min(缓存的follower的LEO，leader的LEO)\n\n![image](https://user-images.githubusercontent.com/4915189/71431213-50af2300-270b-11ea-8af6-8146d902e255.png)\n\n- 当producer生产消息0时，leader的LEO被设为1\n- 此时follower来fetch消息（offset为0），leader更新remote LEO为0（offset的值），leader的HW更新为min(remote LEO, leader LEO)即为0\n- follower收到fetch的消息0，LEO自增1，更新HW为min(follower的LEO，leader的HW)，即为0\n- follower继续fetch消息（offset为1），leader更新remote LEO为1（offset的值），leader的HW更新为min(remote LEO, leader LEO)即为1\n- follower收到fetch的空消息（leader没有新消息了），更新HW为min(follower的LEO，leader的HW)，即为1\n\n可以看到，leader的HW需要在第二次RPC时才更新，且在HW更新的response返回给follower前若follower宕机，则follower重启后LEO会被截断为HW导致未提交的消息丢失，此时若leader也正好宕机则会导致消息的彻底丢失，如下图：\n\n![image](https://user-images.githubusercontent.com/4915189/71431323-0c705280-270c-11ea-92c0-de96d67b89ce.png)\n\n[KIP-101](https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation)提出了利用Epoch解决该问题，follower在重启后向leader获取最新的LEO防止错误截断，如下图：\n![image](https://user-images.githubusercontent.com/4915189/71431336-25790380-270c-11ea-8301-3e582ff3c1cb.png)\n\n## 常见问题\n1. 为何使用MQ\n    - 异步通信（调用解耦、故障隔离）\n    - 流量的削峰（防止流量压垮）\n    - 消息的持久化（可重试，可重复消费）\n1. 与其他MQ的对比\n    - RabbitMQ支持多协议，非常重量级，更适合于企业级开发\n    - Redis的MQ支持，适合于存小消息，且可能丢消息\n    - ZeroMQ是一个代码库，需要自己设计mq通信模式，可能丢消息\n    - ActiveMQ支持多协议，类似于ZeroMQ，它能够以代理人和点对点的技术实现队列\n    - kafka的显示特点：顺序写、push and pull、消息可重复消费、水平扩展、replica\n1. Kafka delivery guarantee\n    - At most once：设置producer为异步发送\n    - At least once：可能会导致消息的重复投递\n    - Exactly once：每个producer在创建时将会被分配一个PID，broker收到数据后将会检测<PID, TOPIC, PARTITION>对应的sequence是否增加，是则接受消息，否则丢弃消息。这种机制只能针对单个分区实现幂等，且要求producer不能宕机\n1. 物理上如何存储\n    - 每个topic-partition组合为一个文件夹，文件夹中存有多个segment，segment的命名为第一条消息的offset+kafka后缀，且伴随有segment的索引文件\n1. push vs pull\n    - 生产时push，由于kafka是顺序追加，因此可以做较高吞吐量的写入；消费时pull，由客户端自己去决定要pull多少，不至于压垮客户端\n1. topic的partition是如何分配的\n    - 假设有n个broker\n    - 第i个partition的leader副本将被分配到第(i mod n)个broker\n    - 第i个partition的第j个follower副本将被分配到第((i+j) mod n)个broker\n1. produer的ACK机制是如何保证的\n    - acks = all\n    - producer将消息给到leader副本，leader副本将消息写到log\n    - ISR副本中的所有follower副本PULL到新消息立即回复ACK给leader，此时消息还在内存中，这算是性能和持久化的一个折中平衡，所有follower同时挂掉的可能性很低\n1. leader副本挂了是如何重新选举的\n    - kafka并非借助zookeeper的临时节点进行重新选举的，因为如果挂掉的broker上面有多个partition将会导致zookeeper负载非常的大。其重选举是由controller角色的broker从ISR集合中挑选的broker作为新leader（具体实现待考究）\n1. kafka是如何实现读写负载均衡的\n    - partition均可能均匀的分发到各个broker\n    - partition是最小并发粒度提供读写，不至于使流量集中压在一台broker上\n1. kafka在网络传输层面的优化\n    - producer并发每次send调用都将消息发送到broker，而是按时间或量积攒后批处理发到broker\n    - broker也不是每收到一条消息就flush落盘，而是先写page cache，如果生产、消费速率相当此时消费者可能从cache直接取到消息绕开读盘，其缺点也由replica机制规避\n    - kafka使用sendfile调用实现segment传输的zero copy\n    - produce、consume传输的都是压缩的数据\n    - kafka支持avro、protocol buffer等序列化方式对消息进行序列化，进一步减少传输的数据量大小\n1. kafka的事务保障\n    - 跨session的幂等写入，producer中间故障后恢复重写依然可以保证幂等\n    - 跨session的事务恢复，producer中间故障后恢复的新实例可以保证旧事务的commit或abort\n    - 跨多个topic-partition的写入，要么全部成功，要么全部失败，不会有中间状态\n    - 注意事项\n        - 需要在producer的配置文件配置唯一的transaction.id\n        - consumer不保证一个已commit的事务的所有消息都会被消费，原因有：consumer不一定订阅全部topic，consumer可以使用seek从任意位置消费\n\n## 最终总结\n\n![image](https://user-images.githubusercontent.com/4915189/71614560-5a42fa00-2be7-11ea-9a9f-f30a025b6381.png)\n\n","source":"_posts/2020-01-12-kafka-geekbang-note.md","raw":"---\ntitle: 《Kafka核心技术与实战》专栏笔记\ndate: 2020-01-03 22:00:32\ntags: ['Kafka']\ncomments: true\ncategories: ['分布式系统']\n---\n\n本文是极客时间专栏《Kafka核心技术与实战》的阅读笔记。\n\n<!--more-->\n\n## Kafka的三层模型\n\n![image](https://user-images.githubusercontent.com/4915189/70886991-c6363780-2017-11ea-9b16-c455e0daf769.png)\n\n- 第一层：主题Topic。主题是承载消息的逻辑容器，物理上通过多个分区来实现。\n- 第二层：分区Partition。一个主题的消息按规则分散（比如轮询、哈希）存储在多个分区，单个分区内的消息是有序的，分区间的消息没有顺序关系。分区还分为leader和follower，leader才对外提供服务（producer写入、consumer消费）并记录消息位移offset，follower用于灾备。消费者以一个组（consumer group）的方式消费多个分区的数据，分配每个消费者消费哪些分区leader的过程称为rebalance，每个消费者自行记录单个分区的消费位移（consumer offset）。\n- 第三层：消息record。存储在分区内的最小单元信息。\n\n## Kafka的几个重要版本\n\n- 0.9.0.0版本：增加基础安全认证，使用Java重写消费API，引入Kafka Connect\n- 0.11.0.0版本：幂等性Producer API、事务API，对Kafka消息格式做了重构\n\n## kafka的重要参数\n\n![image](https://user-images.githubusercontent.com/4915189/70970163-9b5fe800-20d8-11ea-955d-1949f4889d4f.png)\n![image](https://user-images.githubusercontent.com/4915189/70970212-bc283d80-20d8-11ea-9c1d-1e4bd5772adf.png)\n\n\n## 分区策略\n\n- 轮询策略：轮询写到每个分区\n- 随机策略：随机写到每个分区\n- Key-ordering策略：消息指定了key的，会被放到同一个分区，保障了单分区的有序性\n\n## 压缩、解压策略\n\nProducer压缩、Broker保持、Consumer解压\n\n- 吞吐量：lz4 > snappy > zstd & gzip\n- 压缩比：zstd > lz4 > gzip > snappy\n- 带宽：snappy最多，zstd最少\n- CPU：压缩时snappy多，解压时gzip多\n\n## 丢消息问题\n\n- producer应该使用带回调的producer.send(msg, callback)而不是producer.send(msg)，前者在丢消息可以在callback进行处理\n- 消费者应该在消费消息后再提交位移，且不要开启自动提交，而应该用自动提交；\n- broker端应该设置factor参数，将消息多存几份防止丢失；\n- producer设置acks = all\n- producer设置retries为一个比较大的值防止网络抖动导致的失败\n- 禁用unclean的broker leader选举\n- 关闭consumer的自动提交位移\n\n## producer对TCP连接的管理\n- 创建producer时，它会连接bootstrap.servers的所有Broker\n- producer会定时请求更新元数据，判断到连接未建立则会触发创建\n- 发送数据时，同上\n- 关闭有两种，用户主动关闭，空链路被kafka释放\n\n## 拦截器\n\n- 可用于客户端监控、端到端监控、消息审计等；\n- producer可在send之前、send完收到ack触发拦截方法；\n- 消费者可在消费前、消费后commit触发拦截方法；\n\n## __consumer_offsets\n- 早期版本将消费者位移数据保存在zookeeper，但高频的读写zookeeper使得其成为瓶颈点\n- 保存的记录为key/value，key为`<Group ID, 主题名, 分区号>`，消息体为位移数据\n- 当kafka集群的第一个consumer启动时，kafka会自动创建位移主题\n- kafka使用compact策略定期删除过期的位移数据，防止撑爆硬盘\n\n## consumer group\n- consumer提交位移时，其实是向coordinator所在broker提交位移\n- 消费者组注册、成员管理也是由coordinator管理\n- 如何确定消费者组的coordinator\n  - partitionId=Math.abs(groupId.hashCode() % __consumer_offsets的总分区数)\n  - 找出给分区leader副本所在的broker\n- 大部分重平衡都是由于consumer被认为已经挂掉被kafka剔除组导致的，如何防止？\n  - 延长会话\n    - session.timeout.ms建议设为6秒，延长会话存活时间防止被误认为consumer死亡\n    - heartbeat.interval.ms建议设为2秒，值越小能越快感知进入重平衡\n    - **以上两值，consumer被认为死亡至少经历了3次心跳**\n  - 延长消费时间\n    - max.poll.interval.ms，两次poll的间隔如果大于这个值consumer会主动离开组，这可能是消费逻辑太重导致的，适当延长该值\n  - 排查是否FULL GC\n\n## 消费者端多线程设计（KafkaConsumer为单线程）\n- 主线程负责消费数据提交位移，心跳线程负责探活\n- KafkaConsumer不是线程安全的\n- 方案1：消费者端多个线程，每个线程是一个KafkaConsumer（受限于topic_partition分区数）\n- 方案2：消费者端一个KafkaConsumer线程，poll到的消息丢给线程池消费（可能导致消息重复消费、不利于提交位移）\n\n## CommitFailedException\n- poll之后的消费时间超过max.poll.interval.ms，consumer触发LeaveGroup，此时必然会提交位移失败（0.10.1.0版本之后），解决方案\n    - 优化消费逻辑\n    - 增加max.poll.interval.ms\n    - 减少max.poll.records\n    - 消费者端使用多线程消费（但引入多线程提交位移的负责度）\n- 消费者组和standalone的消费者的groupid冲突，也会导致这个错误\n\n## 消费者管理TCP连接\n- 创建KafkaConsumer时不会创建TCP连接，以下3个时机才会发起TCP连接\n    - 发起 FindCoordinator 请求时（发给负载最小的Broker，使用完后关闭）\n    - 连接协调者时（连接coordinator）=> 心跳、Rebalance相关\n    - 消费数据时（消费要消费的leader副本所在broker）=> 数据消费、元数据相关\n\n## 消费者组位移\n- 自动提交可能会导致重复消费，假设每5秒自动提交一次，在两次提交中间发生重平衡就会导致这个问题\n- commitSync会阻塞消费者，失败时会自动重试\n- commitAsync是异步操作，而且可以带回调，失败了不重试（因为此时位移值已经不是最新的了）\n- 大部分情况用异步提交，在consumer要关闭前用同步提交\n- kafka支持一次取多消息如5000条，每消费100条手动提交一次位移\n\n## consumer group的消费监控\n\nconsumer lag指的是滞后未消费的消息数。假如生产了100W条消息，但当下只消费了80W条，那么lag为20W条。监控方法有三种：kafka的consumers-group脚本、comsumer的java api、自带的jmx监控指标（优选）。\n\n## 副本机制\n\nkafka的replica本质是一个只能追加写（append）的日志。kafka在创建分区时，会根据replica参数创建多个分区副本，分区副本分leader副本和follower副本两种，分布在不同的broker，他们的关系如下图：\n\n![image](https://user-images.githubusercontent.com/4915189/70912772-a02c8980-204f-11ea-8643-b0d48cf9741f.png)\n\n针对具体一分区的读/写，都会定位到leader副本。follower副本并不向外提供读取的功能，它们的作用只会在leader副本crash时进行重新选举用到。kafka的副本，没有类似于其他分布式系统的一些好处：\n- 副本可提供读，读的能力得到扩充；\n- 可根据客户端地理位置分配距离较近的副本提供读，加速读取。\n\n但kafka的副本也规避了不能read-your-writes的问题。如果写到分区A，但读的是分区B，分区A、B是异步同步，此时读B可能读不到最新的数据，如果保证能读到即时更新则为read-your-writes。\n\nkafka维护了一个ISR副本集合，领导副本重新选举时从这个集合中进行选择（normal情况），leader副本必会存在ISR集合中。follower副本与leader副本的时间差若小于replica.lag.time.max.ms则会被加到ISR集合，否则会被从ISR集合中踢出。极端情况下，ISR集合可能为空，这意味着leader副本crash了且所有follower副本都“落后”了replica.lag.time.max.ms时间，这种情况意味着丢失数据较严重。此时进行的领导者选举称作unclean选举，需要unclean.leader.election.enable为true时才开启。\n\n## broker的请求处理模型\n\nbroker的socket模型为[reactor模型](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)，reactor负责accept请求，然后dispatch给不同的worker进行处理，大致如下：\n\n![image](https://user-images.githubusercontent.com/4915189/70974586-0e6e5c00-20e3-11ea-8b6f-061ba7136691.png)\n\n专栏提到更细致的线程模型如下：\n\n![image](https://user-images.githubusercontent.com/4915189/70974621-234aef80-20e3-11ea-9465-ae83e6d74c63.png)\n\n（专栏的这张图片有不严谨之处，最终的响应队列如何能直接返回结果给客户端呢？）\n\n网络线程池read()完数据，生产给共享队列，IO线程池取数据消费。请求分两种：一种是数据类，一种是控制类。数据类比如PRODUCE、FETCH等请求，需要落盘或读盘，比较特殊的是当PRODUCE请求的ack设置为all时，在当前leader副本数据落盘后还需要等待其他follower副本落盘成功的消息才返回给客户端，此类PRODUCE请求会被放置到purgatory队列中（延迟队列）。控制类请求有诸如角色变更、停止replica。\n\n![image](https://user-images.githubusercontent.com/4915189/72348031-69ac6200-3714-11ea-87c9-d445e7349d01.png)\n\n（matt33博客的这张图比较靠谱）\n\n数据类、控制类实质上是两套不同的处理流程（可简单理解为两个抽象队列），他们各自有acceptor、网络线程池、IO线程池，即他们的入端口都是不同的。\n\n## kafka重平衡\n\n什么情况下会触发消费者组(consumer group)的重平衡：\n- 新的消费者通过指定group.id加入组\n- 已有的消费退出组（主动退出、崩溃导致的心跳timeout）\n- 消费者组关联的分区数、主题数发生变化\n\nconsumer group的重平衡，需要broker端的协调者组件协调，kafka内部实现了一个状态机协助状态转移：\n![image](https://user-images.githubusercontent.com/4915189/71159642-fcc2bb00-2280-11ea-83c9-3674506d08aa.png)\n- 进入PreparingRebalance，意味着触发了重平衡，所有消费者都需要重新参与一次重平衡\n- Stable意味着重平衡完成\n- Dead意味着这个组的一些元数据被清除了\n\nkafka内部维护了一个_consumer_offsets的topic，一个consumer group消费的全部主题的offset数据，存在该topic的同一个partition，该partition的leader副本所在broker，即为该group的协调者。\n\n从consumer的视角来看，它们参与重平衡的过程如下：\n- 程序刚启动，或者收到了协调者组件含**REBALANCE_IN_PROGRESS**的心跳response（如果是这种情况需要先把当前未提交的位移数据提交）\n- 向协调者组件发起加入组(JoinGroup)请求，协调者组件会回复ACK信号；特殊的是，一般第一个发起JoinGroup的consumer会被协调者组件选为leader consumer，协调者组件回复的ACK会携带上所有发起JoinGroup的consumer信息\n- 向协调者组件发起SyncGroup请求，leader consumer的请求会带上分区分配方案，其余的consumer则是一个空消息\n- 协调者组件将重平衡分配方案回复给每个consumer\n\n对分区消费的并行度有疑问，查资料后整理如下：\n![image](https://user-images.githubusercontent.com/4915189/71161512-727c5600-2284-11ea-816a-0488b3d93976.png)\n\n一个topic下的一个分区只能由一个consumer消费，但反之并不成立，一个consumer可能分配到多个topic_partition。假设分组订阅的topic下的partition总数为N，消费者组的消费者数最好不要超过N，多出来的消费者不会分配topic_partition是一种浪费。\n\n## kafka的控制器（controller）\n\n在Zookeeper的协助下协调和管理整个Kafka集群。多个Broker竞争创建zookeeper的/controller，第一个创建成功的即为controller；当现有的controller宕机时，各broker监听到该事件触发重新选举（创建/controller）。它主要有以下职责：\n- 主题管理（创建、删除、增加分区）\n- 分区重分配\n- preferred领导者选举（避免部分broker负载过重而提供的一种更换leader的方案）\n- 集群成员管理（新增broker、broker主动关闭、broker宕机，/broker/ids/下的临时节点）\n- 元数据服务（从zookeeper同步最新元数据，同步最新元数据给其他broker）\n\n其内部线程设计如下：\n![image](https://user-images.githubusercontent.com/4915189/71415497-f4122080-2696-11ea-92b9-4060d033b866.png)\n\n- 多个zookeeper事件（异步处理）放到queue，由单线程顺序处理防止竞态；\n- 控制类请求有另外一条通道，将比queue中的事件高优处理，如StopReplica请求；\n\n## 高水位和Leader Epoch\n\n![image](https://user-images.githubusercontent.com/4915189/71415605-769ae000-2697-11ea-92a9-faa2fc36bca0.png)\n\n- 高水位（high water mask，简称HW）：表征已提交消息和未提交消息的分界，这里的未提交是指该message未被全部follower副本replicate——大于等于HW的均未被replicate\n    - leader副本的HW即为分区的HW\n    - follower副本的HW表征其与leader副本的同步情况，其值 = min(收到的leader的HW, follower的LEO)\n- 日志末端位移（log end offset，简称LEO）：表征待写入消息的位置位移，新的消息来临时将写入LEO指向的位置，然后LEO自增1\n    - leader副本同时保存有follower的LEO，用途：leader的HW = min(缓存的follower的LEO，leader的LEO)\n\n![image](https://user-images.githubusercontent.com/4915189/71431213-50af2300-270b-11ea-8af6-8146d902e255.png)\n\n- 当producer生产消息0时，leader的LEO被设为1\n- 此时follower来fetch消息（offset为0），leader更新remote LEO为0（offset的值），leader的HW更新为min(remote LEO, leader LEO)即为0\n- follower收到fetch的消息0，LEO自增1，更新HW为min(follower的LEO，leader的HW)，即为0\n- follower继续fetch消息（offset为1），leader更新remote LEO为1（offset的值），leader的HW更新为min(remote LEO, leader LEO)即为1\n- follower收到fetch的空消息（leader没有新消息了），更新HW为min(follower的LEO，leader的HW)，即为1\n\n可以看到，leader的HW需要在第二次RPC时才更新，且在HW更新的response返回给follower前若follower宕机，则follower重启后LEO会被截断为HW导致未提交的消息丢失，此时若leader也正好宕机则会导致消息的彻底丢失，如下图：\n\n![image](https://user-images.githubusercontent.com/4915189/71431323-0c705280-270c-11ea-92c0-de96d67b89ce.png)\n\n[KIP-101](https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation)提出了利用Epoch解决该问题，follower在重启后向leader获取最新的LEO防止错误截断，如下图：\n![image](https://user-images.githubusercontent.com/4915189/71431336-25790380-270c-11ea-8301-3e582ff3c1cb.png)\n\n## 常见问题\n1. 为何使用MQ\n    - 异步通信（调用解耦、故障隔离）\n    - 流量的削峰（防止流量压垮）\n    - 消息的持久化（可重试，可重复消费）\n1. 与其他MQ的对比\n    - RabbitMQ支持多协议，非常重量级，更适合于企业级开发\n    - Redis的MQ支持，适合于存小消息，且可能丢消息\n    - ZeroMQ是一个代码库，需要自己设计mq通信模式，可能丢消息\n    - ActiveMQ支持多协议，类似于ZeroMQ，它能够以代理人和点对点的技术实现队列\n    - kafka的显示特点：顺序写、push and pull、消息可重复消费、水平扩展、replica\n1. Kafka delivery guarantee\n    - At most once：设置producer为异步发送\n    - At least once：可能会导致消息的重复投递\n    - Exactly once：每个producer在创建时将会被分配一个PID，broker收到数据后将会检测<PID, TOPIC, PARTITION>对应的sequence是否增加，是则接受消息，否则丢弃消息。这种机制只能针对单个分区实现幂等，且要求producer不能宕机\n1. 物理上如何存储\n    - 每个topic-partition组合为一个文件夹，文件夹中存有多个segment，segment的命名为第一条消息的offset+kafka后缀，且伴随有segment的索引文件\n1. push vs pull\n    - 生产时push，由于kafka是顺序追加，因此可以做较高吞吐量的写入；消费时pull，由客户端自己去决定要pull多少，不至于压垮客户端\n1. topic的partition是如何分配的\n    - 假设有n个broker\n    - 第i个partition的leader副本将被分配到第(i mod n)个broker\n    - 第i个partition的第j个follower副本将被分配到第((i+j) mod n)个broker\n1. produer的ACK机制是如何保证的\n    - acks = all\n    - producer将消息给到leader副本，leader副本将消息写到log\n    - ISR副本中的所有follower副本PULL到新消息立即回复ACK给leader，此时消息还在内存中，这算是性能和持久化的一个折中平衡，所有follower同时挂掉的可能性很低\n1. leader副本挂了是如何重新选举的\n    - kafka并非借助zookeeper的临时节点进行重新选举的，因为如果挂掉的broker上面有多个partition将会导致zookeeper负载非常的大。其重选举是由controller角色的broker从ISR集合中挑选的broker作为新leader（具体实现待考究）\n1. kafka是如何实现读写负载均衡的\n    - partition均可能均匀的分发到各个broker\n    - partition是最小并发粒度提供读写，不至于使流量集中压在一台broker上\n1. kafka在网络传输层面的优化\n    - producer并发每次send调用都将消息发送到broker，而是按时间或量积攒后批处理发到broker\n    - broker也不是每收到一条消息就flush落盘，而是先写page cache，如果生产、消费速率相当此时消费者可能从cache直接取到消息绕开读盘，其缺点也由replica机制规避\n    - kafka使用sendfile调用实现segment传输的zero copy\n    - produce、consume传输的都是压缩的数据\n    - kafka支持avro、protocol buffer等序列化方式对消息进行序列化，进一步减少传输的数据量大小\n1. kafka的事务保障\n    - 跨session的幂等写入，producer中间故障后恢复重写依然可以保证幂等\n    - 跨session的事务恢复，producer中间故障后恢复的新实例可以保证旧事务的commit或abort\n    - 跨多个topic-partition的写入，要么全部成功，要么全部失败，不会有中间状态\n    - 注意事项\n        - 需要在producer的配置文件配置唯一的transaction.id\n        - consumer不保证一个已commit的事务的所有消息都会被消费，原因有：consumer不一定订阅全部topic，consumer可以使用seek从任意位置消费\n\n## 最终总结\n\n![image](https://user-images.githubusercontent.com/4915189/71614560-5a42fa00-2be7-11ea-9a9f-f30a025b6381.png)\n\n","slug":"kafka-geekbang-note","published":1,"updated":"2022-08-09T15:02:00.659Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14t003tigu810dcam5k","content":"<p>本文是极客时间专栏《Kafka核心技术与实战》的阅读笔记。</p>\n<a id=\"more\"></a>\n<h2 id=\"Kafka的三层模型\"><a href=\"#Kafka的三层模型\" class=\"headerlink\" title=\"Kafka的三层模型\"></a>Kafka的三层模型</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/70886991-c6363780-2017-11ea-9b16-c455e0daf769.png\" alt=\"image\"></p>\n<ul>\n<li>第一层：主题Topic。主题是承载消息的逻辑容器，物理上通过多个分区来实现。</li>\n<li>第二层：分区Partition。一个主题的消息按规则分散（比如轮询、哈希）存储在多个分区，单个分区内的消息是有序的，分区间的消息没有顺序关系。分区还分为leader和follower，leader才对外提供服务（producer写入、consumer消费）并记录消息位移offset，follower用于灾备。消费者以一个组（consumer group）的方式消费多个分区的数据，分配每个消费者消费哪些分区leader的过程称为rebalance，每个消费者自行记录单个分区的消费位移（consumer offset）。</li>\n<li>第三层：消息record。存储在分区内的最小单元信息。</li>\n</ul>\n<h2 id=\"Kafka的几个重要版本\"><a href=\"#Kafka的几个重要版本\" class=\"headerlink\" title=\"Kafka的几个重要版本\"></a>Kafka的几个重要版本</h2><ul>\n<li>0.9.0.0版本：增加基础安全认证，使用Java重写消费API，引入Kafka Connect</li>\n<li>0.11.0.0版本：幂等性Producer API、事务API，对Kafka消息格式做了重构</li>\n</ul>\n<h2 id=\"kafka的重要参数\"><a href=\"#kafka的重要参数\" class=\"headerlink\" title=\"kafka的重要参数\"></a>kafka的重要参数</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/70970163-9b5fe800-20d8-11ea-955d-1949f4889d4f.png\" alt=\"image\"><br><img src=\"https://user-images.githubusercontent.com/4915189/70970212-bc283d80-20d8-11ea-9c1d-1e4bd5772adf.png\" alt=\"image\"></p>\n<h2 id=\"分区策略\"><a href=\"#分区策略\" class=\"headerlink\" title=\"分区策略\"></a>分区策略</h2><ul>\n<li>轮询策略：轮询写到每个分区</li>\n<li>随机策略：随机写到每个分区</li>\n<li>Key-ordering策略：消息指定了key的，会被放到同一个分区，保障了单分区的有序性</li>\n</ul>\n<h2 id=\"压缩、解压策略\"><a href=\"#压缩、解压策略\" class=\"headerlink\" title=\"压缩、解压策略\"></a>压缩、解压策略</h2><p>Producer压缩、Broker保持、Consumer解压</p>\n<ul>\n<li>吞吐量：lz4 &gt; snappy &gt; zstd &amp; gzip</li>\n<li>压缩比：zstd &gt; lz4 &gt; gzip &gt; snappy</li>\n<li>带宽：snappy最多，zstd最少</li>\n<li>CPU：压缩时snappy多，解压时gzip多</li>\n</ul>\n<h2 id=\"丢消息问题\"><a href=\"#丢消息问题\" class=\"headerlink\" title=\"丢消息问题\"></a>丢消息问题</h2><ul>\n<li>producer应该使用带回调的producer.send(msg, callback)而不是producer.send(msg)，前者在丢消息可以在callback进行处理</li>\n<li>消费者应该在消费消息后再提交位移，且不要开启自动提交，而应该用自动提交；</li>\n<li>broker端应该设置factor参数，将消息多存几份防止丢失；</li>\n<li>producer设置acks = all</li>\n<li>producer设置retries为一个比较大的值防止网络抖动导致的失败</li>\n<li>禁用unclean的broker leader选举</li>\n<li>关闭consumer的自动提交位移</li>\n</ul>\n<h2 id=\"producer对TCP连接的管理\"><a href=\"#producer对TCP连接的管理\" class=\"headerlink\" title=\"producer对TCP连接的管理\"></a>producer对TCP连接的管理</h2><ul>\n<li>创建producer时，它会连接bootstrap.servers的所有Broker</li>\n<li>producer会定时请求更新元数据，判断到连接未建立则会触发创建</li>\n<li>发送数据时，同上</li>\n<li>关闭有两种，用户主动关闭，空链路被kafka释放</li>\n</ul>\n<h2 id=\"拦截器\"><a href=\"#拦截器\" class=\"headerlink\" title=\"拦截器\"></a>拦截器</h2><ul>\n<li>可用于客户端监控、端到端监控、消息审计等；</li>\n<li>producer可在send之前、send完收到ack触发拦截方法；</li>\n<li>消费者可在消费前、消费后commit触发拦截方法；</li>\n</ul>\n<h2 id=\"consumer-offsets\"><a href=\"#consumer-offsets\" class=\"headerlink\" title=\"__consumer_offsets\"></a>__consumer_offsets</h2><ul>\n<li>早期版本将消费者位移数据保存在zookeeper，但高频的读写zookeeper使得其成为瓶颈点</li>\n<li>保存的记录为key/value，key为<code>&lt;Group ID, 主题名, 分区号&gt;</code>，消息体为位移数据</li>\n<li>当kafka集群的第一个consumer启动时，kafka会自动创建位移主题</li>\n<li>kafka使用compact策略定期删除过期的位移数据，防止撑爆硬盘</li>\n</ul>\n<h2 id=\"consumer-group\"><a href=\"#consumer-group\" class=\"headerlink\" title=\"consumer group\"></a>consumer group</h2><ul>\n<li>consumer提交位移时，其实是向coordinator所在broker提交位移</li>\n<li>消费者组注册、成员管理也是由coordinator管理</li>\n<li>如何确定消费者组的coordinator<ul>\n<li>partitionId=Math.abs(groupId.hashCode() % __consumer_offsets的总分区数)</li>\n<li>找出给分区leader副本所在的broker</li>\n</ul>\n</li>\n<li>大部分重平衡都是由于consumer被认为已经挂掉被kafka剔除组导致的，如何防止？<ul>\n<li>延长会话<ul>\n<li>session.timeout.ms建议设为6秒，延长会话存活时间防止被误认为consumer死亡</li>\n<li>heartbeat.interval.ms建议设为2秒，值越小能越快感知进入重平衡</li>\n<li><strong>以上两值，consumer被认为死亡至少经历了3次心跳</strong></li>\n</ul>\n</li>\n<li>延长消费时间<ul>\n<li>max.poll.interval.ms，两次poll的间隔如果大于这个值consumer会主动离开组，这可能是消费逻辑太重导致的，适当延长该值</li>\n</ul>\n</li>\n<li>排查是否FULL GC</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"消费者端多线程设计（KafkaConsumer为单线程）\"><a href=\"#消费者端多线程设计（KafkaConsumer为单线程）\" class=\"headerlink\" title=\"消费者端多线程设计（KafkaConsumer为单线程）\"></a>消费者端多线程设计（KafkaConsumer为单线程）</h2><ul>\n<li>主线程负责消费数据提交位移，心跳线程负责探活</li>\n<li>KafkaConsumer不是线程安全的</li>\n<li>方案1：消费者端多个线程，每个线程是一个KafkaConsumer（受限于topic_partition分区数）</li>\n<li>方案2：消费者端一个KafkaConsumer线程，poll到的消息丢给线程池消费（可能导致消息重复消费、不利于提交位移）</li>\n</ul>\n<h2 id=\"CommitFailedException\"><a href=\"#CommitFailedException\" class=\"headerlink\" title=\"CommitFailedException\"></a>CommitFailedException</h2><ul>\n<li>poll之后的消费时间超过max.poll.interval.ms，consumer触发LeaveGroup，此时必然会提交位移失败（0.10.1.0版本之后），解决方案<ul>\n<li>优化消费逻辑</li>\n<li>增加max.poll.interval.ms</li>\n<li>减少max.poll.records</li>\n<li>消费者端使用多线程消费（但引入多线程提交位移的负责度）</li>\n</ul>\n</li>\n<li>消费者组和standalone的消费者的groupid冲突，也会导致这个错误</li>\n</ul>\n<h2 id=\"消费者管理TCP连接\"><a href=\"#消费者管理TCP连接\" class=\"headerlink\" title=\"消费者管理TCP连接\"></a>消费者管理TCP连接</h2><ul>\n<li>创建KafkaConsumer时不会创建TCP连接，以下3个时机才会发起TCP连接<ul>\n<li>发起 FindCoordinator 请求时（发给负载最小的Broker，使用完后关闭）</li>\n<li>连接协调者时（连接coordinator）=&gt; 心跳、Rebalance相关</li>\n<li>消费数据时（消费要消费的leader副本所在broker）=&gt; 数据消费、元数据相关</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"消费者组位移\"><a href=\"#消费者组位移\" class=\"headerlink\" title=\"消费者组位移\"></a>消费者组位移</h2><ul>\n<li>自动提交可能会导致重复消费，假设每5秒自动提交一次，在两次提交中间发生重平衡就会导致这个问题</li>\n<li>commitSync会阻塞消费者，失败时会自动重试</li>\n<li>commitAsync是异步操作，而且可以带回调，失败了不重试（因为此时位移值已经不是最新的了）</li>\n<li>大部分情况用异步提交，在consumer要关闭前用同步提交</li>\n<li>kafka支持一次取多消息如5000条，每消费100条手动提交一次位移</li>\n</ul>\n<h2 id=\"consumer-group的消费监控\"><a href=\"#consumer-group的消费监控\" class=\"headerlink\" title=\"consumer group的消费监控\"></a>consumer group的消费监控</h2><p>consumer lag指的是滞后未消费的消息数。假如生产了100W条消息，但当下只消费了80W条，那么lag为20W条。监控方法有三种：kafka的consumers-group脚本、comsumer的java api、自带的jmx监控指标（优选）。</p>\n<h2 id=\"副本机制\"><a href=\"#副本机制\" class=\"headerlink\" title=\"副本机制\"></a>副本机制</h2><p>kafka的replica本质是一个只能追加写（append）的日志。kafka在创建分区时，会根据replica参数创建多个分区副本，分区副本分leader副本和follower副本两种，分布在不同的broker，他们的关系如下图：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/70912772-a02c8980-204f-11ea-8643-b0d48cf9741f.png\" alt=\"image\"></p>\n<p>针对具体一分区的读/写，都会定位到leader副本。follower副本并不向外提供读取的功能，它们的作用只会在leader副本crash时进行重新选举用到。kafka的副本，没有类似于其他分布式系统的一些好处：</p>\n<ul>\n<li>副本可提供读，读的能力得到扩充；</li>\n<li>可根据客户端地理位置分配距离较近的副本提供读，加速读取。</li>\n</ul>\n<p>但kafka的副本也规避了不能read-your-writes的问题。如果写到分区A，但读的是分区B，分区A、B是异步同步，此时读B可能读不到最新的数据，如果保证能读到即时更新则为read-your-writes。</p>\n<p>kafka维护了一个ISR副本集合，领导副本重新选举时从这个集合中进行选择（normal情况），leader副本必会存在ISR集合中。follower副本与leader副本的时间差若小于replica.lag.time.max.ms则会被加到ISR集合，否则会被从ISR集合中踢出。极端情况下，ISR集合可能为空，这意味着leader副本crash了且所有follower副本都“落后”了replica.lag.time.max.ms时间，这种情况意味着丢失数据较严重。此时进行的领导者选举称作unclean选举，需要unclean.leader.election.enable为true时才开启。</p>\n<h2 id=\"broker的请求处理模型\"><a href=\"#broker的请求处理模型\" class=\"headerlink\" title=\"broker的请求处理模型\"></a>broker的请求处理模型</h2><p>broker的socket模型为<a href=\"http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\" target=\"_blank\" rel=\"noopener\">reactor模型</a>，reactor负责accept请求，然后dispatch给不同的worker进行处理，大致如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/70974586-0e6e5c00-20e3-11ea-8b6f-061ba7136691.png\" alt=\"image\"></p>\n<p>专栏提到更细致的线程模型如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/70974621-234aef80-20e3-11ea-9465-ae83e6d74c63.png\" alt=\"image\"></p>\n<p>（专栏的这张图片有不严谨之处，最终的响应队列如何能直接返回结果给客户端呢？）</p>\n<p>网络线程池read()完数据，生产给共享队列，IO线程池取数据消费。请求分两种：一种是数据类，一种是控制类。数据类比如PRODUCE、FETCH等请求，需要落盘或读盘，比较特殊的是当PRODUCE请求的ack设置为all时，在当前leader副本数据落盘后还需要等待其他follower副本落盘成功的消息才返回给客户端，此类PRODUCE请求会被放置到purgatory队列中（延迟队列）。控制类请求有诸如角色变更、停止replica。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72348031-69ac6200-3714-11ea-87c9-d445e7349d01.png\" alt=\"image\"></p>\n<p>（matt33博客的这张图比较靠谱）</p>\n<p>数据类、控制类实质上是两套不同的处理流程（可简单理解为两个抽象队列），他们各自有acceptor、网络线程池、IO线程池，即他们的入端口都是不同的。</p>\n<h2 id=\"kafka重平衡\"><a href=\"#kafka重平衡\" class=\"headerlink\" title=\"kafka重平衡\"></a>kafka重平衡</h2><p>什么情况下会触发消费者组(consumer group)的重平衡：</p>\n<ul>\n<li>新的消费者通过指定group.id加入组</li>\n<li>已有的消费退出组（主动退出、崩溃导致的心跳timeout）</li>\n<li>消费者组关联的分区数、主题数发生变化</li>\n</ul>\n<p>consumer group的重平衡，需要broker端的协调者组件协调，kafka内部实现了一个状态机协助状态转移：<br><img src=\"https://user-images.githubusercontent.com/4915189/71159642-fcc2bb00-2280-11ea-83c9-3674506d08aa.png\" alt=\"image\"></p>\n<ul>\n<li>进入PreparingRebalance，意味着触发了重平衡，所有消费者都需要重新参与一次重平衡</li>\n<li>Stable意味着重平衡完成</li>\n<li>Dead意味着这个组的一些元数据被清除了</li>\n</ul>\n<p>kafka内部维护了一个_consumer_offsets的topic，一个consumer group消费的全部主题的offset数据，存在该topic的同一个partition，该partition的leader副本所在broker，即为该group的协调者。</p>\n<p>从consumer的视角来看，它们参与重平衡的过程如下：</p>\n<ul>\n<li>程序刚启动，或者收到了协调者组件含<strong>REBALANCE_IN_PROGRESS</strong>的心跳response（如果是这种情况需要先把当前未提交的位移数据提交）</li>\n<li>向协调者组件发起加入组(JoinGroup)请求，协调者组件会回复ACK信号；特殊的是，一般第一个发起JoinGroup的consumer会被协调者组件选为leader consumer，协调者组件回复的ACK会携带上所有发起JoinGroup的consumer信息</li>\n<li>向协调者组件发起SyncGroup请求，leader consumer的请求会带上分区分配方案，其余的consumer则是一个空消息</li>\n<li>协调者组件将重平衡分配方案回复给每个consumer</li>\n</ul>\n<p>对分区消费的并行度有疑问，查资料后整理如下：<br><img src=\"https://user-images.githubusercontent.com/4915189/71161512-727c5600-2284-11ea-816a-0488b3d93976.png\" alt=\"image\"></p>\n<p>一个topic下的一个分区只能由一个consumer消费，但反之并不成立，一个consumer可能分配到多个topic_partition。假设分组订阅的topic下的partition总数为N，消费者组的消费者数最好不要超过N，多出来的消费者不会分配topic_partition是一种浪费。</p>\n<h2 id=\"kafka的控制器（controller）\"><a href=\"#kafka的控制器（controller）\" class=\"headerlink\" title=\"kafka的控制器（controller）\"></a>kafka的控制器（controller）</h2><p>在Zookeeper的协助下协调和管理整个Kafka集群。多个Broker竞争创建zookeeper的/controller，第一个创建成功的即为controller；当现有的controller宕机时，各broker监听到该事件触发重新选举（创建/controller）。它主要有以下职责：</p>\n<ul>\n<li>主题管理（创建、删除、增加分区）</li>\n<li>分区重分配</li>\n<li>preferred领导者选举（避免部分broker负载过重而提供的一种更换leader的方案）</li>\n<li>集群成员管理（新增broker、broker主动关闭、broker宕机，/broker/ids/下的临时节点）</li>\n<li>元数据服务（从zookeeper同步最新元数据，同步最新元数据给其他broker）</li>\n</ul>\n<p>其内部线程设计如下：<br><img src=\"https://user-images.githubusercontent.com/4915189/71415497-f4122080-2696-11ea-92b9-4060d033b866.png\" alt=\"image\"></p>\n<ul>\n<li>多个zookeeper事件（异步处理）放到queue，由单线程顺序处理防止竞态；</li>\n<li>控制类请求有另外一条通道，将比queue中的事件高优处理，如StopReplica请求；</li>\n</ul>\n<h2 id=\"高水位和Leader-Epoch\"><a href=\"#高水位和Leader-Epoch\" class=\"headerlink\" title=\"高水位和Leader Epoch\"></a>高水位和Leader Epoch</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71415605-769ae000-2697-11ea-92a9-faa2fc36bca0.png\" alt=\"image\"></p>\n<ul>\n<li>高水位（high water mask，简称HW）：表征已提交消息和未提交消息的分界，这里的未提交是指该message未被全部follower副本replicate——大于等于HW的均未被replicate<ul>\n<li>leader副本的HW即为分区的HW</li>\n<li>follower副本的HW表征其与leader副本的同步情况，其值 = min(收到的leader的HW, follower的LEO)</li>\n</ul>\n</li>\n<li>日志末端位移（log end offset，简称LEO）：表征待写入消息的位置位移，新的消息来临时将写入LEO指向的位置，然后LEO自增1<ul>\n<li>leader副本同时保存有follower的LEO，用途：leader的HW = min(缓存的follower的LEO，leader的LEO)</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431213-50af2300-270b-11ea-8af6-8146d902e255.png\" alt=\"image\"></p>\n<ul>\n<li>当producer生产消息0时，leader的LEO被设为1</li>\n<li>此时follower来fetch消息（offset为0），leader更新remote LEO为0（offset的值），leader的HW更新为min(remote LEO, leader LEO)即为0</li>\n<li>follower收到fetch的消息0，LEO自增1，更新HW为min(follower的LEO，leader的HW)，即为0</li>\n<li>follower继续fetch消息（offset为1），leader更新remote LEO为1（offset的值），leader的HW更新为min(remote LEO, leader LEO)即为1</li>\n<li>follower收到fetch的空消息（leader没有新消息了），更新HW为min(follower的LEO，leader的HW)，即为1</li>\n</ul>\n<p>可以看到，leader的HW需要在第二次RPC时才更新，且在HW更新的response返回给follower前若follower宕机，则follower重启后LEO会被截断为HW导致未提交的消息丢失，此时若leader也正好宕机则会导致消息的彻底丢失，如下图：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431323-0c705280-270c-11ea-92c0-de96d67b89ce.png\" alt=\"image\"></p>\n<p><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation\" target=\"_blank\" rel=\"noopener\">KIP-101</a>提出了利用Epoch解决该问题，follower在重启后向leader获取最新的LEO防止错误截断，如下图：<br><img src=\"https://user-images.githubusercontent.com/4915189/71431336-25790380-270c-11ea-8301-3e582ff3c1cb.png\" alt=\"image\"></p>\n<h2 id=\"常见问题\"><a href=\"#常见问题\" class=\"headerlink\" title=\"常见问题\"></a>常见问题</h2><ol>\n<li>为何使用MQ<ul>\n<li>异步通信（调用解耦、故障隔离）</li>\n<li>流量的削峰（防止流量压垮）</li>\n<li>消息的持久化（可重试，可重复消费）</li>\n</ul>\n</li>\n<li>与其他MQ的对比<ul>\n<li>RabbitMQ支持多协议，非常重量级，更适合于企业级开发</li>\n<li>Redis的MQ支持，适合于存小消息，且可能丢消息</li>\n<li>ZeroMQ是一个代码库，需要自己设计mq通信模式，可能丢消息</li>\n<li>ActiveMQ支持多协议，类似于ZeroMQ，它能够以代理人和点对点的技术实现队列</li>\n<li>kafka的显示特点：顺序写、push and pull、消息可重复消费、水平扩展、replica</li>\n</ul>\n</li>\n<li>Kafka delivery guarantee<ul>\n<li>At most once：设置producer为异步发送</li>\n<li>At least once：可能会导致消息的重复投递</li>\n<li>Exactly once：每个producer在创建时将会被分配一个PID，broker收到数据后将会检测&lt;PID, TOPIC, PARTITION&gt;对应的sequence是否增加，是则接受消息，否则丢弃消息。这种机制只能针对单个分区实现幂等，且要求producer不能宕机</li>\n</ul>\n</li>\n<li>物理上如何存储<ul>\n<li>每个topic-partition组合为一个文件夹，文件夹中存有多个segment，segment的命名为第一条消息的offset+kafka后缀，且伴随有segment的索引文件</li>\n</ul>\n</li>\n<li>push vs pull<ul>\n<li>生产时push，由于kafka是顺序追加，因此可以做较高吞吐量的写入；消费时pull，由客户端自己去决定要pull多少，不至于压垮客户端</li>\n</ul>\n</li>\n<li>topic的partition是如何分配的<ul>\n<li>假设有n个broker</li>\n<li>第i个partition的leader副本将被分配到第(i mod n)个broker</li>\n<li>第i个partition的第j个follower副本将被分配到第((i+j) mod n)个broker</li>\n</ul>\n</li>\n<li>produer的ACK机制是如何保证的<ul>\n<li>acks = all</li>\n<li>producer将消息给到leader副本，leader副本将消息写到log</li>\n<li>ISR副本中的所有follower副本PULL到新消息立即回复ACK给leader，此时消息还在内存中，这算是性能和持久化的一个折中平衡，所有follower同时挂掉的可能性很低</li>\n</ul>\n</li>\n<li>leader副本挂了是如何重新选举的<ul>\n<li>kafka并非借助zookeeper的临时节点进行重新选举的，因为如果挂掉的broker上面有多个partition将会导致zookeeper负载非常的大。其重选举是由controller角色的broker从ISR集合中挑选的broker作为新leader（具体实现待考究）</li>\n</ul>\n</li>\n<li>kafka是如何实现读写负载均衡的<ul>\n<li>partition均可能均匀的分发到各个broker</li>\n<li>partition是最小并发粒度提供读写，不至于使流量集中压在一台broker上</li>\n</ul>\n</li>\n<li>kafka在网络传输层面的优化<ul>\n<li>producer并发每次send调用都将消息发送到broker，而是按时间或量积攒后批处理发到broker</li>\n<li>broker也不是每收到一条消息就flush落盘，而是先写page cache，如果生产、消费速率相当此时消费者可能从cache直接取到消息绕开读盘，其缺点也由replica机制规避</li>\n<li>kafka使用sendfile调用实现segment传输的zero copy</li>\n<li>produce、consume传输的都是压缩的数据</li>\n<li>kafka支持avro、protocol buffer等序列化方式对消息进行序列化，进一步减少传输的数据量大小</li>\n</ul>\n</li>\n<li>kafka的事务保障<ul>\n<li>跨session的幂等写入，producer中间故障后恢复重写依然可以保证幂等</li>\n<li>跨session的事务恢复，producer中间故障后恢复的新实例可以保证旧事务的commit或abort</li>\n<li>跨多个topic-partition的写入，要么全部成功，要么全部失败，不会有中间状态</li>\n<li>注意事项<ul>\n<li>需要在producer的配置文件配置唯一的transaction.id</li>\n<li>consumer不保证一个已commit的事务的所有消息都会被消费，原因有：consumer不一定订阅全部topic，consumer可以使用seek从任意位置消费</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"最终总结\"><a href=\"#最终总结\" class=\"headerlink\" title=\"最终总结\"></a>最终总结</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71614560-5a42fa00-2be7-11ea-9a9f-f30a025b6381.png\" alt=\"image\"></p>\n","site":{"data":{}},"excerpt":"<p>本文是极客时间专栏《Kafka核心技术与实战》的阅读笔记。</p>","more":"<h2 id=\"Kafka的三层模型\"><a href=\"#Kafka的三层模型\" class=\"headerlink\" title=\"Kafka的三层模型\"></a>Kafka的三层模型</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/70886991-c6363780-2017-11ea-9b16-c455e0daf769.png\" alt=\"image\"></p>\n<ul>\n<li>第一层：主题Topic。主题是承载消息的逻辑容器，物理上通过多个分区来实现。</li>\n<li>第二层：分区Partition。一个主题的消息按规则分散（比如轮询、哈希）存储在多个分区，单个分区内的消息是有序的，分区间的消息没有顺序关系。分区还分为leader和follower，leader才对外提供服务（producer写入、consumer消费）并记录消息位移offset，follower用于灾备。消费者以一个组（consumer group）的方式消费多个分区的数据，分配每个消费者消费哪些分区leader的过程称为rebalance，每个消费者自行记录单个分区的消费位移（consumer offset）。</li>\n<li>第三层：消息record。存储在分区内的最小单元信息。</li>\n</ul>\n<h2 id=\"Kafka的几个重要版本\"><a href=\"#Kafka的几个重要版本\" class=\"headerlink\" title=\"Kafka的几个重要版本\"></a>Kafka的几个重要版本</h2><ul>\n<li>0.9.0.0版本：增加基础安全认证，使用Java重写消费API，引入Kafka Connect</li>\n<li>0.11.0.0版本：幂等性Producer API、事务API，对Kafka消息格式做了重构</li>\n</ul>\n<h2 id=\"kafka的重要参数\"><a href=\"#kafka的重要参数\" class=\"headerlink\" title=\"kafka的重要参数\"></a>kafka的重要参数</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/70970163-9b5fe800-20d8-11ea-955d-1949f4889d4f.png\" alt=\"image\"><br><img src=\"https://user-images.githubusercontent.com/4915189/70970212-bc283d80-20d8-11ea-9c1d-1e4bd5772adf.png\" alt=\"image\"></p>\n<h2 id=\"分区策略\"><a href=\"#分区策略\" class=\"headerlink\" title=\"分区策略\"></a>分区策略</h2><ul>\n<li>轮询策略：轮询写到每个分区</li>\n<li>随机策略：随机写到每个分区</li>\n<li>Key-ordering策略：消息指定了key的，会被放到同一个分区，保障了单分区的有序性</li>\n</ul>\n<h2 id=\"压缩、解压策略\"><a href=\"#压缩、解压策略\" class=\"headerlink\" title=\"压缩、解压策略\"></a>压缩、解压策略</h2><p>Producer压缩、Broker保持、Consumer解压</p>\n<ul>\n<li>吞吐量：lz4 &gt; snappy &gt; zstd &amp; gzip</li>\n<li>压缩比：zstd &gt; lz4 &gt; gzip &gt; snappy</li>\n<li>带宽：snappy最多，zstd最少</li>\n<li>CPU：压缩时snappy多，解压时gzip多</li>\n</ul>\n<h2 id=\"丢消息问题\"><a href=\"#丢消息问题\" class=\"headerlink\" title=\"丢消息问题\"></a>丢消息问题</h2><ul>\n<li>producer应该使用带回调的producer.send(msg, callback)而不是producer.send(msg)，前者在丢消息可以在callback进行处理</li>\n<li>消费者应该在消费消息后再提交位移，且不要开启自动提交，而应该用自动提交；</li>\n<li>broker端应该设置factor参数，将消息多存几份防止丢失；</li>\n<li>producer设置acks = all</li>\n<li>producer设置retries为一个比较大的值防止网络抖动导致的失败</li>\n<li>禁用unclean的broker leader选举</li>\n<li>关闭consumer的自动提交位移</li>\n</ul>\n<h2 id=\"producer对TCP连接的管理\"><a href=\"#producer对TCP连接的管理\" class=\"headerlink\" title=\"producer对TCP连接的管理\"></a>producer对TCP连接的管理</h2><ul>\n<li>创建producer时，它会连接bootstrap.servers的所有Broker</li>\n<li>producer会定时请求更新元数据，判断到连接未建立则会触发创建</li>\n<li>发送数据时，同上</li>\n<li>关闭有两种，用户主动关闭，空链路被kafka释放</li>\n</ul>\n<h2 id=\"拦截器\"><a href=\"#拦截器\" class=\"headerlink\" title=\"拦截器\"></a>拦截器</h2><ul>\n<li>可用于客户端监控、端到端监控、消息审计等；</li>\n<li>producer可在send之前、send完收到ack触发拦截方法；</li>\n<li>消费者可在消费前、消费后commit触发拦截方法；</li>\n</ul>\n<h2 id=\"consumer-offsets\"><a href=\"#consumer-offsets\" class=\"headerlink\" title=\"__consumer_offsets\"></a>__consumer_offsets</h2><ul>\n<li>早期版本将消费者位移数据保存在zookeeper，但高频的读写zookeeper使得其成为瓶颈点</li>\n<li>保存的记录为key/value，key为<code>&lt;Group ID, 主题名, 分区号&gt;</code>，消息体为位移数据</li>\n<li>当kafka集群的第一个consumer启动时，kafka会自动创建位移主题</li>\n<li>kafka使用compact策略定期删除过期的位移数据，防止撑爆硬盘</li>\n</ul>\n<h2 id=\"consumer-group\"><a href=\"#consumer-group\" class=\"headerlink\" title=\"consumer group\"></a>consumer group</h2><ul>\n<li>consumer提交位移时，其实是向coordinator所在broker提交位移</li>\n<li>消费者组注册、成员管理也是由coordinator管理</li>\n<li>如何确定消费者组的coordinator<ul>\n<li>partitionId=Math.abs(groupId.hashCode() % __consumer_offsets的总分区数)</li>\n<li>找出给分区leader副本所在的broker</li>\n</ul>\n</li>\n<li>大部分重平衡都是由于consumer被认为已经挂掉被kafka剔除组导致的，如何防止？<ul>\n<li>延长会话<ul>\n<li>session.timeout.ms建议设为6秒，延长会话存活时间防止被误认为consumer死亡</li>\n<li>heartbeat.interval.ms建议设为2秒，值越小能越快感知进入重平衡</li>\n<li><strong>以上两值，consumer被认为死亡至少经历了3次心跳</strong></li>\n</ul>\n</li>\n<li>延长消费时间<ul>\n<li>max.poll.interval.ms，两次poll的间隔如果大于这个值consumer会主动离开组，这可能是消费逻辑太重导致的，适当延长该值</li>\n</ul>\n</li>\n<li>排查是否FULL GC</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"消费者端多线程设计（KafkaConsumer为单线程）\"><a href=\"#消费者端多线程设计（KafkaConsumer为单线程）\" class=\"headerlink\" title=\"消费者端多线程设计（KafkaConsumer为单线程）\"></a>消费者端多线程设计（KafkaConsumer为单线程）</h2><ul>\n<li>主线程负责消费数据提交位移，心跳线程负责探活</li>\n<li>KafkaConsumer不是线程安全的</li>\n<li>方案1：消费者端多个线程，每个线程是一个KafkaConsumer（受限于topic_partition分区数）</li>\n<li>方案2：消费者端一个KafkaConsumer线程，poll到的消息丢给线程池消费（可能导致消息重复消费、不利于提交位移）</li>\n</ul>\n<h2 id=\"CommitFailedException\"><a href=\"#CommitFailedException\" class=\"headerlink\" title=\"CommitFailedException\"></a>CommitFailedException</h2><ul>\n<li>poll之后的消费时间超过max.poll.interval.ms，consumer触发LeaveGroup，此时必然会提交位移失败（0.10.1.0版本之后），解决方案<ul>\n<li>优化消费逻辑</li>\n<li>增加max.poll.interval.ms</li>\n<li>减少max.poll.records</li>\n<li>消费者端使用多线程消费（但引入多线程提交位移的负责度）</li>\n</ul>\n</li>\n<li>消费者组和standalone的消费者的groupid冲突，也会导致这个错误</li>\n</ul>\n<h2 id=\"消费者管理TCP连接\"><a href=\"#消费者管理TCP连接\" class=\"headerlink\" title=\"消费者管理TCP连接\"></a>消费者管理TCP连接</h2><ul>\n<li>创建KafkaConsumer时不会创建TCP连接，以下3个时机才会发起TCP连接<ul>\n<li>发起 FindCoordinator 请求时（发给负载最小的Broker，使用完后关闭）</li>\n<li>连接协调者时（连接coordinator）=&gt; 心跳、Rebalance相关</li>\n<li>消费数据时（消费要消费的leader副本所在broker）=&gt; 数据消费、元数据相关</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"消费者组位移\"><a href=\"#消费者组位移\" class=\"headerlink\" title=\"消费者组位移\"></a>消费者组位移</h2><ul>\n<li>自动提交可能会导致重复消费，假设每5秒自动提交一次，在两次提交中间发生重平衡就会导致这个问题</li>\n<li>commitSync会阻塞消费者，失败时会自动重试</li>\n<li>commitAsync是异步操作，而且可以带回调，失败了不重试（因为此时位移值已经不是最新的了）</li>\n<li>大部分情况用异步提交，在consumer要关闭前用同步提交</li>\n<li>kafka支持一次取多消息如5000条，每消费100条手动提交一次位移</li>\n</ul>\n<h2 id=\"consumer-group的消费监控\"><a href=\"#consumer-group的消费监控\" class=\"headerlink\" title=\"consumer group的消费监控\"></a>consumer group的消费监控</h2><p>consumer lag指的是滞后未消费的消息数。假如生产了100W条消息，但当下只消费了80W条，那么lag为20W条。监控方法有三种：kafka的consumers-group脚本、comsumer的java api、自带的jmx监控指标（优选）。</p>\n<h2 id=\"副本机制\"><a href=\"#副本机制\" class=\"headerlink\" title=\"副本机制\"></a>副本机制</h2><p>kafka的replica本质是一个只能追加写（append）的日志。kafka在创建分区时，会根据replica参数创建多个分区副本，分区副本分leader副本和follower副本两种，分布在不同的broker，他们的关系如下图：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/70912772-a02c8980-204f-11ea-8643-b0d48cf9741f.png\" alt=\"image\"></p>\n<p>针对具体一分区的读/写，都会定位到leader副本。follower副本并不向外提供读取的功能，它们的作用只会在leader副本crash时进行重新选举用到。kafka的副本，没有类似于其他分布式系统的一些好处：</p>\n<ul>\n<li>副本可提供读，读的能力得到扩充；</li>\n<li>可根据客户端地理位置分配距离较近的副本提供读，加速读取。</li>\n</ul>\n<p>但kafka的副本也规避了不能read-your-writes的问题。如果写到分区A，但读的是分区B，分区A、B是异步同步，此时读B可能读不到最新的数据，如果保证能读到即时更新则为read-your-writes。</p>\n<p>kafka维护了一个ISR副本集合，领导副本重新选举时从这个集合中进行选择（normal情况），leader副本必会存在ISR集合中。follower副本与leader副本的时间差若小于replica.lag.time.max.ms则会被加到ISR集合，否则会被从ISR集合中踢出。极端情况下，ISR集合可能为空，这意味着leader副本crash了且所有follower副本都“落后”了replica.lag.time.max.ms时间，这种情况意味着丢失数据较严重。此时进行的领导者选举称作unclean选举，需要unclean.leader.election.enable为true时才开启。</p>\n<h2 id=\"broker的请求处理模型\"><a href=\"#broker的请求处理模型\" class=\"headerlink\" title=\"broker的请求处理模型\"></a>broker的请求处理模型</h2><p>broker的socket模型为<a href=\"http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\" target=\"_blank\" rel=\"noopener\">reactor模型</a>，reactor负责accept请求，然后dispatch给不同的worker进行处理，大致如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/70974586-0e6e5c00-20e3-11ea-8b6f-061ba7136691.png\" alt=\"image\"></p>\n<p>专栏提到更细致的线程模型如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/70974621-234aef80-20e3-11ea-9465-ae83e6d74c63.png\" alt=\"image\"></p>\n<p>（专栏的这张图片有不严谨之处，最终的响应队列如何能直接返回结果给客户端呢？）</p>\n<p>网络线程池read()完数据，生产给共享队列，IO线程池取数据消费。请求分两种：一种是数据类，一种是控制类。数据类比如PRODUCE、FETCH等请求，需要落盘或读盘，比较特殊的是当PRODUCE请求的ack设置为all时，在当前leader副本数据落盘后还需要等待其他follower副本落盘成功的消息才返回给客户端，此类PRODUCE请求会被放置到purgatory队列中（延迟队列）。控制类请求有诸如角色变更、停止replica。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72348031-69ac6200-3714-11ea-87c9-d445e7349d01.png\" alt=\"image\"></p>\n<p>（matt33博客的这张图比较靠谱）</p>\n<p>数据类、控制类实质上是两套不同的处理流程（可简单理解为两个抽象队列），他们各自有acceptor、网络线程池、IO线程池，即他们的入端口都是不同的。</p>\n<h2 id=\"kafka重平衡\"><a href=\"#kafka重平衡\" class=\"headerlink\" title=\"kafka重平衡\"></a>kafka重平衡</h2><p>什么情况下会触发消费者组(consumer group)的重平衡：</p>\n<ul>\n<li>新的消费者通过指定group.id加入组</li>\n<li>已有的消费退出组（主动退出、崩溃导致的心跳timeout）</li>\n<li>消费者组关联的分区数、主题数发生变化</li>\n</ul>\n<p>consumer group的重平衡，需要broker端的协调者组件协调，kafka内部实现了一个状态机协助状态转移：<br><img src=\"https://user-images.githubusercontent.com/4915189/71159642-fcc2bb00-2280-11ea-83c9-3674506d08aa.png\" alt=\"image\"></p>\n<ul>\n<li>进入PreparingRebalance，意味着触发了重平衡，所有消费者都需要重新参与一次重平衡</li>\n<li>Stable意味着重平衡完成</li>\n<li>Dead意味着这个组的一些元数据被清除了</li>\n</ul>\n<p>kafka内部维护了一个_consumer_offsets的topic，一个consumer group消费的全部主题的offset数据，存在该topic的同一个partition，该partition的leader副本所在broker，即为该group的协调者。</p>\n<p>从consumer的视角来看，它们参与重平衡的过程如下：</p>\n<ul>\n<li>程序刚启动，或者收到了协调者组件含<strong>REBALANCE_IN_PROGRESS</strong>的心跳response（如果是这种情况需要先把当前未提交的位移数据提交）</li>\n<li>向协调者组件发起加入组(JoinGroup)请求，协调者组件会回复ACK信号；特殊的是，一般第一个发起JoinGroup的consumer会被协调者组件选为leader consumer，协调者组件回复的ACK会携带上所有发起JoinGroup的consumer信息</li>\n<li>向协调者组件发起SyncGroup请求，leader consumer的请求会带上分区分配方案，其余的consumer则是一个空消息</li>\n<li>协调者组件将重平衡分配方案回复给每个consumer</li>\n</ul>\n<p>对分区消费的并行度有疑问，查资料后整理如下：<br><img src=\"https://user-images.githubusercontent.com/4915189/71161512-727c5600-2284-11ea-816a-0488b3d93976.png\" alt=\"image\"></p>\n<p>一个topic下的一个分区只能由一个consumer消费，但反之并不成立，一个consumer可能分配到多个topic_partition。假设分组订阅的topic下的partition总数为N，消费者组的消费者数最好不要超过N，多出来的消费者不会分配topic_partition是一种浪费。</p>\n<h2 id=\"kafka的控制器（controller）\"><a href=\"#kafka的控制器（controller）\" class=\"headerlink\" title=\"kafka的控制器（controller）\"></a>kafka的控制器（controller）</h2><p>在Zookeeper的协助下协调和管理整个Kafka集群。多个Broker竞争创建zookeeper的/controller，第一个创建成功的即为controller；当现有的controller宕机时，各broker监听到该事件触发重新选举（创建/controller）。它主要有以下职责：</p>\n<ul>\n<li>主题管理（创建、删除、增加分区）</li>\n<li>分区重分配</li>\n<li>preferred领导者选举（避免部分broker负载过重而提供的一种更换leader的方案）</li>\n<li>集群成员管理（新增broker、broker主动关闭、broker宕机，/broker/ids/下的临时节点）</li>\n<li>元数据服务（从zookeeper同步最新元数据，同步最新元数据给其他broker）</li>\n</ul>\n<p>其内部线程设计如下：<br><img src=\"https://user-images.githubusercontent.com/4915189/71415497-f4122080-2696-11ea-92b9-4060d033b866.png\" alt=\"image\"></p>\n<ul>\n<li>多个zookeeper事件（异步处理）放到queue，由单线程顺序处理防止竞态；</li>\n<li>控制类请求有另外一条通道，将比queue中的事件高优处理，如StopReplica请求；</li>\n</ul>\n<h2 id=\"高水位和Leader-Epoch\"><a href=\"#高水位和Leader-Epoch\" class=\"headerlink\" title=\"高水位和Leader Epoch\"></a>高水位和Leader Epoch</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71415605-769ae000-2697-11ea-92a9-faa2fc36bca0.png\" alt=\"image\"></p>\n<ul>\n<li>高水位（high water mask，简称HW）：表征已提交消息和未提交消息的分界，这里的未提交是指该message未被全部follower副本replicate——大于等于HW的均未被replicate<ul>\n<li>leader副本的HW即为分区的HW</li>\n<li>follower副本的HW表征其与leader副本的同步情况，其值 = min(收到的leader的HW, follower的LEO)</li>\n</ul>\n</li>\n<li>日志末端位移（log end offset，简称LEO）：表征待写入消息的位置位移，新的消息来临时将写入LEO指向的位置，然后LEO自增1<ul>\n<li>leader副本同时保存有follower的LEO，用途：leader的HW = min(缓存的follower的LEO，leader的LEO)</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431213-50af2300-270b-11ea-8af6-8146d902e255.png\" alt=\"image\"></p>\n<ul>\n<li>当producer生产消息0时，leader的LEO被设为1</li>\n<li>此时follower来fetch消息（offset为0），leader更新remote LEO为0（offset的值），leader的HW更新为min(remote LEO, leader LEO)即为0</li>\n<li>follower收到fetch的消息0，LEO自增1，更新HW为min(follower的LEO，leader的HW)，即为0</li>\n<li>follower继续fetch消息（offset为1），leader更新remote LEO为1（offset的值），leader的HW更新为min(remote LEO, leader LEO)即为1</li>\n<li>follower收到fetch的空消息（leader没有新消息了），更新HW为min(follower的LEO，leader的HW)，即为1</li>\n</ul>\n<p>可以看到，leader的HW需要在第二次RPC时才更新，且在HW更新的response返回给follower前若follower宕机，则follower重启后LEO会被截断为HW导致未提交的消息丢失，此时若leader也正好宕机则会导致消息的彻底丢失，如下图：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/71431323-0c705280-270c-11ea-92c0-de96d67b89ce.png\" alt=\"image\"></p>\n<p><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation\" target=\"_blank\" rel=\"noopener\">KIP-101</a>提出了利用Epoch解决该问题，follower在重启后向leader获取最新的LEO防止错误截断，如下图：<br><img src=\"https://user-images.githubusercontent.com/4915189/71431336-25790380-270c-11ea-8301-3e582ff3c1cb.png\" alt=\"image\"></p>\n<h2 id=\"常见问题\"><a href=\"#常见问题\" class=\"headerlink\" title=\"常见问题\"></a>常见问题</h2><ol>\n<li>为何使用MQ<ul>\n<li>异步通信（调用解耦、故障隔离）</li>\n<li>流量的削峰（防止流量压垮）</li>\n<li>消息的持久化（可重试，可重复消费）</li>\n</ul>\n</li>\n<li>与其他MQ的对比<ul>\n<li>RabbitMQ支持多协议，非常重量级，更适合于企业级开发</li>\n<li>Redis的MQ支持，适合于存小消息，且可能丢消息</li>\n<li>ZeroMQ是一个代码库，需要自己设计mq通信模式，可能丢消息</li>\n<li>ActiveMQ支持多协议，类似于ZeroMQ，它能够以代理人和点对点的技术实现队列</li>\n<li>kafka的显示特点：顺序写、push and pull、消息可重复消费、水平扩展、replica</li>\n</ul>\n</li>\n<li>Kafka delivery guarantee<ul>\n<li>At most once：设置producer为异步发送</li>\n<li>At least once：可能会导致消息的重复投递</li>\n<li>Exactly once：每个producer在创建时将会被分配一个PID，broker收到数据后将会检测&lt;PID, TOPIC, PARTITION&gt;对应的sequence是否增加，是则接受消息，否则丢弃消息。这种机制只能针对单个分区实现幂等，且要求producer不能宕机</li>\n</ul>\n</li>\n<li>物理上如何存储<ul>\n<li>每个topic-partition组合为一个文件夹，文件夹中存有多个segment，segment的命名为第一条消息的offset+kafka后缀，且伴随有segment的索引文件</li>\n</ul>\n</li>\n<li>push vs pull<ul>\n<li>生产时push，由于kafka是顺序追加，因此可以做较高吞吐量的写入；消费时pull，由客户端自己去决定要pull多少，不至于压垮客户端</li>\n</ul>\n</li>\n<li>topic的partition是如何分配的<ul>\n<li>假设有n个broker</li>\n<li>第i个partition的leader副本将被分配到第(i mod n)个broker</li>\n<li>第i个partition的第j个follower副本将被分配到第((i+j) mod n)个broker</li>\n</ul>\n</li>\n<li>produer的ACK机制是如何保证的<ul>\n<li>acks = all</li>\n<li>producer将消息给到leader副本，leader副本将消息写到log</li>\n<li>ISR副本中的所有follower副本PULL到新消息立即回复ACK给leader，此时消息还在内存中，这算是性能和持久化的一个折中平衡，所有follower同时挂掉的可能性很低</li>\n</ul>\n</li>\n<li>leader副本挂了是如何重新选举的<ul>\n<li>kafka并非借助zookeeper的临时节点进行重新选举的，因为如果挂掉的broker上面有多个partition将会导致zookeeper负载非常的大。其重选举是由controller角色的broker从ISR集合中挑选的broker作为新leader（具体实现待考究）</li>\n</ul>\n</li>\n<li>kafka是如何实现读写负载均衡的<ul>\n<li>partition均可能均匀的分发到各个broker</li>\n<li>partition是最小并发粒度提供读写，不至于使流量集中压在一台broker上</li>\n</ul>\n</li>\n<li>kafka在网络传输层面的优化<ul>\n<li>producer并发每次send调用都将消息发送到broker，而是按时间或量积攒后批处理发到broker</li>\n<li>broker也不是每收到一条消息就flush落盘，而是先写page cache，如果生产、消费速率相当此时消费者可能从cache直接取到消息绕开读盘，其缺点也由replica机制规避</li>\n<li>kafka使用sendfile调用实现segment传输的zero copy</li>\n<li>produce、consume传输的都是压缩的数据</li>\n<li>kafka支持avro、protocol buffer等序列化方式对消息进行序列化，进一步减少传输的数据量大小</li>\n</ul>\n</li>\n<li>kafka的事务保障<ul>\n<li>跨session的幂等写入，producer中间故障后恢复重写依然可以保证幂等</li>\n<li>跨session的事务恢复，producer中间故障后恢复的新实例可以保证旧事务的commit或abort</li>\n<li>跨多个topic-partition的写入，要么全部成功，要么全部失败，不会有中间状态</li>\n<li>注意事项<ul>\n<li>需要在producer的配置文件配置唯一的transaction.id</li>\n<li>consumer不保证一个已commit的事务的所有消息都会被消费，原因有：consumer不一定订阅全部topic，consumer可以使用seek从任意位置消费</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"最终总结\"><a href=\"#最终总结\" class=\"headerlink\" title=\"最终总结\"></a>最终总结</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71614560-5a42fa00-2be7-11ea-9a9f-f30a025b6381.png\" alt=\"image\"></p>"},{"title":"《左耳听风》笔记：弹性设计篇","date":"2020-01-14T14:43:57.000Z","comments":1,"_content":"\n极客时间《左耳听风》专栏读书笔记之弹性设计篇。\n\n<!--more-->\n\n## 隔离设计 bulkheads\n\n按服务类型进行隔离\n- 域名隔离\n- 服务器隔离\n- 数据库隔离\n\n按请求做分离\n- 完全资源隔离（资源共享度低、实现复杂度低）\n- 共享服务、共享数据（隔离度低、占用成本低）\n- 折中：共享服务、数据分区\n\n## 异步通讯设计 asynchronous\n\n为什么需要异步通讯？先看看同步通讯的缺点：\n- 影响吞吐量、浪费资源：A同步调用B，B同步调用C，当同步调用的链条太长时，系统中响应最慢的那个结点决定了整体调用时间，拖慢了处理快的结点，影响系统吞吐量，浪费上游调用方的资源（因为需要保存context等待结果返回）\n- 只能一对一调用，出故障时极容易出现多米诺骨牌效应（雪崩）\n\n异步通讯有哪几种模式：\n- sender调用receiver，receiver立即返回一个确认信号。紧接着sender间隔轮询receiver，检测调用是否完成；另一种办法是，sender在调用时携带上callback地址，receiver处理完成后主动调用callback地址，sender弱依赖receiver\n- 把sender当成publisher，receiver当成subscriber，subscriber主动订阅publisher的消息，收到消息后触发相应逻辑。如库存服务订阅订单服务，在订单生成后的30分钟内锁住该一定件数的库存。对于publisher，它只需要subscriber的ACK即可，不需要知道subscriber干成什么样，此时subscriber弱依赖publisher\n- sender => broker => receiver。增加一个broker中间件，sender和receiver间的依赖彻底打破，sender只管生产消息到broker，receiver只管从broker消费消息。同步调用本质上是一种函数调用，有入参、需要保存context，然后等待return结果，此时sender是有状态的。broker模式是一种event driven architecture，状态下沉到broker，使得sender无状态化，它们之间交互的只有event（含data）。比如：订单服务 -> broker_a => 支付服务 => broker_b => 物流服务。\n\nbroker模式至少有以下好处：\n- 可替换：服务解耦了，只要遵循broker的消息规范，服务可任意替换\n- 隔离：服务相互隔离，其扩容、运维、开发互不影响\n- adapter：服务增加adapter相当容易（鉴权、熔断、降级、限流、日志）\n- 非阻塞：服务通过事件关联，不会相互block\n- 高吞吐：服务的吞吐量依赖关系也解开了，可各自按照服务自身的情况进行扩容。把抖动的流量变成平均流量，起到了削峰的作用\n\n但同时broker模式也带来以下坏处：\n- 观测性：业务的处理变得复杂，不像同步调用那样容易观测，需要一些辅助可视化工具\n- 事件乱序：分布式化后难以保证事件在消费时的顺序性，因此要求服务本身不依赖事件的时序来设计\n- 事务复杂：事务的处理变得复杂，可能需要二阶段提交或者退化为最终一致性\n\nbroker作为核心的中间件，必须满足以下特性：\n- 高可用；\n- 高性能而且是可水平扩展的；\n- 持久化不丢数据。\n\n## 幂等设计 idempotency\n\n用数学语言表达就是：y = f(x)，只要x值不变，y的值也不变。比如abs(x)，调用多少次得到的都是同一个值。为什么需要幂等设计？对API的调用可能存在timeout，此时有两个解决办法：\n- 系统暴露另外个接口给调用方，去查询调用是否完成\n- 系统支持重复调用，调用方检测到timeout重复调用即可\n\n以上两个方案都需要有一个全局id来标识一次调用，全局id可参考Twitter的snowflake算法，通过机房、机器、时间戳、worker数量、计数器等多参数构造全局id。\n\n对于API系统，需要有存储用于存储和查询全局id，用于判断该调用是否已完成，已完成的话直接返回。存储的全局id必须是无状态的容易扩容的，否则将成为系统的瓶颈，可以使用关系型数据库或者NoSQL服务（如MongoDB）\n\n## 服务的状态 state\n\n服务的状态无处不在，比如：\n- 多服务调用的上下文\n- 幂等调用记录的某次调用的标识ID\n- 用户的session\n\n无状态的服务stateless\n- 可随意扩容伸缩\n- 一般需要把状态下沉到分布式存储，如Redis/MySQL/ZooKeeper等\n- 为了减少服务到分布式存储的网络开销，一般还需要在每台服务上做全量缓存，内存上较为浪费\n\n有状态的服务stateful\n- data locality：状态和数据都是特定机器保存，更低的延时；更强的一致性，更高的可用性\n- 实现方式之一：sticky connection，比如持久化的长连接，这种方式容易造成服务端的负载不均衡，需要客户端配合一起实现反向压力back pressure\n- 实现方式之二：路由节点，根据元数据索引来路由到特定机器\n- 实现方式之三：摘掉路由节点，服务本身也承担路由功能，多服务之间通过gossip发现其他服务的元数据\n- 容错策略：把状态数据持久化到一个高可用的分布式存储，这样在应用重启时可以快速拉取恢复，再从其他replica节点拉取少量数据即可\n\n## 补偿事务 compensating transaction\n\nACID的可扩展性差，BASE是基于ACID的一个变种：\n- basic availability：可能出现短暂的不可用\n- soft-state：介于有状态、无状态之间，这些数据可能不是强一致的（为了提高性能）\n- eventually consistency：最终一致性\n\n亚马逊在创建订单时并不会去锁库存，因此并发创建订单是无锁的，这可能出现超卖，但能提供下单的吞吐量，不用受限于锁库存、更新库存等耗时操作。订单创建后，被并行的进行处理（异步），此时才会真正去扣减库存并发货，此时若发现库存没有了则会触发致歉邮件同时触发退款。这背后就是BASE的思想了。因此，为了实现BASE，我们需要对事物进行补偿（回滚）。业务补偿的设计有两个重点：\n\n- 努力达成业务：这意味着上游应进行重试、且服务的调用需要是幂等的\n- 如果多次尝试都无法成功则需要对事务进行补偿：调用是多服务组合的，需要有一个高可用的工作流引擎记录成功进行到哪一步，把已经成功的有影响的操作进行回滚\n\n## 重试的设计 retry\n\n- when: 什么时候需要重试\n- how: 重试多少次、重试的间隔（fail fast/exponential backoff）\n- 注意：重试要求对端服务支持幂等调用，否则会有副作用；重试逻辑也可以下沉到service mesh，也可由spring进行代理（annotation）\n\n## 熔断设计 circuit breaker\n\n![image](https://user-images.githubusercontent.com/4915189/71655359-517e2f80-2d71-11ea-82a2-3489c1d0ea2e.png)\n\n熔断器设计灵感由于电气中的保险丝，它是介于调用方和被调用方的一个安全保障。熔断器有以下三种状态：\n\n- closed：此时调用直达到调用方\n- open：此时调用直接被熔断器拒绝，当一定时间内的失败调用次数达到阈值会从closed进入此状态\n- half-open：进入open后达到一个阈值时间自动进入此状态，此时新进来的流量若能正常调用成功，则恢复到closed状态，否则重新变为open状态\n\n在设计熔断器时，有以下要点需要考虑：\n- 错误的类型：有些返回（如服务集群crash）就应该让熔断器直接进入open状态\n- 测试服务可用：与其直接进入half-open状态让真实流量来探活，还不如在切换到此状态前先调用对方的健康检查接口确保调用方的可用性\n- 手动重置：提供admin接口，便于运维人员的人为介入改变熔断器状态\n- 分区问题：有些后端服务是分区的，如分库分表，部分分区不可用不代表整个服务不可用\n\n## 限流设计 throttle\n\n限流有4个主要目\n- 保障SLA（可用性）和RT（响应时间）\n- 多租户情况下防止单一租户将资源耗尽\n- 应对突发流量，如秒杀\n- 节约成本，系统不需要时候运行在最高容量\n\n在行为上，它表现为以下几种：\n- 拒绝服务：可以拒绝掉那些请求最多的客户端，防止恶意攻击\n- 服务降级：可以把不重要服务停掉，可以只返回部分而非全量数据，可以返回缓存（牺牲一致性）\n- 特权请求：有限的资源分配给更重要的客户\n- 延时处理：要队列来缓存，达到削峰效果\n- 弹性伸缩：自动化运维对TOP5的高负载服务进行弹性伸缩\n\n限流的静态实现方式有以下几种\n- 计数器方式：请求进来+1，请求结束-1，当计数值大于M触发限流，当计数值小于N解除限流\n- 队列方式：请求积压到队列，processor一空闲就获取任务进行处理。如果需要考虑高优请求先处理，可以将队列设计成两个队列（一个高优、一个次优），多个队列可设置时间权重防止某个队列出现饥饿\n![image](https://user-images.githubusercontent.com/4915189/71948706-d5219b80-320b-11ea-887e-055f03e117d0.png)\n- 漏斗算法：请求积压到队列，processor以特定的速率取任务进行处理，不能超过这个限定的速率\n![image](https://user-images.githubusercontent.com/4915189/71948724-eb2f5c00-320b-11ea-8b45-456a4325b7ff.png)\n- 令牌桶算法：请求积压队列，processor只要能在令牌桶取到令牌就可以进行处理。处理速率受限于令牌桶的令牌数，当令牌桶积压了多数令牌，且恰好有大量待处理请求，则此时可能有一个较高的QPS\n![image](https://user-images.githubusercontent.com/4915189/71948727-f08ca680-320b-11ea-8152-9260165cdafd.png)\n\n以上几种限流方式，都需系统预设一个静态的阈值。限流的动态实现方式是基于RT（response time），实现思路如下：\n- 利用采样，或者reservoir sampling，统计一段时间的RT的P99和P90所在位置（毫秒值）\n- 如果P99和P90的时间慢于我们的期望值，将QPS进行折半限流，然后模仿TCP拥塞处理将QPS值进入慢启动，直到P99和P90又低于期望值，重新折半QPS\n\n最后，限流在设计中还应该有以下考量\n- 限流设计应在架构早期引入\n- 限流模块性能必须足够好，对流量变化需要非常敏感\n- 限流应该有手动开关供应急使用\n- 限流发送应该有事件通知运维\n- 限流发生时，对于拒绝掉的请求带上限流状态码，以供客户端做相应调整\n- 限流应让后端感知到，如设置Header，服务端可决定是否降级\n\n## 降级设计 degradation\n\n降级，本质是为了解决资源不足和访问量过大的问题。降级需要牺牲的一般有：\n- 降低一致性：流程一致性，数据一致性\n- 停止次要功能：停止不重要的功能，把资源释放出来\n- 简化功能：不再返回全量数据，而是部分数据\n\n降低一致性\n- 流程一致性：流程异步化，如果期间某个流程失败需要进行补偿\n- 数据一致性：返回缓存数据，使用cache aside缓存模式（参考[缓存套路](https://coolshell.cn/articles/17416.html)）\n\n停止次要功能\n- 优先停掉次要流量，停次要功能毕竟有损体验\n- 对用户做一些补偿，如跳转到红包页面\n\n简化功能\n- 仅返回最小可用数据\n\n设计要点\n- 定义清楚降级的条件\n- 梳理哪些业务可以牺牲\n- 降级做成配置开关化，或是通过调用参数来辨别是否降级\n- 需要客户端配合，如有些次要数据是否能不返回\n- 不是常规case，需要演练\n\n## 弹性设计的总结\n![image](https://user-images.githubusercontent.com/4915189/72056536-c4565000-3307-11ea-93bb-c1b6f88e4361.png)\n服务冗余：服务不能是单点，需要多个replica，这需要服务发现、负载均衡、动态路由、健康检查4个功能或组件\n- 负载均衡：nginx或haproxy等技术\n- 服务发现、动态路由、健康检查：Zuul作为API网关实现动态路由，Consul或Zookeeper作为服务发现\n- 自动化运维：kubernates服务调度、伸缩和故障转移\n\n服务解耦：把服务隔离开来，使其不相互影响。水平上，可业务分区（业务隔离），或用户分区（多租户；垂直上，需要异步通讯；服务编排和聚合上，需要工作流把服务串起来（如Spring或Akka的Streams）；一致性上，需要业务补偿来做反向交易\n- bulkheads模式：用户分片、业务分片、数据库拆分\n- 自包含系统：无外部服务依赖，把一组相关的微服务给拆出来\n- 异步通讯：异步通讯、消息队列、事件驱动\n- 自动化运维：需要有一个服务调用链和性能监控的监控系统\n\n服务容错：让这个架构能接受失败的设计。重试带来幂等问题，为了保障稳定性需要有限流、降级、熔断\n- 错误方面：重试设计+熔断设计+幂等设计\n- 一致性：强一致性使用两阶段提交，最终一致性使用异步通讯+事件补偿\n- 流控：限流设计+降级设计\n- 自动化运维：网关流量调度，服务监控","source":"_posts/2020-01-14-chenhao-resilience-design.md","raw":"---\ntitle: 《左耳听风》笔记：弹性设计篇\ndate: 2020-01-14 22:43:57\ntags: ['系统设计']\ncomments: true\ncategories: ['系统设计']\n---\n\n极客时间《左耳听风》专栏读书笔记之弹性设计篇。\n\n<!--more-->\n\n## 隔离设计 bulkheads\n\n按服务类型进行隔离\n- 域名隔离\n- 服务器隔离\n- 数据库隔离\n\n按请求做分离\n- 完全资源隔离（资源共享度低、实现复杂度低）\n- 共享服务、共享数据（隔离度低、占用成本低）\n- 折中：共享服务、数据分区\n\n## 异步通讯设计 asynchronous\n\n为什么需要异步通讯？先看看同步通讯的缺点：\n- 影响吞吐量、浪费资源：A同步调用B，B同步调用C，当同步调用的链条太长时，系统中响应最慢的那个结点决定了整体调用时间，拖慢了处理快的结点，影响系统吞吐量，浪费上游调用方的资源（因为需要保存context等待结果返回）\n- 只能一对一调用，出故障时极容易出现多米诺骨牌效应（雪崩）\n\n异步通讯有哪几种模式：\n- sender调用receiver，receiver立即返回一个确认信号。紧接着sender间隔轮询receiver，检测调用是否完成；另一种办法是，sender在调用时携带上callback地址，receiver处理完成后主动调用callback地址，sender弱依赖receiver\n- 把sender当成publisher，receiver当成subscriber，subscriber主动订阅publisher的消息，收到消息后触发相应逻辑。如库存服务订阅订单服务，在订单生成后的30分钟内锁住该一定件数的库存。对于publisher，它只需要subscriber的ACK即可，不需要知道subscriber干成什么样，此时subscriber弱依赖publisher\n- sender => broker => receiver。增加一个broker中间件，sender和receiver间的依赖彻底打破，sender只管生产消息到broker，receiver只管从broker消费消息。同步调用本质上是一种函数调用，有入参、需要保存context，然后等待return结果，此时sender是有状态的。broker模式是一种event driven architecture，状态下沉到broker，使得sender无状态化，它们之间交互的只有event（含data）。比如：订单服务 -> broker_a => 支付服务 => broker_b => 物流服务。\n\nbroker模式至少有以下好处：\n- 可替换：服务解耦了，只要遵循broker的消息规范，服务可任意替换\n- 隔离：服务相互隔离，其扩容、运维、开发互不影响\n- adapter：服务增加adapter相当容易（鉴权、熔断、降级、限流、日志）\n- 非阻塞：服务通过事件关联，不会相互block\n- 高吞吐：服务的吞吐量依赖关系也解开了，可各自按照服务自身的情况进行扩容。把抖动的流量变成平均流量，起到了削峰的作用\n\n但同时broker模式也带来以下坏处：\n- 观测性：业务的处理变得复杂，不像同步调用那样容易观测，需要一些辅助可视化工具\n- 事件乱序：分布式化后难以保证事件在消费时的顺序性，因此要求服务本身不依赖事件的时序来设计\n- 事务复杂：事务的处理变得复杂，可能需要二阶段提交或者退化为最终一致性\n\nbroker作为核心的中间件，必须满足以下特性：\n- 高可用；\n- 高性能而且是可水平扩展的；\n- 持久化不丢数据。\n\n## 幂等设计 idempotency\n\n用数学语言表达就是：y = f(x)，只要x值不变，y的值也不变。比如abs(x)，调用多少次得到的都是同一个值。为什么需要幂等设计？对API的调用可能存在timeout，此时有两个解决办法：\n- 系统暴露另外个接口给调用方，去查询调用是否完成\n- 系统支持重复调用，调用方检测到timeout重复调用即可\n\n以上两个方案都需要有一个全局id来标识一次调用，全局id可参考Twitter的snowflake算法，通过机房、机器、时间戳、worker数量、计数器等多参数构造全局id。\n\n对于API系统，需要有存储用于存储和查询全局id，用于判断该调用是否已完成，已完成的话直接返回。存储的全局id必须是无状态的容易扩容的，否则将成为系统的瓶颈，可以使用关系型数据库或者NoSQL服务（如MongoDB）\n\n## 服务的状态 state\n\n服务的状态无处不在，比如：\n- 多服务调用的上下文\n- 幂等调用记录的某次调用的标识ID\n- 用户的session\n\n无状态的服务stateless\n- 可随意扩容伸缩\n- 一般需要把状态下沉到分布式存储，如Redis/MySQL/ZooKeeper等\n- 为了减少服务到分布式存储的网络开销，一般还需要在每台服务上做全量缓存，内存上较为浪费\n\n有状态的服务stateful\n- data locality：状态和数据都是特定机器保存，更低的延时；更强的一致性，更高的可用性\n- 实现方式之一：sticky connection，比如持久化的长连接，这种方式容易造成服务端的负载不均衡，需要客户端配合一起实现反向压力back pressure\n- 实现方式之二：路由节点，根据元数据索引来路由到特定机器\n- 实现方式之三：摘掉路由节点，服务本身也承担路由功能，多服务之间通过gossip发现其他服务的元数据\n- 容错策略：把状态数据持久化到一个高可用的分布式存储，这样在应用重启时可以快速拉取恢复，再从其他replica节点拉取少量数据即可\n\n## 补偿事务 compensating transaction\n\nACID的可扩展性差，BASE是基于ACID的一个变种：\n- basic availability：可能出现短暂的不可用\n- soft-state：介于有状态、无状态之间，这些数据可能不是强一致的（为了提高性能）\n- eventually consistency：最终一致性\n\n亚马逊在创建订单时并不会去锁库存，因此并发创建订单是无锁的，这可能出现超卖，但能提供下单的吞吐量，不用受限于锁库存、更新库存等耗时操作。订单创建后，被并行的进行处理（异步），此时才会真正去扣减库存并发货，此时若发现库存没有了则会触发致歉邮件同时触发退款。这背后就是BASE的思想了。因此，为了实现BASE，我们需要对事物进行补偿（回滚）。业务补偿的设计有两个重点：\n\n- 努力达成业务：这意味着上游应进行重试、且服务的调用需要是幂等的\n- 如果多次尝试都无法成功则需要对事务进行补偿：调用是多服务组合的，需要有一个高可用的工作流引擎记录成功进行到哪一步，把已经成功的有影响的操作进行回滚\n\n## 重试的设计 retry\n\n- when: 什么时候需要重试\n- how: 重试多少次、重试的间隔（fail fast/exponential backoff）\n- 注意：重试要求对端服务支持幂等调用，否则会有副作用；重试逻辑也可以下沉到service mesh，也可由spring进行代理（annotation）\n\n## 熔断设计 circuit breaker\n\n![image](https://user-images.githubusercontent.com/4915189/71655359-517e2f80-2d71-11ea-82a2-3489c1d0ea2e.png)\n\n熔断器设计灵感由于电气中的保险丝，它是介于调用方和被调用方的一个安全保障。熔断器有以下三种状态：\n\n- closed：此时调用直达到调用方\n- open：此时调用直接被熔断器拒绝，当一定时间内的失败调用次数达到阈值会从closed进入此状态\n- half-open：进入open后达到一个阈值时间自动进入此状态，此时新进来的流量若能正常调用成功，则恢复到closed状态，否则重新变为open状态\n\n在设计熔断器时，有以下要点需要考虑：\n- 错误的类型：有些返回（如服务集群crash）就应该让熔断器直接进入open状态\n- 测试服务可用：与其直接进入half-open状态让真实流量来探活，还不如在切换到此状态前先调用对方的健康检查接口确保调用方的可用性\n- 手动重置：提供admin接口，便于运维人员的人为介入改变熔断器状态\n- 分区问题：有些后端服务是分区的，如分库分表，部分分区不可用不代表整个服务不可用\n\n## 限流设计 throttle\n\n限流有4个主要目\n- 保障SLA（可用性）和RT（响应时间）\n- 多租户情况下防止单一租户将资源耗尽\n- 应对突发流量，如秒杀\n- 节约成本，系统不需要时候运行在最高容量\n\n在行为上，它表现为以下几种：\n- 拒绝服务：可以拒绝掉那些请求最多的客户端，防止恶意攻击\n- 服务降级：可以把不重要服务停掉，可以只返回部分而非全量数据，可以返回缓存（牺牲一致性）\n- 特权请求：有限的资源分配给更重要的客户\n- 延时处理：要队列来缓存，达到削峰效果\n- 弹性伸缩：自动化运维对TOP5的高负载服务进行弹性伸缩\n\n限流的静态实现方式有以下几种\n- 计数器方式：请求进来+1，请求结束-1，当计数值大于M触发限流，当计数值小于N解除限流\n- 队列方式：请求积压到队列，processor一空闲就获取任务进行处理。如果需要考虑高优请求先处理，可以将队列设计成两个队列（一个高优、一个次优），多个队列可设置时间权重防止某个队列出现饥饿\n![image](https://user-images.githubusercontent.com/4915189/71948706-d5219b80-320b-11ea-887e-055f03e117d0.png)\n- 漏斗算法：请求积压到队列，processor以特定的速率取任务进行处理，不能超过这个限定的速率\n![image](https://user-images.githubusercontent.com/4915189/71948724-eb2f5c00-320b-11ea-8b45-456a4325b7ff.png)\n- 令牌桶算法：请求积压队列，processor只要能在令牌桶取到令牌就可以进行处理。处理速率受限于令牌桶的令牌数，当令牌桶积压了多数令牌，且恰好有大量待处理请求，则此时可能有一个较高的QPS\n![image](https://user-images.githubusercontent.com/4915189/71948727-f08ca680-320b-11ea-8152-9260165cdafd.png)\n\n以上几种限流方式，都需系统预设一个静态的阈值。限流的动态实现方式是基于RT（response time），实现思路如下：\n- 利用采样，或者reservoir sampling，统计一段时间的RT的P99和P90所在位置（毫秒值）\n- 如果P99和P90的时间慢于我们的期望值，将QPS进行折半限流，然后模仿TCP拥塞处理将QPS值进入慢启动，直到P99和P90又低于期望值，重新折半QPS\n\n最后，限流在设计中还应该有以下考量\n- 限流设计应在架构早期引入\n- 限流模块性能必须足够好，对流量变化需要非常敏感\n- 限流应该有手动开关供应急使用\n- 限流发送应该有事件通知运维\n- 限流发生时，对于拒绝掉的请求带上限流状态码，以供客户端做相应调整\n- 限流应让后端感知到，如设置Header，服务端可决定是否降级\n\n## 降级设计 degradation\n\n降级，本质是为了解决资源不足和访问量过大的问题。降级需要牺牲的一般有：\n- 降低一致性：流程一致性，数据一致性\n- 停止次要功能：停止不重要的功能，把资源释放出来\n- 简化功能：不再返回全量数据，而是部分数据\n\n降低一致性\n- 流程一致性：流程异步化，如果期间某个流程失败需要进行补偿\n- 数据一致性：返回缓存数据，使用cache aside缓存模式（参考[缓存套路](https://coolshell.cn/articles/17416.html)）\n\n停止次要功能\n- 优先停掉次要流量，停次要功能毕竟有损体验\n- 对用户做一些补偿，如跳转到红包页面\n\n简化功能\n- 仅返回最小可用数据\n\n设计要点\n- 定义清楚降级的条件\n- 梳理哪些业务可以牺牲\n- 降级做成配置开关化，或是通过调用参数来辨别是否降级\n- 需要客户端配合，如有些次要数据是否能不返回\n- 不是常规case，需要演练\n\n## 弹性设计的总结\n![image](https://user-images.githubusercontent.com/4915189/72056536-c4565000-3307-11ea-93bb-c1b6f88e4361.png)\n服务冗余：服务不能是单点，需要多个replica，这需要服务发现、负载均衡、动态路由、健康检查4个功能或组件\n- 负载均衡：nginx或haproxy等技术\n- 服务发现、动态路由、健康检查：Zuul作为API网关实现动态路由，Consul或Zookeeper作为服务发现\n- 自动化运维：kubernates服务调度、伸缩和故障转移\n\n服务解耦：把服务隔离开来，使其不相互影响。水平上，可业务分区（业务隔离），或用户分区（多租户；垂直上，需要异步通讯；服务编排和聚合上，需要工作流把服务串起来（如Spring或Akka的Streams）；一致性上，需要业务补偿来做反向交易\n- bulkheads模式：用户分片、业务分片、数据库拆分\n- 自包含系统：无外部服务依赖，把一组相关的微服务给拆出来\n- 异步通讯：异步通讯、消息队列、事件驱动\n- 自动化运维：需要有一个服务调用链和性能监控的监控系统\n\n服务容错：让这个架构能接受失败的设计。重试带来幂等问题，为了保障稳定性需要有限流、降级、熔断\n- 错误方面：重试设计+熔断设计+幂等设计\n- 一致性：强一致性使用两阶段提交，最终一致性使用异步通讯+事件补偿\n- 流控：限流设计+降级设计\n- 自动化运维：网关流量调度，服务监控","slug":"chenhao-resilience-design","published":1,"updated":"2022-08-09T15:02:00.663Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14v003xigu8isolajcu","content":"<p>极客时间《左耳听风》专栏读书笔记之弹性设计篇。</p>\n<a id=\"more\"></a>\n<h2 id=\"隔离设计-bulkheads\"><a href=\"#隔离设计-bulkheads\" class=\"headerlink\" title=\"隔离设计 bulkheads\"></a>隔离设计 bulkheads</h2><p>按服务类型进行隔离</p>\n<ul>\n<li>域名隔离</li>\n<li>服务器隔离</li>\n<li>数据库隔离</li>\n</ul>\n<p>按请求做分离</p>\n<ul>\n<li>完全资源隔离（资源共享度低、实现复杂度低）</li>\n<li>共享服务、共享数据（隔离度低、占用成本低）</li>\n<li>折中：共享服务、数据分区</li>\n</ul>\n<h2 id=\"异步通讯设计-asynchronous\"><a href=\"#异步通讯设计-asynchronous\" class=\"headerlink\" title=\"异步通讯设计 asynchronous\"></a>异步通讯设计 asynchronous</h2><p>为什么需要异步通讯？先看看同步通讯的缺点：</p>\n<ul>\n<li>影响吞吐量、浪费资源：A同步调用B，B同步调用C，当同步调用的链条太长时，系统中响应最慢的那个结点决定了整体调用时间，拖慢了处理快的结点，影响系统吞吐量，浪费上游调用方的资源（因为需要保存context等待结果返回）</li>\n<li>只能一对一调用，出故障时极容易出现多米诺骨牌效应（雪崩）</li>\n</ul>\n<p>异步通讯有哪几种模式：</p>\n<ul>\n<li>sender调用receiver，receiver立即返回一个确认信号。紧接着sender间隔轮询receiver，检测调用是否完成；另一种办法是，sender在调用时携带上callback地址，receiver处理完成后主动调用callback地址，sender弱依赖receiver</li>\n<li>把sender当成publisher，receiver当成subscriber，subscriber主动订阅publisher的消息，收到消息后触发相应逻辑。如库存服务订阅订单服务，在订单生成后的30分钟内锁住该一定件数的库存。对于publisher，它只需要subscriber的ACK即可，不需要知道subscriber干成什么样，此时subscriber弱依赖publisher</li>\n<li>sender =&gt; broker =&gt; receiver。增加一个broker中间件，sender和receiver间的依赖彻底打破，sender只管生产消息到broker，receiver只管从broker消费消息。同步调用本质上是一种函数调用，有入参、需要保存context，然后等待return结果，此时sender是有状态的。broker模式是一种event driven architecture，状态下沉到broker，使得sender无状态化，它们之间交互的只有event（含data）。比如：订单服务 -&gt; broker_a =&gt; 支付服务 =&gt; broker_b =&gt; 物流服务。</li>\n</ul>\n<p>broker模式至少有以下好处：</p>\n<ul>\n<li>可替换：服务解耦了，只要遵循broker的消息规范，服务可任意替换</li>\n<li>隔离：服务相互隔离，其扩容、运维、开发互不影响</li>\n<li>adapter：服务增加adapter相当容易（鉴权、熔断、降级、限流、日志）</li>\n<li>非阻塞：服务通过事件关联，不会相互block</li>\n<li>高吞吐：服务的吞吐量依赖关系也解开了，可各自按照服务自身的情况进行扩容。把抖动的流量变成平均流量，起到了削峰的作用</li>\n</ul>\n<p>但同时broker模式也带来以下坏处：</p>\n<ul>\n<li>观测性：业务的处理变得复杂，不像同步调用那样容易观测，需要一些辅助可视化工具</li>\n<li>事件乱序：分布式化后难以保证事件在消费时的顺序性，因此要求服务本身不依赖事件的时序来设计</li>\n<li>事务复杂：事务的处理变得复杂，可能需要二阶段提交或者退化为最终一致性</li>\n</ul>\n<p>broker作为核心的中间件，必须满足以下特性：</p>\n<ul>\n<li>高可用；</li>\n<li>高性能而且是可水平扩展的；</li>\n<li>持久化不丢数据。</li>\n</ul>\n<h2 id=\"幂等设计-idempotency\"><a href=\"#幂等设计-idempotency\" class=\"headerlink\" title=\"幂等设计 idempotency\"></a>幂等设计 idempotency</h2><p>用数学语言表达就是：y = f(x)，只要x值不变，y的值也不变。比如abs(x)，调用多少次得到的都是同一个值。为什么需要幂等设计？对API的调用可能存在timeout，此时有两个解决办法：</p>\n<ul>\n<li>系统暴露另外个接口给调用方，去查询调用是否完成</li>\n<li>系统支持重复调用，调用方检测到timeout重复调用即可</li>\n</ul>\n<p>以上两个方案都需要有一个全局id来标识一次调用，全局id可参考Twitter的snowflake算法，通过机房、机器、时间戳、worker数量、计数器等多参数构造全局id。</p>\n<p>对于API系统，需要有存储用于存储和查询全局id，用于判断该调用是否已完成，已完成的话直接返回。存储的全局id必须是无状态的容易扩容的，否则将成为系统的瓶颈，可以使用关系型数据库或者NoSQL服务（如MongoDB）</p>\n<h2 id=\"服务的状态-state\"><a href=\"#服务的状态-state\" class=\"headerlink\" title=\"服务的状态 state\"></a>服务的状态 state</h2><p>服务的状态无处不在，比如：</p>\n<ul>\n<li>多服务调用的上下文</li>\n<li>幂等调用记录的某次调用的标识ID</li>\n<li>用户的session</li>\n</ul>\n<p>无状态的服务stateless</p>\n<ul>\n<li>可随意扩容伸缩</li>\n<li>一般需要把状态下沉到分布式存储，如Redis/MySQL/ZooKeeper等</li>\n<li>为了减少服务到分布式存储的网络开销，一般还需要在每台服务上做全量缓存，内存上较为浪费</li>\n</ul>\n<p>有状态的服务stateful</p>\n<ul>\n<li>data locality：状态和数据都是特定机器保存，更低的延时；更强的一致性，更高的可用性</li>\n<li>实现方式之一：sticky connection，比如持久化的长连接，这种方式容易造成服务端的负载不均衡，需要客户端配合一起实现反向压力back pressure</li>\n<li>实现方式之二：路由节点，根据元数据索引来路由到特定机器</li>\n<li>实现方式之三：摘掉路由节点，服务本身也承担路由功能，多服务之间通过gossip发现其他服务的元数据</li>\n<li>容错策略：把状态数据持久化到一个高可用的分布式存储，这样在应用重启时可以快速拉取恢复，再从其他replica节点拉取少量数据即可</li>\n</ul>\n<h2 id=\"补偿事务-compensating-transaction\"><a href=\"#补偿事务-compensating-transaction\" class=\"headerlink\" title=\"补偿事务 compensating transaction\"></a>补偿事务 compensating transaction</h2><p>ACID的可扩展性差，BASE是基于ACID的一个变种：</p>\n<ul>\n<li>basic availability：可能出现短暂的不可用</li>\n<li>soft-state：介于有状态、无状态之间，这些数据可能不是强一致的（为了提高性能）</li>\n<li>eventually consistency：最终一致性</li>\n</ul>\n<p>亚马逊在创建订单时并不会去锁库存，因此并发创建订单是无锁的，这可能出现超卖，但能提供下单的吞吐量，不用受限于锁库存、更新库存等耗时操作。订单创建后，被并行的进行处理（异步），此时才会真正去扣减库存并发货，此时若发现库存没有了则会触发致歉邮件同时触发退款。这背后就是BASE的思想了。因此，为了实现BASE，我们需要对事物进行补偿（回滚）。业务补偿的设计有两个重点：</p>\n<ul>\n<li>努力达成业务：这意味着上游应进行重试、且服务的调用需要是幂等的</li>\n<li>如果多次尝试都无法成功则需要对事务进行补偿：调用是多服务组合的，需要有一个高可用的工作流引擎记录成功进行到哪一步，把已经成功的有影响的操作进行回滚</li>\n</ul>\n<h2 id=\"重试的设计-retry\"><a href=\"#重试的设计-retry\" class=\"headerlink\" title=\"重试的设计 retry\"></a>重试的设计 retry</h2><ul>\n<li>when: 什么时候需要重试</li>\n<li>how: 重试多少次、重试的间隔（fail fast/exponential backoff）</li>\n<li>注意：重试要求对端服务支持幂等调用，否则会有副作用；重试逻辑也可以下沉到service mesh，也可由spring进行代理（annotation）</li>\n</ul>\n<h2 id=\"熔断设计-circuit-breaker\"><a href=\"#熔断设计-circuit-breaker\" class=\"headerlink\" title=\"熔断设计 circuit breaker\"></a>熔断设计 circuit breaker</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71655359-517e2f80-2d71-11ea-82a2-3489c1d0ea2e.png\" alt=\"image\"></p>\n<p>熔断器设计灵感由于电气中的保险丝，它是介于调用方和被调用方的一个安全保障。熔断器有以下三种状态：</p>\n<ul>\n<li>closed：此时调用直达到调用方</li>\n<li>open：此时调用直接被熔断器拒绝，当一定时间内的失败调用次数达到阈值会从closed进入此状态</li>\n<li>half-open：进入open后达到一个阈值时间自动进入此状态，此时新进来的流量若能正常调用成功，则恢复到closed状态，否则重新变为open状态</li>\n</ul>\n<p>在设计熔断器时，有以下要点需要考虑：</p>\n<ul>\n<li>错误的类型：有些返回（如服务集群crash）就应该让熔断器直接进入open状态</li>\n<li>测试服务可用：与其直接进入half-open状态让真实流量来探活，还不如在切换到此状态前先调用对方的健康检查接口确保调用方的可用性</li>\n<li>手动重置：提供admin接口，便于运维人员的人为介入改变熔断器状态</li>\n<li>分区问题：有些后端服务是分区的，如分库分表，部分分区不可用不代表整个服务不可用</li>\n</ul>\n<h2 id=\"限流设计-throttle\"><a href=\"#限流设计-throttle\" class=\"headerlink\" title=\"限流设计 throttle\"></a>限流设计 throttle</h2><p>限流有4个主要目</p>\n<ul>\n<li>保障SLA（可用性）和RT（响应时间）</li>\n<li>多租户情况下防止单一租户将资源耗尽</li>\n<li>应对突发流量，如秒杀</li>\n<li>节约成本，系统不需要时候运行在最高容量</li>\n</ul>\n<p>在行为上，它表现为以下几种：</p>\n<ul>\n<li>拒绝服务：可以拒绝掉那些请求最多的客户端，防止恶意攻击</li>\n<li>服务降级：可以把不重要服务停掉，可以只返回部分而非全量数据，可以返回缓存（牺牲一致性）</li>\n<li>特权请求：有限的资源分配给更重要的客户</li>\n<li>延时处理：要队列来缓存，达到削峰效果</li>\n<li>弹性伸缩：自动化运维对TOP5的高负载服务进行弹性伸缩</li>\n</ul>\n<p>限流的静态实现方式有以下几种</p>\n<ul>\n<li>计数器方式：请求进来+1，请求结束-1，当计数值大于M触发限流，当计数值小于N解除限流</li>\n<li>队列方式：请求积压到队列，processor一空闲就获取任务进行处理。如果需要考虑高优请求先处理，可以将队列设计成两个队列（一个高优、一个次优），多个队列可设置时间权重防止某个队列出现饥饿<br><img src=\"https://user-images.githubusercontent.com/4915189/71948706-d5219b80-320b-11ea-887e-055f03e117d0.png\" alt=\"image\"></li>\n<li>漏斗算法：请求积压到队列，processor以特定的速率取任务进行处理，不能超过这个限定的速率<br><img src=\"https://user-images.githubusercontent.com/4915189/71948724-eb2f5c00-320b-11ea-8b45-456a4325b7ff.png\" alt=\"image\"></li>\n<li>令牌桶算法：请求积压队列，processor只要能在令牌桶取到令牌就可以进行处理。处理速率受限于令牌桶的令牌数，当令牌桶积压了多数令牌，且恰好有大量待处理请求，则此时可能有一个较高的QPS<br><img src=\"https://user-images.githubusercontent.com/4915189/71948727-f08ca680-320b-11ea-8152-9260165cdafd.png\" alt=\"image\"></li>\n</ul>\n<p>以上几种限流方式，都需系统预设一个静态的阈值。限流的动态实现方式是基于RT（response time），实现思路如下：</p>\n<ul>\n<li>利用采样，或者reservoir sampling，统计一段时间的RT的P99和P90所在位置（毫秒值）</li>\n<li>如果P99和P90的时间慢于我们的期望值，将QPS进行折半限流，然后模仿TCP拥塞处理将QPS值进入慢启动，直到P99和P90又低于期望值，重新折半QPS</li>\n</ul>\n<p>最后，限流在设计中还应该有以下考量</p>\n<ul>\n<li>限流设计应在架构早期引入</li>\n<li>限流模块性能必须足够好，对流量变化需要非常敏感</li>\n<li>限流应该有手动开关供应急使用</li>\n<li>限流发送应该有事件通知运维</li>\n<li>限流发生时，对于拒绝掉的请求带上限流状态码，以供客户端做相应调整</li>\n<li>限流应让后端感知到，如设置Header，服务端可决定是否降级</li>\n</ul>\n<h2 id=\"降级设计-degradation\"><a href=\"#降级设计-degradation\" class=\"headerlink\" title=\"降级设计 degradation\"></a>降级设计 degradation</h2><p>降级，本质是为了解决资源不足和访问量过大的问题。降级需要牺牲的一般有：</p>\n<ul>\n<li>降低一致性：流程一致性，数据一致性</li>\n<li>停止次要功能：停止不重要的功能，把资源释放出来</li>\n<li>简化功能：不再返回全量数据，而是部分数据</li>\n</ul>\n<p>降低一致性</p>\n<ul>\n<li>流程一致性：流程异步化，如果期间某个流程失败需要进行补偿</li>\n<li>数据一致性：返回缓存数据，使用cache aside缓存模式（参考<a href=\"https://coolshell.cn/articles/17416.html\" target=\"_blank\" rel=\"noopener\">缓存套路</a>）</li>\n</ul>\n<p>停止次要功能</p>\n<ul>\n<li>优先停掉次要流量，停次要功能毕竟有损体验</li>\n<li>对用户做一些补偿，如跳转到红包页面</li>\n</ul>\n<p>简化功能</p>\n<ul>\n<li>仅返回最小可用数据</li>\n</ul>\n<p>设计要点</p>\n<ul>\n<li>定义清楚降级的条件</li>\n<li>梳理哪些业务可以牺牲</li>\n<li>降级做成配置开关化，或是通过调用参数来辨别是否降级</li>\n<li>需要客户端配合，如有些次要数据是否能不返回</li>\n<li>不是常规case，需要演练</li>\n</ul>\n<h2 id=\"弹性设计的总结\"><a href=\"#弹性设计的总结\" class=\"headerlink\" title=\"弹性设计的总结\"></a>弹性设计的总结</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/72056536-c4565000-3307-11ea-93bb-c1b6f88e4361.png\" alt=\"image\"><br>服务冗余：服务不能是单点，需要多个replica，这需要服务发现、负载均衡、动态路由、健康检查4个功能或组件</p>\n<ul>\n<li>负载均衡：nginx或haproxy等技术</li>\n<li>服务发现、动态路由、健康检查：Zuul作为API网关实现动态路由，Consul或Zookeeper作为服务发现</li>\n<li>自动化运维：kubernates服务调度、伸缩和故障转移</li>\n</ul>\n<p>服务解耦：把服务隔离开来，使其不相互影响。水平上，可业务分区（业务隔离），或用户分区（多租户；垂直上，需要异步通讯；服务编排和聚合上，需要工作流把服务串起来（如Spring或Akka的Streams）；一致性上，需要业务补偿来做反向交易</p>\n<ul>\n<li>bulkheads模式：用户分片、业务分片、数据库拆分</li>\n<li>自包含系统：无外部服务依赖，把一组相关的微服务给拆出来</li>\n<li>异步通讯：异步通讯、消息队列、事件驱动</li>\n<li>自动化运维：需要有一个服务调用链和性能监控的监控系统</li>\n</ul>\n<p>服务容错：让这个架构能接受失败的设计。重试带来幂等问题，为了保障稳定性需要有限流、降级、熔断</p>\n<ul>\n<li>错误方面：重试设计+熔断设计+幂等设计</li>\n<li>一致性：强一致性使用两阶段提交，最终一致性使用异步通讯+事件补偿</li>\n<li>流控：限流设计+降级设计</li>\n<li>自动化运维：网关流量调度，服务监控</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>极客时间《左耳听风》专栏读书笔记之弹性设计篇。</p>","more":"<h2 id=\"隔离设计-bulkheads\"><a href=\"#隔离设计-bulkheads\" class=\"headerlink\" title=\"隔离设计 bulkheads\"></a>隔离设计 bulkheads</h2><p>按服务类型进行隔离</p>\n<ul>\n<li>域名隔离</li>\n<li>服务器隔离</li>\n<li>数据库隔离</li>\n</ul>\n<p>按请求做分离</p>\n<ul>\n<li>完全资源隔离（资源共享度低、实现复杂度低）</li>\n<li>共享服务、共享数据（隔离度低、占用成本低）</li>\n<li>折中：共享服务、数据分区</li>\n</ul>\n<h2 id=\"异步通讯设计-asynchronous\"><a href=\"#异步通讯设计-asynchronous\" class=\"headerlink\" title=\"异步通讯设计 asynchronous\"></a>异步通讯设计 asynchronous</h2><p>为什么需要异步通讯？先看看同步通讯的缺点：</p>\n<ul>\n<li>影响吞吐量、浪费资源：A同步调用B，B同步调用C，当同步调用的链条太长时，系统中响应最慢的那个结点决定了整体调用时间，拖慢了处理快的结点，影响系统吞吐量，浪费上游调用方的资源（因为需要保存context等待结果返回）</li>\n<li>只能一对一调用，出故障时极容易出现多米诺骨牌效应（雪崩）</li>\n</ul>\n<p>异步通讯有哪几种模式：</p>\n<ul>\n<li>sender调用receiver，receiver立即返回一个确认信号。紧接着sender间隔轮询receiver，检测调用是否完成；另一种办法是，sender在调用时携带上callback地址，receiver处理完成后主动调用callback地址，sender弱依赖receiver</li>\n<li>把sender当成publisher，receiver当成subscriber，subscriber主动订阅publisher的消息，收到消息后触发相应逻辑。如库存服务订阅订单服务，在订单生成后的30分钟内锁住该一定件数的库存。对于publisher，它只需要subscriber的ACK即可，不需要知道subscriber干成什么样，此时subscriber弱依赖publisher</li>\n<li>sender =&gt; broker =&gt; receiver。增加一个broker中间件，sender和receiver间的依赖彻底打破，sender只管生产消息到broker，receiver只管从broker消费消息。同步调用本质上是一种函数调用，有入参、需要保存context，然后等待return结果，此时sender是有状态的。broker模式是一种event driven architecture，状态下沉到broker，使得sender无状态化，它们之间交互的只有event（含data）。比如：订单服务 -&gt; broker_a =&gt; 支付服务 =&gt; broker_b =&gt; 物流服务。</li>\n</ul>\n<p>broker模式至少有以下好处：</p>\n<ul>\n<li>可替换：服务解耦了，只要遵循broker的消息规范，服务可任意替换</li>\n<li>隔离：服务相互隔离，其扩容、运维、开发互不影响</li>\n<li>adapter：服务增加adapter相当容易（鉴权、熔断、降级、限流、日志）</li>\n<li>非阻塞：服务通过事件关联，不会相互block</li>\n<li>高吞吐：服务的吞吐量依赖关系也解开了，可各自按照服务自身的情况进行扩容。把抖动的流量变成平均流量，起到了削峰的作用</li>\n</ul>\n<p>但同时broker模式也带来以下坏处：</p>\n<ul>\n<li>观测性：业务的处理变得复杂，不像同步调用那样容易观测，需要一些辅助可视化工具</li>\n<li>事件乱序：分布式化后难以保证事件在消费时的顺序性，因此要求服务本身不依赖事件的时序来设计</li>\n<li>事务复杂：事务的处理变得复杂，可能需要二阶段提交或者退化为最终一致性</li>\n</ul>\n<p>broker作为核心的中间件，必须满足以下特性：</p>\n<ul>\n<li>高可用；</li>\n<li>高性能而且是可水平扩展的；</li>\n<li>持久化不丢数据。</li>\n</ul>\n<h2 id=\"幂等设计-idempotency\"><a href=\"#幂等设计-idempotency\" class=\"headerlink\" title=\"幂等设计 idempotency\"></a>幂等设计 idempotency</h2><p>用数学语言表达就是：y = f(x)，只要x值不变，y的值也不变。比如abs(x)，调用多少次得到的都是同一个值。为什么需要幂等设计？对API的调用可能存在timeout，此时有两个解决办法：</p>\n<ul>\n<li>系统暴露另外个接口给调用方，去查询调用是否完成</li>\n<li>系统支持重复调用，调用方检测到timeout重复调用即可</li>\n</ul>\n<p>以上两个方案都需要有一个全局id来标识一次调用，全局id可参考Twitter的snowflake算法，通过机房、机器、时间戳、worker数量、计数器等多参数构造全局id。</p>\n<p>对于API系统，需要有存储用于存储和查询全局id，用于判断该调用是否已完成，已完成的话直接返回。存储的全局id必须是无状态的容易扩容的，否则将成为系统的瓶颈，可以使用关系型数据库或者NoSQL服务（如MongoDB）</p>\n<h2 id=\"服务的状态-state\"><a href=\"#服务的状态-state\" class=\"headerlink\" title=\"服务的状态 state\"></a>服务的状态 state</h2><p>服务的状态无处不在，比如：</p>\n<ul>\n<li>多服务调用的上下文</li>\n<li>幂等调用记录的某次调用的标识ID</li>\n<li>用户的session</li>\n</ul>\n<p>无状态的服务stateless</p>\n<ul>\n<li>可随意扩容伸缩</li>\n<li>一般需要把状态下沉到分布式存储，如Redis/MySQL/ZooKeeper等</li>\n<li>为了减少服务到分布式存储的网络开销，一般还需要在每台服务上做全量缓存，内存上较为浪费</li>\n</ul>\n<p>有状态的服务stateful</p>\n<ul>\n<li>data locality：状态和数据都是特定机器保存，更低的延时；更强的一致性，更高的可用性</li>\n<li>实现方式之一：sticky connection，比如持久化的长连接，这种方式容易造成服务端的负载不均衡，需要客户端配合一起实现反向压力back pressure</li>\n<li>实现方式之二：路由节点，根据元数据索引来路由到特定机器</li>\n<li>实现方式之三：摘掉路由节点，服务本身也承担路由功能，多服务之间通过gossip发现其他服务的元数据</li>\n<li>容错策略：把状态数据持久化到一个高可用的分布式存储，这样在应用重启时可以快速拉取恢复，再从其他replica节点拉取少量数据即可</li>\n</ul>\n<h2 id=\"补偿事务-compensating-transaction\"><a href=\"#补偿事务-compensating-transaction\" class=\"headerlink\" title=\"补偿事务 compensating transaction\"></a>补偿事务 compensating transaction</h2><p>ACID的可扩展性差，BASE是基于ACID的一个变种：</p>\n<ul>\n<li>basic availability：可能出现短暂的不可用</li>\n<li>soft-state：介于有状态、无状态之间，这些数据可能不是强一致的（为了提高性能）</li>\n<li>eventually consistency：最终一致性</li>\n</ul>\n<p>亚马逊在创建订单时并不会去锁库存，因此并发创建订单是无锁的，这可能出现超卖，但能提供下单的吞吐量，不用受限于锁库存、更新库存等耗时操作。订单创建后，被并行的进行处理（异步），此时才会真正去扣减库存并发货，此时若发现库存没有了则会触发致歉邮件同时触发退款。这背后就是BASE的思想了。因此，为了实现BASE，我们需要对事物进行补偿（回滚）。业务补偿的设计有两个重点：</p>\n<ul>\n<li>努力达成业务：这意味着上游应进行重试、且服务的调用需要是幂等的</li>\n<li>如果多次尝试都无法成功则需要对事务进行补偿：调用是多服务组合的，需要有一个高可用的工作流引擎记录成功进行到哪一步，把已经成功的有影响的操作进行回滚</li>\n</ul>\n<h2 id=\"重试的设计-retry\"><a href=\"#重试的设计-retry\" class=\"headerlink\" title=\"重试的设计 retry\"></a>重试的设计 retry</h2><ul>\n<li>when: 什么时候需要重试</li>\n<li>how: 重试多少次、重试的间隔（fail fast/exponential backoff）</li>\n<li>注意：重试要求对端服务支持幂等调用，否则会有副作用；重试逻辑也可以下沉到service mesh，也可由spring进行代理（annotation）</li>\n</ul>\n<h2 id=\"熔断设计-circuit-breaker\"><a href=\"#熔断设计-circuit-breaker\" class=\"headerlink\" title=\"熔断设计 circuit breaker\"></a>熔断设计 circuit breaker</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/71655359-517e2f80-2d71-11ea-82a2-3489c1d0ea2e.png\" alt=\"image\"></p>\n<p>熔断器设计灵感由于电气中的保险丝，它是介于调用方和被调用方的一个安全保障。熔断器有以下三种状态：</p>\n<ul>\n<li>closed：此时调用直达到调用方</li>\n<li>open：此时调用直接被熔断器拒绝，当一定时间内的失败调用次数达到阈值会从closed进入此状态</li>\n<li>half-open：进入open后达到一个阈值时间自动进入此状态，此时新进来的流量若能正常调用成功，则恢复到closed状态，否则重新变为open状态</li>\n</ul>\n<p>在设计熔断器时，有以下要点需要考虑：</p>\n<ul>\n<li>错误的类型：有些返回（如服务集群crash）就应该让熔断器直接进入open状态</li>\n<li>测试服务可用：与其直接进入half-open状态让真实流量来探活，还不如在切换到此状态前先调用对方的健康检查接口确保调用方的可用性</li>\n<li>手动重置：提供admin接口，便于运维人员的人为介入改变熔断器状态</li>\n<li>分区问题：有些后端服务是分区的，如分库分表，部分分区不可用不代表整个服务不可用</li>\n</ul>\n<h2 id=\"限流设计-throttle\"><a href=\"#限流设计-throttle\" class=\"headerlink\" title=\"限流设计 throttle\"></a>限流设计 throttle</h2><p>限流有4个主要目</p>\n<ul>\n<li>保障SLA（可用性）和RT（响应时间）</li>\n<li>多租户情况下防止单一租户将资源耗尽</li>\n<li>应对突发流量，如秒杀</li>\n<li>节约成本，系统不需要时候运行在最高容量</li>\n</ul>\n<p>在行为上，它表现为以下几种：</p>\n<ul>\n<li>拒绝服务：可以拒绝掉那些请求最多的客户端，防止恶意攻击</li>\n<li>服务降级：可以把不重要服务停掉，可以只返回部分而非全量数据，可以返回缓存（牺牲一致性）</li>\n<li>特权请求：有限的资源分配给更重要的客户</li>\n<li>延时处理：要队列来缓存，达到削峰效果</li>\n<li>弹性伸缩：自动化运维对TOP5的高负载服务进行弹性伸缩</li>\n</ul>\n<p>限流的静态实现方式有以下几种</p>\n<ul>\n<li>计数器方式：请求进来+1，请求结束-1，当计数值大于M触发限流，当计数值小于N解除限流</li>\n<li>队列方式：请求积压到队列，processor一空闲就获取任务进行处理。如果需要考虑高优请求先处理，可以将队列设计成两个队列（一个高优、一个次优），多个队列可设置时间权重防止某个队列出现饥饿<br><img src=\"https://user-images.githubusercontent.com/4915189/71948706-d5219b80-320b-11ea-887e-055f03e117d0.png\" alt=\"image\"></li>\n<li>漏斗算法：请求积压到队列，processor以特定的速率取任务进行处理，不能超过这个限定的速率<br><img src=\"https://user-images.githubusercontent.com/4915189/71948724-eb2f5c00-320b-11ea-8b45-456a4325b7ff.png\" alt=\"image\"></li>\n<li>令牌桶算法：请求积压队列，processor只要能在令牌桶取到令牌就可以进行处理。处理速率受限于令牌桶的令牌数，当令牌桶积压了多数令牌，且恰好有大量待处理请求，则此时可能有一个较高的QPS<br><img src=\"https://user-images.githubusercontent.com/4915189/71948727-f08ca680-320b-11ea-8152-9260165cdafd.png\" alt=\"image\"></li>\n</ul>\n<p>以上几种限流方式，都需系统预设一个静态的阈值。限流的动态实现方式是基于RT（response time），实现思路如下：</p>\n<ul>\n<li>利用采样，或者reservoir sampling，统计一段时间的RT的P99和P90所在位置（毫秒值）</li>\n<li>如果P99和P90的时间慢于我们的期望值，将QPS进行折半限流，然后模仿TCP拥塞处理将QPS值进入慢启动，直到P99和P90又低于期望值，重新折半QPS</li>\n</ul>\n<p>最后，限流在设计中还应该有以下考量</p>\n<ul>\n<li>限流设计应在架构早期引入</li>\n<li>限流模块性能必须足够好，对流量变化需要非常敏感</li>\n<li>限流应该有手动开关供应急使用</li>\n<li>限流发送应该有事件通知运维</li>\n<li>限流发生时，对于拒绝掉的请求带上限流状态码，以供客户端做相应调整</li>\n<li>限流应让后端感知到，如设置Header，服务端可决定是否降级</li>\n</ul>\n<h2 id=\"降级设计-degradation\"><a href=\"#降级设计-degradation\" class=\"headerlink\" title=\"降级设计 degradation\"></a>降级设计 degradation</h2><p>降级，本质是为了解决资源不足和访问量过大的问题。降级需要牺牲的一般有：</p>\n<ul>\n<li>降低一致性：流程一致性，数据一致性</li>\n<li>停止次要功能：停止不重要的功能，把资源释放出来</li>\n<li>简化功能：不再返回全量数据，而是部分数据</li>\n</ul>\n<p>降低一致性</p>\n<ul>\n<li>流程一致性：流程异步化，如果期间某个流程失败需要进行补偿</li>\n<li>数据一致性：返回缓存数据，使用cache aside缓存模式（参考<a href=\"https://coolshell.cn/articles/17416.html\" target=\"_blank\" rel=\"noopener\">缓存套路</a>）</li>\n</ul>\n<p>停止次要功能</p>\n<ul>\n<li>优先停掉次要流量，停次要功能毕竟有损体验</li>\n<li>对用户做一些补偿，如跳转到红包页面</li>\n</ul>\n<p>简化功能</p>\n<ul>\n<li>仅返回最小可用数据</li>\n</ul>\n<p>设计要点</p>\n<ul>\n<li>定义清楚降级的条件</li>\n<li>梳理哪些业务可以牺牲</li>\n<li>降级做成配置开关化，或是通过调用参数来辨别是否降级</li>\n<li>需要客户端配合，如有些次要数据是否能不返回</li>\n<li>不是常规case，需要演练</li>\n</ul>\n<h2 id=\"弹性设计的总结\"><a href=\"#弹性设计的总结\" class=\"headerlink\" title=\"弹性设计的总结\"></a>弹性设计的总结</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/72056536-c4565000-3307-11ea-93bb-c1b6f88e4361.png\" alt=\"image\"><br>服务冗余：服务不能是单点，需要多个replica，这需要服务发现、负载均衡、动态路由、健康检查4个功能或组件</p>\n<ul>\n<li>负载均衡：nginx或haproxy等技术</li>\n<li>服务发现、动态路由、健康检查：Zuul作为API网关实现动态路由，Consul或Zookeeper作为服务发现</li>\n<li>自动化运维：kubernates服务调度、伸缩和故障转移</li>\n</ul>\n<p>服务解耦：把服务隔离开来，使其不相互影响。水平上，可业务分区（业务隔离），或用户分区（多租户；垂直上，需要异步通讯；服务编排和聚合上，需要工作流把服务串起来（如Spring或Akka的Streams）；一致性上，需要业务补偿来做反向交易</p>\n<ul>\n<li>bulkheads模式：用户分片、业务分片、数据库拆分</li>\n<li>自包含系统：无外部服务依赖，把一组相关的微服务给拆出来</li>\n<li>异步通讯：异步通讯、消息队列、事件驱动</li>\n<li>自动化运维：需要有一个服务调用链和性能监控的监控系统</li>\n</ul>\n<p>服务容错：让这个架构能接受失败的设计。重试带来幂等问题，为了保障稳定性需要有限流、降级、熔断</p>\n<ul>\n<li>错误方面：重试设计+熔断设计+幂等设计</li>\n<li>一致性：强一致性使用两阶段提交，最终一致性使用异步通讯+事件补偿</li>\n<li>流控：限流设计+降级设计</li>\n<li>自动化运维：网关流量调度，服务监控</li>\n</ul>"},{"title":"《左耳听风》笔记：管理设计篇","date":"2020-01-15T03:03:25.000Z","comments":1,"_content":"\n极客时间《左耳听风》专栏读书笔记之管理设计篇。\n\n<!--more-->\n\n## 分布式锁 distributed lock\n\n为什么需要分布式锁，分布式研究者Martin Kleppmann在[How to do distributed locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)提到有以下两点，\n- Efficiency：防止只需要做一次的工作被重复执行，浪费资源\n- Correctness：防止竞态修改资源导致不一致性\n\n分布式锁需要具备以下几个特点，\n- 安全性/排他性：任何时候只能有一个客户端获得锁\n- 避免死锁：客户端最终一定能获得锁，即使获得锁后客户端崩溃也不会影响后来者获取锁\n- 容错性：只要集群中半数以上结点存活，就可以正常加解锁\n\n方案1：Redis分布式锁（RedLock算法，[Distributed locks with Redis](https://redis.io/topics/distlock)）\n- 其算法共5个步骤，详见[redis的分布式锁算法redlock](https://zhangjunjia.github.io/2019/08/21/redlock-algorithm/)\n- 其底层原理依赖于Redis的NX特性和TTL特性\n    - `SET resource_name my_random_value NX PX 30000`\n    - `NX`表示不存在才创建，因此只要有客户端在该Redis实例取锁后，其他客户端就会失败\n    - `PX 30000`表示key的timeout时间，即使客户端取锁后崩溃，其锁也会在timeout后被释放\n    - `my_random_value`必须是一个随机值，在释放锁时使用原子性的Check And Set进行释放，原子性可通过lua脚本实现\n- Martin Kleppmann在[How to do distributed locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)认为此算法在某些情况不安全（下文详细展开），Redis作者antirez的回应[Is Redlock safe?](http://antirez.com/news/101)很有意思，\n    - Martin Kleppmann的方案需要被修改的存储本身具备version自增和校验功能，如果存储本身具备这个功能真的还需要分布式锁吗？\n    - 如果要操作的资源不是存储呢？\n\n方案2：zookeeper分布式锁（[七张图彻底讲清楚ZooKeeper分布式锁的实现原理【石杉的架构笔记】](https://juejin.im/post/5c01532ef265da61362232ed)）\n- [Apache Curator](https://curator.apache.org/)基于ZooKeeper封装了分布锁服务\n- 其底层原理是ZooKeeper的临时顺序节点，以及watch机制\n    - 临时特性在客户端断开时触发sessionTimeout，将会导致锁的释放\n    - 顺序特性在多个客户端竞争锁时，序号最小的那个客户端才认为获取到锁（需要获取znode下的所有子结点用于判断）\n    - 获取锁的结点在使用完锁时，主动删除节点，将触发其他客户端的watch回调，重新进入一轮分布式锁是否获取到的判断\n\n\n方案3：分布式锁fencing。耗子叔以及Martin Kleppmannd都提到，以上方案都会存在一个问题，客户端取锁后进入Stop The World，在恢复后其实锁已经超时，但客户端仍认为自己持有锁依然去操作共享资源，此时将会导致不一致，如下图所示\n\n![image](https://user-images.githubusercontent.com/4915189/72590334-6b566f80-3938-11ea-9ea4-941ff10507cb.png)\n\n解决方案是使用fencing机制，分布式锁服务在每次取锁成功返回的version需要是递增的，操作存储时存储本身要校验操作者的version是不是最新的——若不是则进行拒绝，过程如下：\n\n![image](https://user-images.githubusercontent.com/4915189/72600359-6d2b2d80-394e-11ea-8128-f62d79847adc.png)\n\n方案4：存储支持version自增和校验功能。但如上文所说，如果存储本身支持version自增和校验功能，还需要分布式锁吗？\n\n- 对于普通update，我们可以使用乐观锁，比如`\nUPDATE table_name SET xxx = #{xxx}, version=version+1 where version =#{version};`\n- 如果乐观锁失败，我们可以用CAS，比如`\nSELECT stock FROM tb_product where product_id=#{product_id}; UPDATE tb_product SET stock=stock-#{num} WHERE product_id=#{product_id} AND stock=#{stock};`\n\n其过程大概如下图所示：\n\n![image](https://user-images.githubusercontent.com/4915189/72600725-27bb3000-394f-11ea-9f68-6c96b340c900.png)\n\n分布式锁总结：每个方案都有trade-off，使用RedLock、ZooKeeper方案，则存在锁过期的问题；使用fencing，则存在分布式锁服务冗余的问题；使用存储本身支持的version管理，则又可能存在性能问题。\n\n## 配置中心 Configuration Management\n\n配置中心，一般指的是软件的动态配置部分，有三个区分的维度：\n- 按运行环境分：如开发、预发、线上环境\n- 按依赖区分：如依赖基础服务如Redis，如依赖外部服务的URL，如软件内部的依赖\n- 按层次分：如IaaS、PaaS、SaaS\n\n配置中心的模型设计，应考虑如下因素：\n- 分层：如操作系统层、平台层、应用层，不同层有不同人员负责配置\n- 命名空间：需要有namaspace防止应用间的冲突，还需要制定一套命名规范\n- 环境差异：同一个key/value，在不同环境的值可以是不同的\n- 版本管理以及灰度测试：每一个key/value，都应该进行版本记录便于回滚，同时可以指定该配置灰度的机器范围\n\n配置中心的架构，大致如下：\n\n![image](https://user-images.githubusercontent.com/4915189/72601496-7ddca300-3950-11ea-8134-c643112e15d8.png)\n\n国内比较成熟的开源分布式配置中心：携程的[Apollo](https://github.com/ctripcorp/apollo)\n\n## 边车模式 sidecar\n\n随着微服务的流行，服务需要嵌入越来越多控制层的职责：限流、熔断、日志、服务发现、监视、协议转换。为了实现逻辑和控制的分离，这些控制层职责会被下沉。分别有两种下沉的方式，一是Lib/SDK的方式，二是Sidecar模式。\n\n使用Lib/SDK下沉控制职责，\n- 好处：嵌入到代码逻辑，对应用的性能影响较小\n- 坏处：Lib/SDK通常和编程语言有关，因此业务逻辑必须使用相同的语言\n- 坏处：升级Lib/SDK需要重新打包应用，重新部署所有应用\n\n使用sidecar下沉控制职责，\n- 好处：对应用无侵入，逻辑层、控制层可做到分开开发、部署，逻辑层可使用任意编程语言开发\n- 坏处：增加服务依赖，增加调用时延，增加运维复杂度（一般是结合docker和kubernates降低运维复杂度）\n\nsidecar服务和应用服务部署在同一结点内（一般是同一机器上，这样通信延迟不会明显增加），具备相同的生命周期，一起创建、一起停止。每个应用服务实例都一一对应有一个sidecar，sidecar可以很方便的对应用服务进行扩展而无需修改应用服务，\n- sidecar帮助服务注册到服务发现系统，对其捆绑服务做健康检查，若发现异常从服务发现系统注销捆绑服务\n- 当应用服务要调外部服务时，sidecar帮助在服务发现系统中找到对端服务，做服务路由\n- sidecar接管进出流量，日志、调用链监控、流控熔断等等都可以放在sidecar实现\n- 服务控制系统可以通过sidecar来控制应用服务，如流控、下线等\n\n![image](https://user-images.githubusercontent.com/4915189/74081465-54fc8900-4a8a-11ea-8838-f642af9be652.png)\n\nsidecar在设计上需要注意以下要点，\n- service与sidecar的通信是设计重点，千万不要使用对应用有侵入的方式（如共享内存、信号量），建议使用网络通信（通过127.0.0.1通信开销不大）\n- service与sidecar的通信协议要兼容原先的service间的通信协议，sidecar与sidecar的通信协议使用更开放和高效的协议\n- 业务逻辑不要放在sidecar\n- 需要在服务的整体打包、构建、部署、管控设计好，使用上docker和kubernates这类技术\n- 小心sidecar的通用功能如重试，有些服务不支持幂等调用，这可能产生副作用\n- 应用服务和sidecar可互相传递上下文信息，如应用服务可设置http头告知sidecar最大重试次数、sidecar可在http头告知限流发生\n\nsidecar适合什么场景，\n- 无侵入的改造老应用\n- 对多种语言混合开发的分布式服务系统进行扩展\n- 系统的多应用服务由不同供应商提供，通过sidecar统一通信规范\n- 标准化控制面的逻辑，由更专业人员进行开发（分工考虑）\n\nsidecar不适合什么场景，\n- 架构并不复杂的时候，使用nginx或haproxy即可；\n- 服务间协议不标准；\n- 不打算架构为分布式服务系统。\n\n## 服务网格 service mesh\n\nlinkerd作者在[What’s a service mesh? And why do I need one? ](https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/)定义了service mesh是什么：\n \n> A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.\n\n总结来说，\n- service mesh是处理服务与服务间通信的基础设施；\n- service mesh是一组轻量的服务通讯的网络代理；\n- service mesh对于应用是透明无侵入的；\n- service mesh用于解耦和分离分布式系统中控制层面的职责；\n\nservice mesh本质是一个sidecar集群，[Pattern: Service Mesh](https://philcalcado.com/2017/08/03/pattern_service_mesh.html)介绍了它是如何演化出来的：\n- 一开始是最原始的两台主机上进程进行通信；\n- 然后分离出网络层来，进程的通信由底层的网络模型完成；\n- 由于消费能力不对等，必须在应用层中实现流控；\n- 流控功能下沉到了网络层；\n- 由于微服务的出现，必须在应用层中实现熔断、服务发现、限流等控制层逻辑，这些逻辑起初是以Lib/SDK的方式实现的；\n- 由于Lib/SDK绑定语言、不便于升级的弊端，控制层下沉到sidecar服务；\n- sidecar服务集群与管理控制面板，组成了service mesh，如下图；\n\n![image](https://user-images.githubusercontent.com/4915189/74098340-0f0af800-4b52-11ea-9e13-e5718f806d88.png)\nservice mesh的主流开源方案是linkerd（scala实现，其创始人后面用go和rust实现了另一个版本conduit）和istio。istio的架构如下图：\n\n![image](https://user-images.githubusercontent.com/4915189/74098316-ceab7a00-4b51-11ea-9d63-20d7bdf82969.png)\n\n其中，\n- envoy为sidecar服务；\n- mixer收集envoy的metrics，通过pilot下发控制规则，通过auth下发安全规则；\n\nservice mesh的设计重点，\n- 本地sidecar出问题时，能自动切到灾备的sidecar；\n- sidecar服务为实例粒度，若上升到一组服务的粒度，进一步整体接入的粒度，那它就成了gateway；\n- 能否和kubernates密切结合是关键。\n\n## 网关模式 gateway\n\nservice mesh的粒度太细，把粒度粗化到一组服务的级别，职责转为只负责接入，就成了gateway模式。\n\n![image](https://user-images.githubusercontent.com/4915189/74099636-d292c880-4b60-11ea-8fc8-088a51734e4d.png)\n\n如上图，在架构上，gateway模式是一个多层的星形拓扑。gateway一般需要具备以下功能：\n- 请求路由：接入请求，路由到后端服务\n- 服务注册：开放能力供后端服务注册\n- 负载均衡：如何分发请求的策略\n- 弹力设计：弹力设计的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去\n- 安全方面：SSL加密及证书管理、session鉴权、数据校验、恶意攻击识别\n- 灰度发布：对相同服务的不同版本划分不同比例的流量\n- API聚合：将多个单独请求聚合成一个请求\n- API编排：将前端的api编排能力以插件的方式添加进来\n\n网关的设计重点\n- 高性能：使用什么语言实现是重点\n- 高可用：集群化、服务化（不停机reload+Admin的API）、持续化（不宕机重启）\n- 高扩展：可插拔，如nginx的module\n\n读完本篇有个很大疑问，网关只负责接入流量，那服务的出流量怎么办？即如何访问其他服务。","source":"_posts/2020-01-15-chenhao-manage-design.md","raw":"---\ntitle: 《左耳听风》笔记：管理设计篇\ndate: 2020-01-15 11:03:25\ntags: ['系统设计']\ncomments: true\ncategories: ['系统设计']\n---\n\n极客时间《左耳听风》专栏读书笔记之管理设计篇。\n\n<!--more-->\n\n## 分布式锁 distributed lock\n\n为什么需要分布式锁，分布式研究者Martin Kleppmann在[How to do distributed locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)提到有以下两点，\n- Efficiency：防止只需要做一次的工作被重复执行，浪费资源\n- Correctness：防止竞态修改资源导致不一致性\n\n分布式锁需要具备以下几个特点，\n- 安全性/排他性：任何时候只能有一个客户端获得锁\n- 避免死锁：客户端最终一定能获得锁，即使获得锁后客户端崩溃也不会影响后来者获取锁\n- 容错性：只要集群中半数以上结点存活，就可以正常加解锁\n\n方案1：Redis分布式锁（RedLock算法，[Distributed locks with Redis](https://redis.io/topics/distlock)）\n- 其算法共5个步骤，详见[redis的分布式锁算法redlock](https://zhangjunjia.github.io/2019/08/21/redlock-algorithm/)\n- 其底层原理依赖于Redis的NX特性和TTL特性\n    - `SET resource_name my_random_value NX PX 30000`\n    - `NX`表示不存在才创建，因此只要有客户端在该Redis实例取锁后，其他客户端就会失败\n    - `PX 30000`表示key的timeout时间，即使客户端取锁后崩溃，其锁也会在timeout后被释放\n    - `my_random_value`必须是一个随机值，在释放锁时使用原子性的Check And Set进行释放，原子性可通过lua脚本实现\n- Martin Kleppmann在[How to do distributed locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)认为此算法在某些情况不安全（下文详细展开），Redis作者antirez的回应[Is Redlock safe?](http://antirez.com/news/101)很有意思，\n    - Martin Kleppmann的方案需要被修改的存储本身具备version自增和校验功能，如果存储本身具备这个功能真的还需要分布式锁吗？\n    - 如果要操作的资源不是存储呢？\n\n方案2：zookeeper分布式锁（[七张图彻底讲清楚ZooKeeper分布式锁的实现原理【石杉的架构笔记】](https://juejin.im/post/5c01532ef265da61362232ed)）\n- [Apache Curator](https://curator.apache.org/)基于ZooKeeper封装了分布锁服务\n- 其底层原理是ZooKeeper的临时顺序节点，以及watch机制\n    - 临时特性在客户端断开时触发sessionTimeout，将会导致锁的释放\n    - 顺序特性在多个客户端竞争锁时，序号最小的那个客户端才认为获取到锁（需要获取znode下的所有子结点用于判断）\n    - 获取锁的结点在使用完锁时，主动删除节点，将触发其他客户端的watch回调，重新进入一轮分布式锁是否获取到的判断\n\n\n方案3：分布式锁fencing。耗子叔以及Martin Kleppmannd都提到，以上方案都会存在一个问题，客户端取锁后进入Stop The World，在恢复后其实锁已经超时，但客户端仍认为自己持有锁依然去操作共享资源，此时将会导致不一致，如下图所示\n\n![image](https://user-images.githubusercontent.com/4915189/72590334-6b566f80-3938-11ea-9ea4-941ff10507cb.png)\n\n解决方案是使用fencing机制，分布式锁服务在每次取锁成功返回的version需要是递增的，操作存储时存储本身要校验操作者的version是不是最新的——若不是则进行拒绝，过程如下：\n\n![image](https://user-images.githubusercontent.com/4915189/72600359-6d2b2d80-394e-11ea-8128-f62d79847adc.png)\n\n方案4：存储支持version自增和校验功能。但如上文所说，如果存储本身支持version自增和校验功能，还需要分布式锁吗？\n\n- 对于普通update，我们可以使用乐观锁，比如`\nUPDATE table_name SET xxx = #{xxx}, version=version+1 where version =#{version};`\n- 如果乐观锁失败，我们可以用CAS，比如`\nSELECT stock FROM tb_product where product_id=#{product_id}; UPDATE tb_product SET stock=stock-#{num} WHERE product_id=#{product_id} AND stock=#{stock};`\n\n其过程大概如下图所示：\n\n![image](https://user-images.githubusercontent.com/4915189/72600725-27bb3000-394f-11ea-9f68-6c96b340c900.png)\n\n分布式锁总结：每个方案都有trade-off，使用RedLock、ZooKeeper方案，则存在锁过期的问题；使用fencing，则存在分布式锁服务冗余的问题；使用存储本身支持的version管理，则又可能存在性能问题。\n\n## 配置中心 Configuration Management\n\n配置中心，一般指的是软件的动态配置部分，有三个区分的维度：\n- 按运行环境分：如开发、预发、线上环境\n- 按依赖区分：如依赖基础服务如Redis，如依赖外部服务的URL，如软件内部的依赖\n- 按层次分：如IaaS、PaaS、SaaS\n\n配置中心的模型设计，应考虑如下因素：\n- 分层：如操作系统层、平台层、应用层，不同层有不同人员负责配置\n- 命名空间：需要有namaspace防止应用间的冲突，还需要制定一套命名规范\n- 环境差异：同一个key/value，在不同环境的值可以是不同的\n- 版本管理以及灰度测试：每一个key/value，都应该进行版本记录便于回滚，同时可以指定该配置灰度的机器范围\n\n配置中心的架构，大致如下：\n\n![image](https://user-images.githubusercontent.com/4915189/72601496-7ddca300-3950-11ea-8134-c643112e15d8.png)\n\n国内比较成熟的开源分布式配置中心：携程的[Apollo](https://github.com/ctripcorp/apollo)\n\n## 边车模式 sidecar\n\n随着微服务的流行，服务需要嵌入越来越多控制层的职责：限流、熔断、日志、服务发现、监视、协议转换。为了实现逻辑和控制的分离，这些控制层职责会被下沉。分别有两种下沉的方式，一是Lib/SDK的方式，二是Sidecar模式。\n\n使用Lib/SDK下沉控制职责，\n- 好处：嵌入到代码逻辑，对应用的性能影响较小\n- 坏处：Lib/SDK通常和编程语言有关，因此业务逻辑必须使用相同的语言\n- 坏处：升级Lib/SDK需要重新打包应用，重新部署所有应用\n\n使用sidecar下沉控制职责，\n- 好处：对应用无侵入，逻辑层、控制层可做到分开开发、部署，逻辑层可使用任意编程语言开发\n- 坏处：增加服务依赖，增加调用时延，增加运维复杂度（一般是结合docker和kubernates降低运维复杂度）\n\nsidecar服务和应用服务部署在同一结点内（一般是同一机器上，这样通信延迟不会明显增加），具备相同的生命周期，一起创建、一起停止。每个应用服务实例都一一对应有一个sidecar，sidecar可以很方便的对应用服务进行扩展而无需修改应用服务，\n- sidecar帮助服务注册到服务发现系统，对其捆绑服务做健康检查，若发现异常从服务发现系统注销捆绑服务\n- 当应用服务要调外部服务时，sidecar帮助在服务发现系统中找到对端服务，做服务路由\n- sidecar接管进出流量，日志、调用链监控、流控熔断等等都可以放在sidecar实现\n- 服务控制系统可以通过sidecar来控制应用服务，如流控、下线等\n\n![image](https://user-images.githubusercontent.com/4915189/74081465-54fc8900-4a8a-11ea-8838-f642af9be652.png)\n\nsidecar在设计上需要注意以下要点，\n- service与sidecar的通信是设计重点，千万不要使用对应用有侵入的方式（如共享内存、信号量），建议使用网络通信（通过127.0.0.1通信开销不大）\n- service与sidecar的通信协议要兼容原先的service间的通信协议，sidecar与sidecar的通信协议使用更开放和高效的协议\n- 业务逻辑不要放在sidecar\n- 需要在服务的整体打包、构建、部署、管控设计好，使用上docker和kubernates这类技术\n- 小心sidecar的通用功能如重试，有些服务不支持幂等调用，这可能产生副作用\n- 应用服务和sidecar可互相传递上下文信息，如应用服务可设置http头告知sidecar最大重试次数、sidecar可在http头告知限流发生\n\nsidecar适合什么场景，\n- 无侵入的改造老应用\n- 对多种语言混合开发的分布式服务系统进行扩展\n- 系统的多应用服务由不同供应商提供，通过sidecar统一通信规范\n- 标准化控制面的逻辑，由更专业人员进行开发（分工考虑）\n\nsidecar不适合什么场景，\n- 架构并不复杂的时候，使用nginx或haproxy即可；\n- 服务间协议不标准；\n- 不打算架构为分布式服务系统。\n\n## 服务网格 service mesh\n\nlinkerd作者在[What’s a service mesh? And why do I need one? ](https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/)定义了service mesh是什么：\n \n> A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.\n\n总结来说，\n- service mesh是处理服务与服务间通信的基础设施；\n- service mesh是一组轻量的服务通讯的网络代理；\n- service mesh对于应用是透明无侵入的；\n- service mesh用于解耦和分离分布式系统中控制层面的职责；\n\nservice mesh本质是一个sidecar集群，[Pattern: Service Mesh](https://philcalcado.com/2017/08/03/pattern_service_mesh.html)介绍了它是如何演化出来的：\n- 一开始是最原始的两台主机上进程进行通信；\n- 然后分离出网络层来，进程的通信由底层的网络模型完成；\n- 由于消费能力不对等，必须在应用层中实现流控；\n- 流控功能下沉到了网络层；\n- 由于微服务的出现，必须在应用层中实现熔断、服务发现、限流等控制层逻辑，这些逻辑起初是以Lib/SDK的方式实现的；\n- 由于Lib/SDK绑定语言、不便于升级的弊端，控制层下沉到sidecar服务；\n- sidecar服务集群与管理控制面板，组成了service mesh，如下图；\n\n![image](https://user-images.githubusercontent.com/4915189/74098340-0f0af800-4b52-11ea-9e13-e5718f806d88.png)\nservice mesh的主流开源方案是linkerd（scala实现，其创始人后面用go和rust实现了另一个版本conduit）和istio。istio的架构如下图：\n\n![image](https://user-images.githubusercontent.com/4915189/74098316-ceab7a00-4b51-11ea-9d63-20d7bdf82969.png)\n\n其中，\n- envoy为sidecar服务；\n- mixer收集envoy的metrics，通过pilot下发控制规则，通过auth下发安全规则；\n\nservice mesh的设计重点，\n- 本地sidecar出问题时，能自动切到灾备的sidecar；\n- sidecar服务为实例粒度，若上升到一组服务的粒度，进一步整体接入的粒度，那它就成了gateway；\n- 能否和kubernates密切结合是关键。\n\n## 网关模式 gateway\n\nservice mesh的粒度太细，把粒度粗化到一组服务的级别，职责转为只负责接入，就成了gateway模式。\n\n![image](https://user-images.githubusercontent.com/4915189/74099636-d292c880-4b60-11ea-8fc8-088a51734e4d.png)\n\n如上图，在架构上，gateway模式是一个多层的星形拓扑。gateway一般需要具备以下功能：\n- 请求路由：接入请求，路由到后端服务\n- 服务注册：开放能力供后端服务注册\n- 负载均衡：如何分发请求的策略\n- 弹力设计：弹力设计的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去\n- 安全方面：SSL加密及证书管理、session鉴权、数据校验、恶意攻击识别\n- 灰度发布：对相同服务的不同版本划分不同比例的流量\n- API聚合：将多个单独请求聚合成一个请求\n- API编排：将前端的api编排能力以插件的方式添加进来\n\n网关的设计重点\n- 高性能：使用什么语言实现是重点\n- 高可用：集群化、服务化（不停机reload+Admin的API）、持续化（不宕机重启）\n- 高扩展：可插拔，如nginx的module\n\n读完本篇有个很大疑问，网关只负责接入流量，那服务的出流量怎么办？即如何访问其他服务。","slug":"chenhao-manage-design","published":1,"updated":"2022-08-09T15:02:00.663Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14w0040igu86ug16jyg","content":"<p>极客时间《左耳听风》专栏读书笔记之管理设计篇。</p>\n<a id=\"more\"></a>\n<h2 id=\"分布式锁-distributed-lock\"><a href=\"#分布式锁-distributed-lock\" class=\"headerlink\" title=\"分布式锁 distributed lock\"></a>分布式锁 distributed lock</h2><p>为什么需要分布式锁，分布式研究者Martin Kleppmann在<a href=\"https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\" target=\"_blank\" rel=\"noopener\">How to do distributed locking</a>提到有以下两点，</p>\n<ul>\n<li>Efficiency：防止只需要做一次的工作被重复执行，浪费资源</li>\n<li>Correctness：防止竞态修改资源导致不一致性</li>\n</ul>\n<p>分布式锁需要具备以下几个特点，</p>\n<ul>\n<li>安全性/排他性：任何时候只能有一个客户端获得锁</li>\n<li>避免死锁：客户端最终一定能获得锁，即使获得锁后客户端崩溃也不会影响后来者获取锁</li>\n<li>容错性：只要集群中半数以上结点存活，就可以正常加解锁</li>\n</ul>\n<p>方案1：Redis分布式锁（RedLock算法，<a href=\"https://redis.io/topics/distlock\" target=\"_blank\" rel=\"noopener\">Distributed locks with Redis</a>）</p>\n<ul>\n<li>其算法共5个步骤，详见<a href=\"https://zhangjunjia.github.io/2019/08/21/redlock-algorithm/\">redis的分布式锁算法redlock</a></li>\n<li>其底层原理依赖于Redis的NX特性和TTL特性<ul>\n<li><code>SET resource_name my_random_value NX PX 30000</code></li>\n<li><code>NX</code>表示不存在才创建，因此只要有客户端在该Redis实例取锁后，其他客户端就会失败</li>\n<li><code>PX 30000</code>表示key的timeout时间，即使客户端取锁后崩溃，其锁也会在timeout后被释放</li>\n<li><code>my_random_value</code>必须是一个随机值，在释放锁时使用原子性的Check And Set进行释放，原子性可通过lua脚本实现</li>\n</ul>\n</li>\n<li>Martin Kleppmann在<a href=\"https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\" target=\"_blank\" rel=\"noopener\">How to do distributed locking</a>认为此算法在某些情况不安全（下文详细展开），Redis作者antirez的回应<a href=\"http://antirez.com/news/101\" target=\"_blank\" rel=\"noopener\">Is Redlock safe?</a>很有意思，<ul>\n<li>Martin Kleppmann的方案需要被修改的存储本身具备version自增和校验功能，如果存储本身具备这个功能真的还需要分布式锁吗？</li>\n<li>如果要操作的资源不是存储呢？</li>\n</ul>\n</li>\n</ul>\n<p>方案2：zookeeper分布式锁（<a href=\"https://juejin.im/post/5c01532ef265da61362232ed\" target=\"_blank\" rel=\"noopener\">七张图彻底讲清楚ZooKeeper分布式锁的实现原理【石杉的架构笔记】</a>）</p>\n<ul>\n<li><a href=\"https://curator.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Curator</a>基于ZooKeeper封装了分布锁服务</li>\n<li>其底层原理是ZooKeeper的临时顺序节点，以及watch机制<ul>\n<li>临时特性在客户端断开时触发sessionTimeout，将会导致锁的释放</li>\n<li>顺序特性在多个客户端竞争锁时，序号最小的那个客户端才认为获取到锁（需要获取znode下的所有子结点用于判断）</li>\n<li>获取锁的结点在使用完锁时，主动删除节点，将触发其他客户端的watch回调，重新进入一轮分布式锁是否获取到的判断</li>\n</ul>\n</li>\n</ul>\n<p>方案3：分布式锁fencing。耗子叔以及Martin Kleppmannd都提到，以上方案都会存在一个问题，客户端取锁后进入Stop The World，在恢复后其实锁已经超时，但客户端仍认为自己持有锁依然去操作共享资源，此时将会导致不一致，如下图所示</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72590334-6b566f80-3938-11ea-9ea4-941ff10507cb.png\" alt=\"image\"></p>\n<p>解决方案是使用fencing机制，分布式锁服务在每次取锁成功返回的version需要是递增的，操作存储时存储本身要校验操作者的version是不是最新的——若不是则进行拒绝，过程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72600359-6d2b2d80-394e-11ea-8128-f62d79847adc.png\" alt=\"image\"></p>\n<p>方案4：存储支持version自增和校验功能。但如上文所说，如果存储本身支持version自增和校验功能，还需要分布式锁吗？</p>\n<ul>\n<li>对于普通update，我们可以使用乐观锁，比如<code>UPDATE table_name SET xxx = #{xxx}, version=version+1 where version =#{version};</code></li>\n<li>如果乐观锁失败，我们可以用CAS，比如<code>SELECT stock FROM tb_product where product_id=#{product_id}; UPDATE tb_product SET stock=stock-#{num} WHERE product_id=#{product_id} AND stock=#{stock};</code></li>\n</ul>\n<p>其过程大概如下图所示：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72600725-27bb3000-394f-11ea-9f68-6c96b340c900.png\" alt=\"image\"></p>\n<p>分布式锁总结：每个方案都有trade-off，使用RedLock、ZooKeeper方案，则存在锁过期的问题；使用fencing，则存在分布式锁服务冗余的问题；使用存储本身支持的version管理，则又可能存在性能问题。</p>\n<h2 id=\"配置中心-Configuration-Management\"><a href=\"#配置中心-Configuration-Management\" class=\"headerlink\" title=\"配置中心 Configuration Management\"></a>配置中心 Configuration Management</h2><p>配置中心，一般指的是软件的动态配置部分，有三个区分的维度：</p>\n<ul>\n<li>按运行环境分：如开发、预发、线上环境</li>\n<li>按依赖区分：如依赖基础服务如Redis，如依赖外部服务的URL，如软件内部的依赖</li>\n<li>按层次分：如IaaS、PaaS、SaaS</li>\n</ul>\n<p>配置中心的模型设计，应考虑如下因素：</p>\n<ul>\n<li>分层：如操作系统层、平台层、应用层，不同层有不同人员负责配置</li>\n<li>命名空间：需要有namaspace防止应用间的冲突，还需要制定一套命名规范</li>\n<li>环境差异：同一个key/value，在不同环境的值可以是不同的</li>\n<li>版本管理以及灰度测试：每一个key/value，都应该进行版本记录便于回滚，同时可以指定该配置灰度的机器范围</li>\n</ul>\n<p>配置中心的架构，大致如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72601496-7ddca300-3950-11ea-8134-c643112e15d8.png\" alt=\"image\"></p>\n<p>国内比较成熟的开源分布式配置中心：携程的<a href=\"https://github.com/ctripcorp/apollo\" target=\"_blank\" rel=\"noopener\">Apollo</a></p>\n<h2 id=\"边车模式-sidecar\"><a href=\"#边车模式-sidecar\" class=\"headerlink\" title=\"边车模式 sidecar\"></a>边车模式 sidecar</h2><p>随着微服务的流行，服务需要嵌入越来越多控制层的职责：限流、熔断、日志、服务发现、监视、协议转换。为了实现逻辑和控制的分离，这些控制层职责会被下沉。分别有两种下沉的方式，一是Lib/SDK的方式，二是Sidecar模式。</p>\n<p>使用Lib/SDK下沉控制职责，</p>\n<ul>\n<li>好处：嵌入到代码逻辑，对应用的性能影响较小</li>\n<li>坏处：Lib/SDK通常和编程语言有关，因此业务逻辑必须使用相同的语言</li>\n<li>坏处：升级Lib/SDK需要重新打包应用，重新部署所有应用</li>\n</ul>\n<p>使用sidecar下沉控制职责，</p>\n<ul>\n<li>好处：对应用无侵入，逻辑层、控制层可做到分开开发、部署，逻辑层可使用任意编程语言开发</li>\n<li>坏处：增加服务依赖，增加调用时延，增加运维复杂度（一般是结合docker和kubernates降低运维复杂度）</li>\n</ul>\n<p>sidecar服务和应用服务部署在同一结点内（一般是同一机器上，这样通信延迟不会明显增加），具备相同的生命周期，一起创建、一起停止。每个应用服务实例都一一对应有一个sidecar，sidecar可以很方便的对应用服务进行扩展而无需修改应用服务，</p>\n<ul>\n<li>sidecar帮助服务注册到服务发现系统，对其捆绑服务做健康检查，若发现异常从服务发现系统注销捆绑服务</li>\n<li>当应用服务要调外部服务时，sidecar帮助在服务发现系统中找到对端服务，做服务路由</li>\n<li>sidecar接管进出流量，日志、调用链监控、流控熔断等等都可以放在sidecar实现</li>\n<li>服务控制系统可以通过sidecar来控制应用服务，如流控、下线等</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74081465-54fc8900-4a8a-11ea-8838-f642af9be652.png\" alt=\"image\"></p>\n<p>sidecar在设计上需要注意以下要点，</p>\n<ul>\n<li>service与sidecar的通信是设计重点，千万不要使用对应用有侵入的方式（如共享内存、信号量），建议使用网络通信（通过127.0.0.1通信开销不大）</li>\n<li>service与sidecar的通信协议要兼容原先的service间的通信协议，sidecar与sidecar的通信协议使用更开放和高效的协议</li>\n<li>业务逻辑不要放在sidecar</li>\n<li>需要在服务的整体打包、构建、部署、管控设计好，使用上docker和kubernates这类技术</li>\n<li>小心sidecar的通用功能如重试，有些服务不支持幂等调用，这可能产生副作用</li>\n<li>应用服务和sidecar可互相传递上下文信息，如应用服务可设置http头告知sidecar最大重试次数、sidecar可在http头告知限流发生</li>\n</ul>\n<p>sidecar适合什么场景，</p>\n<ul>\n<li>无侵入的改造老应用</li>\n<li>对多种语言混合开发的分布式服务系统进行扩展</li>\n<li>系统的多应用服务由不同供应商提供，通过sidecar统一通信规范</li>\n<li>标准化控制面的逻辑，由更专业人员进行开发（分工考虑）</li>\n</ul>\n<p>sidecar不适合什么场景，</p>\n<ul>\n<li>架构并不复杂的时候，使用nginx或haproxy即可；</li>\n<li>服务间协议不标准；</li>\n<li>不打算架构为分布式服务系统。</li>\n</ul>\n<h2 id=\"服务网格-service-mesh\"><a href=\"#服务网格-service-mesh\" class=\"headerlink\" title=\"服务网格 service mesh\"></a>服务网格 service mesh</h2><p>linkerd作者在<a href=\"https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/\" target=\"_blank\" rel=\"noopener\">What’s a service mesh? And why do I need one? </a>定义了service mesh是什么：</p>\n<blockquote>\n<p>A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.</p>\n</blockquote>\n<p>总结来说，</p>\n<ul>\n<li>service mesh是处理服务与服务间通信的基础设施；</li>\n<li>service mesh是一组轻量的服务通讯的网络代理；</li>\n<li>service mesh对于应用是透明无侵入的；</li>\n<li>service mesh用于解耦和分离分布式系统中控制层面的职责；</li>\n</ul>\n<p>service mesh本质是一个sidecar集群，<a href=\"https://philcalcado.com/2017/08/03/pattern_service_mesh.html\" target=\"_blank\" rel=\"noopener\">Pattern: Service Mesh</a>介绍了它是如何演化出来的：</p>\n<ul>\n<li>一开始是最原始的两台主机上进程进行通信；</li>\n<li>然后分离出网络层来，进程的通信由底层的网络模型完成；</li>\n<li>由于消费能力不对等，必须在应用层中实现流控；</li>\n<li>流控功能下沉到了网络层；</li>\n<li>由于微服务的出现，必须在应用层中实现熔断、服务发现、限流等控制层逻辑，这些逻辑起初是以Lib/SDK的方式实现的；</li>\n<li>由于Lib/SDK绑定语言、不便于升级的弊端，控制层下沉到sidecar服务；</li>\n<li>sidecar服务集群与管理控制面板，组成了service mesh，如下图；</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74098340-0f0af800-4b52-11ea-9e13-e5718f806d88.png\" alt=\"image\"><br>service mesh的主流开源方案是linkerd（scala实现，其创始人后面用go和rust实现了另一个版本conduit）和istio。istio的架构如下图：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74098316-ceab7a00-4b51-11ea-9d63-20d7bdf82969.png\" alt=\"image\"></p>\n<p>其中，</p>\n<ul>\n<li>envoy为sidecar服务；</li>\n<li>mixer收集envoy的metrics，通过pilot下发控制规则，通过auth下发安全规则；</li>\n</ul>\n<p>service mesh的设计重点，</p>\n<ul>\n<li>本地sidecar出问题时，能自动切到灾备的sidecar；</li>\n<li>sidecar服务为实例粒度，若上升到一组服务的粒度，进一步整体接入的粒度，那它就成了gateway；</li>\n<li>能否和kubernates密切结合是关键。</li>\n</ul>\n<h2 id=\"网关模式-gateway\"><a href=\"#网关模式-gateway\" class=\"headerlink\" title=\"网关模式 gateway\"></a>网关模式 gateway</h2><p>service mesh的粒度太细，把粒度粗化到一组服务的级别，职责转为只负责接入，就成了gateway模式。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74099636-d292c880-4b60-11ea-8fc8-088a51734e4d.png\" alt=\"image\"></p>\n<p>如上图，在架构上，gateway模式是一个多层的星形拓扑。gateway一般需要具备以下功能：</p>\n<ul>\n<li>请求路由：接入请求，路由到后端服务</li>\n<li>服务注册：开放能力供后端服务注册</li>\n<li>负载均衡：如何分发请求的策略</li>\n<li>弹力设计：弹力设计的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去</li>\n<li>安全方面：SSL加密及证书管理、session鉴权、数据校验、恶意攻击识别</li>\n<li>灰度发布：对相同服务的不同版本划分不同比例的流量</li>\n<li>API聚合：将多个单独请求聚合成一个请求</li>\n<li>API编排：将前端的api编排能力以插件的方式添加进来</li>\n</ul>\n<p>网关的设计重点</p>\n<ul>\n<li>高性能：使用什么语言实现是重点</li>\n<li>高可用：集群化、服务化（不停机reload+Admin的API）、持续化（不宕机重启）</li>\n<li>高扩展：可插拔，如nginx的module</li>\n</ul>\n<p>读完本篇有个很大疑问，网关只负责接入流量，那服务的出流量怎么办？即如何访问其他服务。</p>\n","site":{"data":{}},"excerpt":"<p>极客时间《左耳听风》专栏读书笔记之管理设计篇。</p>","more":"<h2 id=\"分布式锁-distributed-lock\"><a href=\"#分布式锁-distributed-lock\" class=\"headerlink\" title=\"分布式锁 distributed lock\"></a>分布式锁 distributed lock</h2><p>为什么需要分布式锁，分布式研究者Martin Kleppmann在<a href=\"https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\" target=\"_blank\" rel=\"noopener\">How to do distributed locking</a>提到有以下两点，</p>\n<ul>\n<li>Efficiency：防止只需要做一次的工作被重复执行，浪费资源</li>\n<li>Correctness：防止竞态修改资源导致不一致性</li>\n</ul>\n<p>分布式锁需要具备以下几个特点，</p>\n<ul>\n<li>安全性/排他性：任何时候只能有一个客户端获得锁</li>\n<li>避免死锁：客户端最终一定能获得锁，即使获得锁后客户端崩溃也不会影响后来者获取锁</li>\n<li>容错性：只要集群中半数以上结点存活，就可以正常加解锁</li>\n</ul>\n<p>方案1：Redis分布式锁（RedLock算法，<a href=\"https://redis.io/topics/distlock\" target=\"_blank\" rel=\"noopener\">Distributed locks with Redis</a>）</p>\n<ul>\n<li>其算法共5个步骤，详见<a href=\"https://zhangjunjia.github.io/2019/08/21/redlock-algorithm/\">redis的分布式锁算法redlock</a></li>\n<li>其底层原理依赖于Redis的NX特性和TTL特性<ul>\n<li><code>SET resource_name my_random_value NX PX 30000</code></li>\n<li><code>NX</code>表示不存在才创建，因此只要有客户端在该Redis实例取锁后，其他客户端就会失败</li>\n<li><code>PX 30000</code>表示key的timeout时间，即使客户端取锁后崩溃，其锁也会在timeout后被释放</li>\n<li><code>my_random_value</code>必须是一个随机值，在释放锁时使用原子性的Check And Set进行释放，原子性可通过lua脚本实现</li>\n</ul>\n</li>\n<li>Martin Kleppmann在<a href=\"https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\" target=\"_blank\" rel=\"noopener\">How to do distributed locking</a>认为此算法在某些情况不安全（下文详细展开），Redis作者antirez的回应<a href=\"http://antirez.com/news/101\" target=\"_blank\" rel=\"noopener\">Is Redlock safe?</a>很有意思，<ul>\n<li>Martin Kleppmann的方案需要被修改的存储本身具备version自增和校验功能，如果存储本身具备这个功能真的还需要分布式锁吗？</li>\n<li>如果要操作的资源不是存储呢？</li>\n</ul>\n</li>\n</ul>\n<p>方案2：zookeeper分布式锁（<a href=\"https://juejin.im/post/5c01532ef265da61362232ed\" target=\"_blank\" rel=\"noopener\">七张图彻底讲清楚ZooKeeper分布式锁的实现原理【石杉的架构笔记】</a>）</p>\n<ul>\n<li><a href=\"https://curator.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Curator</a>基于ZooKeeper封装了分布锁服务</li>\n<li>其底层原理是ZooKeeper的临时顺序节点，以及watch机制<ul>\n<li>临时特性在客户端断开时触发sessionTimeout，将会导致锁的释放</li>\n<li>顺序特性在多个客户端竞争锁时，序号最小的那个客户端才认为获取到锁（需要获取znode下的所有子结点用于判断）</li>\n<li>获取锁的结点在使用完锁时，主动删除节点，将触发其他客户端的watch回调，重新进入一轮分布式锁是否获取到的判断</li>\n</ul>\n</li>\n</ul>\n<p>方案3：分布式锁fencing。耗子叔以及Martin Kleppmannd都提到，以上方案都会存在一个问题，客户端取锁后进入Stop The World，在恢复后其实锁已经超时，但客户端仍认为自己持有锁依然去操作共享资源，此时将会导致不一致，如下图所示</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72590334-6b566f80-3938-11ea-9ea4-941ff10507cb.png\" alt=\"image\"></p>\n<p>解决方案是使用fencing机制，分布式锁服务在每次取锁成功返回的version需要是递增的，操作存储时存储本身要校验操作者的version是不是最新的——若不是则进行拒绝，过程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72600359-6d2b2d80-394e-11ea-8128-f62d79847adc.png\" alt=\"image\"></p>\n<p>方案4：存储支持version自增和校验功能。但如上文所说，如果存储本身支持version自增和校验功能，还需要分布式锁吗？</p>\n<ul>\n<li>对于普通update，我们可以使用乐观锁，比如<code>UPDATE table_name SET xxx = #{xxx}, version=version+1 where version =#{version};</code></li>\n<li>如果乐观锁失败，我们可以用CAS，比如<code>SELECT stock FROM tb_product where product_id=#{product_id}; UPDATE tb_product SET stock=stock-#{num} WHERE product_id=#{product_id} AND stock=#{stock};</code></li>\n</ul>\n<p>其过程大概如下图所示：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72600725-27bb3000-394f-11ea-9f68-6c96b340c900.png\" alt=\"image\"></p>\n<p>分布式锁总结：每个方案都有trade-off，使用RedLock、ZooKeeper方案，则存在锁过期的问题；使用fencing，则存在分布式锁服务冗余的问题；使用存储本身支持的version管理，则又可能存在性能问题。</p>\n<h2 id=\"配置中心-Configuration-Management\"><a href=\"#配置中心-Configuration-Management\" class=\"headerlink\" title=\"配置中心 Configuration Management\"></a>配置中心 Configuration Management</h2><p>配置中心，一般指的是软件的动态配置部分，有三个区分的维度：</p>\n<ul>\n<li>按运行环境分：如开发、预发、线上环境</li>\n<li>按依赖区分：如依赖基础服务如Redis，如依赖外部服务的URL，如软件内部的依赖</li>\n<li>按层次分：如IaaS、PaaS、SaaS</li>\n</ul>\n<p>配置中心的模型设计，应考虑如下因素：</p>\n<ul>\n<li>分层：如操作系统层、平台层、应用层，不同层有不同人员负责配置</li>\n<li>命名空间：需要有namaspace防止应用间的冲突，还需要制定一套命名规范</li>\n<li>环境差异：同一个key/value，在不同环境的值可以是不同的</li>\n<li>版本管理以及灰度测试：每一个key/value，都应该进行版本记录便于回滚，同时可以指定该配置灰度的机器范围</li>\n</ul>\n<p>配置中心的架构，大致如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/72601496-7ddca300-3950-11ea-8134-c643112e15d8.png\" alt=\"image\"></p>\n<p>国内比较成熟的开源分布式配置中心：携程的<a href=\"https://github.com/ctripcorp/apollo\" target=\"_blank\" rel=\"noopener\">Apollo</a></p>\n<h2 id=\"边车模式-sidecar\"><a href=\"#边车模式-sidecar\" class=\"headerlink\" title=\"边车模式 sidecar\"></a>边车模式 sidecar</h2><p>随着微服务的流行，服务需要嵌入越来越多控制层的职责：限流、熔断、日志、服务发现、监视、协议转换。为了实现逻辑和控制的分离，这些控制层职责会被下沉。分别有两种下沉的方式，一是Lib/SDK的方式，二是Sidecar模式。</p>\n<p>使用Lib/SDK下沉控制职责，</p>\n<ul>\n<li>好处：嵌入到代码逻辑，对应用的性能影响较小</li>\n<li>坏处：Lib/SDK通常和编程语言有关，因此业务逻辑必须使用相同的语言</li>\n<li>坏处：升级Lib/SDK需要重新打包应用，重新部署所有应用</li>\n</ul>\n<p>使用sidecar下沉控制职责，</p>\n<ul>\n<li>好处：对应用无侵入，逻辑层、控制层可做到分开开发、部署，逻辑层可使用任意编程语言开发</li>\n<li>坏处：增加服务依赖，增加调用时延，增加运维复杂度（一般是结合docker和kubernates降低运维复杂度）</li>\n</ul>\n<p>sidecar服务和应用服务部署在同一结点内（一般是同一机器上，这样通信延迟不会明显增加），具备相同的生命周期，一起创建、一起停止。每个应用服务实例都一一对应有一个sidecar，sidecar可以很方便的对应用服务进行扩展而无需修改应用服务，</p>\n<ul>\n<li>sidecar帮助服务注册到服务发现系统，对其捆绑服务做健康检查，若发现异常从服务发现系统注销捆绑服务</li>\n<li>当应用服务要调外部服务时，sidecar帮助在服务发现系统中找到对端服务，做服务路由</li>\n<li>sidecar接管进出流量，日志、调用链监控、流控熔断等等都可以放在sidecar实现</li>\n<li>服务控制系统可以通过sidecar来控制应用服务，如流控、下线等</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74081465-54fc8900-4a8a-11ea-8838-f642af9be652.png\" alt=\"image\"></p>\n<p>sidecar在设计上需要注意以下要点，</p>\n<ul>\n<li>service与sidecar的通信是设计重点，千万不要使用对应用有侵入的方式（如共享内存、信号量），建议使用网络通信（通过127.0.0.1通信开销不大）</li>\n<li>service与sidecar的通信协议要兼容原先的service间的通信协议，sidecar与sidecar的通信协议使用更开放和高效的协议</li>\n<li>业务逻辑不要放在sidecar</li>\n<li>需要在服务的整体打包、构建、部署、管控设计好，使用上docker和kubernates这类技术</li>\n<li>小心sidecar的通用功能如重试，有些服务不支持幂等调用，这可能产生副作用</li>\n<li>应用服务和sidecar可互相传递上下文信息，如应用服务可设置http头告知sidecar最大重试次数、sidecar可在http头告知限流发生</li>\n</ul>\n<p>sidecar适合什么场景，</p>\n<ul>\n<li>无侵入的改造老应用</li>\n<li>对多种语言混合开发的分布式服务系统进行扩展</li>\n<li>系统的多应用服务由不同供应商提供，通过sidecar统一通信规范</li>\n<li>标准化控制面的逻辑，由更专业人员进行开发（分工考虑）</li>\n</ul>\n<p>sidecar不适合什么场景，</p>\n<ul>\n<li>架构并不复杂的时候，使用nginx或haproxy即可；</li>\n<li>服务间协议不标准；</li>\n<li>不打算架构为分布式服务系统。</li>\n</ul>\n<h2 id=\"服务网格-service-mesh\"><a href=\"#服务网格-service-mesh\" class=\"headerlink\" title=\"服务网格 service mesh\"></a>服务网格 service mesh</h2><p>linkerd作者在<a href=\"https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/\" target=\"_blank\" rel=\"noopener\">What’s a service mesh? And why do I need one? </a>定义了service mesh是什么：</p>\n<blockquote>\n<p>A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.</p>\n</blockquote>\n<p>总结来说，</p>\n<ul>\n<li>service mesh是处理服务与服务间通信的基础设施；</li>\n<li>service mesh是一组轻量的服务通讯的网络代理；</li>\n<li>service mesh对于应用是透明无侵入的；</li>\n<li>service mesh用于解耦和分离分布式系统中控制层面的职责；</li>\n</ul>\n<p>service mesh本质是一个sidecar集群，<a href=\"https://philcalcado.com/2017/08/03/pattern_service_mesh.html\" target=\"_blank\" rel=\"noopener\">Pattern: Service Mesh</a>介绍了它是如何演化出来的：</p>\n<ul>\n<li>一开始是最原始的两台主机上进程进行通信；</li>\n<li>然后分离出网络层来，进程的通信由底层的网络模型完成；</li>\n<li>由于消费能力不对等，必须在应用层中实现流控；</li>\n<li>流控功能下沉到了网络层；</li>\n<li>由于微服务的出现，必须在应用层中实现熔断、服务发现、限流等控制层逻辑，这些逻辑起初是以Lib/SDK的方式实现的；</li>\n<li>由于Lib/SDK绑定语言、不便于升级的弊端，控制层下沉到sidecar服务；</li>\n<li>sidecar服务集群与管理控制面板，组成了service mesh，如下图；</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74098340-0f0af800-4b52-11ea-9e13-e5718f806d88.png\" alt=\"image\"><br>service mesh的主流开源方案是linkerd（scala实现，其创始人后面用go和rust实现了另一个版本conduit）和istio。istio的架构如下图：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74098316-ceab7a00-4b51-11ea-9d63-20d7bdf82969.png\" alt=\"image\"></p>\n<p>其中，</p>\n<ul>\n<li>envoy为sidecar服务；</li>\n<li>mixer收集envoy的metrics，通过pilot下发控制规则，通过auth下发安全规则；</li>\n</ul>\n<p>service mesh的设计重点，</p>\n<ul>\n<li>本地sidecar出问题时，能自动切到灾备的sidecar；</li>\n<li>sidecar服务为实例粒度，若上升到一组服务的粒度，进一步整体接入的粒度，那它就成了gateway；</li>\n<li>能否和kubernates密切结合是关键。</li>\n</ul>\n<h2 id=\"网关模式-gateway\"><a href=\"#网关模式-gateway\" class=\"headerlink\" title=\"网关模式 gateway\"></a>网关模式 gateway</h2><p>service mesh的粒度太细，把粒度粗化到一组服务的级别，职责转为只负责接入，就成了gateway模式。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74099636-d292c880-4b60-11ea-8fc8-088a51734e4d.png\" alt=\"image\"></p>\n<p>如上图，在架构上，gateway模式是一个多层的星形拓扑。gateway一般需要具备以下功能：</p>\n<ul>\n<li>请求路由：接入请求，路由到后端服务</li>\n<li>服务注册：开放能力供后端服务注册</li>\n<li>负载均衡：如何分发请求的策略</li>\n<li>弹力设计：弹力设计的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去</li>\n<li>安全方面：SSL加密及证书管理、session鉴权、数据校验、恶意攻击识别</li>\n<li>灰度发布：对相同服务的不同版本划分不同比例的流量</li>\n<li>API聚合：将多个单独请求聚合成一个请求</li>\n<li>API编排：将前端的api编排能力以插件的方式添加进来</li>\n</ul>\n<p>网关的设计重点</p>\n<ul>\n<li>高性能：使用什么语言实现是重点</li>\n<li>高可用：集群化、服务化（不停机reload+Admin的API）、持续化（不宕机重启）</li>\n<li>高扩展：可插拔，如nginx的module</li>\n</ul>\n<p>读完本篇有个很大疑问，网关只负责接入流量，那服务的出流量怎么办？即如何访问其他服务。</p>"},{"title":"Paper阅读：Scaling Memcache at Facebook","date":"2020-03-31T12:33:29.000Z","comments":1,"_content":"\n记录阅读论文[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)的笔记。\n\n<!--more-->\n\n## 背景介绍\n\n[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)是Facebook团队2013年的一篇论文，讲述Facebook如何使用开源的memcached构建分布式内存KV集群，以响应billion级QPS。\n\nFacebook作为社交网络服务基础设施，需要满足：\n- 近似实时通信；\n- 实时聚合多个来源的内容；\n- 读取/更新热点的共享内容；\n- 可伸缩以处理billion级用户并发。\n\n为满足以上需求，Facebook从单机(memcached)、集群(cluster)、区域(region)、跨区域(cross-region)这4个方面以bottom up的方式讲述他们是如何scale的。memcache作为一个cache集群：用户大量读QPS，相比之下写QPS非常小；读的数据有多个后端源（MySQL/HDFS等），使用memcache集群做为query cache缓存可以极大的降低对后端存储系统的负载。Facebook使用一种cache aside的模式维护缓存，如图1：\n\n![imagex](https://user-images.githubusercontent.com/4915189/78672026-a9997480-7912-11ea-9d8b-6837cd7f498e.png)\n（图1 缓存更新模式）\n\n[缓存更新的套路](https://coolshell.cn/articles/17416.html)提到这种模式在极端条件下会出错：A会话读完数据库网络阻塞，B会话删除并失效缓存，A会话将脏数据写到缓存。这种极端条件概率比较低，cache aside是在更复杂方案与简单但小概率出错之间的取舍。\n\n在进入正文之前，需要厘清以下概念（见图2）：\n- memcached：开源memcached技术，在文中指运行时的单台实例；\n- cluster：指多台memcached组成的最小单位的集群，memcached之间相互不通信，由client端使用consistent hash将数据分布到多台memcached；\n- region：多web server集群和多cluster集群组成frontend clusters，共享一个storage cluster组成一个region；\n- cross-region：多个region，每个region分布在不同地理位置。只有一个region的storage cluster是master角色，其他的是slave角色，从master同步数据。\n\n![image](https://user-images.githubusercontent.com/4915189/78672689-933fe880-7913-11ea-8557-74d5a3fac5bf.png)\n（图2 以上概念的整体架构图示）\n\n## memcached单机优化\n\n对于开源的memcached，Facebook贡献给了社区的hashtable自动扩容、多线程加全局锁等优化。下面讲解一些未贡献给社区的。\n\n其一是支持UDP通信，通过UDP实现的的multiget，要比TCP性能优异13%；\n\n其二是动态的slab allocator。memcache预分配有多种size的slab桶，size从64 byte指数增长到1M不等，每个size的slab桶的个数是一定的。发起set调用时，根据value大小分配到满足条件的最小size的slab桶中。当负载增加时，某个size的slab桶可能会内存不足导致频繁该slab桶频繁的LRU，而其他slab桶因为命中率比较低其实是空闲的。Facebook做的优化是，检测slab桶中即将LRU的item，是否比其他slab桶的LRU item的使用次数要多20%，若是则保有该item从其他slab桶腾挪内存。\n\n其三是，short-lived key的清理。memcached对于已经expired的short-lived key的清理，是在get调用或LRU时触发的，这样可能导致short-lived key的堆积，Facebook使用circular buffer来加速其清理。circular buffer有固定的桶数量（比方说10个桶），每个桶代表1秒，short-lived key根据其expired时间将key分配到某个桶中。每1秒清除circular buffer头结点上的所有key，同时向前进一格，如此循环反复。\n\n其四，是使用shared memory解决memcached的热部署问题，这点在[Fast Database Restarts at Facebook](https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf)有详细的阐述。\n\n## cluster最小单位集群\n\ncluster的主要目标是get调用的低延迟，以及cache miss时不造成storage服务的load剧增。cluster主要围绕client端做优化，client是无状态的，表现为织入到web server的SDK，或独立运行的进程mcrouter（代理程序）。\n\n![image](https://user-images.githubusercontent.com/4915189/78765359-79a5ac00-79ba-11ea-8e1e-fd8fa31c4ed9.png)\n（图3 web server与memcached的通信示意图）\n\nweb server client如何减少延迟：\n- web server client将所需key构造为DAG（有向无环图）描绘依赖关系，对于能并发请求的数据batch化获取减少fetch调用次数，经统计每次batch平均有24个key。\n- web server client使用UDP（见图3）绕过mcrouter直接向memcached实例get数据，以实现低通信延迟。峰值负载下，0.25%的UDP的get请求失败，失败原因80%是因为丢包、超时。UDP的get请求错误会被当成cache miss，client从数据库load数据但不更新cache，因为get错误表明网络情况不佳，若还更新cache则加重网络负载。相比使用TCP执行get请求，有20%的通信延迟降低。\n- mcrouter负责set和delete请求（见图3），和web server结对部署，使用TCP和需要通信的memcached建立长连接。这样设计是因为set和delete请求需要TCP的可靠重试，以及不需要每个web server thread都和memcached直接建立长连接，由mcrouter统一接管减少长连接数量可节省CPU、内存、带宽。\n- all-to-all拥塞控制：UDP的get请求，是一种all-to-all通信模式，每个web server client都可直接与cluster内的N台memcached通信，这带来的潜在问题是网络拥塞。当每个client发送大量get请求，交换机、路由等网络设备将出现瓶颈。Facebook实现了一种划窗式(window)拥塞算法控制请求并发度，window大小表示request并发数，即每个request都要占据window的一个坑位并在request结束才释放坑位。window设置得太小，并发度低近似于串行，响应时间长；window设置得太大，并发请求多导致拥塞，响应时间也变长了。client与每个memcached的window是单独控制的，类似于TCP的拥塞控制算法。\n\nweb server如何减轻对存储的负载？\n- stale sets问题，在并发写memcached被重排序时会发生。论文设计了一个lease机制，在get调用cache miss时会返回一个token（这个token可以设置成每N秒只生成一个），client端从存储系统load到数据后将token和数据一起set到memcached，若token校验通过则写成功，否则写失败，这样就避免了stale sets问题。\n- thundering herds问题，是一个key被重度读写导致，写频繁失效缓存导致不断读存储。假设某个key刚被失效，此时有M个client读取发现cache miss，若M个client都去读存储系统那么将给其带来极大压力。首先，delete调用会使memcached为该key生成的token立即失效，相当于memcached又有配额为该key生成token；其次，get调用cache miss时，memcached可以只返回token给一个client，其他client返回一个短时间通知其休眠；最后，拿到token的client负责读盘set缓存，其他client短暂休眠后也就能读到数据了。\n- lease机制使得高峰读数据库从17K/s降至1.3K/s。memcached的key被客户端失效时，可以打上一个stale标记延期清除，这样在get调用时可以顺带返回过期的数据由客户端决定是否需要重新更新cache。多数情况下，过期数据是无害的，这能在高峰时期降低系统负载。\n- pool池化设计。将频繁访问且cache miss代价较小的key，与较少访问但cache miss代价昂贵的key，划分到不同的memcached pool，防止相互影响。key默认存放的pool叫wildcard pool，若在默认pool找不到key，则key可能存在于其他dedicated pool（专用pool）。论文没有阐述client是如何定位到不同pool查询key的。\n- pool的replication设计。假设单机memcached需要处理1M request/sec，每个request返回100个key。为了降低负载，策略一是将一半的key分到另外一台机，但这样单机的请求还是1M request/sec，只是返回key数量变成了50个。单个request返回100还是50个key，没有实质性区别。策略二是将数据replicate到另外一台机，这样每台机只需承担500K request/sec，单机负载就大大降低了。\n\nweb server如何做错误处理？\n- 小部分机器请求failed时，表现为get没有response，Facebook设计了Gutter来容错。当get调用failed时，请求会重试提交到Gutter pool。Gutter占cluster总机器1%，是一个stand by的pool，且为了减轻数据库负载是允许返回stale数据的。当出现hot key问题时，部分request将频繁失败，使用Gutter来有效分流，避免hot key压垮memcached（上文的pool replication也是这个目的）。如果没有Gutter容错，所有failed的get调用都会触发读盘，因为负责该key的memcached已经crash了。这是不同于rehash的设计，若使用consistent hash的方法，陡增的流量极可能把哈希环的下一个节点压垮。\n- 如果整个cluster需要offline，则切流量到其他cluster。\n\n## region区域单元化\n\n当cluster不断扩容，网络拥塞、热key问题不断加剧，再扩容时问题已经得不到缓解，此时需要split成多个frontend cluster了。一个frontend cluster，由一个web server cluster和一个memcached cluster构成。多个frontend cluster，共享一个storge cluster(database)，组成一个region。\n\n![image](https://user-images.githubusercontent.com/4915189/79035537-29b12a00-7bf2-11ea-82e9-def08fc08928.png)\n（图4 mcsqueal失效缓存）\n\nregion内部如何失效缓存\n- 提交SQL带有要失效的key，mcsqueal（database级别，见图4）监听数据库的commit log，解析出delete事件广播给region内所有mcrouter失效缓存。web server在delete后会直接失效其关联cluster的缓存，减少其关联cluster的stale data停留时间以提供read-after-write。mcsqueal方案设计缘由，在跨region设计章节有阐述。\n- 减少失效package rate：mcsqueal将delete batch化提交到专用的mcrouter服务器，由其去分发到真实memcached。\n- 为什么不由web server触发缓存失效，分散的web server比收敛到数据库commit log的mcsqueal做batch低效，会造成更多package。且web server对于配置错误导致的错误路由无法重试，commit log+mcsqueal则是可靠的可重放的。\n\nregional pool：多个frontend cluster共享一个专用的pool称为regional pool，避免在每个cluster中replica低频访问的数据。\n- 数据量大访问量很小的，适合共享到regional pool。访问量大的，适合每个cluster都存一份。若regional pool的机器failed了，Gutter又派上了用场，且regional pool占据每个cluster的wildcard的25%机器。\n- 冷启动：前提是data replicate到多个cluster。从其他warm cluster获取数据加速冷启动，直至新cluster的hit rate达到预设的一个稳定值。这可能带来不一致性的问题。冷cluster先触发update，紧接着又一client从冷cluster取数据（冷启动未结束，实际是从warm cluster取），warm cluster此时还没收到mcsqueal失效缓存指令返回脏数据。delete操作可设置hold-off时间（2秒）拒绝掉add操作（可能是从warm cluster同步过来的脏数据），client发起add失败意味着要去数据库重新fetch以避免上述问题。delete操作如果被2秒后才同步到warm cluster执行，client还是有可能拿到脏数据，相比warm up这个代价可接受且概率低。\n\n## cross-region跨区域\n\n演变到multi region的原因是，用户可接入到更近的region降低latency、容灾考虑和电费考虑。多个region中，一个region的storage master负责读写，其他region的storage  cluster是read-only的（数据通过MySQL replication同步）。cross-region很容易带来一致性问题，这主要是主从数据库集群lag太大导致的。主要考虑两种情况的写操作对缓存一致性的影响。\n\nwrite from master region：使用MySQL同步+mcsqueal触发失效cache是必要的，如果通过web server去触发其他region失效，数据有可能还没同步到其他region。\n\nwrite from non-master region：web server发起写可能影响key k，如何避免该web server随后request的k的脏读？\n1. 在regional pool设置marker rk；\n2. 写操作路由到主库；\n3. 删除local cluster的key k；\n4. 从库mcsqueal消费写操作时，失效本地region的key k，更新最新数据到数据库；\n5. 第4步为完成时，如果rk存在，get k被路由到master region。\n\n（并发写key k仍然会导致脏读，但概率较小，相比带来的好处可容忍）\n\n## 结语\n\n这篇paper有许多值得学习借鉴的，很多关于trade off的推敲，能设身处地的看到他们是怎么想的。\n\n另外值得一提的是，paper对于数据监控也是非常重视的，如请求百分比与server参与数、请求百分比与包大小，以及其p50、p75、p95等数据，做监控可以从这里学习和借鉴思想。\n\n## 参考文献\n\n[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)\n[缓存更新的套路](https://coolshell.cn/articles/17416.html)\n[How Facebook Scaled Memcache ?](https://efficientcodeblog.wordpress.com/2017/11/05/how-facebook-scale-memcache/)\n[Scaling Memcache in Facebook 笔记（一）](https://zhuanlan.zhihu.com/p/20734038)\n","source":"_posts/2020-03-31-Scaling-Memcache-at-Facebook.md","raw":"---\ntitle: Paper阅读：Scaling Memcache at Facebook\ndate: 2020-03-31 20:33:29\ntags: ['Paper阅读', 'Memcached']\ncomments: true\ncategories: ['系统设计']\n---\n\n记录阅读论文[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)的笔记。\n\n<!--more-->\n\n## 背景介绍\n\n[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)是Facebook团队2013年的一篇论文，讲述Facebook如何使用开源的memcached构建分布式内存KV集群，以响应billion级QPS。\n\nFacebook作为社交网络服务基础设施，需要满足：\n- 近似实时通信；\n- 实时聚合多个来源的内容；\n- 读取/更新热点的共享内容；\n- 可伸缩以处理billion级用户并发。\n\n为满足以上需求，Facebook从单机(memcached)、集群(cluster)、区域(region)、跨区域(cross-region)这4个方面以bottom up的方式讲述他们是如何scale的。memcache作为一个cache集群：用户大量读QPS，相比之下写QPS非常小；读的数据有多个后端源（MySQL/HDFS等），使用memcache集群做为query cache缓存可以极大的降低对后端存储系统的负载。Facebook使用一种cache aside的模式维护缓存，如图1：\n\n![imagex](https://user-images.githubusercontent.com/4915189/78672026-a9997480-7912-11ea-9d8b-6837cd7f498e.png)\n（图1 缓存更新模式）\n\n[缓存更新的套路](https://coolshell.cn/articles/17416.html)提到这种模式在极端条件下会出错：A会话读完数据库网络阻塞，B会话删除并失效缓存，A会话将脏数据写到缓存。这种极端条件概率比较低，cache aside是在更复杂方案与简单但小概率出错之间的取舍。\n\n在进入正文之前，需要厘清以下概念（见图2）：\n- memcached：开源memcached技术，在文中指运行时的单台实例；\n- cluster：指多台memcached组成的最小单位的集群，memcached之间相互不通信，由client端使用consistent hash将数据分布到多台memcached；\n- region：多web server集群和多cluster集群组成frontend clusters，共享一个storage cluster组成一个region；\n- cross-region：多个region，每个region分布在不同地理位置。只有一个region的storage cluster是master角色，其他的是slave角色，从master同步数据。\n\n![image](https://user-images.githubusercontent.com/4915189/78672689-933fe880-7913-11ea-8557-74d5a3fac5bf.png)\n（图2 以上概念的整体架构图示）\n\n## memcached单机优化\n\n对于开源的memcached，Facebook贡献给了社区的hashtable自动扩容、多线程加全局锁等优化。下面讲解一些未贡献给社区的。\n\n其一是支持UDP通信，通过UDP实现的的multiget，要比TCP性能优异13%；\n\n其二是动态的slab allocator。memcache预分配有多种size的slab桶，size从64 byte指数增长到1M不等，每个size的slab桶的个数是一定的。发起set调用时，根据value大小分配到满足条件的最小size的slab桶中。当负载增加时，某个size的slab桶可能会内存不足导致频繁该slab桶频繁的LRU，而其他slab桶因为命中率比较低其实是空闲的。Facebook做的优化是，检测slab桶中即将LRU的item，是否比其他slab桶的LRU item的使用次数要多20%，若是则保有该item从其他slab桶腾挪内存。\n\n其三是，short-lived key的清理。memcached对于已经expired的short-lived key的清理，是在get调用或LRU时触发的，这样可能导致short-lived key的堆积，Facebook使用circular buffer来加速其清理。circular buffer有固定的桶数量（比方说10个桶），每个桶代表1秒，short-lived key根据其expired时间将key分配到某个桶中。每1秒清除circular buffer头结点上的所有key，同时向前进一格，如此循环反复。\n\n其四，是使用shared memory解决memcached的热部署问题，这点在[Fast Database Restarts at Facebook](https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf)有详细的阐述。\n\n## cluster最小单位集群\n\ncluster的主要目标是get调用的低延迟，以及cache miss时不造成storage服务的load剧增。cluster主要围绕client端做优化，client是无状态的，表现为织入到web server的SDK，或独立运行的进程mcrouter（代理程序）。\n\n![image](https://user-images.githubusercontent.com/4915189/78765359-79a5ac00-79ba-11ea-8e1e-fd8fa31c4ed9.png)\n（图3 web server与memcached的通信示意图）\n\nweb server client如何减少延迟：\n- web server client将所需key构造为DAG（有向无环图）描绘依赖关系，对于能并发请求的数据batch化获取减少fetch调用次数，经统计每次batch平均有24个key。\n- web server client使用UDP（见图3）绕过mcrouter直接向memcached实例get数据，以实现低通信延迟。峰值负载下，0.25%的UDP的get请求失败，失败原因80%是因为丢包、超时。UDP的get请求错误会被当成cache miss，client从数据库load数据但不更新cache，因为get错误表明网络情况不佳，若还更新cache则加重网络负载。相比使用TCP执行get请求，有20%的通信延迟降低。\n- mcrouter负责set和delete请求（见图3），和web server结对部署，使用TCP和需要通信的memcached建立长连接。这样设计是因为set和delete请求需要TCP的可靠重试，以及不需要每个web server thread都和memcached直接建立长连接，由mcrouter统一接管减少长连接数量可节省CPU、内存、带宽。\n- all-to-all拥塞控制：UDP的get请求，是一种all-to-all通信模式，每个web server client都可直接与cluster内的N台memcached通信，这带来的潜在问题是网络拥塞。当每个client发送大量get请求，交换机、路由等网络设备将出现瓶颈。Facebook实现了一种划窗式(window)拥塞算法控制请求并发度，window大小表示request并发数，即每个request都要占据window的一个坑位并在request结束才释放坑位。window设置得太小，并发度低近似于串行，响应时间长；window设置得太大，并发请求多导致拥塞，响应时间也变长了。client与每个memcached的window是单独控制的，类似于TCP的拥塞控制算法。\n\nweb server如何减轻对存储的负载？\n- stale sets问题，在并发写memcached被重排序时会发生。论文设计了一个lease机制，在get调用cache miss时会返回一个token（这个token可以设置成每N秒只生成一个），client端从存储系统load到数据后将token和数据一起set到memcached，若token校验通过则写成功，否则写失败，这样就避免了stale sets问题。\n- thundering herds问题，是一个key被重度读写导致，写频繁失效缓存导致不断读存储。假设某个key刚被失效，此时有M个client读取发现cache miss，若M个client都去读存储系统那么将给其带来极大压力。首先，delete调用会使memcached为该key生成的token立即失效，相当于memcached又有配额为该key生成token；其次，get调用cache miss时，memcached可以只返回token给一个client，其他client返回一个短时间通知其休眠；最后，拿到token的client负责读盘set缓存，其他client短暂休眠后也就能读到数据了。\n- lease机制使得高峰读数据库从17K/s降至1.3K/s。memcached的key被客户端失效时，可以打上一个stale标记延期清除，这样在get调用时可以顺带返回过期的数据由客户端决定是否需要重新更新cache。多数情况下，过期数据是无害的，这能在高峰时期降低系统负载。\n- pool池化设计。将频繁访问且cache miss代价较小的key，与较少访问但cache miss代价昂贵的key，划分到不同的memcached pool，防止相互影响。key默认存放的pool叫wildcard pool，若在默认pool找不到key，则key可能存在于其他dedicated pool（专用pool）。论文没有阐述client是如何定位到不同pool查询key的。\n- pool的replication设计。假设单机memcached需要处理1M request/sec，每个request返回100个key。为了降低负载，策略一是将一半的key分到另外一台机，但这样单机的请求还是1M request/sec，只是返回key数量变成了50个。单个request返回100还是50个key，没有实质性区别。策略二是将数据replicate到另外一台机，这样每台机只需承担500K request/sec，单机负载就大大降低了。\n\nweb server如何做错误处理？\n- 小部分机器请求failed时，表现为get没有response，Facebook设计了Gutter来容错。当get调用failed时，请求会重试提交到Gutter pool。Gutter占cluster总机器1%，是一个stand by的pool，且为了减轻数据库负载是允许返回stale数据的。当出现hot key问题时，部分request将频繁失败，使用Gutter来有效分流，避免hot key压垮memcached（上文的pool replication也是这个目的）。如果没有Gutter容错，所有failed的get调用都会触发读盘，因为负责该key的memcached已经crash了。这是不同于rehash的设计，若使用consistent hash的方法，陡增的流量极可能把哈希环的下一个节点压垮。\n- 如果整个cluster需要offline，则切流量到其他cluster。\n\n## region区域单元化\n\n当cluster不断扩容，网络拥塞、热key问题不断加剧，再扩容时问题已经得不到缓解，此时需要split成多个frontend cluster了。一个frontend cluster，由一个web server cluster和一个memcached cluster构成。多个frontend cluster，共享一个storge cluster(database)，组成一个region。\n\n![image](https://user-images.githubusercontent.com/4915189/79035537-29b12a00-7bf2-11ea-82e9-def08fc08928.png)\n（图4 mcsqueal失效缓存）\n\nregion内部如何失效缓存\n- 提交SQL带有要失效的key，mcsqueal（database级别，见图4）监听数据库的commit log，解析出delete事件广播给region内所有mcrouter失效缓存。web server在delete后会直接失效其关联cluster的缓存，减少其关联cluster的stale data停留时间以提供read-after-write。mcsqueal方案设计缘由，在跨region设计章节有阐述。\n- 减少失效package rate：mcsqueal将delete batch化提交到专用的mcrouter服务器，由其去分发到真实memcached。\n- 为什么不由web server触发缓存失效，分散的web server比收敛到数据库commit log的mcsqueal做batch低效，会造成更多package。且web server对于配置错误导致的错误路由无法重试，commit log+mcsqueal则是可靠的可重放的。\n\nregional pool：多个frontend cluster共享一个专用的pool称为regional pool，避免在每个cluster中replica低频访问的数据。\n- 数据量大访问量很小的，适合共享到regional pool。访问量大的，适合每个cluster都存一份。若regional pool的机器failed了，Gutter又派上了用场，且regional pool占据每个cluster的wildcard的25%机器。\n- 冷启动：前提是data replicate到多个cluster。从其他warm cluster获取数据加速冷启动，直至新cluster的hit rate达到预设的一个稳定值。这可能带来不一致性的问题。冷cluster先触发update，紧接着又一client从冷cluster取数据（冷启动未结束，实际是从warm cluster取），warm cluster此时还没收到mcsqueal失效缓存指令返回脏数据。delete操作可设置hold-off时间（2秒）拒绝掉add操作（可能是从warm cluster同步过来的脏数据），client发起add失败意味着要去数据库重新fetch以避免上述问题。delete操作如果被2秒后才同步到warm cluster执行，client还是有可能拿到脏数据，相比warm up这个代价可接受且概率低。\n\n## cross-region跨区域\n\n演变到multi region的原因是，用户可接入到更近的region降低latency、容灾考虑和电费考虑。多个region中，一个region的storage master负责读写，其他region的storage  cluster是read-only的（数据通过MySQL replication同步）。cross-region很容易带来一致性问题，这主要是主从数据库集群lag太大导致的。主要考虑两种情况的写操作对缓存一致性的影响。\n\nwrite from master region：使用MySQL同步+mcsqueal触发失效cache是必要的，如果通过web server去触发其他region失效，数据有可能还没同步到其他region。\n\nwrite from non-master region：web server发起写可能影响key k，如何避免该web server随后request的k的脏读？\n1. 在regional pool设置marker rk；\n2. 写操作路由到主库；\n3. 删除local cluster的key k；\n4. 从库mcsqueal消费写操作时，失效本地region的key k，更新最新数据到数据库；\n5. 第4步为完成时，如果rk存在，get k被路由到master region。\n\n（并发写key k仍然会导致脏读，但概率较小，相比带来的好处可容忍）\n\n## 结语\n\n这篇paper有许多值得学习借鉴的，很多关于trade off的推敲，能设身处地的看到他们是怎么想的。\n\n另外值得一提的是，paper对于数据监控也是非常重视的，如请求百分比与server参与数、请求百分比与包大小，以及其p50、p75、p95等数据，做监控可以从这里学习和借鉴思想。\n\n## 参考文献\n\n[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)\n[缓存更新的套路](https://coolshell.cn/articles/17416.html)\n[How Facebook Scaled Memcache ?](https://efficientcodeblog.wordpress.com/2017/11/05/how-facebook-scale-memcache/)\n[Scaling Memcache in Facebook 笔记（一）](https://zhuanlan.zhihu.com/p/20734038)\n","slug":"Scaling-Memcache-at-Facebook","published":1,"updated":"2022-08-09T15:02:00.672Z","layout":"post","photos":[],"link":"","_id":"cl6mbc14y0044igu8nm2o4pju","content":"<p>记录阅读论文<a href=\"https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf\" target=\"_blank\" rel=\"noopener\">Scaling Memcache at Facebook</a>的笔记。</p>\n<a id=\"more\"></a>\n<h2 id=\"背景介绍\"><a href=\"#背景介绍\" class=\"headerlink\" title=\"背景介绍\"></a>背景介绍</h2><p><a href=\"https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf\" target=\"_blank\" rel=\"noopener\">Scaling Memcache at Facebook</a>是Facebook团队2013年的一篇论文，讲述Facebook如何使用开源的memcached构建分布式内存KV集群，以响应billion级QPS。</p>\n<p>Facebook作为社交网络服务基础设施，需要满足：</p>\n<ul>\n<li>近似实时通信；</li>\n<li>实时聚合多个来源的内容；</li>\n<li>读取/更新热点的共享内容；</li>\n<li>可伸缩以处理billion级用户并发。</li>\n</ul>\n<p>为满足以上需求，Facebook从单机(memcached)、集群(cluster)、区域(region)、跨区域(cross-region)这4个方面以bottom up的方式讲述他们是如何scale的。memcache作为一个cache集群：用户大量读QPS，相比之下写QPS非常小；读的数据有多个后端源（MySQL/HDFS等），使用memcache集群做为query cache缓存可以极大的降低对后端存储系统的负载。Facebook使用一种cache aside的模式维护缓存，如图1：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/78672026-a9997480-7912-11ea-9d8b-6837cd7f498e.png\" alt=\"imagex\"><br>（图1 缓存更新模式）</p>\n<p><a href=\"https://coolshell.cn/articles/17416.html\" target=\"_blank\" rel=\"noopener\">缓存更新的套路</a>提到这种模式在极端条件下会出错：A会话读完数据库网络阻塞，B会话删除并失效缓存，A会话将脏数据写到缓存。这种极端条件概率比较低，cache aside是在更复杂方案与简单但小概率出错之间的取舍。</p>\n<p>在进入正文之前，需要厘清以下概念（见图2）：</p>\n<ul>\n<li>memcached：开源memcached技术，在文中指运行时的单台实例；</li>\n<li>cluster：指多台memcached组成的最小单位的集群，memcached之间相互不通信，由client端使用consistent hash将数据分布到多台memcached；</li>\n<li>region：多web server集群和多cluster集群组成frontend clusters，共享一个storage cluster组成一个region；</li>\n<li>cross-region：多个region，每个region分布在不同地理位置。只有一个region的storage cluster是master角色，其他的是slave角色，从master同步数据。</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/78672689-933fe880-7913-11ea-8557-74d5a3fac5bf.png\" alt=\"image\"><br>（图2 以上概念的整体架构图示）</p>\n<h2 id=\"memcached单机优化\"><a href=\"#memcached单机优化\" class=\"headerlink\" title=\"memcached单机优化\"></a>memcached单机优化</h2><p>对于开源的memcached，Facebook贡献给了社区的hashtable自动扩容、多线程加全局锁等优化。下面讲解一些未贡献给社区的。</p>\n<p>其一是支持UDP通信，通过UDP实现的的multiget，要比TCP性能优异13%；</p>\n<p>其二是动态的slab allocator。memcache预分配有多种size的slab桶，size从64 byte指数增长到1M不等，每个size的slab桶的个数是一定的。发起set调用时，根据value大小分配到满足条件的最小size的slab桶中。当负载增加时，某个size的slab桶可能会内存不足导致频繁该slab桶频繁的LRU，而其他slab桶因为命中率比较低其实是空闲的。Facebook做的优化是，检测slab桶中即将LRU的item，是否比其他slab桶的LRU item的使用次数要多20%，若是则保有该item从其他slab桶腾挪内存。</p>\n<p>其三是，short-lived key的清理。memcached对于已经expired的short-lived key的清理，是在get调用或LRU时触发的，这样可能导致short-lived key的堆积，Facebook使用circular buffer来加速其清理。circular buffer有固定的桶数量（比方说10个桶），每个桶代表1秒，short-lived key根据其expired时间将key分配到某个桶中。每1秒清除circular buffer头结点上的所有key，同时向前进一格，如此循环反复。</p>\n<p>其四，是使用shared memory解决memcached的热部署问题，这点在<a href=\"https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf\" target=\"_blank\" rel=\"noopener\">Fast Database Restarts at Facebook</a>有详细的阐述。</p>\n<h2 id=\"cluster最小单位集群\"><a href=\"#cluster最小单位集群\" class=\"headerlink\" title=\"cluster最小单位集群\"></a>cluster最小单位集群</h2><p>cluster的主要目标是get调用的低延迟，以及cache miss时不造成storage服务的load剧增。cluster主要围绕client端做优化，client是无状态的，表现为织入到web server的SDK，或独立运行的进程mcrouter（代理程序）。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/78765359-79a5ac00-79ba-11ea-8e1e-fd8fa31c4ed9.png\" alt=\"image\"><br>（图3 web server与memcached的通信示意图）</p>\n<p>web server client如何减少延迟：</p>\n<ul>\n<li>web server client将所需key构造为DAG（有向无环图）描绘依赖关系，对于能并发请求的数据batch化获取减少fetch调用次数，经统计每次batch平均有24个key。</li>\n<li>web server client使用UDP（见图3）绕过mcrouter直接向memcached实例get数据，以实现低通信延迟。峰值负载下，0.25%的UDP的get请求失败，失败原因80%是因为丢包、超时。UDP的get请求错误会被当成cache miss，client从数据库load数据但不更新cache，因为get错误表明网络情况不佳，若还更新cache则加重网络负载。相比使用TCP执行get请求，有20%的通信延迟降低。</li>\n<li>mcrouter负责set和delete请求（见图3），和web server结对部署，使用TCP和需要通信的memcached建立长连接。这样设计是因为set和delete请求需要TCP的可靠重试，以及不需要每个web server thread都和memcached直接建立长连接，由mcrouter统一接管减少长连接数量可节省CPU、内存、带宽。</li>\n<li>all-to-all拥塞控制：UDP的get请求，是一种all-to-all通信模式，每个web server client都可直接与cluster内的N台memcached通信，这带来的潜在问题是网络拥塞。当每个client发送大量get请求，交换机、路由等网络设备将出现瓶颈。Facebook实现了一种划窗式(window)拥塞算法控制请求并发度，window大小表示request并发数，即每个request都要占据window的一个坑位并在request结束才释放坑位。window设置得太小，并发度低近似于串行，响应时间长；window设置得太大，并发请求多导致拥塞，响应时间也变长了。client与每个memcached的window是单独控制的，类似于TCP的拥塞控制算法。</li>\n</ul>\n<p>web server如何减轻对存储的负载？</p>\n<ul>\n<li>stale sets问题，在并发写memcached被重排序时会发生。论文设计了一个lease机制，在get调用cache miss时会返回一个token（这个token可以设置成每N秒只生成一个），client端从存储系统load到数据后将token和数据一起set到memcached，若token校验通过则写成功，否则写失败，这样就避免了stale sets问题。</li>\n<li>thundering herds问题，是一个key被重度读写导致，写频繁失效缓存导致不断读存储。假设某个key刚被失效，此时有M个client读取发现cache miss，若M个client都去读存储系统那么将给其带来极大压力。首先，delete调用会使memcached为该key生成的token立即失效，相当于memcached又有配额为该key生成token；其次，get调用cache miss时，memcached可以只返回token给一个client，其他client返回一个短时间通知其休眠；最后，拿到token的client负责读盘set缓存，其他client短暂休眠后也就能读到数据了。</li>\n<li>lease机制使得高峰读数据库从17K/s降至1.3K/s。memcached的key被客户端失效时，可以打上一个stale标记延期清除，这样在get调用时可以顺带返回过期的数据由客户端决定是否需要重新更新cache。多数情况下，过期数据是无害的，这能在高峰时期降低系统负载。</li>\n<li>pool池化设计。将频繁访问且cache miss代价较小的key，与较少访问但cache miss代价昂贵的key，划分到不同的memcached pool，防止相互影响。key默认存放的pool叫wildcard pool，若在默认pool找不到key，则key可能存在于其他dedicated pool（专用pool）。论文没有阐述client是如何定位到不同pool查询key的。</li>\n<li>pool的replication设计。假设单机memcached需要处理1M request/sec，每个request返回100个key。为了降低负载，策略一是将一半的key分到另外一台机，但这样单机的请求还是1M request/sec，只是返回key数量变成了50个。单个request返回100还是50个key，没有实质性区别。策略二是将数据replicate到另外一台机，这样每台机只需承担500K request/sec，单机负载就大大降低了。</li>\n</ul>\n<p>web server如何做错误处理？</p>\n<ul>\n<li>小部分机器请求failed时，表现为get没有response，Facebook设计了Gutter来容错。当get调用failed时，请求会重试提交到Gutter pool。Gutter占cluster总机器1%，是一个stand by的pool，且为了减轻数据库负载是允许返回stale数据的。当出现hot key问题时，部分request将频繁失败，使用Gutter来有效分流，避免hot key压垮memcached（上文的pool replication也是这个目的）。如果没有Gutter容错，所有failed的get调用都会触发读盘，因为负责该key的memcached已经crash了。这是不同于rehash的设计，若使用consistent hash的方法，陡增的流量极可能把哈希环的下一个节点压垮。</li>\n<li>如果整个cluster需要offline，则切流量到其他cluster。</li>\n</ul>\n<h2 id=\"region区域单元化\"><a href=\"#region区域单元化\" class=\"headerlink\" title=\"region区域单元化\"></a>region区域单元化</h2><p>当cluster不断扩容，网络拥塞、热key问题不断加剧，再扩容时问题已经得不到缓解，此时需要split成多个frontend cluster了。一个frontend cluster，由一个web server cluster和一个memcached cluster构成。多个frontend cluster，共享一个storge cluster(database)，组成一个region。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/79035537-29b12a00-7bf2-11ea-82e9-def08fc08928.png\" alt=\"image\"><br>（图4 mcsqueal失效缓存）</p>\n<p>region内部如何失效缓存</p>\n<ul>\n<li>提交SQL带有要失效的key，mcsqueal（database级别，见图4）监听数据库的commit log，解析出delete事件广播给region内所有mcrouter失效缓存。web server在delete后会直接失效其关联cluster的缓存，减少其关联cluster的stale data停留时间以提供read-after-write。mcsqueal方案设计缘由，在跨region设计章节有阐述。</li>\n<li>减少失效package rate：mcsqueal将delete batch化提交到专用的mcrouter服务器，由其去分发到真实memcached。</li>\n<li>为什么不由web server触发缓存失效，分散的web server比收敛到数据库commit log的mcsqueal做batch低效，会造成更多package。且web server对于配置错误导致的错误路由无法重试，commit log+mcsqueal则是可靠的可重放的。</li>\n</ul>\n<p>regional pool：多个frontend cluster共享一个专用的pool称为regional pool，避免在每个cluster中replica低频访问的数据。</p>\n<ul>\n<li>数据量大访问量很小的，适合共享到regional pool。访问量大的，适合每个cluster都存一份。若regional pool的机器failed了，Gutter又派上了用场，且regional pool占据每个cluster的wildcard的25%机器。</li>\n<li>冷启动：前提是data replicate到多个cluster。从其他warm cluster获取数据加速冷启动，直至新cluster的hit rate达到预设的一个稳定值。这可能带来不一致性的问题。冷cluster先触发update，紧接着又一client从冷cluster取数据（冷启动未结束，实际是从warm cluster取），warm cluster此时还没收到mcsqueal失效缓存指令返回脏数据。delete操作可设置hold-off时间（2秒）拒绝掉add操作（可能是从warm cluster同步过来的脏数据），client发起add失败意味着要去数据库重新fetch以避免上述问题。delete操作如果被2秒后才同步到warm cluster执行，client还是有可能拿到脏数据，相比warm up这个代价可接受且概率低。</li>\n</ul>\n<h2 id=\"cross-region跨区域\"><a href=\"#cross-region跨区域\" class=\"headerlink\" title=\"cross-region跨区域\"></a>cross-region跨区域</h2><p>演变到multi region的原因是，用户可接入到更近的region降低latency、容灾考虑和电费考虑。多个region中，一个region的storage master负责读写，其他region的storage  cluster是read-only的（数据通过MySQL replication同步）。cross-region很容易带来一致性问题，这主要是主从数据库集群lag太大导致的。主要考虑两种情况的写操作对缓存一致性的影响。</p>\n<p>write from master region：使用MySQL同步+mcsqueal触发失效cache是必要的，如果通过web server去触发其他region失效，数据有可能还没同步到其他region。</p>\n<p>write from non-master region：web server发起写可能影响key k，如何避免该web server随后request的k的脏读？</p>\n<ol>\n<li>在regional pool设置marker rk；</li>\n<li>写操作路由到主库；</li>\n<li>删除local cluster的key k；</li>\n<li>从库mcsqueal消费写操作时，失效本地region的key k，更新最新数据到数据库；</li>\n<li>第4步为完成时，如果rk存在，get k被路由到master region。</li>\n</ol>\n<p>（并发写key k仍然会导致脏读，但概率较小，相比带来的好处可容忍）</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>这篇paper有许多值得学习借鉴的，很多关于trade off的推敲，能设身处地的看到他们是怎么想的。</p>\n<p>另外值得一提的是，paper对于数据监控也是非常重视的，如请求百分比与server参与数、请求百分比与包大小，以及其p50、p75、p95等数据，做监控可以从这里学习和借鉴思想。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p><a href=\"https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf\" target=\"_blank\" rel=\"noopener\">Scaling Memcache at Facebook</a><br><a href=\"https://coolshell.cn/articles/17416.html\" target=\"_blank\" rel=\"noopener\">缓存更新的套路</a><br><a href=\"https://efficientcodeblog.wordpress.com/2017/11/05/how-facebook-scale-memcache/\" target=\"_blank\" rel=\"noopener\">How Facebook Scaled Memcache ?</a><br><a href=\"https://zhuanlan.zhihu.com/p/20734038\" target=\"_blank\" rel=\"noopener\">Scaling Memcache in Facebook 笔记（一）</a></p>\n","site":{"data":{}},"excerpt":"<p>记录阅读论文<a href=\"https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf\" target=\"_blank\" rel=\"noopener\">Scaling Memcache at Facebook</a>的笔记。</p>","more":"<h2 id=\"背景介绍\"><a href=\"#背景介绍\" class=\"headerlink\" title=\"背景介绍\"></a>背景介绍</h2><p><a href=\"https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf\" target=\"_blank\" rel=\"noopener\">Scaling Memcache at Facebook</a>是Facebook团队2013年的一篇论文，讲述Facebook如何使用开源的memcached构建分布式内存KV集群，以响应billion级QPS。</p>\n<p>Facebook作为社交网络服务基础设施，需要满足：</p>\n<ul>\n<li>近似实时通信；</li>\n<li>实时聚合多个来源的内容；</li>\n<li>读取/更新热点的共享内容；</li>\n<li>可伸缩以处理billion级用户并发。</li>\n</ul>\n<p>为满足以上需求，Facebook从单机(memcached)、集群(cluster)、区域(region)、跨区域(cross-region)这4个方面以bottom up的方式讲述他们是如何scale的。memcache作为一个cache集群：用户大量读QPS，相比之下写QPS非常小；读的数据有多个后端源（MySQL/HDFS等），使用memcache集群做为query cache缓存可以极大的降低对后端存储系统的负载。Facebook使用一种cache aside的模式维护缓存，如图1：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/78672026-a9997480-7912-11ea-9d8b-6837cd7f498e.png\" alt=\"imagex\"><br>（图1 缓存更新模式）</p>\n<p><a href=\"https://coolshell.cn/articles/17416.html\" target=\"_blank\" rel=\"noopener\">缓存更新的套路</a>提到这种模式在极端条件下会出错：A会话读完数据库网络阻塞，B会话删除并失效缓存，A会话将脏数据写到缓存。这种极端条件概率比较低，cache aside是在更复杂方案与简单但小概率出错之间的取舍。</p>\n<p>在进入正文之前，需要厘清以下概念（见图2）：</p>\n<ul>\n<li>memcached：开源memcached技术，在文中指运行时的单台实例；</li>\n<li>cluster：指多台memcached组成的最小单位的集群，memcached之间相互不通信，由client端使用consistent hash将数据分布到多台memcached；</li>\n<li>region：多web server集群和多cluster集群组成frontend clusters，共享一个storage cluster组成一个region；</li>\n<li>cross-region：多个region，每个region分布在不同地理位置。只有一个region的storage cluster是master角色，其他的是slave角色，从master同步数据。</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/78672689-933fe880-7913-11ea-8557-74d5a3fac5bf.png\" alt=\"image\"><br>（图2 以上概念的整体架构图示）</p>\n<h2 id=\"memcached单机优化\"><a href=\"#memcached单机优化\" class=\"headerlink\" title=\"memcached单机优化\"></a>memcached单机优化</h2><p>对于开源的memcached，Facebook贡献给了社区的hashtable自动扩容、多线程加全局锁等优化。下面讲解一些未贡献给社区的。</p>\n<p>其一是支持UDP通信，通过UDP实现的的multiget，要比TCP性能优异13%；</p>\n<p>其二是动态的slab allocator。memcache预分配有多种size的slab桶，size从64 byte指数增长到1M不等，每个size的slab桶的个数是一定的。发起set调用时，根据value大小分配到满足条件的最小size的slab桶中。当负载增加时，某个size的slab桶可能会内存不足导致频繁该slab桶频繁的LRU，而其他slab桶因为命中率比较低其实是空闲的。Facebook做的优化是，检测slab桶中即将LRU的item，是否比其他slab桶的LRU item的使用次数要多20%，若是则保有该item从其他slab桶腾挪内存。</p>\n<p>其三是，short-lived key的清理。memcached对于已经expired的short-lived key的清理，是在get调用或LRU时触发的，这样可能导致short-lived key的堆积，Facebook使用circular buffer来加速其清理。circular buffer有固定的桶数量（比方说10个桶），每个桶代表1秒，short-lived key根据其expired时间将key分配到某个桶中。每1秒清除circular buffer头结点上的所有key，同时向前进一格，如此循环反复。</p>\n<p>其四，是使用shared memory解决memcached的热部署问题，这点在<a href=\"https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf\" target=\"_blank\" rel=\"noopener\">Fast Database Restarts at Facebook</a>有详细的阐述。</p>\n<h2 id=\"cluster最小单位集群\"><a href=\"#cluster最小单位集群\" class=\"headerlink\" title=\"cluster最小单位集群\"></a>cluster最小单位集群</h2><p>cluster的主要目标是get调用的低延迟，以及cache miss时不造成storage服务的load剧增。cluster主要围绕client端做优化，client是无状态的，表现为织入到web server的SDK，或独立运行的进程mcrouter（代理程序）。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/78765359-79a5ac00-79ba-11ea-8e1e-fd8fa31c4ed9.png\" alt=\"image\"><br>（图3 web server与memcached的通信示意图）</p>\n<p>web server client如何减少延迟：</p>\n<ul>\n<li>web server client将所需key构造为DAG（有向无环图）描绘依赖关系，对于能并发请求的数据batch化获取减少fetch调用次数，经统计每次batch平均有24个key。</li>\n<li>web server client使用UDP（见图3）绕过mcrouter直接向memcached实例get数据，以实现低通信延迟。峰值负载下，0.25%的UDP的get请求失败，失败原因80%是因为丢包、超时。UDP的get请求错误会被当成cache miss，client从数据库load数据但不更新cache，因为get错误表明网络情况不佳，若还更新cache则加重网络负载。相比使用TCP执行get请求，有20%的通信延迟降低。</li>\n<li>mcrouter负责set和delete请求（见图3），和web server结对部署，使用TCP和需要通信的memcached建立长连接。这样设计是因为set和delete请求需要TCP的可靠重试，以及不需要每个web server thread都和memcached直接建立长连接，由mcrouter统一接管减少长连接数量可节省CPU、内存、带宽。</li>\n<li>all-to-all拥塞控制：UDP的get请求，是一种all-to-all通信模式，每个web server client都可直接与cluster内的N台memcached通信，这带来的潜在问题是网络拥塞。当每个client发送大量get请求，交换机、路由等网络设备将出现瓶颈。Facebook实现了一种划窗式(window)拥塞算法控制请求并发度，window大小表示request并发数，即每个request都要占据window的一个坑位并在request结束才释放坑位。window设置得太小，并发度低近似于串行，响应时间长；window设置得太大，并发请求多导致拥塞，响应时间也变长了。client与每个memcached的window是单独控制的，类似于TCP的拥塞控制算法。</li>\n</ul>\n<p>web server如何减轻对存储的负载？</p>\n<ul>\n<li>stale sets问题，在并发写memcached被重排序时会发生。论文设计了一个lease机制，在get调用cache miss时会返回一个token（这个token可以设置成每N秒只生成一个），client端从存储系统load到数据后将token和数据一起set到memcached，若token校验通过则写成功，否则写失败，这样就避免了stale sets问题。</li>\n<li>thundering herds问题，是一个key被重度读写导致，写频繁失效缓存导致不断读存储。假设某个key刚被失效，此时有M个client读取发现cache miss，若M个client都去读存储系统那么将给其带来极大压力。首先，delete调用会使memcached为该key生成的token立即失效，相当于memcached又有配额为该key生成token；其次，get调用cache miss时，memcached可以只返回token给一个client，其他client返回一个短时间通知其休眠；最后，拿到token的client负责读盘set缓存，其他client短暂休眠后也就能读到数据了。</li>\n<li>lease机制使得高峰读数据库从17K/s降至1.3K/s。memcached的key被客户端失效时，可以打上一个stale标记延期清除，这样在get调用时可以顺带返回过期的数据由客户端决定是否需要重新更新cache。多数情况下，过期数据是无害的，这能在高峰时期降低系统负载。</li>\n<li>pool池化设计。将频繁访问且cache miss代价较小的key，与较少访问但cache miss代价昂贵的key，划分到不同的memcached pool，防止相互影响。key默认存放的pool叫wildcard pool，若在默认pool找不到key，则key可能存在于其他dedicated pool（专用pool）。论文没有阐述client是如何定位到不同pool查询key的。</li>\n<li>pool的replication设计。假设单机memcached需要处理1M request/sec，每个request返回100个key。为了降低负载，策略一是将一半的key分到另外一台机，但这样单机的请求还是1M request/sec，只是返回key数量变成了50个。单个request返回100还是50个key，没有实质性区别。策略二是将数据replicate到另外一台机，这样每台机只需承担500K request/sec，单机负载就大大降低了。</li>\n</ul>\n<p>web server如何做错误处理？</p>\n<ul>\n<li>小部分机器请求failed时，表现为get没有response，Facebook设计了Gutter来容错。当get调用failed时，请求会重试提交到Gutter pool。Gutter占cluster总机器1%，是一个stand by的pool，且为了减轻数据库负载是允许返回stale数据的。当出现hot key问题时，部分request将频繁失败，使用Gutter来有效分流，避免hot key压垮memcached（上文的pool replication也是这个目的）。如果没有Gutter容错，所有failed的get调用都会触发读盘，因为负责该key的memcached已经crash了。这是不同于rehash的设计，若使用consistent hash的方法，陡增的流量极可能把哈希环的下一个节点压垮。</li>\n<li>如果整个cluster需要offline，则切流量到其他cluster。</li>\n</ul>\n<h2 id=\"region区域单元化\"><a href=\"#region区域单元化\" class=\"headerlink\" title=\"region区域单元化\"></a>region区域单元化</h2><p>当cluster不断扩容，网络拥塞、热key问题不断加剧，再扩容时问题已经得不到缓解，此时需要split成多个frontend cluster了。一个frontend cluster，由一个web server cluster和一个memcached cluster构成。多个frontend cluster，共享一个storge cluster(database)，组成一个region。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/79035537-29b12a00-7bf2-11ea-82e9-def08fc08928.png\" alt=\"image\"><br>（图4 mcsqueal失效缓存）</p>\n<p>region内部如何失效缓存</p>\n<ul>\n<li>提交SQL带有要失效的key，mcsqueal（database级别，见图4）监听数据库的commit log，解析出delete事件广播给region内所有mcrouter失效缓存。web server在delete后会直接失效其关联cluster的缓存，减少其关联cluster的stale data停留时间以提供read-after-write。mcsqueal方案设计缘由，在跨region设计章节有阐述。</li>\n<li>减少失效package rate：mcsqueal将delete batch化提交到专用的mcrouter服务器，由其去分发到真实memcached。</li>\n<li>为什么不由web server触发缓存失效，分散的web server比收敛到数据库commit log的mcsqueal做batch低效，会造成更多package。且web server对于配置错误导致的错误路由无法重试，commit log+mcsqueal则是可靠的可重放的。</li>\n</ul>\n<p>regional pool：多个frontend cluster共享一个专用的pool称为regional pool，避免在每个cluster中replica低频访问的数据。</p>\n<ul>\n<li>数据量大访问量很小的，适合共享到regional pool。访问量大的，适合每个cluster都存一份。若regional pool的机器failed了，Gutter又派上了用场，且regional pool占据每个cluster的wildcard的25%机器。</li>\n<li>冷启动：前提是data replicate到多个cluster。从其他warm cluster获取数据加速冷启动，直至新cluster的hit rate达到预设的一个稳定值。这可能带来不一致性的问题。冷cluster先触发update，紧接着又一client从冷cluster取数据（冷启动未结束，实际是从warm cluster取），warm cluster此时还没收到mcsqueal失效缓存指令返回脏数据。delete操作可设置hold-off时间（2秒）拒绝掉add操作（可能是从warm cluster同步过来的脏数据），client发起add失败意味着要去数据库重新fetch以避免上述问题。delete操作如果被2秒后才同步到warm cluster执行，client还是有可能拿到脏数据，相比warm up这个代价可接受且概率低。</li>\n</ul>\n<h2 id=\"cross-region跨区域\"><a href=\"#cross-region跨区域\" class=\"headerlink\" title=\"cross-region跨区域\"></a>cross-region跨区域</h2><p>演变到multi region的原因是，用户可接入到更近的region降低latency、容灾考虑和电费考虑。多个region中，一个region的storage master负责读写，其他region的storage  cluster是read-only的（数据通过MySQL replication同步）。cross-region很容易带来一致性问题，这主要是主从数据库集群lag太大导致的。主要考虑两种情况的写操作对缓存一致性的影响。</p>\n<p>write from master region：使用MySQL同步+mcsqueal触发失效cache是必要的，如果通过web server去触发其他region失效，数据有可能还没同步到其他region。</p>\n<p>write from non-master region：web server发起写可能影响key k，如何避免该web server随后request的k的脏读？</p>\n<ol>\n<li>在regional pool设置marker rk；</li>\n<li>写操作路由到主库；</li>\n<li>删除local cluster的key k；</li>\n<li>从库mcsqueal消费写操作时，失效本地region的key k，更新最新数据到数据库；</li>\n<li>第4步为完成时，如果rk存在，get k被路由到master region。</li>\n</ol>\n<p>（并发写key k仍然会导致脏读，但概率较小，相比带来的好处可容忍）</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>这篇paper有许多值得学习借鉴的，很多关于trade off的推敲，能设身处地的看到他们是怎么想的。</p>\n<p>另外值得一提的是，paper对于数据监控也是非常重视的，如请求百分比与server参与数、请求百分比与包大小，以及其p50、p75、p95等数据，做监控可以从这里学习和借鉴思想。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p><a href=\"https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf\" target=\"_blank\" rel=\"noopener\">Scaling Memcache at Facebook</a><br><a href=\"https://coolshell.cn/articles/17416.html\" target=\"_blank\" rel=\"noopener\">缓存更新的套路</a><br><a href=\"https://efficientcodeblog.wordpress.com/2017/11/05/how-facebook-scale-memcache/\" target=\"_blank\" rel=\"noopener\">How Facebook Scaled Memcache ?</a><br><a href=\"https://zhuanlan.zhihu.com/p/20734038\" target=\"_blank\" rel=\"noopener\">Scaling Memcache in Facebook 笔记（一）</a></p>"},{"title":"《左耳听风》笔记：性能设计篇","date":"2020-02-15T12:20:26.000Z","comments":1,"_content":"\n极客时间《左耳听风》专栏读书笔记之性能设计篇。\n\n<!--more-->\n\n# 性能设计\n## 缓存 cache\n\n本篇主要讲解了缓存读取更新的三种设计模式，cache章节的图片取自[A beginner’s guide to Cache synchronization strategies](https://vladmihalcea.com/a-beginners-guide-to-cache-synchronization-strategies/)。\n\n模式其一，cache aside。其特点是cache本身不与storage打交道，cache中item的新增由应用调用触发，其过程如下：\n\n![image](https://user-images.githubusercontent.com/4915189/82789987-d9d6ab80-9e9d-11ea-8fb0-6ce300f0cf55.png)\n（图片源自《Scaling Memcache at Facebook》）\n\n- miss：应用读cache发现缓存不存在，应用从数据库加载记录写入到cache，需要注意如果数据库也读不到最后设置某个占位符到cache防止因为不存在的key导致频繁读盘\n- hit：从cache取值返回\n- update：更新数据库，然后失效cache\n\n假定有以下时序，以上cache aside方案将存在问题：\n- cache已失效；\n- A读cache，发现cache不存在；\n- A读数据库，网络拥堵；\n- B更新数据库；\n- B使缓存失效；\n- 网络拥堵结束，A将数据写到cache（BOOM，脏数据）\n- 总结：以上时序出现概率特别低，因为读操作一般远快于写操作（需要加锁）。但还是有可能发生的，业务需要能容忍，cache需要加过期时间，这是在不动用分布式锁下的较简单方案（Facebook的方案）。\n\n模式其二，read/write-through，程序不直接和storage打交道，由cache代理负责缓存更新，如下：\n\n![image](https://user-images.githubusercontent.com/4915189/82790438-a2b4ca00-9e9e-11ea-9340-112f79c3c907.png)\n![image](https://user-images.githubusercontent.com/4915189/82790449-a7797e00-9e9e-11ea-8e4c-8d1ca60efaf4.png)\n（图片源自 https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/）\n\n模式其三，write back，是基于r/w through的优化，将写批量化提交，缺点是未提交的写可能丢失。\n![image](https://user-images.githubusercontent.com/4915189/82790494-ba8c4e00-9e9e-11ea-9912-7bcfcecdc517.png)\n\n需要注意的是，LRU是把无序的key-value数据结构变成有序的，在读写时都需要加锁修改数据结构，在高并发时可能成为瓶颈。\n\n## 异步处理 asynchronize\n\n弹性设计讲了异步通讯，异步处理是指收到上游任务后立即返回一个确认信号，然后使用PULL模型或PUSH模型（需要考虑消费者的更多信息防止投递不出去或压垮消费者）将任务分发给下游消费者处理。\n\n异步处理一般会搭配另外一个设计模式event sourcing（事件溯源）。event sourcing不直接修改结果数据，而是把对数据的操作存储为一个个不可变的event，通过顺序重放event即可得出最终结果。\n\n异步处理也可用于处理分布式事务，如A给B转账。\n- A扣款，生成扣款凭证；\n- 凭证发到B，B收款，B对凭证和收款的处理是幂等的；\n- 转账失败需要事务补偿；\n\n异步处理设计需要有以下考量：\n- 异步处理完成需要通知发起方；\n- 发起方定时检查那些没有回传的任务，需要异步处理系统支持幂等；\n- 事务需要补偿；\n- 强一致不适合使用异步处理；\n- 异步处理需要监控队列堆积；\n\n## 数据库扩展\n\n读写分离\n- 写库容易出现单点故障\n- 需要强一致性的还是得落在写库上\n\nCQRS(Command and Query Responsibility Segregation)\n- command只返回执行状态，会修改数据\n- query返回结果数据，但不修改状态\n- command和query分离，提高系统扩展性，将command转为event sourcing可使得写无状态化\n\n![image](https://user-images.githubusercontent.com/4915189/74600725-6f5ce500-50d0-11ea-87e4-3b75d7c7b8a9.png)\n\nsharding是解决数据库太大的问题，把单体库按照某个规则分为多个库。分片的方式其一是按业务（需要仔细评估业务），其二是按哈希（扩展时会有重哈希的问题）。sharding后，需要有一个数据访问层解析SQL将任务分发给多个库，同时数据访问层还需要聚合多个库的结果返回给调用方。\n\n根本的解法，还是得将数据库、微服务从单体库拆分开。\n\n## 秒杀 flash sales\n\n第一道关，带简单逻辑的CDN（需要和运营商沟通，亚马逊目前有Lambda）。100W用户经过CDN这第一道关后，只放一定比例的用户到数据中心，这个比例值是动态算出来的。\n\n第二道关，数据中心的应对真实流量，之前所讲的弹性设计都可以在这里用上。\n\nCDN玩法非常适合那些用户有地域特征分布的。\n\n## 边缘计算 edge computing\n\n边缘计算是为了降低数据中心架构复杂度，把一部分计算逻辑分到离用户较近的边缘节点。其关键技术有两个：API Gateway、Serverless/Faas。\n","source":"_posts/2020-02-15-chenhao-performance-design.md","raw":"---\ntitle: 《左耳听风》笔记：性能设计篇\ndate: 2020-02-15 20:20:26\ntags: ['系统设计']\ncomments: true\ncategories: ['系统设计']\n---\n\n极客时间《左耳听风》专栏读书笔记之性能设计篇。\n\n<!--more-->\n\n# 性能设计\n## 缓存 cache\n\n本篇主要讲解了缓存读取更新的三种设计模式，cache章节的图片取自[A beginner’s guide to Cache synchronization strategies](https://vladmihalcea.com/a-beginners-guide-to-cache-synchronization-strategies/)。\n\n模式其一，cache aside。其特点是cache本身不与storage打交道，cache中item的新增由应用调用触发，其过程如下：\n\n![image](https://user-images.githubusercontent.com/4915189/82789987-d9d6ab80-9e9d-11ea-8fb0-6ce300f0cf55.png)\n（图片源自《Scaling Memcache at Facebook》）\n\n- miss：应用读cache发现缓存不存在，应用从数据库加载记录写入到cache，需要注意如果数据库也读不到最后设置某个占位符到cache防止因为不存在的key导致频繁读盘\n- hit：从cache取值返回\n- update：更新数据库，然后失效cache\n\n假定有以下时序，以上cache aside方案将存在问题：\n- cache已失效；\n- A读cache，发现cache不存在；\n- A读数据库，网络拥堵；\n- B更新数据库；\n- B使缓存失效；\n- 网络拥堵结束，A将数据写到cache（BOOM，脏数据）\n- 总结：以上时序出现概率特别低，因为读操作一般远快于写操作（需要加锁）。但还是有可能发生的，业务需要能容忍，cache需要加过期时间，这是在不动用分布式锁下的较简单方案（Facebook的方案）。\n\n模式其二，read/write-through，程序不直接和storage打交道，由cache代理负责缓存更新，如下：\n\n![image](https://user-images.githubusercontent.com/4915189/82790438-a2b4ca00-9e9e-11ea-9340-112f79c3c907.png)\n![image](https://user-images.githubusercontent.com/4915189/82790449-a7797e00-9e9e-11ea-8e4c-8d1ca60efaf4.png)\n（图片源自 https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/）\n\n模式其三，write back，是基于r/w through的优化，将写批量化提交，缺点是未提交的写可能丢失。\n![image](https://user-images.githubusercontent.com/4915189/82790494-ba8c4e00-9e9e-11ea-9912-7bcfcecdc517.png)\n\n需要注意的是，LRU是把无序的key-value数据结构变成有序的，在读写时都需要加锁修改数据结构，在高并发时可能成为瓶颈。\n\n## 异步处理 asynchronize\n\n弹性设计讲了异步通讯，异步处理是指收到上游任务后立即返回一个确认信号，然后使用PULL模型或PUSH模型（需要考虑消费者的更多信息防止投递不出去或压垮消费者）将任务分发给下游消费者处理。\n\n异步处理一般会搭配另外一个设计模式event sourcing（事件溯源）。event sourcing不直接修改结果数据，而是把对数据的操作存储为一个个不可变的event，通过顺序重放event即可得出最终结果。\n\n异步处理也可用于处理分布式事务，如A给B转账。\n- A扣款，生成扣款凭证；\n- 凭证发到B，B收款，B对凭证和收款的处理是幂等的；\n- 转账失败需要事务补偿；\n\n异步处理设计需要有以下考量：\n- 异步处理完成需要通知发起方；\n- 发起方定时检查那些没有回传的任务，需要异步处理系统支持幂等；\n- 事务需要补偿；\n- 强一致不适合使用异步处理；\n- 异步处理需要监控队列堆积；\n\n## 数据库扩展\n\n读写分离\n- 写库容易出现单点故障\n- 需要强一致性的还是得落在写库上\n\nCQRS(Command and Query Responsibility Segregation)\n- command只返回执行状态，会修改数据\n- query返回结果数据，但不修改状态\n- command和query分离，提高系统扩展性，将command转为event sourcing可使得写无状态化\n\n![image](https://user-images.githubusercontent.com/4915189/74600725-6f5ce500-50d0-11ea-87e4-3b75d7c7b8a9.png)\n\nsharding是解决数据库太大的问题，把单体库按照某个规则分为多个库。分片的方式其一是按业务（需要仔细评估业务），其二是按哈希（扩展时会有重哈希的问题）。sharding后，需要有一个数据访问层解析SQL将任务分发给多个库，同时数据访问层还需要聚合多个库的结果返回给调用方。\n\n根本的解法，还是得将数据库、微服务从单体库拆分开。\n\n## 秒杀 flash sales\n\n第一道关，带简单逻辑的CDN（需要和运营商沟通，亚马逊目前有Lambda）。100W用户经过CDN这第一道关后，只放一定比例的用户到数据中心，这个比例值是动态算出来的。\n\n第二道关，数据中心的应对真实流量，之前所讲的弹性设计都可以在这里用上。\n\nCDN玩法非常适合那些用户有地域特征分布的。\n\n## 边缘计算 edge computing\n\n边缘计算是为了降低数据中心架构复杂度，把一部分计算逻辑分到离用户较近的边缘节点。其关键技术有两个：API Gateway、Serverless/Faas。\n","slug":"chenhao-performance-design","published":1,"updated":"2022-08-09T15:02:00.670Z","layout":"post","photos":[],"link":"","_id":"cl6mbc1500047igu8tdg9iu8v","content":"<p>极客时间《左耳听风》专栏读书笔记之性能设计篇。</p>\n<a id=\"more\"></a>\n<h1 id=\"性能设计\"><a href=\"#性能设计\" class=\"headerlink\" title=\"性能设计\"></a>性能设计</h1><h2 id=\"缓存-cache\"><a href=\"#缓存-cache\" class=\"headerlink\" title=\"缓存 cache\"></a>缓存 cache</h2><p>本篇主要讲解了缓存读取更新的三种设计模式，cache章节的图片取自<a href=\"https://vladmihalcea.com/a-beginners-guide-to-cache-synchronization-strategies/\" target=\"_blank\" rel=\"noopener\">A beginner’s guide to Cache synchronization strategies</a>。</p>\n<p>模式其一，cache aside。其特点是cache本身不与storage打交道，cache中item的新增由应用调用触发，其过程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/82789987-d9d6ab80-9e9d-11ea-8fb0-6ce300f0cf55.png\" alt=\"image\"><br>（图片源自《Scaling Memcache at Facebook》）</p>\n<ul>\n<li>miss：应用读cache发现缓存不存在，应用从数据库加载记录写入到cache，需要注意如果数据库也读不到最后设置某个占位符到cache防止因为不存在的key导致频繁读盘</li>\n<li>hit：从cache取值返回</li>\n<li>update：更新数据库，然后失效cache</li>\n</ul>\n<p>假定有以下时序，以上cache aside方案将存在问题：</p>\n<ul>\n<li>cache已失效；</li>\n<li>A读cache，发现cache不存在；</li>\n<li>A读数据库，网络拥堵；</li>\n<li>B更新数据库；</li>\n<li>B使缓存失效；</li>\n<li>网络拥堵结束，A将数据写到cache（BOOM，脏数据）</li>\n<li>总结：以上时序出现概率特别低，因为读操作一般远快于写操作（需要加锁）。但还是有可能发生的，业务需要能容忍，cache需要加过期时间，这是在不动用分布式锁下的较简单方案（Facebook的方案）。</li>\n</ul>\n<p>模式其二，read/write-through，程序不直接和storage打交道，由cache代理负责缓存更新，如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/82790438-a2b4ca00-9e9e-11ea-9340-112f79c3c907.png\" alt=\"image\"><br><img src=\"https://user-images.githubusercontent.com/4915189/82790449-a7797e00-9e9e-11ea-8e4c-8d1ca60efaf4.png\" alt=\"image\"><br>（图片源自 <a href=\"https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/）\" target=\"_blank\" rel=\"noopener\">https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/）</a></p>\n<p>模式其三，write back，是基于r/w through的优化，将写批量化提交，缺点是未提交的写可能丢失。<br><img src=\"https://user-images.githubusercontent.com/4915189/82790494-ba8c4e00-9e9e-11ea-9912-7bcfcecdc517.png\" alt=\"image\"></p>\n<p>需要注意的是，LRU是把无序的key-value数据结构变成有序的，在读写时都需要加锁修改数据结构，在高并发时可能成为瓶颈。</p>\n<h2 id=\"异步处理-asynchronize\"><a href=\"#异步处理-asynchronize\" class=\"headerlink\" title=\"异步处理 asynchronize\"></a>异步处理 asynchronize</h2><p>弹性设计讲了异步通讯，异步处理是指收到上游任务后立即返回一个确认信号，然后使用PULL模型或PUSH模型（需要考虑消费者的更多信息防止投递不出去或压垮消费者）将任务分发给下游消费者处理。</p>\n<p>异步处理一般会搭配另外一个设计模式event sourcing（事件溯源）。event sourcing不直接修改结果数据，而是把对数据的操作存储为一个个不可变的event，通过顺序重放event即可得出最终结果。</p>\n<p>异步处理也可用于处理分布式事务，如A给B转账。</p>\n<ul>\n<li>A扣款，生成扣款凭证；</li>\n<li>凭证发到B，B收款，B对凭证和收款的处理是幂等的；</li>\n<li>转账失败需要事务补偿；</li>\n</ul>\n<p>异步处理设计需要有以下考量：</p>\n<ul>\n<li>异步处理完成需要通知发起方；</li>\n<li>发起方定时检查那些没有回传的任务，需要异步处理系统支持幂等；</li>\n<li>事务需要补偿；</li>\n<li>强一致不适合使用异步处理；</li>\n<li>异步处理需要监控队列堆积；</li>\n</ul>\n<h2 id=\"数据库扩展\"><a href=\"#数据库扩展\" class=\"headerlink\" title=\"数据库扩展\"></a>数据库扩展</h2><p>读写分离</p>\n<ul>\n<li>写库容易出现单点故障</li>\n<li>需要强一致性的还是得落在写库上</li>\n</ul>\n<p>CQRS(Command and Query Responsibility Segregation)</p>\n<ul>\n<li>command只返回执行状态，会修改数据</li>\n<li>query返回结果数据，但不修改状态</li>\n<li>command和query分离，提高系统扩展性，将command转为event sourcing可使得写无状态化</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74600725-6f5ce500-50d0-11ea-87e4-3b75d7c7b8a9.png\" alt=\"image\"></p>\n<p>sharding是解决数据库太大的问题，把单体库按照某个规则分为多个库。分片的方式其一是按业务（需要仔细评估业务），其二是按哈希（扩展时会有重哈希的问题）。sharding后，需要有一个数据访问层解析SQL将任务分发给多个库，同时数据访问层还需要聚合多个库的结果返回给调用方。</p>\n<p>根本的解法，还是得将数据库、微服务从单体库拆分开。</p>\n<h2 id=\"秒杀-flash-sales\"><a href=\"#秒杀-flash-sales\" class=\"headerlink\" title=\"秒杀 flash sales\"></a>秒杀 flash sales</h2><p>第一道关，带简单逻辑的CDN（需要和运营商沟通，亚马逊目前有Lambda）。100W用户经过CDN这第一道关后，只放一定比例的用户到数据中心，这个比例值是动态算出来的。</p>\n<p>第二道关，数据中心的应对真实流量，之前所讲的弹性设计都可以在这里用上。</p>\n<p>CDN玩法非常适合那些用户有地域特征分布的。</p>\n<h2 id=\"边缘计算-edge-computing\"><a href=\"#边缘计算-edge-computing\" class=\"headerlink\" title=\"边缘计算 edge computing\"></a>边缘计算 edge computing</h2><p>边缘计算是为了降低数据中心架构复杂度，把一部分计算逻辑分到离用户较近的边缘节点。其关键技术有两个：API Gateway、Serverless/Faas。</p>\n","site":{"data":{}},"excerpt":"<p>极客时间《左耳听风》专栏读书笔记之性能设计篇。</p>","more":"<h1 id=\"性能设计\"><a href=\"#性能设计\" class=\"headerlink\" title=\"性能设计\"></a>性能设计</h1><h2 id=\"缓存-cache\"><a href=\"#缓存-cache\" class=\"headerlink\" title=\"缓存 cache\"></a>缓存 cache</h2><p>本篇主要讲解了缓存读取更新的三种设计模式，cache章节的图片取自<a href=\"https://vladmihalcea.com/a-beginners-guide-to-cache-synchronization-strategies/\" target=\"_blank\" rel=\"noopener\">A beginner’s guide to Cache synchronization strategies</a>。</p>\n<p>模式其一，cache aside。其特点是cache本身不与storage打交道，cache中item的新增由应用调用触发，其过程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/82789987-d9d6ab80-9e9d-11ea-8fb0-6ce300f0cf55.png\" alt=\"image\"><br>（图片源自《Scaling Memcache at Facebook》）</p>\n<ul>\n<li>miss：应用读cache发现缓存不存在，应用从数据库加载记录写入到cache，需要注意如果数据库也读不到最后设置某个占位符到cache防止因为不存在的key导致频繁读盘</li>\n<li>hit：从cache取值返回</li>\n<li>update：更新数据库，然后失效cache</li>\n</ul>\n<p>假定有以下时序，以上cache aside方案将存在问题：</p>\n<ul>\n<li>cache已失效；</li>\n<li>A读cache，发现cache不存在；</li>\n<li>A读数据库，网络拥堵；</li>\n<li>B更新数据库；</li>\n<li>B使缓存失效；</li>\n<li>网络拥堵结束，A将数据写到cache（BOOM，脏数据）</li>\n<li>总结：以上时序出现概率特别低，因为读操作一般远快于写操作（需要加锁）。但还是有可能发生的，业务需要能容忍，cache需要加过期时间，这是在不动用分布式锁下的较简单方案（Facebook的方案）。</li>\n</ul>\n<p>模式其二，read/write-through，程序不直接和storage打交道，由cache代理负责缓存更新，如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/82790438-a2b4ca00-9e9e-11ea-9340-112f79c3c907.png\" alt=\"image\"><br><img src=\"https://user-images.githubusercontent.com/4915189/82790449-a7797e00-9e9e-11ea-8e4c-8d1ca60efaf4.png\" alt=\"image\"><br>（图片源自 <a href=\"https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/）\" target=\"_blank\" rel=\"noopener\">https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/）</a></p>\n<p>模式其三，write back，是基于r/w through的优化，将写批量化提交，缺点是未提交的写可能丢失。<br><img src=\"https://user-images.githubusercontent.com/4915189/82790494-ba8c4e00-9e9e-11ea-9912-7bcfcecdc517.png\" alt=\"image\"></p>\n<p>需要注意的是，LRU是把无序的key-value数据结构变成有序的，在读写时都需要加锁修改数据结构，在高并发时可能成为瓶颈。</p>\n<h2 id=\"异步处理-asynchronize\"><a href=\"#异步处理-asynchronize\" class=\"headerlink\" title=\"异步处理 asynchronize\"></a>异步处理 asynchronize</h2><p>弹性设计讲了异步通讯，异步处理是指收到上游任务后立即返回一个确认信号，然后使用PULL模型或PUSH模型（需要考虑消费者的更多信息防止投递不出去或压垮消费者）将任务分发给下游消费者处理。</p>\n<p>异步处理一般会搭配另外一个设计模式event sourcing（事件溯源）。event sourcing不直接修改结果数据，而是把对数据的操作存储为一个个不可变的event，通过顺序重放event即可得出最终结果。</p>\n<p>异步处理也可用于处理分布式事务，如A给B转账。</p>\n<ul>\n<li>A扣款，生成扣款凭证；</li>\n<li>凭证发到B，B收款，B对凭证和收款的处理是幂等的；</li>\n<li>转账失败需要事务补偿；</li>\n</ul>\n<p>异步处理设计需要有以下考量：</p>\n<ul>\n<li>异步处理完成需要通知发起方；</li>\n<li>发起方定时检查那些没有回传的任务，需要异步处理系统支持幂等；</li>\n<li>事务需要补偿；</li>\n<li>强一致不适合使用异步处理；</li>\n<li>异步处理需要监控队列堆积；</li>\n</ul>\n<h2 id=\"数据库扩展\"><a href=\"#数据库扩展\" class=\"headerlink\" title=\"数据库扩展\"></a>数据库扩展</h2><p>读写分离</p>\n<ul>\n<li>写库容易出现单点故障</li>\n<li>需要强一致性的还是得落在写库上</li>\n</ul>\n<p>CQRS(Command and Query Responsibility Segregation)</p>\n<ul>\n<li>command只返回执行状态，会修改数据</li>\n<li>query返回结果数据，但不修改状态</li>\n<li>command和query分离，提高系统扩展性，将command转为event sourcing可使得写无状态化</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74600725-6f5ce500-50d0-11ea-87e4-3b75d7c7b8a9.png\" alt=\"image\"></p>\n<p>sharding是解决数据库太大的问题，把单体库按照某个规则分为多个库。分片的方式其一是按业务（需要仔细评估业务），其二是按哈希（扩展时会有重哈希的问题）。sharding后，需要有一个数据访问层解析SQL将任务分发给多个库，同时数据访问层还需要聚合多个库的结果返回给调用方。</p>\n<p>根本的解法，还是得将数据库、微服务从单体库拆分开。</p>\n<h2 id=\"秒杀-flash-sales\"><a href=\"#秒杀-flash-sales\" class=\"headerlink\" title=\"秒杀 flash sales\"></a>秒杀 flash sales</h2><p>第一道关，带简单逻辑的CDN（需要和运营商沟通，亚马逊目前有Lambda）。100W用户经过CDN这第一道关后，只放一定比例的用户到数据中心，这个比例值是动态算出来的。</p>\n<p>第二道关，数据中心的应对真实流量，之前所讲的弹性设计都可以在这里用上。</p>\n<p>CDN玩法非常适合那些用户有地域特征分布的。</p>\n<h2 id=\"边缘计算-edge-computing\"><a href=\"#边缘计算-edge-computing\" class=\"headerlink\" title=\"边缘计算 edge computing\"></a>边缘计算 edge computing</h2><p>边缘计算是为了降低数据中心架构复杂度，把一部分计算逻辑分到离用户较近的边缘节点。其关键技术有两个：API Gateway、Serverless/Faas。</p>"},{"title":"浅谈MySQL/Redis/Kafka高可用","date":"2020-03-16T12:29:45.000Z","comments":1,"_content":"\n浅谈MySQL/Redis/Kafka高可用设计。\n\n<!--more-->\n\n## 前言\n\n工作中负责的一个有状态(stateful)服务需要实现高可用，借鉴MySQL/Kafka/Redis是如何实现故障转移(failover)的。主要从以下几个方面浅谈MySQL/Kafka/Redis高可用设计：\n- 如何replicate数据？\n- 如何发现master failed？\n- 如何选举/提升(elect)新的master？\n\n## Kafka\n\nKafka的故障转移，有两个场景：\n- Broker出现故障，由于TopicPartition是单Master提供读写的设计，若该Broker上有Master级别的TopicPartition，需要触发该TopicPartition的重新选主；\n- Controller负责监控Broker并对其进行故障转移，Controller在Kafka集群中也是单Master，出现故障时需要从剩余Broker中从新选举；\n\n### Broker的故障转移\n\n在Topic创建时，Kafka集群根据分区配置创建多个TopicPartition。每个TopicPartition有且仅有一个leader，有一或多个slave（数量由replicate因子而定）。Kafka使用以下方法将TopicPartition分散到多个Broker，使得TopicPartition尽可能的打散：\n\n- 假设有n个broker；\n- 第i个partition的leader副本将被分配到第(i mod n)个broker；\n- 第i个partition的第j个follower副本将被分配到第((i+j) mod n)个broker。\n\n往Kafka集群生产数据时，若将ack配置为all，Broker将确保在所有slave拉取到该消息时才返回给producer确认信号，如下图所示：\n\n![image](https://user-images.githubusercontent.com/4915189/77650148-fd689d00-6fa5-11ea-94ba-e701f614c37c.png)\n（图片源自[Kafka学习之路 （三）Kafka的高可用](https://www.cnblogs.com/qingyunzong/p/9004703.html)）\n\nleader收到新消息会有落盘动作，slave的IO线程拉取到新消息后，在落盘之前会回复给leader以ACK信号，此时新消息只在slave的内存中。这样设计是在可靠性和性能之间做权衡，因为leader和所有slave全部挂掉的概率是极低的，只要有slave在内存中保有新消息，就会在未来被落盘。关于leader和slave之间的数据同步，笔者在[《Kafka核心技术与实战》专栏笔记](https://zhangjunjia.github.io/2020/01/03/kafka-geekbang-note/)有更详细的介绍。\n\nKafka集群使用Controller模块负责Broker的故障转移，如下图所示：\n\n![image](https://user-images.githubusercontent.com/4915189/77652048-9f898480-6fa8-11ea-8a91-1f17a638f9ca.png)\n（图片源自[Kafka学习之路 （三）Kafka的高可用](https://www.cnblogs.com/qingyunzong/p/9004703.html)）\n\n- Controller在Zookeeper注册watcher，当Broker宕机时Zookeeper会fire事件；\n- Controller从Zookeeper读取可用的Broker列表；\n- Controller构造宕机Broker需要故障转移的TopicPartition，对于每个TopicPartition：\n   - 从Zookeeper获取该TopicPartition的ISR集合；\n   - 决定新的leader分配到ISR的某个Broker；\n   - 将新leader所在Broker、ISR、leader_epoch等信息写回Zookeeper；\n   - 通过RPC直接向新leader所在Broker发送leaderAndISRRequest命令；\n   - 原slave与Controller心跳监听到leader变化，改为从leader拉取最新消息。\n\nKafka针对每个TopicPartition维护了ISR集合，只要slave存在于该集合中就意味着slave与leader的消息延迟在可接受范围内，这个可接受范围是通过消息落后条数、最近一次同步时间来配置的。极端情况下，ISR集合可能为空，这意味着已存活的但不在ISR集合中的slave落后于leader太多。此时若进行slave提升则有丢消息的风险，用户需要在可用性和一致性之间做出选择。\n\n这里引申出另一个问题，Kafka集群为何不使用Zookeeper进行leader选举？\n- Broker宕机时，其管理的N个leader角色的TopicPartition都要触发重新选举，如果N太大将给Zookeeper带来非常大的压力，即剩余的Broker同时进行N次leader选举；\n- 引入Controller模块可以减轻Zookeeper压力，通过Controller可使得leader尽可能分散到各Broker中。\n\n### Controller的故障转移\n\nController模块，是所有Broker借助Zookeeper临时节点选举出来的领导者Broker。它是无状态的，不像Broker需要管理TopicPartition的数据。当Controller宕机时，通过Zookeeper触发重新选举即可。\n\n## Redis\n\nRedis主要谈论的是Redis Cluster的故障转移，关于非Cluster方案的故障转移可参考[【原创】那些年用过的Redis集群架构（含面试解析）](https://www.cnblogs.com/rjzheng/p/10360619.html)。\n\n官方文档[Redis cluster tutorial](https://redis.io/topics/cluster-tutorial)提到：\n\n> The first reason why Redis Cluster can lose writes is because it uses asynchronous replication. This means that during writes the following happens:\n> - Your client writes to the master B.\n> - The master B replies OK to your client.\n> - The master B propagates the write to its slaves B1, B2 and B3.\n> \n> As you can see, B does not wait for an acknowledgement from B1, B2, B3 before replying to the client, since this would be a prohibitive latency penalty for Redis, so if your client writes something, B acknowledges the write, but crashes before being able to send the write to its slaves, one of the slaves (that did not receive the write) can be promoted to master, losing the write forever.\n\n从上面这段话我们可以得到Redis Cluster的一些信息，\n- master/slave使用异步的方式同步消息；\n- 消息写到master后立即返回给客户端，此时slave可能还未同步到新写入的消息；\n- 如果master突然崩溃，slave被提升为master，master那部分未同步到slave的消息将永远丢失掉；\n\n那么，Redis Cluster是如何探测master失效，然后提升slave为master的呢？书籍[Redis开发与运维](https://book.douban.com/subject/26971561/)\n[Redis cluster tutorial](https://redis.io/topics/cluster-tutorial)的【10.6 故障转移】有关于这方面的详尽内容。\n\n对于master失效检测，需要经历主观下线、客观下线的过程，**只有master角色的node才有参与主观下线、客观下线的权利**。主观下线的主要过程如下：\n\n![image](https://user-images.githubusercontent.com/4915189/77818292-4470a280-710c-11ea-866a-71c4ea525a6d.png)\n（PING/PING并标记主观下线）\n\n- 集群中的单一node（假定为A），使用gossip协议遵循一定规则（最近最长未通信原则、通信超时原则），定期主动PING集群中的其他node，正常情况下其他node会立即回复PONG；\n- A发出PING后，若未在cluster-node-timeout内收到来自其他node的PONG，则将timeout的node加入到A的pfail主观下线队列中，即A单方面认为其他node已经timeout；\n\n客观下线的主要过程如下：\n- PING/PONG会携带1/10其他node的pfail状态信息，通过gossip传播到其他node；\n- 任一node收到来自其他node的PING信息时，提取其中的pfail信息，更新到其自身维护的pfail队列；\n- 当pfail队列中，有半数以上的node认为某一node已经pfail，且这些主观pfail的消息还未过期(cluster-node-timeout x 2)，则标记失效的master node为主观下线；\n- 通过gossip广播消息到集群其他master node，通知它们某个master node已被标记为客观下线。\n\n之所以要半数以上的node投票(majority vote)，是为防止网络分区时，选举出多个master。极端情况下，master node A和集群其他master被划分到两个网络分区P1和P2，经历cluster-node-timeout时间后master node A也会自我标识为failed的状态：\n> Similarly after node timeout has elapsed without a master node to be able to sense the majority of the other master nodes, it enters an error state and stops accepting writes.\n\n标记为客观下线后，slave提升为master的过程是怎样的呢？失效master node的slave通过定时任务发现其master失效后，slave会触发以下流程：\n- 资格检查：判断与master断线的时间是否长于配置值，若是则不具备提升为master的资格；\n- 准备选举时间：获取其他slave的主从复制offset计算排名，offset最大者表示消息和master最接近，排名为第一。排名第一者，延迟1秒触发故障选举；排名第二，延迟2秒，以此类推，这样设计主要是考虑slave选举优先级；\n![image](https://user-images.githubusercontent.com/4915189/77825513-c5e42700-7144-11ea-9ada-493814af1df5.png)\n- 发起选举：在slave内存中自增集群的全局epoch（在PING/PONG的过程中可以得知集群当前全局epoch），向其他master node广播选举消息；\n- 选举投票：其他master node判断该选举消息携带的epoch是否投票过，若是则忽略，否则投上一票，也即一个epoch只能投一票。若该次选举获得半数以上master node的投票，则slave可提升为master；\n- 替换主节点：取消复制把自身改为主节点，将原先主节点复制的slot委派给自己，广播信息通知其他master和slave自身已提升为master。\n\n## MySQL\n\nMySQL高可用方案，有官方的Cluster方案，有已经不维护的master-master方案，有Group Replication方案（参见[MySQL · 引擎特性 · Group Replication内核解析](http://mysql.taobao.org/monthly/2017/08/01/)和\n[MGR和HAProxy实现高可靠性MySQL集群](https://tmcdcgeek.club/2019/05/24/mgr_haproxy/)），本文主要讨论的是[MHA](https://github.com/yoshinorim/mha4mysql-manager)方案。\n\n关于replicate，MHA支持binlog方案和GTID方案。关于如何监控master失效并提升slave为master，MHA官方文档[Sequences_of_MHA](https://github.com/yoshinorim/mha4mysql-manager/wiki/Sequences_of_MHA)有一份详尽的介绍（以binlog方案为例）：\n- mha-manager验证MHA配置的MySQL实例能否正常连接，每个MySQL实例是否结对部署有mha-node，识别出实例中的master角色；\n- mha-manager不断监测master是否failed，若是则触发failover流程；\n- mha-manager检测其他slave是否更换了追随的master，以及最近是否发生过失败的failover，若是则中断；\n- mha-manager识别出数据offset最大的slave A，若failed的master仍能通过SSH链接，将slave A的binlog补齐到和master一致的状态；\n- mha-manager提升slave A为新master，为确保提升对业务无影响，需要触发脚本将master的虚拟IP指向到新的master，若不使用虚拟IP可参考[详解Mysql 高可用方案 之 Failover mha](https://juejin.im/post/5cc90ef26fb9a03232198ace)提到的proxy方案；\n- 将其他slaves的binlog与新的master对齐，然后change master到新的master。\n\nMHA的问题在于引入了mha-manager的高可用问题，按下葫芦浮起瓢。\n\n## 总结\n\n以上3个方案，极端情况下都可能在故障转移后丢失数据，而且故障转移过程master所负责的服务是不可用的。\n- 一类方案是通过中介监控master失效并提升slave，但这引入了中介的高可用问题；\n- 一类方案是去中介，所有节点互相连接通过gossip故障转移，其代价是gossip通信将耗费较大带宽。\n\n## 参考文献\n\n[Kafka学习之路 （三）Kafka的高可用](https://www.cnblogs.com/qingyunzong/p/9004703.html)\n[Redis开发与运维](https://book.douban.com/subject/26971561/)\n[Redis cluster tutorial](https://redis.io/topics/cluster-tutorial)\n[详解Mysql 高可用方案 之 Failover mha](https://juejin.im/post/5cc90ef26fb9a03232198ace)\n[Sequences_of_MHA](https://github.com/yoshinorim/mha4mysql-manager/wiki/Sequences_of_MHA)\n","source":"_posts/2020-03-16-mysql-redis-kafka-high-availability.md","raw":"---\ntitle: 浅谈MySQL/Redis/Kafka高可用\ndate: 2020-03-16 20:29:45\ntags: ['系统设计', 'MySQL', 'Redis', 'Kafka']\ncomments: true\ncategories: ['系统设计']\n---\n\n浅谈MySQL/Redis/Kafka高可用设计。\n\n<!--more-->\n\n## 前言\n\n工作中负责的一个有状态(stateful)服务需要实现高可用，借鉴MySQL/Kafka/Redis是如何实现故障转移(failover)的。主要从以下几个方面浅谈MySQL/Kafka/Redis高可用设计：\n- 如何replicate数据？\n- 如何发现master failed？\n- 如何选举/提升(elect)新的master？\n\n## Kafka\n\nKafka的故障转移，有两个场景：\n- Broker出现故障，由于TopicPartition是单Master提供读写的设计，若该Broker上有Master级别的TopicPartition，需要触发该TopicPartition的重新选主；\n- Controller负责监控Broker并对其进行故障转移，Controller在Kafka集群中也是单Master，出现故障时需要从剩余Broker中从新选举；\n\n### Broker的故障转移\n\n在Topic创建时，Kafka集群根据分区配置创建多个TopicPartition。每个TopicPartition有且仅有一个leader，有一或多个slave（数量由replicate因子而定）。Kafka使用以下方法将TopicPartition分散到多个Broker，使得TopicPartition尽可能的打散：\n\n- 假设有n个broker；\n- 第i个partition的leader副本将被分配到第(i mod n)个broker；\n- 第i个partition的第j个follower副本将被分配到第((i+j) mod n)个broker。\n\n往Kafka集群生产数据时，若将ack配置为all，Broker将确保在所有slave拉取到该消息时才返回给producer确认信号，如下图所示：\n\n![image](https://user-images.githubusercontent.com/4915189/77650148-fd689d00-6fa5-11ea-94ba-e701f614c37c.png)\n（图片源自[Kafka学习之路 （三）Kafka的高可用](https://www.cnblogs.com/qingyunzong/p/9004703.html)）\n\nleader收到新消息会有落盘动作，slave的IO线程拉取到新消息后，在落盘之前会回复给leader以ACK信号，此时新消息只在slave的内存中。这样设计是在可靠性和性能之间做权衡，因为leader和所有slave全部挂掉的概率是极低的，只要有slave在内存中保有新消息，就会在未来被落盘。关于leader和slave之间的数据同步，笔者在[《Kafka核心技术与实战》专栏笔记](https://zhangjunjia.github.io/2020/01/03/kafka-geekbang-note/)有更详细的介绍。\n\nKafka集群使用Controller模块负责Broker的故障转移，如下图所示：\n\n![image](https://user-images.githubusercontent.com/4915189/77652048-9f898480-6fa8-11ea-8a91-1f17a638f9ca.png)\n（图片源自[Kafka学习之路 （三）Kafka的高可用](https://www.cnblogs.com/qingyunzong/p/9004703.html)）\n\n- Controller在Zookeeper注册watcher，当Broker宕机时Zookeeper会fire事件；\n- Controller从Zookeeper读取可用的Broker列表；\n- Controller构造宕机Broker需要故障转移的TopicPartition，对于每个TopicPartition：\n   - 从Zookeeper获取该TopicPartition的ISR集合；\n   - 决定新的leader分配到ISR的某个Broker；\n   - 将新leader所在Broker、ISR、leader_epoch等信息写回Zookeeper；\n   - 通过RPC直接向新leader所在Broker发送leaderAndISRRequest命令；\n   - 原slave与Controller心跳监听到leader变化，改为从leader拉取最新消息。\n\nKafka针对每个TopicPartition维护了ISR集合，只要slave存在于该集合中就意味着slave与leader的消息延迟在可接受范围内，这个可接受范围是通过消息落后条数、最近一次同步时间来配置的。极端情况下，ISR集合可能为空，这意味着已存活的但不在ISR集合中的slave落后于leader太多。此时若进行slave提升则有丢消息的风险，用户需要在可用性和一致性之间做出选择。\n\n这里引申出另一个问题，Kafka集群为何不使用Zookeeper进行leader选举？\n- Broker宕机时，其管理的N个leader角色的TopicPartition都要触发重新选举，如果N太大将给Zookeeper带来非常大的压力，即剩余的Broker同时进行N次leader选举；\n- 引入Controller模块可以减轻Zookeeper压力，通过Controller可使得leader尽可能分散到各Broker中。\n\n### Controller的故障转移\n\nController模块，是所有Broker借助Zookeeper临时节点选举出来的领导者Broker。它是无状态的，不像Broker需要管理TopicPartition的数据。当Controller宕机时，通过Zookeeper触发重新选举即可。\n\n## Redis\n\nRedis主要谈论的是Redis Cluster的故障转移，关于非Cluster方案的故障转移可参考[【原创】那些年用过的Redis集群架构（含面试解析）](https://www.cnblogs.com/rjzheng/p/10360619.html)。\n\n官方文档[Redis cluster tutorial](https://redis.io/topics/cluster-tutorial)提到：\n\n> The first reason why Redis Cluster can lose writes is because it uses asynchronous replication. This means that during writes the following happens:\n> - Your client writes to the master B.\n> - The master B replies OK to your client.\n> - The master B propagates the write to its slaves B1, B2 and B3.\n> \n> As you can see, B does not wait for an acknowledgement from B1, B2, B3 before replying to the client, since this would be a prohibitive latency penalty for Redis, so if your client writes something, B acknowledges the write, but crashes before being able to send the write to its slaves, one of the slaves (that did not receive the write) can be promoted to master, losing the write forever.\n\n从上面这段话我们可以得到Redis Cluster的一些信息，\n- master/slave使用异步的方式同步消息；\n- 消息写到master后立即返回给客户端，此时slave可能还未同步到新写入的消息；\n- 如果master突然崩溃，slave被提升为master，master那部分未同步到slave的消息将永远丢失掉；\n\n那么，Redis Cluster是如何探测master失效，然后提升slave为master的呢？书籍[Redis开发与运维](https://book.douban.com/subject/26971561/)\n[Redis cluster tutorial](https://redis.io/topics/cluster-tutorial)的【10.6 故障转移】有关于这方面的详尽内容。\n\n对于master失效检测，需要经历主观下线、客观下线的过程，**只有master角色的node才有参与主观下线、客观下线的权利**。主观下线的主要过程如下：\n\n![image](https://user-images.githubusercontent.com/4915189/77818292-4470a280-710c-11ea-866a-71c4ea525a6d.png)\n（PING/PING并标记主观下线）\n\n- 集群中的单一node（假定为A），使用gossip协议遵循一定规则（最近最长未通信原则、通信超时原则），定期主动PING集群中的其他node，正常情况下其他node会立即回复PONG；\n- A发出PING后，若未在cluster-node-timeout内收到来自其他node的PONG，则将timeout的node加入到A的pfail主观下线队列中，即A单方面认为其他node已经timeout；\n\n客观下线的主要过程如下：\n- PING/PONG会携带1/10其他node的pfail状态信息，通过gossip传播到其他node；\n- 任一node收到来自其他node的PING信息时，提取其中的pfail信息，更新到其自身维护的pfail队列；\n- 当pfail队列中，有半数以上的node认为某一node已经pfail，且这些主观pfail的消息还未过期(cluster-node-timeout x 2)，则标记失效的master node为主观下线；\n- 通过gossip广播消息到集群其他master node，通知它们某个master node已被标记为客观下线。\n\n之所以要半数以上的node投票(majority vote)，是为防止网络分区时，选举出多个master。极端情况下，master node A和集群其他master被划分到两个网络分区P1和P2，经历cluster-node-timeout时间后master node A也会自我标识为failed的状态：\n> Similarly after node timeout has elapsed without a master node to be able to sense the majority of the other master nodes, it enters an error state and stops accepting writes.\n\n标记为客观下线后，slave提升为master的过程是怎样的呢？失效master node的slave通过定时任务发现其master失效后，slave会触发以下流程：\n- 资格检查：判断与master断线的时间是否长于配置值，若是则不具备提升为master的资格；\n- 准备选举时间：获取其他slave的主从复制offset计算排名，offset最大者表示消息和master最接近，排名为第一。排名第一者，延迟1秒触发故障选举；排名第二，延迟2秒，以此类推，这样设计主要是考虑slave选举优先级；\n![image](https://user-images.githubusercontent.com/4915189/77825513-c5e42700-7144-11ea-9ada-493814af1df5.png)\n- 发起选举：在slave内存中自增集群的全局epoch（在PING/PONG的过程中可以得知集群当前全局epoch），向其他master node广播选举消息；\n- 选举投票：其他master node判断该选举消息携带的epoch是否投票过，若是则忽略，否则投上一票，也即一个epoch只能投一票。若该次选举获得半数以上master node的投票，则slave可提升为master；\n- 替换主节点：取消复制把自身改为主节点，将原先主节点复制的slot委派给自己，广播信息通知其他master和slave自身已提升为master。\n\n## MySQL\n\nMySQL高可用方案，有官方的Cluster方案，有已经不维护的master-master方案，有Group Replication方案（参见[MySQL · 引擎特性 · Group Replication内核解析](http://mysql.taobao.org/monthly/2017/08/01/)和\n[MGR和HAProxy实现高可靠性MySQL集群](https://tmcdcgeek.club/2019/05/24/mgr_haproxy/)），本文主要讨论的是[MHA](https://github.com/yoshinorim/mha4mysql-manager)方案。\n\n关于replicate，MHA支持binlog方案和GTID方案。关于如何监控master失效并提升slave为master，MHA官方文档[Sequences_of_MHA](https://github.com/yoshinorim/mha4mysql-manager/wiki/Sequences_of_MHA)有一份详尽的介绍（以binlog方案为例）：\n- mha-manager验证MHA配置的MySQL实例能否正常连接，每个MySQL实例是否结对部署有mha-node，识别出实例中的master角色；\n- mha-manager不断监测master是否failed，若是则触发failover流程；\n- mha-manager检测其他slave是否更换了追随的master，以及最近是否发生过失败的failover，若是则中断；\n- mha-manager识别出数据offset最大的slave A，若failed的master仍能通过SSH链接，将slave A的binlog补齐到和master一致的状态；\n- mha-manager提升slave A为新master，为确保提升对业务无影响，需要触发脚本将master的虚拟IP指向到新的master，若不使用虚拟IP可参考[详解Mysql 高可用方案 之 Failover mha](https://juejin.im/post/5cc90ef26fb9a03232198ace)提到的proxy方案；\n- 将其他slaves的binlog与新的master对齐，然后change master到新的master。\n\nMHA的问题在于引入了mha-manager的高可用问题，按下葫芦浮起瓢。\n\n## 总结\n\n以上3个方案，极端情况下都可能在故障转移后丢失数据，而且故障转移过程master所负责的服务是不可用的。\n- 一类方案是通过中介监控master失效并提升slave，但这引入了中介的高可用问题；\n- 一类方案是去中介，所有节点互相连接通过gossip故障转移，其代价是gossip通信将耗费较大带宽。\n\n## 参考文献\n\n[Kafka学习之路 （三）Kafka的高可用](https://www.cnblogs.com/qingyunzong/p/9004703.html)\n[Redis开发与运维](https://book.douban.com/subject/26971561/)\n[Redis cluster tutorial](https://redis.io/topics/cluster-tutorial)\n[详解Mysql 高可用方案 之 Failover mha](https://juejin.im/post/5cc90ef26fb9a03232198ace)\n[Sequences_of_MHA](https://github.com/yoshinorim/mha4mysql-manager/wiki/Sequences_of_MHA)\n","slug":"mysql-redis-kafka-high-availability","published":1,"updated":"2022-08-09T15:02:00.670Z","layout":"post","photos":[],"link":"","_id":"cl6mbc151004bigu89cr87x0w","content":"<p>浅谈MySQL/Redis/Kafka高可用设计。</p>\n<a id=\"more\"></a>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>工作中负责的一个有状态(stateful)服务需要实现高可用，借鉴MySQL/Kafka/Redis是如何实现故障转移(failover)的。主要从以下几个方面浅谈MySQL/Kafka/Redis高可用设计：</p>\n<ul>\n<li>如何replicate数据？</li>\n<li>如何发现master failed？</li>\n<li>如何选举/提升(elect)新的master？</li>\n</ul>\n<h2 id=\"Kafka\"><a href=\"#Kafka\" class=\"headerlink\" title=\"Kafka\"></a>Kafka</h2><p>Kafka的故障转移，有两个场景：</p>\n<ul>\n<li>Broker出现故障，由于TopicPartition是单Master提供读写的设计，若该Broker上有Master级别的TopicPartition，需要触发该TopicPartition的重新选主；</li>\n<li>Controller负责监控Broker并对其进行故障转移，Controller在Kafka集群中也是单Master，出现故障时需要从剩余Broker中从新选举；</li>\n</ul>\n<h3 id=\"Broker的故障转移\"><a href=\"#Broker的故障转移\" class=\"headerlink\" title=\"Broker的故障转移\"></a>Broker的故障转移</h3><p>在Topic创建时，Kafka集群根据分区配置创建多个TopicPartition。每个TopicPartition有且仅有一个leader，有一或多个slave（数量由replicate因子而定）。Kafka使用以下方法将TopicPartition分散到多个Broker，使得TopicPartition尽可能的打散：</p>\n<ul>\n<li>假设有n个broker；</li>\n<li>第i个partition的leader副本将被分配到第(i mod n)个broker；</li>\n<li>第i个partition的第j个follower副本将被分配到第((i+j) mod n)个broker。</li>\n</ul>\n<p>往Kafka集群生产数据时，若将ack配置为all，Broker将确保在所有slave拉取到该消息时才返回给producer确认信号，如下图所示：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/77650148-fd689d00-6fa5-11ea-94ba-e701f614c37c.png\" alt=\"image\"><br>（图片源自<a href=\"https://www.cnblogs.com/qingyunzong/p/9004703.html\" target=\"_blank\" rel=\"noopener\">Kafka学习之路 （三）Kafka的高可用</a>）</p>\n<p>leader收到新消息会有落盘动作，slave的IO线程拉取到新消息后，在落盘之前会回复给leader以ACK信号，此时新消息只在slave的内存中。这样设计是在可靠性和性能之间做权衡，因为leader和所有slave全部挂掉的概率是极低的，只要有slave在内存中保有新消息，就会在未来被落盘。关于leader和slave之间的数据同步，笔者在<a href=\"https://zhangjunjia.github.io/2020/01/03/kafka-geekbang-note/\">《Kafka核心技术与实战》专栏笔记</a>有更详细的介绍。</p>\n<p>Kafka集群使用Controller模块负责Broker的故障转移，如下图所示：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/77652048-9f898480-6fa8-11ea-8a91-1f17a638f9ca.png\" alt=\"image\"><br>（图片源自<a href=\"https://www.cnblogs.com/qingyunzong/p/9004703.html\" target=\"_blank\" rel=\"noopener\">Kafka学习之路 （三）Kafka的高可用</a>）</p>\n<ul>\n<li>Controller在Zookeeper注册watcher，当Broker宕机时Zookeeper会fire事件；</li>\n<li>Controller从Zookeeper读取可用的Broker列表；</li>\n<li>Controller构造宕机Broker需要故障转移的TopicPartition，对于每个TopicPartition：<ul>\n<li>从Zookeeper获取该TopicPartition的ISR集合；</li>\n<li>决定新的leader分配到ISR的某个Broker；</li>\n<li>将新leader所在Broker、ISR、leader_epoch等信息写回Zookeeper；</li>\n<li>通过RPC直接向新leader所在Broker发送leaderAndISRRequest命令；</li>\n<li>原slave与Controller心跳监听到leader变化，改为从leader拉取最新消息。</li>\n</ul>\n</li>\n</ul>\n<p>Kafka针对每个TopicPartition维护了ISR集合，只要slave存在于该集合中就意味着slave与leader的消息延迟在可接受范围内，这个可接受范围是通过消息落后条数、最近一次同步时间来配置的。极端情况下，ISR集合可能为空，这意味着已存活的但不在ISR集合中的slave落后于leader太多。此时若进行slave提升则有丢消息的风险，用户需要在可用性和一致性之间做出选择。</p>\n<p>这里引申出另一个问题，Kafka集群为何不使用Zookeeper进行leader选举？</p>\n<ul>\n<li>Broker宕机时，其管理的N个leader角色的TopicPartition都要触发重新选举，如果N太大将给Zookeeper带来非常大的压力，即剩余的Broker同时进行N次leader选举；</li>\n<li>引入Controller模块可以减轻Zookeeper压力，通过Controller可使得leader尽可能分散到各Broker中。</li>\n</ul>\n<h3 id=\"Controller的故障转移\"><a href=\"#Controller的故障转移\" class=\"headerlink\" title=\"Controller的故障转移\"></a>Controller的故障转移</h3><p>Controller模块，是所有Broker借助Zookeeper临时节点选举出来的领导者Broker。它是无状态的，不像Broker需要管理TopicPartition的数据。当Controller宕机时，通过Zookeeper触发重新选举即可。</p>\n<h2 id=\"Redis\"><a href=\"#Redis\" class=\"headerlink\" title=\"Redis\"></a>Redis</h2><p>Redis主要谈论的是Redis Cluster的故障转移，关于非Cluster方案的故障转移可参考<a href=\"https://www.cnblogs.com/rjzheng/p/10360619.html\" target=\"_blank\" rel=\"noopener\">【原创】那些年用过的Redis集群架构（含面试解析）</a>。</p>\n<p>官方文档<a href=\"https://redis.io/topics/cluster-tutorial\" target=\"_blank\" rel=\"noopener\">Redis cluster tutorial</a>提到：</p>\n<blockquote>\n<p>The first reason why Redis Cluster can lose writes is because it uses asynchronous replication. This means that during writes the following happens:</p>\n<ul>\n<li>Your client writes to the master B.</li>\n<li>The master B replies OK to your client.</li>\n<li>The master B propagates the write to its slaves B1, B2 and B3.</li>\n</ul>\n<p>As you can see, B does not wait for an acknowledgement from B1, B2, B3 before replying to the client, since this would be a prohibitive latency penalty for Redis, so if your client writes something, B acknowledges the write, but crashes before being able to send the write to its slaves, one of the slaves (that did not receive the write) can be promoted to master, losing the write forever.</p>\n</blockquote>\n<p>从上面这段话我们可以得到Redis Cluster的一些信息，</p>\n<ul>\n<li>master/slave使用异步的方式同步消息；</li>\n<li>消息写到master后立即返回给客户端，此时slave可能还未同步到新写入的消息；</li>\n<li>如果master突然崩溃，slave被提升为master，master那部分未同步到slave的消息将永远丢失掉；</li>\n</ul>\n<p>那么，Redis Cluster是如何探测master失效，然后提升slave为master的呢？书籍<a href=\"https://book.douban.com/subject/26971561/\" target=\"_blank\" rel=\"noopener\">Redis开发与运维</a><br><a href=\"https://redis.io/topics/cluster-tutorial\" target=\"_blank\" rel=\"noopener\">Redis cluster tutorial</a>的【10.6 故障转移】有关于这方面的详尽内容。</p>\n<p>对于master失效检测，需要经历主观下线、客观下线的过程，<strong>只有master角色的node才有参与主观下线、客观下线的权利</strong>。主观下线的主要过程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/77818292-4470a280-710c-11ea-866a-71c4ea525a6d.png\" alt=\"image\"><br>（PING/PING并标记主观下线）</p>\n<ul>\n<li>集群中的单一node（假定为A），使用gossip协议遵循一定规则（最近最长未通信原则、通信超时原则），定期主动PING集群中的其他node，正常情况下其他node会立即回复PONG；</li>\n<li>A发出PING后，若未在cluster-node-timeout内收到来自其他node的PONG，则将timeout的node加入到A的pfail主观下线队列中，即A单方面认为其他node已经timeout；</li>\n</ul>\n<p>客观下线的主要过程如下：</p>\n<ul>\n<li>PING/PONG会携带1/10其他node的pfail状态信息，通过gossip传播到其他node；</li>\n<li>任一node收到来自其他node的PING信息时，提取其中的pfail信息，更新到其自身维护的pfail队列；</li>\n<li>当pfail队列中，有半数以上的node认为某一node已经pfail，且这些主观pfail的消息还未过期(cluster-node-timeout x 2)，则标记失效的master node为主观下线；</li>\n<li>通过gossip广播消息到集群其他master node，通知它们某个master node已被标记为客观下线。</li>\n</ul>\n<p>之所以要半数以上的node投票(majority vote)，是为防止网络分区时，选举出多个master。极端情况下，master node A和集群其他master被划分到两个网络分区P1和P2，经历cluster-node-timeout时间后master node A也会自我标识为failed的状态：</p>\n<blockquote>\n<p>Similarly after node timeout has elapsed without a master node to be able to sense the majority of the other master nodes, it enters an error state and stops accepting writes.</p>\n</blockquote>\n<p>标记为客观下线后，slave提升为master的过程是怎样的呢？失效master node的slave通过定时任务发现其master失效后，slave会触发以下流程：</p>\n<ul>\n<li>资格检查：判断与master断线的时间是否长于配置值，若是则不具备提升为master的资格；</li>\n<li>准备选举时间：获取其他slave的主从复制offset计算排名，offset最大者表示消息和master最接近，排名为第一。排名第一者，延迟1秒触发故障选举；排名第二，延迟2秒，以此类推，这样设计主要是考虑slave选举优先级；<br><img src=\"https://user-images.githubusercontent.com/4915189/77825513-c5e42700-7144-11ea-9ada-493814af1df5.png\" alt=\"image\"></li>\n<li>发起选举：在slave内存中自增集群的全局epoch（在PING/PONG的过程中可以得知集群当前全局epoch），向其他master node广播选举消息；</li>\n<li>选举投票：其他master node判断该选举消息携带的epoch是否投票过，若是则忽略，否则投上一票，也即一个epoch只能投一票。若该次选举获得半数以上master node的投票，则slave可提升为master；</li>\n<li>替换主节点：取消复制把自身改为主节点，将原先主节点复制的slot委派给自己，广播信息通知其他master和slave自身已提升为master。</li>\n</ul>\n<h2 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h2><p>MySQL高可用方案，有官方的Cluster方案，有已经不维护的master-master方案，有Group Replication方案（参见<a href=\"http://mysql.taobao.org/monthly/2017/08/01/\" target=\"_blank\" rel=\"noopener\">MySQL · 引擎特性 · Group Replication内核解析</a>和<br><a href=\"https://tmcdcgeek.club/2019/05/24/mgr_haproxy/\" target=\"_blank\" rel=\"noopener\">MGR和HAProxy实现高可靠性MySQL集群</a>），本文主要讨论的是<a href=\"https://github.com/yoshinorim/mha4mysql-manager\" target=\"_blank\" rel=\"noopener\">MHA</a>方案。</p>\n<p>关于replicate，MHA支持binlog方案和GTID方案。关于如何监控master失效并提升slave为master，MHA官方文档<a href=\"https://github.com/yoshinorim/mha4mysql-manager/wiki/Sequences_of_MHA\" target=\"_blank\" rel=\"noopener\">Sequences_of_MHA</a>有一份详尽的介绍（以binlog方案为例）：</p>\n<ul>\n<li>mha-manager验证MHA配置的MySQL实例能否正常连接，每个MySQL实例是否结对部署有mha-node，识别出实例中的master角色；</li>\n<li>mha-manager不断监测master是否failed，若是则触发failover流程；</li>\n<li>mha-manager检测其他slave是否更换了追随的master，以及最近是否发生过失败的failover，若是则中断；</li>\n<li>mha-manager识别出数据offset最大的slave A，若failed的master仍能通过SSH链接，将slave A的binlog补齐到和master一致的状态；</li>\n<li>mha-manager提升slave A为新master，为确保提升对业务无影响，需要触发脚本将master的虚拟IP指向到新的master，若不使用虚拟IP可参考<a href=\"https://juejin.im/post/5cc90ef26fb9a03232198ace\" target=\"_blank\" rel=\"noopener\">详解Mysql 高可用方案 之 Failover mha</a>提到的proxy方案；</li>\n<li>将其他slaves的binlog与新的master对齐，然后change master到新的master。</li>\n</ul>\n<p>MHA的问题在于引入了mha-manager的高可用问题，按下葫芦浮起瓢。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>以上3个方案，极端情况下都可能在故障转移后丢失数据，而且故障转移过程master所负责的服务是不可用的。</p>\n<ul>\n<li>一类方案是通过中介监控master失效并提升slave，但这引入了中介的高可用问题；</li>\n<li>一类方案是去中介，所有节点互相连接通过gossip故障转移，其代价是gossip通信将耗费较大带宽。</li>\n</ul>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p><a href=\"https://www.cnblogs.com/qingyunzong/p/9004703.html\" target=\"_blank\" rel=\"noopener\">Kafka学习之路 （三）Kafka的高可用</a><br><a href=\"https://book.douban.com/subject/26971561/\" target=\"_blank\" rel=\"noopener\">Redis开发与运维</a><br><a href=\"https://redis.io/topics/cluster-tutorial\" target=\"_blank\" rel=\"noopener\">Redis cluster tutorial</a><br><a href=\"https://juejin.im/post/5cc90ef26fb9a03232198ace\" target=\"_blank\" rel=\"noopener\">详解Mysql 高可用方案 之 Failover mha</a><br><a href=\"https://github.com/yoshinorim/mha4mysql-manager/wiki/Sequences_of_MHA\" target=\"_blank\" rel=\"noopener\">Sequences_of_MHA</a></p>\n","site":{"data":{}},"excerpt":"<p>浅谈MySQL/Redis/Kafka高可用设计。</p>","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>工作中负责的一个有状态(stateful)服务需要实现高可用，借鉴MySQL/Kafka/Redis是如何实现故障转移(failover)的。主要从以下几个方面浅谈MySQL/Kafka/Redis高可用设计：</p>\n<ul>\n<li>如何replicate数据？</li>\n<li>如何发现master failed？</li>\n<li>如何选举/提升(elect)新的master？</li>\n</ul>\n<h2 id=\"Kafka\"><a href=\"#Kafka\" class=\"headerlink\" title=\"Kafka\"></a>Kafka</h2><p>Kafka的故障转移，有两个场景：</p>\n<ul>\n<li>Broker出现故障，由于TopicPartition是单Master提供读写的设计，若该Broker上有Master级别的TopicPartition，需要触发该TopicPartition的重新选主；</li>\n<li>Controller负责监控Broker并对其进行故障转移，Controller在Kafka集群中也是单Master，出现故障时需要从剩余Broker中从新选举；</li>\n</ul>\n<h3 id=\"Broker的故障转移\"><a href=\"#Broker的故障转移\" class=\"headerlink\" title=\"Broker的故障转移\"></a>Broker的故障转移</h3><p>在Topic创建时，Kafka集群根据分区配置创建多个TopicPartition。每个TopicPartition有且仅有一个leader，有一或多个slave（数量由replicate因子而定）。Kafka使用以下方法将TopicPartition分散到多个Broker，使得TopicPartition尽可能的打散：</p>\n<ul>\n<li>假设有n个broker；</li>\n<li>第i个partition的leader副本将被分配到第(i mod n)个broker；</li>\n<li>第i个partition的第j个follower副本将被分配到第((i+j) mod n)个broker。</li>\n</ul>\n<p>往Kafka集群生产数据时，若将ack配置为all，Broker将确保在所有slave拉取到该消息时才返回给producer确认信号，如下图所示：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/77650148-fd689d00-6fa5-11ea-94ba-e701f614c37c.png\" alt=\"image\"><br>（图片源自<a href=\"https://www.cnblogs.com/qingyunzong/p/9004703.html\" target=\"_blank\" rel=\"noopener\">Kafka学习之路 （三）Kafka的高可用</a>）</p>\n<p>leader收到新消息会有落盘动作，slave的IO线程拉取到新消息后，在落盘之前会回复给leader以ACK信号，此时新消息只在slave的内存中。这样设计是在可靠性和性能之间做权衡，因为leader和所有slave全部挂掉的概率是极低的，只要有slave在内存中保有新消息，就会在未来被落盘。关于leader和slave之间的数据同步，笔者在<a href=\"https://zhangjunjia.github.io/2020/01/03/kafka-geekbang-note/\">《Kafka核心技术与实战》专栏笔记</a>有更详细的介绍。</p>\n<p>Kafka集群使用Controller模块负责Broker的故障转移，如下图所示：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/77652048-9f898480-6fa8-11ea-8a91-1f17a638f9ca.png\" alt=\"image\"><br>（图片源自<a href=\"https://www.cnblogs.com/qingyunzong/p/9004703.html\" target=\"_blank\" rel=\"noopener\">Kafka学习之路 （三）Kafka的高可用</a>）</p>\n<ul>\n<li>Controller在Zookeeper注册watcher，当Broker宕机时Zookeeper会fire事件；</li>\n<li>Controller从Zookeeper读取可用的Broker列表；</li>\n<li>Controller构造宕机Broker需要故障转移的TopicPartition，对于每个TopicPartition：<ul>\n<li>从Zookeeper获取该TopicPartition的ISR集合；</li>\n<li>决定新的leader分配到ISR的某个Broker；</li>\n<li>将新leader所在Broker、ISR、leader_epoch等信息写回Zookeeper；</li>\n<li>通过RPC直接向新leader所在Broker发送leaderAndISRRequest命令；</li>\n<li>原slave与Controller心跳监听到leader变化，改为从leader拉取最新消息。</li>\n</ul>\n</li>\n</ul>\n<p>Kafka针对每个TopicPartition维护了ISR集合，只要slave存在于该集合中就意味着slave与leader的消息延迟在可接受范围内，这个可接受范围是通过消息落后条数、最近一次同步时间来配置的。极端情况下，ISR集合可能为空，这意味着已存活的但不在ISR集合中的slave落后于leader太多。此时若进行slave提升则有丢消息的风险，用户需要在可用性和一致性之间做出选择。</p>\n<p>这里引申出另一个问题，Kafka集群为何不使用Zookeeper进行leader选举？</p>\n<ul>\n<li>Broker宕机时，其管理的N个leader角色的TopicPartition都要触发重新选举，如果N太大将给Zookeeper带来非常大的压力，即剩余的Broker同时进行N次leader选举；</li>\n<li>引入Controller模块可以减轻Zookeeper压力，通过Controller可使得leader尽可能分散到各Broker中。</li>\n</ul>\n<h3 id=\"Controller的故障转移\"><a href=\"#Controller的故障转移\" class=\"headerlink\" title=\"Controller的故障转移\"></a>Controller的故障转移</h3><p>Controller模块，是所有Broker借助Zookeeper临时节点选举出来的领导者Broker。它是无状态的，不像Broker需要管理TopicPartition的数据。当Controller宕机时，通过Zookeeper触发重新选举即可。</p>\n<h2 id=\"Redis\"><a href=\"#Redis\" class=\"headerlink\" title=\"Redis\"></a>Redis</h2><p>Redis主要谈论的是Redis Cluster的故障转移，关于非Cluster方案的故障转移可参考<a href=\"https://www.cnblogs.com/rjzheng/p/10360619.html\" target=\"_blank\" rel=\"noopener\">【原创】那些年用过的Redis集群架构（含面试解析）</a>。</p>\n<p>官方文档<a href=\"https://redis.io/topics/cluster-tutorial\" target=\"_blank\" rel=\"noopener\">Redis cluster tutorial</a>提到：</p>\n<blockquote>\n<p>The first reason why Redis Cluster can lose writes is because it uses asynchronous replication. This means that during writes the following happens:</p>\n<ul>\n<li>Your client writes to the master B.</li>\n<li>The master B replies OK to your client.</li>\n<li>The master B propagates the write to its slaves B1, B2 and B3.</li>\n</ul>\n<p>As you can see, B does not wait for an acknowledgement from B1, B2, B3 before replying to the client, since this would be a prohibitive latency penalty for Redis, so if your client writes something, B acknowledges the write, but crashes before being able to send the write to its slaves, one of the slaves (that did not receive the write) can be promoted to master, losing the write forever.</p>\n</blockquote>\n<p>从上面这段话我们可以得到Redis Cluster的一些信息，</p>\n<ul>\n<li>master/slave使用异步的方式同步消息；</li>\n<li>消息写到master后立即返回给客户端，此时slave可能还未同步到新写入的消息；</li>\n<li>如果master突然崩溃，slave被提升为master，master那部分未同步到slave的消息将永远丢失掉；</li>\n</ul>\n<p>那么，Redis Cluster是如何探测master失效，然后提升slave为master的呢？书籍<a href=\"https://book.douban.com/subject/26971561/\" target=\"_blank\" rel=\"noopener\">Redis开发与运维</a><br><a href=\"https://redis.io/topics/cluster-tutorial\" target=\"_blank\" rel=\"noopener\">Redis cluster tutorial</a>的【10.6 故障转移】有关于这方面的详尽内容。</p>\n<p>对于master失效检测，需要经历主观下线、客观下线的过程，<strong>只有master角色的node才有参与主观下线、客观下线的权利</strong>。主观下线的主要过程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/77818292-4470a280-710c-11ea-866a-71c4ea525a6d.png\" alt=\"image\"><br>（PING/PING并标记主观下线）</p>\n<ul>\n<li>集群中的单一node（假定为A），使用gossip协议遵循一定规则（最近最长未通信原则、通信超时原则），定期主动PING集群中的其他node，正常情况下其他node会立即回复PONG；</li>\n<li>A发出PING后，若未在cluster-node-timeout内收到来自其他node的PONG，则将timeout的node加入到A的pfail主观下线队列中，即A单方面认为其他node已经timeout；</li>\n</ul>\n<p>客观下线的主要过程如下：</p>\n<ul>\n<li>PING/PONG会携带1/10其他node的pfail状态信息，通过gossip传播到其他node；</li>\n<li>任一node收到来自其他node的PING信息时，提取其中的pfail信息，更新到其自身维护的pfail队列；</li>\n<li>当pfail队列中，有半数以上的node认为某一node已经pfail，且这些主观pfail的消息还未过期(cluster-node-timeout x 2)，则标记失效的master node为主观下线；</li>\n<li>通过gossip广播消息到集群其他master node，通知它们某个master node已被标记为客观下线。</li>\n</ul>\n<p>之所以要半数以上的node投票(majority vote)，是为防止网络分区时，选举出多个master。极端情况下，master node A和集群其他master被划分到两个网络分区P1和P2，经历cluster-node-timeout时间后master node A也会自我标识为failed的状态：</p>\n<blockquote>\n<p>Similarly after node timeout has elapsed without a master node to be able to sense the majority of the other master nodes, it enters an error state and stops accepting writes.</p>\n</blockquote>\n<p>标记为客观下线后，slave提升为master的过程是怎样的呢？失效master node的slave通过定时任务发现其master失效后，slave会触发以下流程：</p>\n<ul>\n<li>资格检查：判断与master断线的时间是否长于配置值，若是则不具备提升为master的资格；</li>\n<li>准备选举时间：获取其他slave的主从复制offset计算排名，offset最大者表示消息和master最接近，排名为第一。排名第一者，延迟1秒触发故障选举；排名第二，延迟2秒，以此类推，这样设计主要是考虑slave选举优先级；<br><img src=\"https://user-images.githubusercontent.com/4915189/77825513-c5e42700-7144-11ea-9ada-493814af1df5.png\" alt=\"image\"></li>\n<li>发起选举：在slave内存中自增集群的全局epoch（在PING/PONG的过程中可以得知集群当前全局epoch），向其他master node广播选举消息；</li>\n<li>选举投票：其他master node判断该选举消息携带的epoch是否投票过，若是则忽略，否则投上一票，也即一个epoch只能投一票。若该次选举获得半数以上master node的投票，则slave可提升为master；</li>\n<li>替换主节点：取消复制把自身改为主节点，将原先主节点复制的slot委派给自己，广播信息通知其他master和slave自身已提升为master。</li>\n</ul>\n<h2 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h2><p>MySQL高可用方案，有官方的Cluster方案，有已经不维护的master-master方案，有Group Replication方案（参见<a href=\"http://mysql.taobao.org/monthly/2017/08/01/\" target=\"_blank\" rel=\"noopener\">MySQL · 引擎特性 · Group Replication内核解析</a>和<br><a href=\"https://tmcdcgeek.club/2019/05/24/mgr_haproxy/\" target=\"_blank\" rel=\"noopener\">MGR和HAProxy实现高可靠性MySQL集群</a>），本文主要讨论的是<a href=\"https://github.com/yoshinorim/mha4mysql-manager\" target=\"_blank\" rel=\"noopener\">MHA</a>方案。</p>\n<p>关于replicate，MHA支持binlog方案和GTID方案。关于如何监控master失效并提升slave为master，MHA官方文档<a href=\"https://github.com/yoshinorim/mha4mysql-manager/wiki/Sequences_of_MHA\" target=\"_blank\" rel=\"noopener\">Sequences_of_MHA</a>有一份详尽的介绍（以binlog方案为例）：</p>\n<ul>\n<li>mha-manager验证MHA配置的MySQL实例能否正常连接，每个MySQL实例是否结对部署有mha-node，识别出实例中的master角色；</li>\n<li>mha-manager不断监测master是否failed，若是则触发failover流程；</li>\n<li>mha-manager检测其他slave是否更换了追随的master，以及最近是否发生过失败的failover，若是则中断；</li>\n<li>mha-manager识别出数据offset最大的slave A，若failed的master仍能通过SSH链接，将slave A的binlog补齐到和master一致的状态；</li>\n<li>mha-manager提升slave A为新master，为确保提升对业务无影响，需要触发脚本将master的虚拟IP指向到新的master，若不使用虚拟IP可参考<a href=\"https://juejin.im/post/5cc90ef26fb9a03232198ace\" target=\"_blank\" rel=\"noopener\">详解Mysql 高可用方案 之 Failover mha</a>提到的proxy方案；</li>\n<li>将其他slaves的binlog与新的master对齐，然后change master到新的master。</li>\n</ul>\n<p>MHA的问题在于引入了mha-manager的高可用问题，按下葫芦浮起瓢。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>以上3个方案，极端情况下都可能在故障转移后丢失数据，而且故障转移过程master所负责的服务是不可用的。</p>\n<ul>\n<li>一类方案是通过中介监控master失效并提升slave，但这引入了中介的高可用问题；</li>\n<li>一类方案是去中介，所有节点互相连接通过gossip故障转移，其代价是gossip通信将耗费较大带宽。</li>\n</ul>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p><a href=\"https://www.cnblogs.com/qingyunzong/p/9004703.html\" target=\"_blank\" rel=\"noopener\">Kafka学习之路 （三）Kafka的高可用</a><br><a href=\"https://book.douban.com/subject/26971561/\" target=\"_blank\" rel=\"noopener\">Redis开发与运维</a><br><a href=\"https://redis.io/topics/cluster-tutorial\" target=\"_blank\" rel=\"noopener\">Redis cluster tutorial</a><br><a href=\"https://juejin.im/post/5cc90ef26fb9a03232198ace\" target=\"_blank\" rel=\"noopener\">详解Mysql 高可用方案 之 Failover mha</a><br><a href=\"https://github.com/yoshinorim/mha4mysql-manager/wiki/Sequences_of_MHA\" target=\"_blank\" rel=\"noopener\">Sequences_of_MHA</a></p>"},{"title":"聊天室高并发架构概要","date":"2020-02-09T12:25:32.000Z","comments":1,"_content":"\n简单总结下我理解的聊天室的高并发架构概要设计。\n\n<!--more-->\n\n![image](https://user-images.githubusercontent.com/4915189/74101810-b00ca980-4b78-11ea-897c-d8b416eb6cab.png)\n\n- client在页面初始化时，先访问scheduler服务获取可用的gateway列表，然后长连接gateway接入聊天室服务集群；\n- scheduler服务应设计为异地多活，通过DNS路由给不同scheduler服务集群；\n- scheduler收集所有gateway的metrics，根据HTTPDNS信息、gateway负载信息决定要返回哪些gateway；\n- scheduler长连接gateway列表的第一个gateway，若失败则尝试连接列表的下一个直至连接成功，若列表的gateway都连接失败则重新向scheduler获取gateway列表（根据聊天室返回不同类型gateway，gateway资源是隔离的）；\n- scheduler以stick connection的方式和gateway连接上，此时该gateway是有状态的；\n- gateway在负载较大出于自保护的考虑，可能主动断掉一部分client的connection，即反向压力（back pressure）。client收到反向压力信号，主动去连接下一个可用的gateway。\n\nclient连接上gateway后，其消息流转流程如下：\n\n![image](https://user-images.githubusercontent.com/4915189/74102481-af771180-4b7e-11ea-9073-7aed55fed1a4.png)\n\n- gateway作为聊天室服务集群的接入层，需要考虑限流、降级、鉴权以及反向压力等设计；\n- gateway通过之后的消息，投递给实时消息队列nsq；\n- 具体业务逻辑的logic模块，异步消费上游消息后，将回复给client的消息投递到另一个nsq，等待gateway进行消费；\n- 若有其他业务方需要投递消息给client，也是将消息投递到nsq，等待gateway消费；\n- 需要有一个分布式配置中心（携程的Apollo），通过配置的实时变更实现开关、限流值调整、灰度等等动态特性。","source":"_posts/2020-02-09-chat-root-design.md","raw":"---\ntitle: 聊天室高并发架构概要\ndate: 2020-02-09 20:25:32\ntags: ['系统设计']\ncomments: true\ncategories: ['系统设计']\n---\n\n简单总结下我理解的聊天室的高并发架构概要设计。\n\n<!--more-->\n\n![image](https://user-images.githubusercontent.com/4915189/74101810-b00ca980-4b78-11ea-897c-d8b416eb6cab.png)\n\n- client在页面初始化时，先访问scheduler服务获取可用的gateway列表，然后长连接gateway接入聊天室服务集群；\n- scheduler服务应设计为异地多活，通过DNS路由给不同scheduler服务集群；\n- scheduler收集所有gateway的metrics，根据HTTPDNS信息、gateway负载信息决定要返回哪些gateway；\n- scheduler长连接gateway列表的第一个gateway，若失败则尝试连接列表的下一个直至连接成功，若列表的gateway都连接失败则重新向scheduler获取gateway列表（根据聊天室返回不同类型gateway，gateway资源是隔离的）；\n- scheduler以stick connection的方式和gateway连接上，此时该gateway是有状态的；\n- gateway在负载较大出于自保护的考虑，可能主动断掉一部分client的connection，即反向压力（back pressure）。client收到反向压力信号，主动去连接下一个可用的gateway。\n\nclient连接上gateway后，其消息流转流程如下：\n\n![image](https://user-images.githubusercontent.com/4915189/74102481-af771180-4b7e-11ea-9073-7aed55fed1a4.png)\n\n- gateway作为聊天室服务集群的接入层，需要考虑限流、降级、鉴权以及反向压力等设计；\n- gateway通过之后的消息，投递给实时消息队列nsq；\n- 具体业务逻辑的logic模块，异步消费上游消息后，将回复给client的消息投递到另一个nsq，等待gateway进行消费；\n- 若有其他业务方需要投递消息给client，也是将消息投递到nsq，等待gateway消费；\n- 需要有一个分布式配置中心（携程的Apollo），通过配置的实时变更实现开关、限流值调整、灰度等等动态特性。","slug":"chat-root-design","published":1,"updated":"2022-08-09T15:02:00.667Z","layout":"post","photos":[],"link":"","_id":"cl6mbc154004eigu8uwqroltp","content":"<p>简单总结下我理解的聊天室的高并发架构概要设计。</p>\n<a id=\"more\"></a>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74101810-b00ca980-4b78-11ea-897c-d8b416eb6cab.png\" alt=\"image\"></p>\n<ul>\n<li>client在页面初始化时，先访问scheduler服务获取可用的gateway列表，然后长连接gateway接入聊天室服务集群；</li>\n<li>scheduler服务应设计为异地多活，通过DNS路由给不同scheduler服务集群；</li>\n<li>scheduler收集所有gateway的metrics，根据HTTPDNS信息、gateway负载信息决定要返回哪些gateway；</li>\n<li>scheduler长连接gateway列表的第一个gateway，若失败则尝试连接列表的下一个直至连接成功，若列表的gateway都连接失败则重新向scheduler获取gateway列表（根据聊天室返回不同类型gateway，gateway资源是隔离的）；</li>\n<li>scheduler以stick connection的方式和gateway连接上，此时该gateway是有状态的；</li>\n<li>gateway在负载较大出于自保护的考虑，可能主动断掉一部分client的connection，即反向压力（back pressure）。client收到反向压力信号，主动去连接下一个可用的gateway。</li>\n</ul>\n<p>client连接上gateway后，其消息流转流程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74102481-af771180-4b7e-11ea-9073-7aed55fed1a4.png\" alt=\"image\"></p>\n<ul>\n<li>gateway作为聊天室服务集群的接入层，需要考虑限流、降级、鉴权以及反向压力等设计；</li>\n<li>gateway通过之后的消息，投递给实时消息队列nsq；</li>\n<li>具体业务逻辑的logic模块，异步消费上游消息后，将回复给client的消息投递到另一个nsq，等待gateway进行消费；</li>\n<li>若有其他业务方需要投递消息给client，也是将消息投递到nsq，等待gateway消费；</li>\n<li>需要有一个分布式配置中心（携程的Apollo），通过配置的实时变更实现开关、限流值调整、灰度等等动态特性。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>简单总结下我理解的聊天室的高并发架构概要设计。</p>","more":"<p><img src=\"https://user-images.githubusercontent.com/4915189/74101810-b00ca980-4b78-11ea-897c-d8b416eb6cab.png\" alt=\"image\"></p>\n<ul>\n<li>client在页面初始化时，先访问scheduler服务获取可用的gateway列表，然后长连接gateway接入聊天室服务集群；</li>\n<li>scheduler服务应设计为异地多活，通过DNS路由给不同scheduler服务集群；</li>\n<li>scheduler收集所有gateway的metrics，根据HTTPDNS信息、gateway负载信息决定要返回哪些gateway；</li>\n<li>scheduler长连接gateway列表的第一个gateway，若失败则尝试连接列表的下一个直至连接成功，若列表的gateway都连接失败则重新向scheduler获取gateway列表（根据聊天室返回不同类型gateway，gateway资源是隔离的）；</li>\n<li>scheduler以stick connection的方式和gateway连接上，此时该gateway是有状态的；</li>\n<li>gateway在负载较大出于自保护的考虑，可能主动断掉一部分client的connection，即反向压力（back pressure）。client收到反向压力信号，主动去连接下一个可用的gateway。</li>\n</ul>\n<p>client连接上gateway后，其消息流转流程如下：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/74102481-af771180-4b7e-11ea-9073-7aed55fed1a4.png\" alt=\"image\"></p>\n<ul>\n<li>gateway作为聊天室服务集群的接入层，需要考虑限流、降级、鉴权以及反向压力等设计；</li>\n<li>gateway通过之后的消息，投递给实时消息队列nsq；</li>\n<li>具体业务逻辑的logic模块，异步消费上游消息后，将回复给client的消息投递到另一个nsq，等待gateway进行消费；</li>\n<li>若有其他业务方需要投递消息给client，也是将消息投递到nsq，等待gateway消费；</li>\n<li>需要有一个分布式配置中心（携程的Apollo），通过配置的实时变更实现开关、限流值调整、灰度等等动态特性。</li>\n</ul>"},{"title":"chronicle-map与apache ignite的使用场景及限制性","date":"2020-05-25T13:11:00.000Z","comments":1,"_content":"\n本文浅谈HashMap从Java Heap中offload的方案考虑.\n\n<!--more-->\n\n现工作负责的一个datanode项目，其本质是一个巨大的分布式hashmap。其含有亿级别的key，value则是用户信息UserInfo。通过hash将该巨大的hashmap分成了多个partition，然后分布到50多台机器上，即每台机器有1至3个partition。partition的数据存放于机器上datanode进程的Java Heap中，这有几个好处：\n- datanode进程中的业务逻辑代码直接访问Java Heap处理UserInfo，只有内存访问开销，无反序列化/网络开销；\n- datanode进程可以将partition进一步分成多个slot，这样就可以多线程并行去读/写partition的UserInfo数据加速业务逻辑；\n- partition数据存放于Java Heap中，datanode进程天生可以基于Heap中的UserInfo对象做各种锁操作保证并发安全。\n\n但这也带来了一些坏处：\n- datanode业务逻辑和Java Heap数据绑定在一起，无法在不重启JVM情况下热更新datanode业务逻辑。\n\n上一篇文章[浅谈有状态Java服务热部署方案](https://github.com/zhangjunjia/zhangjunjia.github.io/issues/16)探讨了解决这个问题的一些方案，本文继续讨论此问题——将Java Heap做offload的方案。\n\n## chronicle-map\n\n[chronicle-map](https://github.com/OpenHFT/Chronicle-Map)是Chronicle Software公司开源的一款堆外hashmap，它支持两种内存模式：\n- 与JVM进程绑定，数据存放于堆外内存（direct memory），JVM进程退出数据也就没了；\n- 不与JVM进程绑定，**数据存放于共享内存**（使用[Ram Drive](https://en.wikipedia.org/wiki/RAM_drive)和MappedByteBuffer实现的共享内存，Linux系统自带的Ram Drive是`/dev/shm/`），JVM进程退出了数据还在；\n\n第二种模式显然比较适合做Java Heap的offload。但对我们的datanode业务而言，Chronicle-Map存在着几个问题：\n- Chronicle-Map建议的ValueType数据类型，只适合那种确定长度的业务数据，如每个Value对象由2个int和1个长度在10以内的string组成这样确定性的数据视图。而我们的业务数据，有大量的`int[]`、`float[]`、`String[]`对象，长度有非常大的不确定性，因此无法使用其建议的ValueType数据类型。因此我方业务只能使用实现其建议的ByteReader/ByteWriter接口写自定义数据序列化/反序列化操作，序列化开销对于我方业务频繁需要遍历几百万个Key的场景是无法接受的。\n- Chronicle-Map的entrySet全量遍历会产生大量新生代对象，这个GC开销也是不能忽略的。\n\n其实第一个问题也不是不能规避。我们可以自行维护一套内存地址到Java数据结构（UserInfo）的映射关系，在访问第N个属性时再去按需反序列化该属性。但这样又带了新问题，按下葫芦浮起瓢：\n- 每个Value数据是不定长的，因此它们的映射关系也是不一样的，这一套映射关系需要能按照一定规则生成，维护好这样一套映射关系有一定的复杂度，而且对于新增/删除数据结构成员并不友好；\n- 读直接操作内存地址，在没有锁保护的情况下很容易和写操作冲突，产生难以预期的后果。\n\n综上，chronicle-map虽然好但不适合我们。\n\n## apache ignite\n\n> Apache Ignite® is a horizontally scalable, fault-tolerant distributed in-memory computing platform for building real-time applications that can process terabytes of data with in-memory speed.\n\n[ignite](https://ignite.apache.org/)是apache顶级项目之一，上文是其官方定义，它可以和以下应用扮演同样角色：\n- Memcache；\n- Redis；\n- MySQL；\n- ...\n\nignite支持以下几种模式：\n- in-memory：这种情况下，数据是全部in-memory的，这和我们的datanode有点像，在内存不足时是否要触发swap则是optional的；\n- in-memory+native persistence：这种情况下，和Redis的AOF模式有点像，write操作更新内存后做append-only操作后立即返回，由后台线程定期去compact这些append-only的log。不同于Redis的是：ignite在这种模式下是支持SQL查询的，且可以根据B+树索引直接定位到DISK的数据记录，且in-memory的数据量是多少也是可配置的。\n- in-memory+3rd database：这种情况下，ignite作为一个cache store，接管了对database的read/write操作，即cache模式中的[read-through和write-through](https://docs.oracle.com/cd/E15357_01/coh.360/e15723/cache_rtwtwbra.htm#COHDG5180)。ignite在这种模式下的SQL查询是受限的，它必须先把database的数据全部load到内存。\n\nignite还有其他强大的特性：\n- Queue、Set等数据结构支持（类比Redis）；\n- 客户端支持near cache（在业务进程的cache）；\n- 支持将计算闭包逻辑从业务端传输到ignite的node结点中运行（把计算搬到了存储结点中）；\n- 支持分布式join；\n- 支持分布式transaction（2PC，两阶段提交）；\n- 支持异步cache接口；\n- 支持集群化，非常方便scale，且有高可用方案支持；\n- 集群拓扑变化时自动进行数据rebalance；\n- 支持对cache对象加锁；\n- 对Hadoop、Spark等计算引擎有良好支持；\n- 对machine learning有很好的支持；\n- 支持多种语言客户端；\n- 支持作为微服务通信框架；\n- 支持Streaming；\n- 支持Kubernetes部署；\n- ...\n\n总的来讲，ignite非常强悍而且功能特性非常的多，且有很多production上应用的[示例](https://ignite.apache.org/use-cases/provenusecases.html)。但ignite的以下几点不符合我方的业务需求：\n- ignite最小级别的高可用要求每个node的data有一份backup，这相当于总数据量乘以2，我们没有这么多的机器quota，要知道我们现在的数据量已经有几亿个KV了；\n- ignite作为server端，客户端与其通信难免会有网络通信、序列化开销，对于我们动辄扫描几百万个key的应用场景，这些开销带来的时延是无法容忍的。\n","source":"_posts/2020-05-25-chronicle-map-and-ignite.md","raw":"---\ntitle: chronicle-map与apache ignite的使用场景及限制性\ndate: 2020-05-25 21:11:00\ntags: ['Java', 'ChronicleMap', 'ApacheIgnite']\ncomments: true\ncategories: ['分布式系统']\n---\n\n本文浅谈HashMap从Java Heap中offload的方案考虑.\n\n<!--more-->\n\n现工作负责的一个datanode项目，其本质是一个巨大的分布式hashmap。其含有亿级别的key，value则是用户信息UserInfo。通过hash将该巨大的hashmap分成了多个partition，然后分布到50多台机器上，即每台机器有1至3个partition。partition的数据存放于机器上datanode进程的Java Heap中，这有几个好处：\n- datanode进程中的业务逻辑代码直接访问Java Heap处理UserInfo，只有内存访问开销，无反序列化/网络开销；\n- datanode进程可以将partition进一步分成多个slot，这样就可以多线程并行去读/写partition的UserInfo数据加速业务逻辑；\n- partition数据存放于Java Heap中，datanode进程天生可以基于Heap中的UserInfo对象做各种锁操作保证并发安全。\n\n但这也带来了一些坏处：\n- datanode业务逻辑和Java Heap数据绑定在一起，无法在不重启JVM情况下热更新datanode业务逻辑。\n\n上一篇文章[浅谈有状态Java服务热部署方案](https://github.com/zhangjunjia/zhangjunjia.github.io/issues/16)探讨了解决这个问题的一些方案，本文继续讨论此问题——将Java Heap做offload的方案。\n\n## chronicle-map\n\n[chronicle-map](https://github.com/OpenHFT/Chronicle-Map)是Chronicle Software公司开源的一款堆外hashmap，它支持两种内存模式：\n- 与JVM进程绑定，数据存放于堆外内存（direct memory），JVM进程退出数据也就没了；\n- 不与JVM进程绑定，**数据存放于共享内存**（使用[Ram Drive](https://en.wikipedia.org/wiki/RAM_drive)和MappedByteBuffer实现的共享内存，Linux系统自带的Ram Drive是`/dev/shm/`），JVM进程退出了数据还在；\n\n第二种模式显然比较适合做Java Heap的offload。但对我们的datanode业务而言，Chronicle-Map存在着几个问题：\n- Chronicle-Map建议的ValueType数据类型，只适合那种确定长度的业务数据，如每个Value对象由2个int和1个长度在10以内的string组成这样确定性的数据视图。而我们的业务数据，有大量的`int[]`、`float[]`、`String[]`对象，长度有非常大的不确定性，因此无法使用其建议的ValueType数据类型。因此我方业务只能使用实现其建议的ByteReader/ByteWriter接口写自定义数据序列化/反序列化操作，序列化开销对于我方业务频繁需要遍历几百万个Key的场景是无法接受的。\n- Chronicle-Map的entrySet全量遍历会产生大量新生代对象，这个GC开销也是不能忽略的。\n\n其实第一个问题也不是不能规避。我们可以自行维护一套内存地址到Java数据结构（UserInfo）的映射关系，在访问第N个属性时再去按需反序列化该属性。但这样又带了新问题，按下葫芦浮起瓢：\n- 每个Value数据是不定长的，因此它们的映射关系也是不一样的，这一套映射关系需要能按照一定规则生成，维护好这样一套映射关系有一定的复杂度，而且对于新增/删除数据结构成员并不友好；\n- 读直接操作内存地址，在没有锁保护的情况下很容易和写操作冲突，产生难以预期的后果。\n\n综上，chronicle-map虽然好但不适合我们。\n\n## apache ignite\n\n> Apache Ignite® is a horizontally scalable, fault-tolerant distributed in-memory computing platform for building real-time applications that can process terabytes of data with in-memory speed.\n\n[ignite](https://ignite.apache.org/)是apache顶级项目之一，上文是其官方定义，它可以和以下应用扮演同样角色：\n- Memcache；\n- Redis；\n- MySQL；\n- ...\n\nignite支持以下几种模式：\n- in-memory：这种情况下，数据是全部in-memory的，这和我们的datanode有点像，在内存不足时是否要触发swap则是optional的；\n- in-memory+native persistence：这种情况下，和Redis的AOF模式有点像，write操作更新内存后做append-only操作后立即返回，由后台线程定期去compact这些append-only的log。不同于Redis的是：ignite在这种模式下是支持SQL查询的，且可以根据B+树索引直接定位到DISK的数据记录，且in-memory的数据量是多少也是可配置的。\n- in-memory+3rd database：这种情况下，ignite作为一个cache store，接管了对database的read/write操作，即cache模式中的[read-through和write-through](https://docs.oracle.com/cd/E15357_01/coh.360/e15723/cache_rtwtwbra.htm#COHDG5180)。ignite在这种模式下的SQL查询是受限的，它必须先把database的数据全部load到内存。\n\nignite还有其他强大的特性：\n- Queue、Set等数据结构支持（类比Redis）；\n- 客户端支持near cache（在业务进程的cache）；\n- 支持将计算闭包逻辑从业务端传输到ignite的node结点中运行（把计算搬到了存储结点中）；\n- 支持分布式join；\n- 支持分布式transaction（2PC，两阶段提交）；\n- 支持异步cache接口；\n- 支持集群化，非常方便scale，且有高可用方案支持；\n- 集群拓扑变化时自动进行数据rebalance；\n- 支持对cache对象加锁；\n- 对Hadoop、Spark等计算引擎有良好支持；\n- 对machine learning有很好的支持；\n- 支持多种语言客户端；\n- 支持作为微服务通信框架；\n- 支持Streaming；\n- 支持Kubernetes部署；\n- ...\n\n总的来讲，ignite非常强悍而且功能特性非常的多，且有很多production上应用的[示例](https://ignite.apache.org/use-cases/provenusecases.html)。但ignite的以下几点不符合我方的业务需求：\n- ignite最小级别的高可用要求每个node的data有一份backup，这相当于总数据量乘以2，我们没有这么多的机器quota，要知道我们现在的数据量已经有几亿个KV了；\n- ignite作为server端，客户端与其通信难免会有网络通信、序列化开销，对于我们动辄扫描几百万个key的应用场景，这些开销带来的时延是无法容忍的。\n","slug":"chronicle-map-and-ignite","published":1,"updated":"2022-08-09T15:02:00.672Z","layout":"post","photos":[],"link":"","_id":"cl6mbc160006eigu8odjgcm03","content":"<p>本文浅谈HashMap从Java Heap中offload的方案考虑.</p>\n<a id=\"more\"></a>\n<p>现工作负责的一个datanode项目，其本质是一个巨大的分布式hashmap。其含有亿级别的key，value则是用户信息UserInfo。通过hash将该巨大的hashmap分成了多个partition，然后分布到50多台机器上，即每台机器有1至3个partition。partition的数据存放于机器上datanode进程的Java Heap中，这有几个好处：</p>\n<ul>\n<li>datanode进程中的业务逻辑代码直接访问Java Heap处理UserInfo，只有内存访问开销，无反序列化/网络开销；</li>\n<li>datanode进程可以将partition进一步分成多个slot，这样就可以多线程并行去读/写partition的UserInfo数据加速业务逻辑；</li>\n<li>partition数据存放于Java Heap中，datanode进程天生可以基于Heap中的UserInfo对象做各种锁操作保证并发安全。</li>\n</ul>\n<p>但这也带来了一些坏处：</p>\n<ul>\n<li>datanode业务逻辑和Java Heap数据绑定在一起，无法在不重启JVM情况下热更新datanode业务逻辑。</li>\n</ul>\n<p>上一篇文章<a href=\"https://github.com/zhangjunjia/zhangjunjia.github.io/issues/16\" target=\"_blank\" rel=\"noopener\">浅谈有状态Java服务热部署方案</a>探讨了解决这个问题的一些方案，本文继续讨论此问题——将Java Heap做offload的方案。</p>\n<h2 id=\"chronicle-map\"><a href=\"#chronicle-map\" class=\"headerlink\" title=\"chronicle-map\"></a>chronicle-map</h2><p><a href=\"https://github.com/OpenHFT/Chronicle-Map\" target=\"_blank\" rel=\"noopener\">chronicle-map</a>是Chronicle Software公司开源的一款堆外hashmap，它支持两种内存模式：</p>\n<ul>\n<li>与JVM进程绑定，数据存放于堆外内存（direct memory），JVM进程退出数据也就没了；</li>\n<li>不与JVM进程绑定，<strong>数据存放于共享内存</strong>（使用<a href=\"https://en.wikipedia.org/wiki/RAM_drive\" target=\"_blank\" rel=\"noopener\">Ram Drive</a>和MappedByteBuffer实现的共享内存，Linux系统自带的Ram Drive是<code>/dev/shm/</code>），JVM进程退出了数据还在；</li>\n</ul>\n<p>第二种模式显然比较适合做Java Heap的offload。但对我们的datanode业务而言，Chronicle-Map存在着几个问题：</p>\n<ul>\n<li>Chronicle-Map建议的ValueType数据类型，只适合那种确定长度的业务数据，如每个Value对象由2个int和1个长度在10以内的string组成这样确定性的数据视图。而我们的业务数据，有大量的<code>int[]</code>、<code>float[]</code>、<code>String[]</code>对象，长度有非常大的不确定性，因此无法使用其建议的ValueType数据类型。因此我方业务只能使用实现其建议的ByteReader/ByteWriter接口写自定义数据序列化/反序列化操作，序列化开销对于我方业务频繁需要遍历几百万个Key的场景是无法接受的。</li>\n<li>Chronicle-Map的entrySet全量遍历会产生大量新生代对象，这个GC开销也是不能忽略的。</li>\n</ul>\n<p>其实第一个问题也不是不能规避。我们可以自行维护一套内存地址到Java数据结构（UserInfo）的映射关系，在访问第N个属性时再去按需反序列化该属性。但这样又带了新问题，按下葫芦浮起瓢：</p>\n<ul>\n<li>每个Value数据是不定长的，因此它们的映射关系也是不一样的，这一套映射关系需要能按照一定规则生成，维护好这样一套映射关系有一定的复杂度，而且对于新增/删除数据结构成员并不友好；</li>\n<li>读直接操作内存地址，在没有锁保护的情况下很容易和写操作冲突，产生难以预期的后果。</li>\n</ul>\n<p>综上，chronicle-map虽然好但不适合我们。</p>\n<h2 id=\"apache-ignite\"><a href=\"#apache-ignite\" class=\"headerlink\" title=\"apache ignite\"></a>apache ignite</h2><blockquote>\n<p>Apache Ignite® is a horizontally scalable, fault-tolerant distributed in-memory computing platform for building real-time applications that can process terabytes of data with in-memory speed.</p>\n</blockquote>\n<p><a href=\"https://ignite.apache.org/\" target=\"_blank\" rel=\"noopener\">ignite</a>是apache顶级项目之一，上文是其官方定义，它可以和以下应用扮演同样角色：</p>\n<ul>\n<li>Memcache；</li>\n<li>Redis；</li>\n<li>MySQL；</li>\n<li>…</li>\n</ul>\n<p>ignite支持以下几种模式：</p>\n<ul>\n<li>in-memory：这种情况下，数据是全部in-memory的，这和我们的datanode有点像，在内存不足时是否要触发swap则是optional的；</li>\n<li>in-memory+native persistence：这种情况下，和Redis的AOF模式有点像，write操作更新内存后做append-only操作后立即返回，由后台线程定期去compact这些append-only的log。不同于Redis的是：ignite在这种模式下是支持SQL查询的，且可以根据B+树索引直接定位到DISK的数据记录，且in-memory的数据量是多少也是可配置的。</li>\n<li>in-memory+3rd database：这种情况下，ignite作为一个cache store，接管了对database的read/write操作，即cache模式中的<a href=\"https://docs.oracle.com/cd/E15357_01/coh.360/e15723/cache_rtwtwbra.htm#COHDG5180\" target=\"_blank\" rel=\"noopener\">read-through和write-through</a>。ignite在这种模式下的SQL查询是受限的，它必须先把database的数据全部load到内存。</li>\n</ul>\n<p>ignite还有其他强大的特性：</p>\n<ul>\n<li>Queue、Set等数据结构支持（类比Redis）；</li>\n<li>客户端支持near cache（在业务进程的cache）；</li>\n<li>支持将计算闭包逻辑从业务端传输到ignite的node结点中运行（把计算搬到了存储结点中）；</li>\n<li>支持分布式join；</li>\n<li>支持分布式transaction（2PC，两阶段提交）；</li>\n<li>支持异步cache接口；</li>\n<li>支持集群化，非常方便scale，且有高可用方案支持；</li>\n<li>集群拓扑变化时自动进行数据rebalance；</li>\n<li>支持对cache对象加锁；</li>\n<li>对Hadoop、Spark等计算引擎有良好支持；</li>\n<li>对machine learning有很好的支持；</li>\n<li>支持多种语言客户端；</li>\n<li>支持作为微服务通信框架；</li>\n<li>支持Streaming；</li>\n<li>支持Kubernetes部署；</li>\n<li>…</li>\n</ul>\n<p>总的来讲，ignite非常强悍而且功能特性非常的多，且有很多production上应用的<a href=\"https://ignite.apache.org/use-cases/provenusecases.html\" target=\"_blank\" rel=\"noopener\">示例</a>。但ignite的以下几点不符合我方的业务需求：</p>\n<ul>\n<li>ignite最小级别的高可用要求每个node的data有一份backup，这相当于总数据量乘以2，我们没有这么多的机器quota，要知道我们现在的数据量已经有几亿个KV了；</li>\n<li>ignite作为server端，客户端与其通信难免会有网络通信、序列化开销，对于我们动辄扫描几百万个key的应用场景，这些开销带来的时延是无法容忍的。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>本文浅谈HashMap从Java Heap中offload的方案考虑.</p>","more":"<p>现工作负责的一个datanode项目，其本质是一个巨大的分布式hashmap。其含有亿级别的key，value则是用户信息UserInfo。通过hash将该巨大的hashmap分成了多个partition，然后分布到50多台机器上，即每台机器有1至3个partition。partition的数据存放于机器上datanode进程的Java Heap中，这有几个好处：</p>\n<ul>\n<li>datanode进程中的业务逻辑代码直接访问Java Heap处理UserInfo，只有内存访问开销，无反序列化/网络开销；</li>\n<li>datanode进程可以将partition进一步分成多个slot，这样就可以多线程并行去读/写partition的UserInfo数据加速业务逻辑；</li>\n<li>partition数据存放于Java Heap中，datanode进程天生可以基于Heap中的UserInfo对象做各种锁操作保证并发安全。</li>\n</ul>\n<p>但这也带来了一些坏处：</p>\n<ul>\n<li>datanode业务逻辑和Java Heap数据绑定在一起，无法在不重启JVM情况下热更新datanode业务逻辑。</li>\n</ul>\n<p>上一篇文章<a href=\"https://github.com/zhangjunjia/zhangjunjia.github.io/issues/16\" target=\"_blank\" rel=\"noopener\">浅谈有状态Java服务热部署方案</a>探讨了解决这个问题的一些方案，本文继续讨论此问题——将Java Heap做offload的方案。</p>\n<h2 id=\"chronicle-map\"><a href=\"#chronicle-map\" class=\"headerlink\" title=\"chronicle-map\"></a>chronicle-map</h2><p><a href=\"https://github.com/OpenHFT/Chronicle-Map\" target=\"_blank\" rel=\"noopener\">chronicle-map</a>是Chronicle Software公司开源的一款堆外hashmap，它支持两种内存模式：</p>\n<ul>\n<li>与JVM进程绑定，数据存放于堆外内存（direct memory），JVM进程退出数据也就没了；</li>\n<li>不与JVM进程绑定，<strong>数据存放于共享内存</strong>（使用<a href=\"https://en.wikipedia.org/wiki/RAM_drive\" target=\"_blank\" rel=\"noopener\">Ram Drive</a>和MappedByteBuffer实现的共享内存，Linux系统自带的Ram Drive是<code>/dev/shm/</code>），JVM进程退出了数据还在；</li>\n</ul>\n<p>第二种模式显然比较适合做Java Heap的offload。但对我们的datanode业务而言，Chronicle-Map存在着几个问题：</p>\n<ul>\n<li>Chronicle-Map建议的ValueType数据类型，只适合那种确定长度的业务数据，如每个Value对象由2个int和1个长度在10以内的string组成这样确定性的数据视图。而我们的业务数据，有大量的<code>int[]</code>、<code>float[]</code>、<code>String[]</code>对象，长度有非常大的不确定性，因此无法使用其建议的ValueType数据类型。因此我方业务只能使用实现其建议的ByteReader/ByteWriter接口写自定义数据序列化/反序列化操作，序列化开销对于我方业务频繁需要遍历几百万个Key的场景是无法接受的。</li>\n<li>Chronicle-Map的entrySet全量遍历会产生大量新生代对象，这个GC开销也是不能忽略的。</li>\n</ul>\n<p>其实第一个问题也不是不能规避。我们可以自行维护一套内存地址到Java数据结构（UserInfo）的映射关系，在访问第N个属性时再去按需反序列化该属性。但这样又带了新问题，按下葫芦浮起瓢：</p>\n<ul>\n<li>每个Value数据是不定长的，因此它们的映射关系也是不一样的，这一套映射关系需要能按照一定规则生成，维护好这样一套映射关系有一定的复杂度，而且对于新增/删除数据结构成员并不友好；</li>\n<li>读直接操作内存地址，在没有锁保护的情况下很容易和写操作冲突，产生难以预期的后果。</li>\n</ul>\n<p>综上，chronicle-map虽然好但不适合我们。</p>\n<h2 id=\"apache-ignite\"><a href=\"#apache-ignite\" class=\"headerlink\" title=\"apache ignite\"></a>apache ignite</h2><blockquote>\n<p>Apache Ignite® is a horizontally scalable, fault-tolerant distributed in-memory computing platform for building real-time applications that can process terabytes of data with in-memory speed.</p>\n</blockquote>\n<p><a href=\"https://ignite.apache.org/\" target=\"_blank\" rel=\"noopener\">ignite</a>是apache顶级项目之一，上文是其官方定义，它可以和以下应用扮演同样角色：</p>\n<ul>\n<li>Memcache；</li>\n<li>Redis；</li>\n<li>MySQL；</li>\n<li>…</li>\n</ul>\n<p>ignite支持以下几种模式：</p>\n<ul>\n<li>in-memory：这种情况下，数据是全部in-memory的，这和我们的datanode有点像，在内存不足时是否要触发swap则是optional的；</li>\n<li>in-memory+native persistence：这种情况下，和Redis的AOF模式有点像，write操作更新内存后做append-only操作后立即返回，由后台线程定期去compact这些append-only的log。不同于Redis的是：ignite在这种模式下是支持SQL查询的，且可以根据B+树索引直接定位到DISK的数据记录，且in-memory的数据量是多少也是可配置的。</li>\n<li>in-memory+3rd database：这种情况下，ignite作为一个cache store，接管了对database的read/write操作，即cache模式中的<a href=\"https://docs.oracle.com/cd/E15357_01/coh.360/e15723/cache_rtwtwbra.htm#COHDG5180\" target=\"_blank\" rel=\"noopener\">read-through和write-through</a>。ignite在这种模式下的SQL查询是受限的，它必须先把database的数据全部load到内存。</li>\n</ul>\n<p>ignite还有其他强大的特性：</p>\n<ul>\n<li>Queue、Set等数据结构支持（类比Redis）；</li>\n<li>客户端支持near cache（在业务进程的cache）；</li>\n<li>支持将计算闭包逻辑从业务端传输到ignite的node结点中运行（把计算搬到了存储结点中）；</li>\n<li>支持分布式join；</li>\n<li>支持分布式transaction（2PC，两阶段提交）；</li>\n<li>支持异步cache接口；</li>\n<li>支持集群化，非常方便scale，且有高可用方案支持；</li>\n<li>集群拓扑变化时自动进行数据rebalance；</li>\n<li>支持对cache对象加锁；</li>\n<li>对Hadoop、Spark等计算引擎有良好支持；</li>\n<li>对machine learning有很好的支持；</li>\n<li>支持多种语言客户端；</li>\n<li>支持作为微服务通信框架；</li>\n<li>支持Streaming；</li>\n<li>支持Kubernetes部署；</li>\n<li>…</li>\n</ul>\n<p>总的来讲，ignite非常强悍而且功能特性非常的多，且有很多production上应用的<a href=\"https://ignite.apache.org/use-cases/provenusecases.html\" target=\"_blank\" rel=\"noopener\">示例</a>。但ignite的以下几点不符合我方的业务需求：</p>\n<ul>\n<li>ignite最小级别的高可用要求每个node的data有一份backup，这相当于总数据量乘以2，我们没有这么多的机器quota，要知道我们现在的数据量已经有几亿个KV了；</li>\n<li>ignite作为server端，客户端与其通信难免会有网络通信、序列化开销，对于我们动辄扫描几百万个key的应用场景，这些开销带来的时延是无法容忍的。</li>\n</ul>"},{"title":"浅谈event sourcing和cqrs","date":"2020-05-07T13:07:14.000Z","comments":1,"_content":"\n本文浅谈event sourcing和cqrs的一些认识.\n\n<!--more-->\n\n## Event Sourcing\n\nMartin Fowler在[Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)提到：\n> Event Sourcing ensures that all changes to application state are stored as a sequence of events.\n> The key to Event Sourcing is that we guarantee that all changes to the domain objects are initiated by the event objects: Complete Rebuild, Temporal Query, Event Replay.\n> A system in use during a working day could be started at the beginning of the day from an overnight snapshot and hold the current application state in memory.\n\n概括来说，Event Sourcing有别于CRUD直接操作数据源，只记录数据的状态变化(state event)，通过replay这些event可以得到最终的数据状态视图。它的优点是Complete Rebuild（重新生成状态视图）, Temporal Query（查询历史视图，类似Git查看某个版本数据视图）, Event Replay（新模块可重放event满足自身需求）。在event积累太多的情况下，从头开始replay的耗时将难以接受，可以通过增加Snapshot记录中间状态来解决此问题。\n\n什么时候会用到Event Sourcing？\n- 需要做audit trail的时候，即需要审计追踪所有的状态变化；\n- 需要借助这些event来debug系统的时候，由于其可重放特性可重现问题；\n- 和cqrs结合做读写分离。\n\n## CQRS(Command and Query Responsibility Segregation)\n\nCQRS的想法很朴素，在CRUD模式read/write都是操作同一个数据源，CQRS把write的数据源和read的数据源分开。通过Command模块写到write库，write库的数据异步同步到read库，以供Query模块查询数据。CQRS的优点是数据库分离成了read库和write库，这样他们就可以各自scale了，不存在相互拖累的情况。分离之后，我们可以自行选择更适合的方案实现read库和write库，比如Apache Cassandra实现write库，Elasticsearch实现读库。\n\nMartin Fowler对[CQRS](https://martinfowler.com/bliki/CQRS.html)的评价是较为负面的：\n> For some situations, this separation can be valuable, but beware that for most systems CQRS adds risky complexity.\n\n## Event Sourcing + CQRS\n\n这两者经常会被结合起来使用，[codecentric AG: CQRS and Event Sourcing Applications with Cassandra](https://www.slideshare.net/planetcassandra/codecentric-ag-cqrs-and-event-sourcing-applications-with-cassandra)提到了一种两种结合使用的pattern，如下图：\n\n![image](https://user-images.githubusercontent.com/4915189/81551856-1c37bd00-93b5-11ea-94fa-62a167b93f51.png)\n（Event Sourcing + CQRS）\n\n上图中，\n- Event Store使用Apache Cassandra实现；\n- Query Store使用ElasticSearch实现；\n- Command Model异步触发Event Processor更新Query Store，具体实现如下：\n\n![image](https://user-images.githubusercontent.com/4915189/81569729-3d5ad680-93d2-11ea-88c2-1666a0295ab5.png)\n\n- Command Model需保证写Event Store和投递消息到Kafka是transaction的；\n- Spark Job处理Kafka中的Event将最终数据产出到ElasticSearch；\n\n在需要生成新的数据视图时，只需要新建Spark Job直接重放处理Event Store中的数据，然后将结果写到Query Store中即可。\n\n这种Event Source+ES的组合能同时享受两者的好处，但同时也引入了问题：\n- Query Store是最终一致性的，如果要依赖最新状态去做决策抱歉这做不到，如`update table set a = ? where a = ?`这类操作；\n- Kafka只支持at least once投递，在产生重复event时消费端必须能够容错；\n- Command Service必须能保证并发写的顺序性，并在重放时依然保持该顺序；Kafka的partition间是无序的，顺序写在实际被消费时顺序可能错乱；\n- .....\n\n## Reference\n\n[Event Sourcing in practice](https://ookami86.github.io/event-sourcing-in-practice/)\n[Event sourcing, CQRS, stream processing and Apache Kafka: What’s the connection?](https://www.confluent.io/blog/event-sourcing-cqrs-stream-processing-apache-kafka-whats-connection/)\n[Clarified CQRS](http://udidahan.com/2009/12/09/clarified-cqrs/)\n[Building Scalable Applications Using Event Sourcing and CQRS](https://medium.com/technology-learning/event-sourcing-and-cqrs-a-look-at-kafka-e0c1b90d17d8)\n[Event Sourcing pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing)\n[Command and Query Responsibility Segregation (CQRS) pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs)\n[Martin Fowler: Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)\n[codecentric AG: CQRS and Event Sourcing Applications with Cassandra](https://www.slideshare.net/planetcassandra/codecentric-ag-cqrs-and-event-sourcing-applications-with-cassandra)\n[A CQRS Journey by Microsoft](http://msdn.microsoft.com/en-us/library/jj554200.aspx)\n[Martin Fowler: CQRS](https://martinfowler.com/bliki/CQRS.html)\n","source":"_posts/2020-05-25-event-sc-and-cqrs.md","raw":"---\ntitle: 浅谈event sourcing和cqrs\ndate: 2020-05-07 21:07:14\ntags: ['CQRS', 'EventSourcing']\ncomments: true\ncategories: ['系统设计']\n---\n\n本文浅谈event sourcing和cqrs的一些认识.\n\n<!--more-->\n\n## Event Sourcing\n\nMartin Fowler在[Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)提到：\n> Event Sourcing ensures that all changes to application state are stored as a sequence of events.\n> The key to Event Sourcing is that we guarantee that all changes to the domain objects are initiated by the event objects: Complete Rebuild, Temporal Query, Event Replay.\n> A system in use during a working day could be started at the beginning of the day from an overnight snapshot and hold the current application state in memory.\n\n概括来说，Event Sourcing有别于CRUD直接操作数据源，只记录数据的状态变化(state event)，通过replay这些event可以得到最终的数据状态视图。它的优点是Complete Rebuild（重新生成状态视图）, Temporal Query（查询历史视图，类似Git查看某个版本数据视图）, Event Replay（新模块可重放event满足自身需求）。在event积累太多的情况下，从头开始replay的耗时将难以接受，可以通过增加Snapshot记录中间状态来解决此问题。\n\n什么时候会用到Event Sourcing？\n- 需要做audit trail的时候，即需要审计追踪所有的状态变化；\n- 需要借助这些event来debug系统的时候，由于其可重放特性可重现问题；\n- 和cqrs结合做读写分离。\n\n## CQRS(Command and Query Responsibility Segregation)\n\nCQRS的想法很朴素，在CRUD模式read/write都是操作同一个数据源，CQRS把write的数据源和read的数据源分开。通过Command模块写到write库，write库的数据异步同步到read库，以供Query模块查询数据。CQRS的优点是数据库分离成了read库和write库，这样他们就可以各自scale了，不存在相互拖累的情况。分离之后，我们可以自行选择更适合的方案实现read库和write库，比如Apache Cassandra实现write库，Elasticsearch实现读库。\n\nMartin Fowler对[CQRS](https://martinfowler.com/bliki/CQRS.html)的评价是较为负面的：\n> For some situations, this separation can be valuable, but beware that for most systems CQRS adds risky complexity.\n\n## Event Sourcing + CQRS\n\n这两者经常会被结合起来使用，[codecentric AG: CQRS and Event Sourcing Applications with Cassandra](https://www.slideshare.net/planetcassandra/codecentric-ag-cqrs-and-event-sourcing-applications-with-cassandra)提到了一种两种结合使用的pattern，如下图：\n\n![image](https://user-images.githubusercontent.com/4915189/81551856-1c37bd00-93b5-11ea-94fa-62a167b93f51.png)\n（Event Sourcing + CQRS）\n\n上图中，\n- Event Store使用Apache Cassandra实现；\n- Query Store使用ElasticSearch实现；\n- Command Model异步触发Event Processor更新Query Store，具体实现如下：\n\n![image](https://user-images.githubusercontent.com/4915189/81569729-3d5ad680-93d2-11ea-88c2-1666a0295ab5.png)\n\n- Command Model需保证写Event Store和投递消息到Kafka是transaction的；\n- Spark Job处理Kafka中的Event将最终数据产出到ElasticSearch；\n\n在需要生成新的数据视图时，只需要新建Spark Job直接重放处理Event Store中的数据，然后将结果写到Query Store中即可。\n\n这种Event Source+ES的组合能同时享受两者的好处，但同时也引入了问题：\n- Query Store是最终一致性的，如果要依赖最新状态去做决策抱歉这做不到，如`update table set a = ? where a = ?`这类操作；\n- Kafka只支持at least once投递，在产生重复event时消费端必须能够容错；\n- Command Service必须能保证并发写的顺序性，并在重放时依然保持该顺序；Kafka的partition间是无序的，顺序写在实际被消费时顺序可能错乱；\n- .....\n\n## Reference\n\n[Event Sourcing in practice](https://ookami86.github.io/event-sourcing-in-practice/)\n[Event sourcing, CQRS, stream processing and Apache Kafka: What’s the connection?](https://www.confluent.io/blog/event-sourcing-cqrs-stream-processing-apache-kafka-whats-connection/)\n[Clarified CQRS](http://udidahan.com/2009/12/09/clarified-cqrs/)\n[Building Scalable Applications Using Event Sourcing and CQRS](https://medium.com/technology-learning/event-sourcing-and-cqrs-a-look-at-kafka-e0c1b90d17d8)\n[Event Sourcing pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing)\n[Command and Query Responsibility Segregation (CQRS) pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs)\n[Martin Fowler: Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)\n[codecentric AG: CQRS and Event Sourcing Applications with Cassandra](https://www.slideshare.net/planetcassandra/codecentric-ag-cqrs-and-event-sourcing-applications-with-cassandra)\n[A CQRS Journey by Microsoft](http://msdn.microsoft.com/en-us/library/jj554200.aspx)\n[Martin Fowler: CQRS](https://martinfowler.com/bliki/CQRS.html)\n","slug":"event-sc-and-cqrs","published":1,"updated":"2022-08-09T15:02:00.677Z","layout":"post","photos":[],"link":"","_id":"cl6mbc161006figu86qvt7r7i","content":"<p>本文浅谈event sourcing和cqrs的一些认识.</p>\n<a id=\"more\"></a>\n<h2 id=\"Event-Sourcing\"><a href=\"#Event-Sourcing\" class=\"headerlink\" title=\"Event Sourcing\"></a>Event Sourcing</h2><p>Martin Fowler在<a href=\"https://martinfowler.com/eaaDev/EventSourcing.html\" target=\"_blank\" rel=\"noopener\">Event Sourcing</a>提到：</p>\n<blockquote>\n<p>Event Sourcing ensures that all changes to application state are stored as a sequence of events.<br>The key to Event Sourcing is that we guarantee that all changes to the domain objects are initiated by the event objects: Complete Rebuild, Temporal Query, Event Replay.<br>A system in use during a working day could be started at the beginning of the day from an overnight snapshot and hold the current application state in memory.</p>\n</blockquote>\n<p>概括来说，Event Sourcing有别于CRUD直接操作数据源，只记录数据的状态变化(state event)，通过replay这些event可以得到最终的数据状态视图。它的优点是Complete Rebuild（重新生成状态视图）, Temporal Query（查询历史视图，类似Git查看某个版本数据视图）, Event Replay（新模块可重放event满足自身需求）。在event积累太多的情况下，从头开始replay的耗时将难以接受，可以通过增加Snapshot记录中间状态来解决此问题。</p>\n<p>什么时候会用到Event Sourcing？</p>\n<ul>\n<li>需要做audit trail的时候，即需要审计追踪所有的状态变化；</li>\n<li>需要借助这些event来debug系统的时候，由于其可重放特性可重现问题；</li>\n<li>和cqrs结合做读写分离。</li>\n</ul>\n<h2 id=\"CQRS-Command-and-Query-Responsibility-Segregation\"><a href=\"#CQRS-Command-and-Query-Responsibility-Segregation\" class=\"headerlink\" title=\"CQRS(Command and Query Responsibility Segregation)\"></a>CQRS(Command and Query Responsibility Segregation)</h2><p>CQRS的想法很朴素，在CRUD模式read/write都是操作同一个数据源，CQRS把write的数据源和read的数据源分开。通过Command模块写到write库，write库的数据异步同步到read库，以供Query模块查询数据。CQRS的优点是数据库分离成了read库和write库，这样他们就可以各自scale了，不存在相互拖累的情况。分离之后，我们可以自行选择更适合的方案实现read库和write库，比如Apache Cassandra实现write库，Elasticsearch实现读库。</p>\n<p>Martin Fowler对<a href=\"https://martinfowler.com/bliki/CQRS.html\" target=\"_blank\" rel=\"noopener\">CQRS</a>的评价是较为负面的：</p>\n<blockquote>\n<p>For some situations, this separation can be valuable, but beware that for most systems CQRS adds risky complexity.</p>\n</blockquote>\n<h2 id=\"Event-Sourcing-CQRS\"><a href=\"#Event-Sourcing-CQRS\" class=\"headerlink\" title=\"Event Sourcing + CQRS\"></a>Event Sourcing + CQRS</h2><p>这两者经常会被结合起来使用，<a href=\"https://www.slideshare.net/planetcassandra/codecentric-ag-cqrs-and-event-sourcing-applications-with-cassandra\" target=\"_blank\" rel=\"noopener\">codecentric AG: CQRS and Event Sourcing Applications with Cassandra</a>提到了一种两种结合使用的pattern，如下图：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/81551856-1c37bd00-93b5-11ea-94fa-62a167b93f51.png\" alt=\"image\"><br>（Event Sourcing + CQRS）</p>\n<p>上图中，</p>\n<ul>\n<li>Event Store使用Apache Cassandra实现；</li>\n<li>Query Store使用ElasticSearch实现；</li>\n<li>Command Model异步触发Event Processor更新Query Store，具体实现如下：</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/81569729-3d5ad680-93d2-11ea-88c2-1666a0295ab5.png\" alt=\"image\"></p>\n<ul>\n<li>Command Model需保证写Event Store和投递消息到Kafka是transaction的；</li>\n<li>Spark Job处理Kafka中的Event将最终数据产出到ElasticSearch；</li>\n</ul>\n<p>在需要生成新的数据视图时，只需要新建Spark Job直接重放处理Event Store中的数据，然后将结果写到Query Store中即可。</p>\n<p>这种Event Source+ES的组合能同时享受两者的好处，但同时也引入了问题：</p>\n<ul>\n<li>Query Store是最终一致性的，如果要依赖最新状态去做决策抱歉这做不到，如<code>update table set a = ? where a = ?</code>这类操作；</li>\n<li>Kafka只支持at least once投递，在产生重复event时消费端必须能够容错；</li>\n<li>Command Service必须能保证并发写的顺序性，并在重放时依然保持该顺序；Kafka的partition间是无序的，顺序写在实际被消费时顺序可能错乱；</li>\n<li>…..</li>\n</ul>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://ookami86.github.io/event-sourcing-in-practice/\" target=\"_blank\" rel=\"noopener\">Event Sourcing in practice</a><br><a href=\"https://www.confluent.io/blog/event-sourcing-cqrs-stream-processing-apache-kafka-whats-connection/\" target=\"_blank\" rel=\"noopener\">Event sourcing, CQRS, stream processing and Apache Kafka: What’s the connection?</a><br><a href=\"http://udidahan.com/2009/12/09/clarified-cqrs/\" target=\"_blank\" rel=\"noopener\">Clarified CQRS</a><br><a href=\"https://medium.com/technology-learning/event-sourcing-and-cqrs-a-look-at-kafka-e0c1b90d17d8\" target=\"_blank\" rel=\"noopener\">Building Scalable Applications Using Event Sourcing and CQRS</a><br><a href=\"https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing\" target=\"_blank\" rel=\"noopener\">Event Sourcing pattern</a><br><a href=\"https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs\" target=\"_blank\" rel=\"noopener\">Command and Query Responsibility Segregation (CQRS) pattern</a><br><a href=\"https://martinfowler.com/eaaDev/EventSourcing.html\" target=\"_blank\" rel=\"noopener\">Martin Fowler: Event Sourcing</a><br><a href=\"https://www.slideshare.net/planetcassandra/codecentric-ag-cqrs-and-event-sourcing-applications-with-cassandra\" target=\"_blank\" rel=\"noopener\">codecentric AG: CQRS and Event Sourcing Applications with Cassandra</a><br><a href=\"http://msdn.microsoft.com/en-us/library/jj554200.aspx\" target=\"_blank\" rel=\"noopener\">A CQRS Journey by Microsoft</a><br><a href=\"https://martinfowler.com/bliki/CQRS.html\" target=\"_blank\" rel=\"noopener\">Martin Fowler: CQRS</a></p>\n","site":{"data":{}},"excerpt":"<p>本文浅谈event sourcing和cqrs的一些认识.</p>","more":"<h2 id=\"Event-Sourcing\"><a href=\"#Event-Sourcing\" class=\"headerlink\" title=\"Event Sourcing\"></a>Event Sourcing</h2><p>Martin Fowler在<a href=\"https://martinfowler.com/eaaDev/EventSourcing.html\" target=\"_blank\" rel=\"noopener\">Event Sourcing</a>提到：</p>\n<blockquote>\n<p>Event Sourcing ensures that all changes to application state are stored as a sequence of events.<br>The key to Event Sourcing is that we guarantee that all changes to the domain objects are initiated by the event objects: Complete Rebuild, Temporal Query, Event Replay.<br>A system in use during a working day could be started at the beginning of the day from an overnight snapshot and hold the current application state in memory.</p>\n</blockquote>\n<p>概括来说，Event Sourcing有别于CRUD直接操作数据源，只记录数据的状态变化(state event)，通过replay这些event可以得到最终的数据状态视图。它的优点是Complete Rebuild（重新生成状态视图）, Temporal Query（查询历史视图，类似Git查看某个版本数据视图）, Event Replay（新模块可重放event满足自身需求）。在event积累太多的情况下，从头开始replay的耗时将难以接受，可以通过增加Snapshot记录中间状态来解决此问题。</p>\n<p>什么时候会用到Event Sourcing？</p>\n<ul>\n<li>需要做audit trail的时候，即需要审计追踪所有的状态变化；</li>\n<li>需要借助这些event来debug系统的时候，由于其可重放特性可重现问题；</li>\n<li>和cqrs结合做读写分离。</li>\n</ul>\n<h2 id=\"CQRS-Command-and-Query-Responsibility-Segregation\"><a href=\"#CQRS-Command-and-Query-Responsibility-Segregation\" class=\"headerlink\" title=\"CQRS(Command and Query Responsibility Segregation)\"></a>CQRS(Command and Query Responsibility Segregation)</h2><p>CQRS的想法很朴素，在CRUD模式read/write都是操作同一个数据源，CQRS把write的数据源和read的数据源分开。通过Command模块写到write库，write库的数据异步同步到read库，以供Query模块查询数据。CQRS的优点是数据库分离成了read库和write库，这样他们就可以各自scale了，不存在相互拖累的情况。分离之后，我们可以自行选择更适合的方案实现read库和write库，比如Apache Cassandra实现write库，Elasticsearch实现读库。</p>\n<p>Martin Fowler对<a href=\"https://martinfowler.com/bliki/CQRS.html\" target=\"_blank\" rel=\"noopener\">CQRS</a>的评价是较为负面的：</p>\n<blockquote>\n<p>For some situations, this separation can be valuable, but beware that for most systems CQRS adds risky complexity.</p>\n</blockquote>\n<h2 id=\"Event-Sourcing-CQRS\"><a href=\"#Event-Sourcing-CQRS\" class=\"headerlink\" title=\"Event Sourcing + CQRS\"></a>Event Sourcing + CQRS</h2><p>这两者经常会被结合起来使用，<a href=\"https://www.slideshare.net/planetcassandra/codecentric-ag-cqrs-and-event-sourcing-applications-with-cassandra\" target=\"_blank\" rel=\"noopener\">codecentric AG: CQRS and Event Sourcing Applications with Cassandra</a>提到了一种两种结合使用的pattern，如下图：</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/81551856-1c37bd00-93b5-11ea-94fa-62a167b93f51.png\" alt=\"image\"><br>（Event Sourcing + CQRS）</p>\n<p>上图中，</p>\n<ul>\n<li>Event Store使用Apache Cassandra实现；</li>\n<li>Query Store使用ElasticSearch实现；</li>\n<li>Command Model异步触发Event Processor更新Query Store，具体实现如下：</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/81569729-3d5ad680-93d2-11ea-88c2-1666a0295ab5.png\" alt=\"image\"></p>\n<ul>\n<li>Command Model需保证写Event Store和投递消息到Kafka是transaction的；</li>\n<li>Spark Job处理Kafka中的Event将最终数据产出到ElasticSearch；</li>\n</ul>\n<p>在需要生成新的数据视图时，只需要新建Spark Job直接重放处理Event Store中的数据，然后将结果写到Query Store中即可。</p>\n<p>这种Event Source+ES的组合能同时享受两者的好处，但同时也引入了问题：</p>\n<ul>\n<li>Query Store是最终一致性的，如果要依赖最新状态去做决策抱歉这做不到，如<code>update table set a = ? where a = ?</code>这类操作；</li>\n<li>Kafka只支持at least once投递，在产生重复event时消费端必须能够容错；</li>\n<li>Command Service必须能保证并发写的顺序性，并在重放时依然保持该顺序；Kafka的partition间是无序的，顺序写在实际被消费时顺序可能错乱；</li>\n<li>…..</li>\n</ul>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://ookami86.github.io/event-sourcing-in-practice/\" target=\"_blank\" rel=\"noopener\">Event Sourcing in practice</a><br><a href=\"https://www.confluent.io/blog/event-sourcing-cqrs-stream-processing-apache-kafka-whats-connection/\" target=\"_blank\" rel=\"noopener\">Event sourcing, CQRS, stream processing and Apache Kafka: What’s the connection?</a><br><a href=\"http://udidahan.com/2009/12/09/clarified-cqrs/\" target=\"_blank\" rel=\"noopener\">Clarified CQRS</a><br><a href=\"https://medium.com/technology-learning/event-sourcing-and-cqrs-a-look-at-kafka-e0c1b90d17d8\" target=\"_blank\" rel=\"noopener\">Building Scalable Applications Using Event Sourcing and CQRS</a><br><a href=\"https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing\" target=\"_blank\" rel=\"noopener\">Event Sourcing pattern</a><br><a href=\"https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs\" target=\"_blank\" rel=\"noopener\">Command and Query Responsibility Segregation (CQRS) pattern</a><br><a href=\"https://martinfowler.com/eaaDev/EventSourcing.html\" target=\"_blank\" rel=\"noopener\">Martin Fowler: Event Sourcing</a><br><a href=\"https://www.slideshare.net/planetcassandra/codecentric-ag-cqrs-and-event-sourcing-applications-with-cassandra\" target=\"_blank\" rel=\"noopener\">codecentric AG: CQRS and Event Sourcing Applications with Cassandra</a><br><a href=\"http://msdn.microsoft.com/en-us/library/jj554200.aspx\" target=\"_blank\" rel=\"noopener\">A CQRS Journey by Microsoft</a><br><a href=\"https://martinfowler.com/bliki/CQRS.html\" target=\"_blank\" rel=\"noopener\">Martin Fowler: CQRS</a></p>"},{"title":"浅谈有状态Java服务热部署方案","date":"2020-04-25T13:03:36.000Z","comments":1,"_content":"\n近期工作中需解决Java有状态服务的热部署问题，将调研的方案以及其trade-off阐述如下。\n\n<!--more-->\n\n## Java语言层面解决方案\n\n**方案一**是ClassLoader方案。\n\nJava的类加载遵循双亲委派模式，检查类加载时从`AppClassLoader->ExtClassLoader->BoostrapClassLoader`自底向上检查类是否加载，若已加载则直接取缓存的Class返回。否则，按照`BoostrapClassLoader->ExtClassLoader->AppClassLoader`的顺序自顶向下尝试加载类，若上层不具备加载能力则由下层负责，直至类加载成功或抛出异常。Classpath的类默认由AppClassLoader加载，双亲委派模式使得Class只会加载一次，后续对Class的获取都是从ClassLoader中取缓存。\n\n使用自定义ClassLoader可以破坏双亲委派模式的这种缓存机制，需要继承ClassLoader类重写`loadClass`方法破坏双亲委派的向上查找行为。当`.class`文件变化时，创建新的自定义ClassLoader实例`cl`，然后用`cl`读取`.class`文件加载新的Class，再用该Class的`newInstance`方法创建新的对象，这样就规避了双亲加载的Class缓存机制。这种做法的限制是，由于对象的方法/属性是动态变化的，因此只能通过反射调用去操作该对象的方法和成员变量。\n\n文章[Add dynamic Java code to your application](https://www.javaworld.com/article/2071777/add-dynamic-java-code-to-your-application.html?page=1)提出了一种使用ClassLoader以及预定义好的Interface接口，热部署接口实现类的思路。\n\n**方案二**是Java Agent方案。\n\nJava程序启动时借助`-javaagent`的VM参数可以实现在main函数之前的`premain`调用，`premain`可以设置`ClassFileTransformer`实现对指定Class的拦截，拦截后可以借助于ASM等字节码修改技术对Class进行修改。\n\n在Java程序启动后，可以利用JVM的attach技术将agent代码attach到指定的JVM，将会触发`agentmain`调用。`agentmain`调用将对attach之后的类加载行为进行拦截，也可以使用`retransformClasses`触发特定Class的立即转换，转换代码同样需设置`ClassFileTransformer`，同样是借助ASM等字节码修改技术修改Class。也可借助`redefineClasses`调用强制覆盖指定Class的字节码。\n\n以上两种方式的实现都得借助于`Instrument`类，这种做法的限制是只能**修改方法体内的内容**，此外的行为都做不了。\n\n**方案三**是OSGi。这种方案需要对现有代码按照OSGi标准进行大改造，会引入额外工作量，一般不予考虑，可参考[Apache Karaf](http://karaf.apache.org/)。\n\n**方案四**是ClassLoader与Java Agent的结合。其思想是，通过Java Agent拦截修改原有类的字节码，将方法调用/属性访问等行为都转变成代理行为，具体实现则放到自定义ClassLoader动态加载的Class通过`newInstance`方法创建的对象。\n\n假设原始的Worker类代码及使用方式如下：\n\n```java\nWorker worker = new Worker();\nSystem.out.println(worker.workCount);\nworker.run(1);\n\nClass Worker {\n    ......\n    int workCount = 0;\n    public void run(int ticket) {\n        ......\n    }\n}\n```\n\n通过Java Agent拦截修改后，其实现变成以下方式：\n```java\nWorker worker = new Worker();\nSystem.out.println((int) worker._property_invoke_get('workCount'));\nworker._method_invoke_noreturn('run', 1);\n\nClass Worker {\n    ......\n    int workCount = 0;\n    public void run(int ticket) {\n        ......\n    }\n    public Object _property_invoke_get(String property) {\n        // 属性路由\n    }\n    public void _method_invoke_void(String method) {\n        // 方法路由\n    }\n}\n```\n\n属性路由、方法路由的具体实现，则调用自定义ClassLoader动态加载的Class创建出来的实例实现。这样既满足`Instrument`只能修改方法体的规约，又可以动态新增/修改类成员、类方法了。缺点是实现起来有一定复杂度。\n\n## 状态下沉方案\n\nFacebook的论文[Fast Database Restarts at Facebook](https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf)阐述了一种借助于shared memory实现快速部署的方案。\n\n在服务RUNNING阶段，他们并未使用shared memory，他们服务的数据仍然存在于Java Heap。在Java程序即将结束前，会把Java Heap数据逐一复制到shared memory；在Java程序启动后，再逐一将shared memory的数据复制到Java Heap。服务RUNNING阶段，之所以不直接把数据存储在shared memory，他们主要考虑的是内存碎片的不可控。\n> We worried that an allocator in shared memory would lead to increased fragmentation over time.\n\n使用shared memory必然会带来的问题是：\n- Java官方不支持直接操作shared memory。Tomcat基于Apache Portable Runtime库做了JNI封装， 论文基于Boost:Interprocess做了JNI封装，才得以访问shared memory。\n- shared memory的二进制数据和Java堆对象的相互转换，必然存在序列化/反序列化的开销。\n\n和shared memory方案类似的一种方案是：我们可以创建一个[RAM drive](https://en.wikipedia.org/wiki/RAM_drive)，Java程序停止前将数据offload到RAM drive，Java程序启动后再从RAM drive中将状态还原到Java Heap。无论是shared memory还是RAM drive，都需要考虑边复制边释放的问题，否则内存占用就double了。\n\n除了将状态数据下沉到shared memory，还可以考虑将状态下沉到诸如Redis、Memcached之类的服务，但这除了带来序列化/反序列化问题，还带来了网络开销问题。\n\n## 异步系统方案\n\n假如对于有状态服务的调用是同步的，可以考虑进行异步化改造。\n\n```\n改造前：调用方 -> 有状态服务\n改造后：调用方 -> 分布式消息队列 -> 弱状态服务\n```\n\n调用方的调用不直接投递到有状态服务，而是暂存在分布式消息队列，这样有状态服务完成部署后重新从分布式消息队列拉取任务进行消费即可。\n\n## Reference\n\n[深入浅出JVM ClassLoader](https://www.jianshu.com/p/85eba062b9c1)\n[Java程序员必知：深入理解Instrument](https://www.jianshu.com/p/5c62b71fd882)\n[Fast Database Restarts at Facebook](https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf)\n[Add dynamic Java code to your application](https://www.javaworld.com/article/2071777/add-dynamic-java-code-to-your-application.html?page=1)\n","source":"_posts/2020-05-25-java-stateful-deploy.md","raw":"---\ntitle: 浅谈有状态Java服务热部署方案\ndate: 2020-04-25 21:03:36\ntags: ['Java', '系统设计']\ncomments: true\ncategories: ['编程语言']\n---\n\n近期工作中需解决Java有状态服务的热部署问题，将调研的方案以及其trade-off阐述如下。\n\n<!--more-->\n\n## Java语言层面解决方案\n\n**方案一**是ClassLoader方案。\n\nJava的类加载遵循双亲委派模式，检查类加载时从`AppClassLoader->ExtClassLoader->BoostrapClassLoader`自底向上检查类是否加载，若已加载则直接取缓存的Class返回。否则，按照`BoostrapClassLoader->ExtClassLoader->AppClassLoader`的顺序自顶向下尝试加载类，若上层不具备加载能力则由下层负责，直至类加载成功或抛出异常。Classpath的类默认由AppClassLoader加载，双亲委派模式使得Class只会加载一次，后续对Class的获取都是从ClassLoader中取缓存。\n\n使用自定义ClassLoader可以破坏双亲委派模式的这种缓存机制，需要继承ClassLoader类重写`loadClass`方法破坏双亲委派的向上查找行为。当`.class`文件变化时，创建新的自定义ClassLoader实例`cl`，然后用`cl`读取`.class`文件加载新的Class，再用该Class的`newInstance`方法创建新的对象，这样就规避了双亲加载的Class缓存机制。这种做法的限制是，由于对象的方法/属性是动态变化的，因此只能通过反射调用去操作该对象的方法和成员变量。\n\n文章[Add dynamic Java code to your application](https://www.javaworld.com/article/2071777/add-dynamic-java-code-to-your-application.html?page=1)提出了一种使用ClassLoader以及预定义好的Interface接口，热部署接口实现类的思路。\n\n**方案二**是Java Agent方案。\n\nJava程序启动时借助`-javaagent`的VM参数可以实现在main函数之前的`premain`调用，`premain`可以设置`ClassFileTransformer`实现对指定Class的拦截，拦截后可以借助于ASM等字节码修改技术对Class进行修改。\n\n在Java程序启动后，可以利用JVM的attach技术将agent代码attach到指定的JVM，将会触发`agentmain`调用。`agentmain`调用将对attach之后的类加载行为进行拦截，也可以使用`retransformClasses`触发特定Class的立即转换，转换代码同样需设置`ClassFileTransformer`，同样是借助ASM等字节码修改技术修改Class。也可借助`redefineClasses`调用强制覆盖指定Class的字节码。\n\n以上两种方式的实现都得借助于`Instrument`类，这种做法的限制是只能**修改方法体内的内容**，此外的行为都做不了。\n\n**方案三**是OSGi。这种方案需要对现有代码按照OSGi标准进行大改造，会引入额外工作量，一般不予考虑，可参考[Apache Karaf](http://karaf.apache.org/)。\n\n**方案四**是ClassLoader与Java Agent的结合。其思想是，通过Java Agent拦截修改原有类的字节码，将方法调用/属性访问等行为都转变成代理行为，具体实现则放到自定义ClassLoader动态加载的Class通过`newInstance`方法创建的对象。\n\n假设原始的Worker类代码及使用方式如下：\n\n```java\nWorker worker = new Worker();\nSystem.out.println(worker.workCount);\nworker.run(1);\n\nClass Worker {\n    ......\n    int workCount = 0;\n    public void run(int ticket) {\n        ......\n    }\n}\n```\n\n通过Java Agent拦截修改后，其实现变成以下方式：\n```java\nWorker worker = new Worker();\nSystem.out.println((int) worker._property_invoke_get('workCount'));\nworker._method_invoke_noreturn('run', 1);\n\nClass Worker {\n    ......\n    int workCount = 0;\n    public void run(int ticket) {\n        ......\n    }\n    public Object _property_invoke_get(String property) {\n        // 属性路由\n    }\n    public void _method_invoke_void(String method) {\n        // 方法路由\n    }\n}\n```\n\n属性路由、方法路由的具体实现，则调用自定义ClassLoader动态加载的Class创建出来的实例实现。这样既满足`Instrument`只能修改方法体的规约，又可以动态新增/修改类成员、类方法了。缺点是实现起来有一定复杂度。\n\n## 状态下沉方案\n\nFacebook的论文[Fast Database Restarts at Facebook](https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf)阐述了一种借助于shared memory实现快速部署的方案。\n\n在服务RUNNING阶段，他们并未使用shared memory，他们服务的数据仍然存在于Java Heap。在Java程序即将结束前，会把Java Heap数据逐一复制到shared memory；在Java程序启动后，再逐一将shared memory的数据复制到Java Heap。服务RUNNING阶段，之所以不直接把数据存储在shared memory，他们主要考虑的是内存碎片的不可控。\n> We worried that an allocator in shared memory would lead to increased fragmentation over time.\n\n使用shared memory必然会带来的问题是：\n- Java官方不支持直接操作shared memory。Tomcat基于Apache Portable Runtime库做了JNI封装， 论文基于Boost:Interprocess做了JNI封装，才得以访问shared memory。\n- shared memory的二进制数据和Java堆对象的相互转换，必然存在序列化/反序列化的开销。\n\n和shared memory方案类似的一种方案是：我们可以创建一个[RAM drive](https://en.wikipedia.org/wiki/RAM_drive)，Java程序停止前将数据offload到RAM drive，Java程序启动后再从RAM drive中将状态还原到Java Heap。无论是shared memory还是RAM drive，都需要考虑边复制边释放的问题，否则内存占用就double了。\n\n除了将状态数据下沉到shared memory，还可以考虑将状态下沉到诸如Redis、Memcached之类的服务，但这除了带来序列化/反序列化问题，还带来了网络开销问题。\n\n## 异步系统方案\n\n假如对于有状态服务的调用是同步的，可以考虑进行异步化改造。\n\n```\n改造前：调用方 -> 有状态服务\n改造后：调用方 -> 分布式消息队列 -> 弱状态服务\n```\n\n调用方的调用不直接投递到有状态服务，而是暂存在分布式消息队列，这样有状态服务完成部署后重新从分布式消息队列拉取任务进行消费即可。\n\n## Reference\n\n[深入浅出JVM ClassLoader](https://www.jianshu.com/p/85eba062b9c1)\n[Java程序员必知：深入理解Instrument](https://www.jianshu.com/p/5c62b71fd882)\n[Fast Database Restarts at Facebook](https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf)\n[Add dynamic Java code to your application](https://www.javaworld.com/article/2071777/add-dynamic-java-code-to-your-application.html?page=1)\n","slug":"java-stateful-deploy","published":1,"updated":"2022-08-09T15:02:00.677Z","layout":"post","photos":[],"link":"","_id":"cl6mbc163006higu8z1e5n727","content":"<p>近期工作中需解决Java有状态服务的热部署问题，将调研的方案以及其trade-off阐述如下。</p>\n<a id=\"more\"></a>\n<h2 id=\"Java语言层面解决方案\"><a href=\"#Java语言层面解决方案\" class=\"headerlink\" title=\"Java语言层面解决方案\"></a>Java语言层面解决方案</h2><p><strong>方案一</strong>是ClassLoader方案。</p>\n<p>Java的类加载遵循双亲委派模式，检查类加载时从<code>AppClassLoader-&gt;ExtClassLoader-&gt;BoostrapClassLoader</code>自底向上检查类是否加载，若已加载则直接取缓存的Class返回。否则，按照<code>BoostrapClassLoader-&gt;ExtClassLoader-&gt;AppClassLoader</code>的顺序自顶向下尝试加载类，若上层不具备加载能力则由下层负责，直至类加载成功或抛出异常。Classpath的类默认由AppClassLoader加载，双亲委派模式使得Class只会加载一次，后续对Class的获取都是从ClassLoader中取缓存。</p>\n<p>使用自定义ClassLoader可以破坏双亲委派模式的这种缓存机制，需要继承ClassLoader类重写<code>loadClass</code>方法破坏双亲委派的向上查找行为。当<code>.class</code>文件变化时，创建新的自定义ClassLoader实例<code>cl</code>，然后用<code>cl</code>读取<code>.class</code>文件加载新的Class，再用该Class的<code>newInstance</code>方法创建新的对象，这样就规避了双亲加载的Class缓存机制。这种做法的限制是，由于对象的方法/属性是动态变化的，因此只能通过反射调用去操作该对象的方法和成员变量。</p>\n<p>文章<a href=\"https://www.javaworld.com/article/2071777/add-dynamic-java-code-to-your-application.html?page=1\" target=\"_blank\" rel=\"noopener\">Add dynamic Java code to your application</a>提出了一种使用ClassLoader以及预定义好的Interface接口，热部署接口实现类的思路。</p>\n<p><strong>方案二</strong>是Java Agent方案。</p>\n<p>Java程序启动时借助<code>-javaagent</code>的VM参数可以实现在main函数之前的<code>premain</code>调用，<code>premain</code>可以设置<code>ClassFileTransformer</code>实现对指定Class的拦截，拦截后可以借助于ASM等字节码修改技术对Class进行修改。</p>\n<p>在Java程序启动后，可以利用JVM的attach技术将agent代码attach到指定的JVM，将会触发<code>agentmain</code>调用。<code>agentmain</code>调用将对attach之后的类加载行为进行拦截，也可以使用<code>retransformClasses</code>触发特定Class的立即转换，转换代码同样需设置<code>ClassFileTransformer</code>，同样是借助ASM等字节码修改技术修改Class。也可借助<code>redefineClasses</code>调用强制覆盖指定Class的字节码。</p>\n<p>以上两种方式的实现都得借助于<code>Instrument</code>类，这种做法的限制是只能<strong>修改方法体内的内容</strong>，此外的行为都做不了。</p>\n<p><strong>方案三</strong>是OSGi。这种方案需要对现有代码按照OSGi标准进行大改造，会引入额外工作量，一般不予考虑，可参考<a href=\"http://karaf.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Karaf</a>。</p>\n<p><strong>方案四</strong>是ClassLoader与Java Agent的结合。其思想是，通过Java Agent拦截修改原有类的字节码，将方法调用/属性访问等行为都转变成代理行为，具体实现则放到自定义ClassLoader动态加载的Class通过<code>newInstance</code>方法创建的对象。</p>\n<p>假设原始的Worker类代码及使用方式如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Worker worker = <span class=\"keyword\">new</span> Worker();</span><br><span class=\"line\">System.out.println(worker.workCount);</span><br><span class=\"line\">worker.run(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Class Worker &#123;</span><br><span class=\"line\">    ......</span><br><span class=\"line\">    <span class=\"keyword\">int</span> workCount = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">(<span class=\"keyword\">int</span> ticket)</span> </span>&#123;</span><br><span class=\"line\">        ......</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>通过Java Agent拦截修改后，其实现变成以下方式：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Worker worker = <span class=\"keyword\">new</span> Worker();</span><br><span class=\"line\">System.out.println((<span class=\"keyword\">int</span>) worker._property_invoke_get(<span class=\"string\">'workCount'</span>));</span><br><span class=\"line\">worker._method_invoke_noreturn(<span class=\"string\">'run'</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Class Worker &#123;</span><br><span class=\"line\">    ......</span><br><span class=\"line\">    <span class=\"keyword\">int</span> workCount = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">(<span class=\"keyword\">int</span> ticket)</span> </span>&#123;</span><br><span class=\"line\">        ......</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">_property_invoke_get</span><span class=\"params\">(String property)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 属性路由</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">_method_invoke_void</span><span class=\"params\">(String method)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 方法路由</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>属性路由、方法路由的具体实现，则调用自定义ClassLoader动态加载的Class创建出来的实例实现。这样既满足<code>Instrument</code>只能修改方法体的规约，又可以动态新增/修改类成员、类方法了。缺点是实现起来有一定复杂度。</p>\n<h2 id=\"状态下沉方案\"><a href=\"#状态下沉方案\" class=\"headerlink\" title=\"状态下沉方案\"></a>状态下沉方案</h2><p>Facebook的论文<a href=\"https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf\" target=\"_blank\" rel=\"noopener\">Fast Database Restarts at Facebook</a>阐述了一种借助于shared memory实现快速部署的方案。</p>\n<p>在服务RUNNING阶段，他们并未使用shared memory，他们服务的数据仍然存在于Java Heap。在Java程序即将结束前，会把Java Heap数据逐一复制到shared memory；在Java程序启动后，再逐一将shared memory的数据复制到Java Heap。服务RUNNING阶段，之所以不直接把数据存储在shared memory，他们主要考虑的是内存碎片的不可控。</p>\n<blockquote>\n<p>We worried that an allocator in shared memory would lead to increased fragmentation over time.</p>\n</blockquote>\n<p>使用shared memory必然会带来的问题是：</p>\n<ul>\n<li>Java官方不支持直接操作shared memory。Tomcat基于Apache Portable Runtime库做了JNI封装， 论文基于Boost:Interprocess做了JNI封装，才得以访问shared memory。</li>\n<li>shared memory的二进制数据和Java堆对象的相互转换，必然存在序列化/反序列化的开销。</li>\n</ul>\n<p>和shared memory方案类似的一种方案是：我们可以创建一个<a href=\"https://en.wikipedia.org/wiki/RAM_drive\" target=\"_blank\" rel=\"noopener\">RAM drive</a>，Java程序停止前将数据offload到RAM drive，Java程序启动后再从RAM drive中将状态还原到Java Heap。无论是shared memory还是RAM drive，都需要考虑边复制边释放的问题，否则内存占用就double了。</p>\n<p>除了将状态数据下沉到shared memory，还可以考虑将状态下沉到诸如Redis、Memcached之类的服务，但这除了带来序列化/反序列化问题，还带来了网络开销问题。</p>\n<h2 id=\"异步系统方案\"><a href=\"#异步系统方案\" class=\"headerlink\" title=\"异步系统方案\"></a>异步系统方案</h2><p>假如对于有状态服务的调用是同步的，可以考虑进行异步化改造。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">改造前：调用方 -&gt; 有状态服务</span><br><span class=\"line\">改造后：调用方 -&gt; 分布式消息队列 -&gt; 弱状态服务</span><br></pre></td></tr></table></figure>\n<p>调用方的调用不直接投递到有状态服务，而是暂存在分布式消息队列，这样有状态服务完成部署后重新从分布式消息队列拉取任务进行消费即可。</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://www.jianshu.com/p/85eba062b9c1\" target=\"_blank\" rel=\"noopener\">深入浅出JVM ClassLoader</a><br><a href=\"https://www.jianshu.com/p/5c62b71fd882\" target=\"_blank\" rel=\"noopener\">Java程序员必知：深入理解Instrument</a><br><a href=\"https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf\" target=\"_blank\" rel=\"noopener\">Fast Database Restarts at Facebook</a><br><a href=\"https://www.javaworld.com/article/2071777/add-dynamic-java-code-to-your-application.html?page=1\" target=\"_blank\" rel=\"noopener\">Add dynamic Java code to your application</a></p>\n","site":{"data":{}},"excerpt":"<p>近期工作中需解决Java有状态服务的热部署问题，将调研的方案以及其trade-off阐述如下。</p>","more":"<h2 id=\"Java语言层面解决方案\"><a href=\"#Java语言层面解决方案\" class=\"headerlink\" title=\"Java语言层面解决方案\"></a>Java语言层面解决方案</h2><p><strong>方案一</strong>是ClassLoader方案。</p>\n<p>Java的类加载遵循双亲委派模式，检查类加载时从<code>AppClassLoader-&gt;ExtClassLoader-&gt;BoostrapClassLoader</code>自底向上检查类是否加载，若已加载则直接取缓存的Class返回。否则，按照<code>BoostrapClassLoader-&gt;ExtClassLoader-&gt;AppClassLoader</code>的顺序自顶向下尝试加载类，若上层不具备加载能力则由下层负责，直至类加载成功或抛出异常。Classpath的类默认由AppClassLoader加载，双亲委派模式使得Class只会加载一次，后续对Class的获取都是从ClassLoader中取缓存。</p>\n<p>使用自定义ClassLoader可以破坏双亲委派模式的这种缓存机制，需要继承ClassLoader类重写<code>loadClass</code>方法破坏双亲委派的向上查找行为。当<code>.class</code>文件变化时，创建新的自定义ClassLoader实例<code>cl</code>，然后用<code>cl</code>读取<code>.class</code>文件加载新的Class，再用该Class的<code>newInstance</code>方法创建新的对象，这样就规避了双亲加载的Class缓存机制。这种做法的限制是，由于对象的方法/属性是动态变化的，因此只能通过反射调用去操作该对象的方法和成员变量。</p>\n<p>文章<a href=\"https://www.javaworld.com/article/2071777/add-dynamic-java-code-to-your-application.html?page=1\" target=\"_blank\" rel=\"noopener\">Add dynamic Java code to your application</a>提出了一种使用ClassLoader以及预定义好的Interface接口，热部署接口实现类的思路。</p>\n<p><strong>方案二</strong>是Java Agent方案。</p>\n<p>Java程序启动时借助<code>-javaagent</code>的VM参数可以实现在main函数之前的<code>premain</code>调用，<code>premain</code>可以设置<code>ClassFileTransformer</code>实现对指定Class的拦截，拦截后可以借助于ASM等字节码修改技术对Class进行修改。</p>\n<p>在Java程序启动后，可以利用JVM的attach技术将agent代码attach到指定的JVM，将会触发<code>agentmain</code>调用。<code>agentmain</code>调用将对attach之后的类加载行为进行拦截，也可以使用<code>retransformClasses</code>触发特定Class的立即转换，转换代码同样需设置<code>ClassFileTransformer</code>，同样是借助ASM等字节码修改技术修改Class。也可借助<code>redefineClasses</code>调用强制覆盖指定Class的字节码。</p>\n<p>以上两种方式的实现都得借助于<code>Instrument</code>类，这种做法的限制是只能<strong>修改方法体内的内容</strong>，此外的行为都做不了。</p>\n<p><strong>方案三</strong>是OSGi。这种方案需要对现有代码按照OSGi标准进行大改造，会引入额外工作量，一般不予考虑，可参考<a href=\"http://karaf.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Karaf</a>。</p>\n<p><strong>方案四</strong>是ClassLoader与Java Agent的结合。其思想是，通过Java Agent拦截修改原有类的字节码，将方法调用/属性访问等行为都转变成代理行为，具体实现则放到自定义ClassLoader动态加载的Class通过<code>newInstance</code>方法创建的对象。</p>\n<p>假设原始的Worker类代码及使用方式如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Worker worker = <span class=\"keyword\">new</span> Worker();</span><br><span class=\"line\">System.out.println(worker.workCount);</span><br><span class=\"line\">worker.run(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Class Worker &#123;</span><br><span class=\"line\">    ......</span><br><span class=\"line\">    <span class=\"keyword\">int</span> workCount = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">(<span class=\"keyword\">int</span> ticket)</span> </span>&#123;</span><br><span class=\"line\">        ......</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>通过Java Agent拦截修改后，其实现变成以下方式：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Worker worker = <span class=\"keyword\">new</span> Worker();</span><br><span class=\"line\">System.out.println((<span class=\"keyword\">int</span>) worker._property_invoke_get(<span class=\"string\">'workCount'</span>));</span><br><span class=\"line\">worker._method_invoke_noreturn(<span class=\"string\">'run'</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Class Worker &#123;</span><br><span class=\"line\">    ......</span><br><span class=\"line\">    <span class=\"keyword\">int</span> workCount = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">(<span class=\"keyword\">int</span> ticket)</span> </span>&#123;</span><br><span class=\"line\">        ......</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">_property_invoke_get</span><span class=\"params\">(String property)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 属性路由</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">_method_invoke_void</span><span class=\"params\">(String method)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 方法路由</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>属性路由、方法路由的具体实现，则调用自定义ClassLoader动态加载的Class创建出来的实例实现。这样既满足<code>Instrument</code>只能修改方法体的规约，又可以动态新增/修改类成员、类方法了。缺点是实现起来有一定复杂度。</p>\n<h2 id=\"状态下沉方案\"><a href=\"#状态下沉方案\" class=\"headerlink\" title=\"状态下沉方案\"></a>状态下沉方案</h2><p>Facebook的论文<a href=\"https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf\" target=\"_blank\" rel=\"noopener\">Fast Database Restarts at Facebook</a>阐述了一种借助于shared memory实现快速部署的方案。</p>\n<p>在服务RUNNING阶段，他们并未使用shared memory，他们服务的数据仍然存在于Java Heap。在Java程序即将结束前，会把Java Heap数据逐一复制到shared memory；在Java程序启动后，再逐一将shared memory的数据复制到Java Heap。服务RUNNING阶段，之所以不直接把数据存储在shared memory，他们主要考虑的是内存碎片的不可控。</p>\n<blockquote>\n<p>We worried that an allocator in shared memory would lead to increased fragmentation over time.</p>\n</blockquote>\n<p>使用shared memory必然会带来的问题是：</p>\n<ul>\n<li>Java官方不支持直接操作shared memory。Tomcat基于Apache Portable Runtime库做了JNI封装， 论文基于Boost:Interprocess做了JNI封装，才得以访问shared memory。</li>\n<li>shared memory的二进制数据和Java堆对象的相互转换，必然存在序列化/反序列化的开销。</li>\n</ul>\n<p>和shared memory方案类似的一种方案是：我们可以创建一个<a href=\"https://en.wikipedia.org/wiki/RAM_drive\" target=\"_blank\" rel=\"noopener\">RAM drive</a>，Java程序停止前将数据offload到RAM drive，Java程序启动后再从RAM drive中将状态还原到Java Heap。无论是shared memory还是RAM drive，都需要考虑边复制边释放的问题，否则内存占用就double了。</p>\n<p>除了将状态数据下沉到shared memory，还可以考虑将状态下沉到诸如Redis、Memcached之类的服务，但这除了带来序列化/反序列化问题，还带来了网络开销问题。</p>\n<h2 id=\"异步系统方案\"><a href=\"#异步系统方案\" class=\"headerlink\" title=\"异步系统方案\"></a>异步系统方案</h2><p>假如对于有状态服务的调用是同步的，可以考虑进行异步化改造。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">改造前：调用方 -&gt; 有状态服务</span><br><span class=\"line\">改造后：调用方 -&gt; 分布式消息队列 -&gt; 弱状态服务</span><br></pre></td></tr></table></figure>\n<p>调用方的调用不直接投递到有状态服务，而是暂存在分布式消息队列，这样有状态服务完成部署后重新从分布式消息队列拉取任务进行消费即可。</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://www.jianshu.com/p/85eba062b9c1\" target=\"_blank\" rel=\"noopener\">深入浅出JVM ClassLoader</a><br><a href=\"https://www.jianshu.com/p/5c62b71fd882\" target=\"_blank\" rel=\"noopener\">Java程序员必知：深入理解Instrument</a><br><a href=\"https://research.fb.com/wp-content/uploads/2016/11/fast-database-restarts-at-facebook.pdf\" target=\"_blank\" rel=\"noopener\">Fast Database Restarts at Facebook</a><br><a href=\"https://www.javaworld.com/article/2071777/add-dynamic-java-code-to-your-application.html?page=1\" target=\"_blank\" rel=\"noopener\">Add dynamic Java code to your application</a></p>"},{"title":"Paper阅读：Kafka: a Distributed Messaging System for Log Processing","date":"2020-06-04T14:02:22.000Z","comments":1,"_content":"\n这篇论文是LinkedIn与2011年发表的关于Kafka的论文，从中可以窥探Kafka最源头的设计理念。\n\n<!--more-->\n\n## 总览\n\n论文开篇就介绍到Kafka是：\n> a distributed messaging system that we developed for **collecting** and **delivering high volumes of log data** with **low latency**.\n\nKafka一开始的设计目标就是聚集于收集数据、分发数据、大容量、日志数据、低延迟（高吞吐）。基于此目标，它做出了一些取舍：\n- 不保证数据的强一致。`losing a few pageview events occasionally is certainly not the end of the world`，Producer生产时可能丢失数据，Kafka最新版本可通过设置ACK以及callback逻辑做生产失败的容错。`when a consumer process crashes without a clean shutdown, the consumer process that takes over those partitions owned by the failed consumer may get some duplicate messages that are after the last offset successfully committed to zookeeper`，Consumer消费数据时若没有正常提交offset，遇到crash会导致消息的重复投递。\n- 为了高吞吐和低延迟做了一些针对性优化。Producer端会batch提交消息，Broker端依赖操作系统的page cache实现`write-through caching and read- ahead`，Consumer端会batch拉取消息。\n- Broker端采用多分片设计，使得生产、消费的负载均衡的打到多台机。\n- Consumer使用pull模型，由Consumer的消费能力决定拉取消息速率防止压垮进程，便于Consumer进行rewind消费旧的消息。\n\n![image](https://user-images.githubusercontent.com/4915189/83505149-f86d2000-a4f7-11ea-9955-be8e4104cb55.png)\n（图1 Kafka设计总览）\n\n如图1，Kafka的三个核心是Producer、Broker和Consumer。论文对其逐一进行介绍。\n\n## Broker\n\nKafka的Topic的数据，会被划分为多个Partition，这些Partiton会被打散到多台Broker进行存储。这样设计是为了负载均衡，生产、消费的流量均分到了多台Broker机器防止压垮某一台机器。\n\n![image](https://user-images.githubusercontent.com/4915189/83505122-f0ad7b80-a4f7-11ea-967a-2c2b4717e9e9.png)\n（图2 Partition的物理表示）\n\nPartition是一个逻辑概念，在物理上它由多个segment文件组成，如图2所示。从图片可以看出每个segment文件存储一定offset范围的消息，segment文件在内存中建立索引。offset是递增的，每条消息都有唯一的offset标识其在segment文件中的偏移位置。Kafka的消息是没有唯一ID的，论文认为唯一ID会增加设计的复杂度，而offset设计既可以满足消息索引需求又足够简单。\n\nBroker收到Producer的消息后，将其append到最新segment文件的末尾。这个append动作不是立即刷盘的，Broker会攒一定数量的消息或者等达到一定时间后才刷盘，刷盘后Consumer才能读取到消息。这个设计虽然能提高吞吐，但如果Broker突然崩溃将导致数据的一致性问题，在最新版本的Kafka通过ISR机制最大程度的减少这种问题的发生。\n\nBroker并不会缓存消息到Java Heap中，它利用操作系统的`sendFile`调用减少内存的拷贝。不使用`sendFile`调用时，Broker提供消费消息的流程如下：\n> (1) read data from the storage media to the page cache in an OS\n> (2) copy data in the page cache to an application buffer\n> (3) copy application buffer to another kernel buffer\n> (4) send the kernel buffer to the socket\n\n使用`sendFile`调用可以避免(2)和(3)的两次内存拷贝，假设生产、消费的速率相同第(1)步可能也是不需要的，即数据刷盘后其对应的page cache还未失效可被重用。当然这种极度依赖page cache的设计，在消费进度落后太多的情况下会有问题，部分Consumer拉取冷数据大量占用了操作系统的page cache，使得那些生产、消费相近的Consumer也受到牵连（即步骤(1)必不可少）。\n\nBroker的这种读、写设计，在Partition比较少的情况下，几乎都是顺序IO，这也是它高吞吐的原因之一。但如果Broker上面的Partition急剧增加，维护多个文件的顺序读、写时随机IO将无法避免。另外需要注意的是，消息在单个Partition内是有序的，但Partition之间的消息是没有顺序保证的。\n\nBroker在设计上是无状态的，这使得它可以保持简单。Consumer端需要自己负责消费进度offset的保存，这在Broker滚动清除数据时会有问题，因此它只能做time-based的数据滚动清除，即假定在一定时间内消息一定会被Consumer消费。\n\n## Producer和Consumer\n\nProducer生成消息时，按照随机、指定或者函数计算的策略，将消息投递到Broker。Consumer在消费消息时会有一个消费者组(Consumer Group)的概念，比如2个消费者消费2个Topic的数据。消费的粒度是Partition级别，即一个Topic的其中一个Partition只会分配给一个Consumer，一个Consumer可能会被分配到多个Partition。\n\nConsumer Group内各Consumer分配消费任务的过程称为rebalance，这个过程是没有master参与的，论文认为引入master还需要考虑master崩溃的情况增加复杂度。论文阐述的reblance过程的大概思想如下：\n- Consumer监听Zookeeper是否有Consumer/Broker的新增或删除，若有触发rebalance；\n- 当前Consumer移除Zookeeper中分配给它消费的Partition占用数据；\n- Consumer从Zookeeper获取待消费的Partition列表和待分配任务的Consumer列表，分别对他们进行排序；\n- 假设Partition列表为N份，Consumer列表有M个，将N份顺序均分给M个消费者。如将`1,2,3,4,5,6`分成2份，即`1,2,3`和`4,5,6`。\n- 当前消费者由上一步计算得知它分配到的Partition列表，再去Zookeeper中检测这些Partition是否被其他Consumer占据了消费权，若是则回到第一步重新开始，这种情况一般是Zookeeper消息延迟导致其他Consumer还未进入rebalance导致的。否则Consumer写Zookeeper，将分配到的Partition列表占用方更新为自身，然后启动pull数据线程开始拉Partition的数据消费。\n\n投递Consumer的策略是at-least-once，Consumer消费完未提交offset后崩溃，会导致消息被重复消费，Consumer端需要自行容错这类问题。这个设计足够简单，避免引入2PC（两阶段提交）实现精准一次消费而使设计变得复杂。\n\n## 总结\n\nKafka最初的设计理念，就是重吞吐量而牺牲一致性。它是一个优秀的中间件，但如果你需要在关键业务中使用，可以考虑下阿里系的RocketMQ，或者微信系的PhxQueue。\n\n## 扩展阅读\n\n[聊聊page cache与Kafka之间的事儿](https://cloud.tencent.com/developer/article/1488144)\n[《Kafka核心技术与实战》专栏笔记](https://zhangjunjia.github.io/2020/01/03/kafka-geekbang-note/)\n[Page Cache, the Affair Between Memory and Files](https://manybutfinite.com/post/page-cache-the-affair-between-memory-and-files/)\n","source":"_posts/2020-06-04-kafka-paper.md","raw":"---\ntitle: 'Paper阅读：Kafka: a Distributed Messaging System for Log Processing'\ndate: 2020-06-04 22:02:22\ntags: ['Kafka', 'Paper阅读']\ncomments: true\ncategories: ['分布式系统']\n---\n\n这篇论文是LinkedIn与2011年发表的关于Kafka的论文，从中可以窥探Kafka最源头的设计理念。\n\n<!--more-->\n\n## 总览\n\n论文开篇就介绍到Kafka是：\n> a distributed messaging system that we developed for **collecting** and **delivering high volumes of log data** with **low latency**.\n\nKafka一开始的设计目标就是聚集于收集数据、分发数据、大容量、日志数据、低延迟（高吞吐）。基于此目标，它做出了一些取舍：\n- 不保证数据的强一致。`losing a few pageview events occasionally is certainly not the end of the world`，Producer生产时可能丢失数据，Kafka最新版本可通过设置ACK以及callback逻辑做生产失败的容错。`when a consumer process crashes without a clean shutdown, the consumer process that takes over those partitions owned by the failed consumer may get some duplicate messages that are after the last offset successfully committed to zookeeper`，Consumer消费数据时若没有正常提交offset，遇到crash会导致消息的重复投递。\n- 为了高吞吐和低延迟做了一些针对性优化。Producer端会batch提交消息，Broker端依赖操作系统的page cache实现`write-through caching and read- ahead`，Consumer端会batch拉取消息。\n- Broker端采用多分片设计，使得生产、消费的负载均衡的打到多台机。\n- Consumer使用pull模型，由Consumer的消费能力决定拉取消息速率防止压垮进程，便于Consumer进行rewind消费旧的消息。\n\n![image](https://user-images.githubusercontent.com/4915189/83505149-f86d2000-a4f7-11ea-9955-be8e4104cb55.png)\n（图1 Kafka设计总览）\n\n如图1，Kafka的三个核心是Producer、Broker和Consumer。论文对其逐一进行介绍。\n\n## Broker\n\nKafka的Topic的数据，会被划分为多个Partition，这些Partiton会被打散到多台Broker进行存储。这样设计是为了负载均衡，生产、消费的流量均分到了多台Broker机器防止压垮某一台机器。\n\n![image](https://user-images.githubusercontent.com/4915189/83505122-f0ad7b80-a4f7-11ea-967a-2c2b4717e9e9.png)\n（图2 Partition的物理表示）\n\nPartition是一个逻辑概念，在物理上它由多个segment文件组成，如图2所示。从图片可以看出每个segment文件存储一定offset范围的消息，segment文件在内存中建立索引。offset是递增的，每条消息都有唯一的offset标识其在segment文件中的偏移位置。Kafka的消息是没有唯一ID的，论文认为唯一ID会增加设计的复杂度，而offset设计既可以满足消息索引需求又足够简单。\n\nBroker收到Producer的消息后，将其append到最新segment文件的末尾。这个append动作不是立即刷盘的，Broker会攒一定数量的消息或者等达到一定时间后才刷盘，刷盘后Consumer才能读取到消息。这个设计虽然能提高吞吐，但如果Broker突然崩溃将导致数据的一致性问题，在最新版本的Kafka通过ISR机制最大程度的减少这种问题的发生。\n\nBroker并不会缓存消息到Java Heap中，它利用操作系统的`sendFile`调用减少内存的拷贝。不使用`sendFile`调用时，Broker提供消费消息的流程如下：\n> (1) read data from the storage media to the page cache in an OS\n> (2) copy data in the page cache to an application buffer\n> (3) copy application buffer to another kernel buffer\n> (4) send the kernel buffer to the socket\n\n使用`sendFile`调用可以避免(2)和(3)的两次内存拷贝，假设生产、消费的速率相同第(1)步可能也是不需要的，即数据刷盘后其对应的page cache还未失效可被重用。当然这种极度依赖page cache的设计，在消费进度落后太多的情况下会有问题，部分Consumer拉取冷数据大量占用了操作系统的page cache，使得那些生产、消费相近的Consumer也受到牵连（即步骤(1)必不可少）。\n\nBroker的这种读、写设计，在Partition比较少的情况下，几乎都是顺序IO，这也是它高吞吐的原因之一。但如果Broker上面的Partition急剧增加，维护多个文件的顺序读、写时随机IO将无法避免。另外需要注意的是，消息在单个Partition内是有序的，但Partition之间的消息是没有顺序保证的。\n\nBroker在设计上是无状态的，这使得它可以保持简单。Consumer端需要自己负责消费进度offset的保存，这在Broker滚动清除数据时会有问题，因此它只能做time-based的数据滚动清除，即假定在一定时间内消息一定会被Consumer消费。\n\n## Producer和Consumer\n\nProducer生成消息时，按照随机、指定或者函数计算的策略，将消息投递到Broker。Consumer在消费消息时会有一个消费者组(Consumer Group)的概念，比如2个消费者消费2个Topic的数据。消费的粒度是Partition级别，即一个Topic的其中一个Partition只会分配给一个Consumer，一个Consumer可能会被分配到多个Partition。\n\nConsumer Group内各Consumer分配消费任务的过程称为rebalance，这个过程是没有master参与的，论文认为引入master还需要考虑master崩溃的情况增加复杂度。论文阐述的reblance过程的大概思想如下：\n- Consumer监听Zookeeper是否有Consumer/Broker的新增或删除，若有触发rebalance；\n- 当前Consumer移除Zookeeper中分配给它消费的Partition占用数据；\n- Consumer从Zookeeper获取待消费的Partition列表和待分配任务的Consumer列表，分别对他们进行排序；\n- 假设Partition列表为N份，Consumer列表有M个，将N份顺序均分给M个消费者。如将`1,2,3,4,5,6`分成2份，即`1,2,3`和`4,5,6`。\n- 当前消费者由上一步计算得知它分配到的Partition列表，再去Zookeeper中检测这些Partition是否被其他Consumer占据了消费权，若是则回到第一步重新开始，这种情况一般是Zookeeper消息延迟导致其他Consumer还未进入rebalance导致的。否则Consumer写Zookeeper，将分配到的Partition列表占用方更新为自身，然后启动pull数据线程开始拉Partition的数据消费。\n\n投递Consumer的策略是at-least-once，Consumer消费完未提交offset后崩溃，会导致消息被重复消费，Consumer端需要自行容错这类问题。这个设计足够简单，避免引入2PC（两阶段提交）实现精准一次消费而使设计变得复杂。\n\n## 总结\n\nKafka最初的设计理念，就是重吞吐量而牺牲一致性。它是一个优秀的中间件，但如果你需要在关键业务中使用，可以考虑下阿里系的RocketMQ，或者微信系的PhxQueue。\n\n## 扩展阅读\n\n[聊聊page cache与Kafka之间的事儿](https://cloud.tencent.com/developer/article/1488144)\n[《Kafka核心技术与实战》专栏笔记](https://zhangjunjia.github.io/2020/01/03/kafka-geekbang-note/)\n[Page Cache, the Affair Between Memory and Files](https://manybutfinite.com/post/page-cache-the-affair-between-memory-and-files/)\n","slug":"kafka-paper","published":1,"updated":"2022-08-09T15:02:00.679Z","layout":"post","photos":[],"link":"","_id":"cl6mbc164006iigu8ztymq0hs","content":"<p>这篇论文是LinkedIn与2011年发表的关于Kafka的论文，从中可以窥探Kafka最源头的设计理念。</p>\n<a id=\"more\"></a>\n<h2 id=\"总览\"><a href=\"#总览\" class=\"headerlink\" title=\"总览\"></a>总览</h2><p>论文开篇就介绍到Kafka是：</p>\n<blockquote>\n<p>a distributed messaging system that we developed for <strong>collecting</strong> and <strong>delivering high volumes of log data</strong> with <strong>low latency</strong>.</p>\n</blockquote>\n<p>Kafka一开始的设计目标就是聚集于收集数据、分发数据、大容量、日志数据、低延迟（高吞吐）。基于此目标，它做出了一些取舍：</p>\n<ul>\n<li>不保证数据的强一致。<code>losing a few pageview events occasionally is certainly not the end of the world</code>，Producer生产时可能丢失数据，Kafka最新版本可通过设置ACK以及callback逻辑做生产失败的容错。<code>when a consumer process crashes without a clean shutdown, the consumer process that takes over those partitions owned by the failed consumer may get some duplicate messages that are after the last offset successfully committed to zookeeper</code>，Consumer消费数据时若没有正常提交offset，遇到crash会导致消息的重复投递。</li>\n<li>为了高吞吐和低延迟做了一些针对性优化。Producer端会batch提交消息，Broker端依赖操作系统的page cache实现<code>write-through caching and read- ahead</code>，Consumer端会batch拉取消息。</li>\n<li>Broker端采用多分片设计，使得生产、消费的负载均衡的打到多台机。</li>\n<li>Consumer使用pull模型，由Consumer的消费能力决定拉取消息速率防止压垮进程，便于Consumer进行rewind消费旧的消息。</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/83505149-f86d2000-a4f7-11ea-9955-be8e4104cb55.png\" alt=\"image\"><br>（图1 Kafka设计总览）</p>\n<p>如图1，Kafka的三个核心是Producer、Broker和Consumer。论文对其逐一进行介绍。</p>\n<h2 id=\"Broker\"><a href=\"#Broker\" class=\"headerlink\" title=\"Broker\"></a>Broker</h2><p>Kafka的Topic的数据，会被划分为多个Partition，这些Partiton会被打散到多台Broker进行存储。这样设计是为了负载均衡，生产、消费的流量均分到了多台Broker机器防止压垮某一台机器。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/83505122-f0ad7b80-a4f7-11ea-967a-2c2b4717e9e9.png\" alt=\"image\"><br>（图2 Partition的物理表示）</p>\n<p>Partition是一个逻辑概念，在物理上它由多个segment文件组成，如图2所示。从图片可以看出每个segment文件存储一定offset范围的消息，segment文件在内存中建立索引。offset是递增的，每条消息都有唯一的offset标识其在segment文件中的偏移位置。Kafka的消息是没有唯一ID的，论文认为唯一ID会增加设计的复杂度，而offset设计既可以满足消息索引需求又足够简单。</p>\n<p>Broker收到Producer的消息后，将其append到最新segment文件的末尾。这个append动作不是立即刷盘的，Broker会攒一定数量的消息或者等达到一定时间后才刷盘，刷盘后Consumer才能读取到消息。这个设计虽然能提高吞吐，但如果Broker突然崩溃将导致数据的一致性问题，在最新版本的Kafka通过ISR机制最大程度的减少这种问题的发生。</p>\n<p>Broker并不会缓存消息到Java Heap中，它利用操作系统的<code>sendFile</code>调用减少内存的拷贝。不使用<code>sendFile</code>调用时，Broker提供消费消息的流程如下：</p>\n<blockquote>\n<p>(1) read data from the storage media to the page cache in an OS<br>(2) copy data in the page cache to an application buffer<br>(3) copy application buffer to another kernel buffer<br>(4) send the kernel buffer to the socket</p>\n</blockquote>\n<p>使用<code>sendFile</code>调用可以避免(2)和(3)的两次内存拷贝，假设生产、消费的速率相同第(1)步可能也是不需要的，即数据刷盘后其对应的page cache还未失效可被重用。当然这种极度依赖page cache的设计，在消费进度落后太多的情况下会有问题，部分Consumer拉取冷数据大量占用了操作系统的page cache，使得那些生产、消费相近的Consumer也受到牵连（即步骤(1)必不可少）。</p>\n<p>Broker的这种读、写设计，在Partition比较少的情况下，几乎都是顺序IO，这也是它高吞吐的原因之一。但如果Broker上面的Partition急剧增加，维护多个文件的顺序读、写时随机IO将无法避免。另外需要注意的是，消息在单个Partition内是有序的，但Partition之间的消息是没有顺序保证的。</p>\n<p>Broker在设计上是无状态的，这使得它可以保持简单。Consumer端需要自己负责消费进度offset的保存，这在Broker滚动清除数据时会有问题，因此它只能做time-based的数据滚动清除，即假定在一定时间内消息一定会被Consumer消费。</p>\n<h2 id=\"Producer和Consumer\"><a href=\"#Producer和Consumer\" class=\"headerlink\" title=\"Producer和Consumer\"></a>Producer和Consumer</h2><p>Producer生成消息时，按照随机、指定或者函数计算的策略，将消息投递到Broker。Consumer在消费消息时会有一个消费者组(Consumer Group)的概念，比如2个消费者消费2个Topic的数据。消费的粒度是Partition级别，即一个Topic的其中一个Partition只会分配给一个Consumer，一个Consumer可能会被分配到多个Partition。</p>\n<p>Consumer Group内各Consumer分配消费任务的过程称为rebalance，这个过程是没有master参与的，论文认为引入master还需要考虑master崩溃的情况增加复杂度。论文阐述的reblance过程的大概思想如下：</p>\n<ul>\n<li>Consumer监听Zookeeper是否有Consumer/Broker的新增或删除，若有触发rebalance；</li>\n<li>当前Consumer移除Zookeeper中分配给它消费的Partition占用数据；</li>\n<li>Consumer从Zookeeper获取待消费的Partition列表和待分配任务的Consumer列表，分别对他们进行排序；</li>\n<li>假设Partition列表为N份，Consumer列表有M个，将N份顺序均分给M个消费者。如将<code>1,2,3,4,5,6</code>分成2份，即<code>1,2,3</code>和<code>4,5,6</code>。</li>\n<li>当前消费者由上一步计算得知它分配到的Partition列表，再去Zookeeper中检测这些Partition是否被其他Consumer占据了消费权，若是则回到第一步重新开始，这种情况一般是Zookeeper消息延迟导致其他Consumer还未进入rebalance导致的。否则Consumer写Zookeeper，将分配到的Partition列表占用方更新为自身，然后启动pull数据线程开始拉Partition的数据消费。</li>\n</ul>\n<p>投递Consumer的策略是at-least-once，Consumer消费完未提交offset后崩溃，会导致消息被重复消费，Consumer端需要自行容错这类问题。这个设计足够简单，避免引入2PC（两阶段提交）实现精准一次消费而使设计变得复杂。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Kafka最初的设计理念，就是重吞吐量而牺牲一致性。它是一个优秀的中间件，但如果你需要在关键业务中使用，可以考虑下阿里系的RocketMQ，或者微信系的PhxQueue。</p>\n<h2 id=\"扩展阅读\"><a href=\"#扩展阅读\" class=\"headerlink\" title=\"扩展阅读\"></a>扩展阅读</h2><p><a href=\"https://cloud.tencent.com/developer/article/1488144\" target=\"_blank\" rel=\"noopener\">聊聊page cache与Kafka之间的事儿</a><br><a href=\"https://zhangjunjia.github.io/2020/01/03/kafka-geekbang-note/\">《Kafka核心技术与实战》专栏笔记</a><br><a href=\"https://manybutfinite.com/post/page-cache-the-affair-between-memory-and-files/\" target=\"_blank\" rel=\"noopener\">Page Cache, the Affair Between Memory and Files</a></p>\n","site":{"data":{}},"excerpt":"<p>这篇论文是LinkedIn与2011年发表的关于Kafka的论文，从中可以窥探Kafka最源头的设计理念。</p>","more":"<h2 id=\"总览\"><a href=\"#总览\" class=\"headerlink\" title=\"总览\"></a>总览</h2><p>论文开篇就介绍到Kafka是：</p>\n<blockquote>\n<p>a distributed messaging system that we developed for <strong>collecting</strong> and <strong>delivering high volumes of log data</strong> with <strong>low latency</strong>.</p>\n</blockquote>\n<p>Kafka一开始的设计目标就是聚集于收集数据、分发数据、大容量、日志数据、低延迟（高吞吐）。基于此目标，它做出了一些取舍：</p>\n<ul>\n<li>不保证数据的强一致。<code>losing a few pageview events occasionally is certainly not the end of the world</code>，Producer生产时可能丢失数据，Kafka最新版本可通过设置ACK以及callback逻辑做生产失败的容错。<code>when a consumer process crashes without a clean shutdown, the consumer process that takes over those partitions owned by the failed consumer may get some duplicate messages that are after the last offset successfully committed to zookeeper</code>，Consumer消费数据时若没有正常提交offset，遇到crash会导致消息的重复投递。</li>\n<li>为了高吞吐和低延迟做了一些针对性优化。Producer端会batch提交消息，Broker端依赖操作系统的page cache实现<code>write-through caching and read- ahead</code>，Consumer端会batch拉取消息。</li>\n<li>Broker端采用多分片设计，使得生产、消费的负载均衡的打到多台机。</li>\n<li>Consumer使用pull模型，由Consumer的消费能力决定拉取消息速率防止压垮进程，便于Consumer进行rewind消费旧的消息。</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/83505149-f86d2000-a4f7-11ea-9955-be8e4104cb55.png\" alt=\"image\"><br>（图1 Kafka设计总览）</p>\n<p>如图1，Kafka的三个核心是Producer、Broker和Consumer。论文对其逐一进行介绍。</p>\n<h2 id=\"Broker\"><a href=\"#Broker\" class=\"headerlink\" title=\"Broker\"></a>Broker</h2><p>Kafka的Topic的数据，会被划分为多个Partition，这些Partiton会被打散到多台Broker进行存储。这样设计是为了负载均衡，生产、消费的流量均分到了多台Broker机器防止压垮某一台机器。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/83505122-f0ad7b80-a4f7-11ea-967a-2c2b4717e9e9.png\" alt=\"image\"><br>（图2 Partition的物理表示）</p>\n<p>Partition是一个逻辑概念，在物理上它由多个segment文件组成，如图2所示。从图片可以看出每个segment文件存储一定offset范围的消息，segment文件在内存中建立索引。offset是递增的，每条消息都有唯一的offset标识其在segment文件中的偏移位置。Kafka的消息是没有唯一ID的，论文认为唯一ID会增加设计的复杂度，而offset设计既可以满足消息索引需求又足够简单。</p>\n<p>Broker收到Producer的消息后，将其append到最新segment文件的末尾。这个append动作不是立即刷盘的，Broker会攒一定数量的消息或者等达到一定时间后才刷盘，刷盘后Consumer才能读取到消息。这个设计虽然能提高吞吐，但如果Broker突然崩溃将导致数据的一致性问题，在最新版本的Kafka通过ISR机制最大程度的减少这种问题的发生。</p>\n<p>Broker并不会缓存消息到Java Heap中，它利用操作系统的<code>sendFile</code>调用减少内存的拷贝。不使用<code>sendFile</code>调用时，Broker提供消费消息的流程如下：</p>\n<blockquote>\n<p>(1) read data from the storage media to the page cache in an OS<br>(2) copy data in the page cache to an application buffer<br>(3) copy application buffer to another kernel buffer<br>(4) send the kernel buffer to the socket</p>\n</blockquote>\n<p>使用<code>sendFile</code>调用可以避免(2)和(3)的两次内存拷贝，假设生产、消费的速率相同第(1)步可能也是不需要的，即数据刷盘后其对应的page cache还未失效可被重用。当然这种极度依赖page cache的设计，在消费进度落后太多的情况下会有问题，部分Consumer拉取冷数据大量占用了操作系统的page cache，使得那些生产、消费相近的Consumer也受到牵连（即步骤(1)必不可少）。</p>\n<p>Broker的这种读、写设计，在Partition比较少的情况下，几乎都是顺序IO，这也是它高吞吐的原因之一。但如果Broker上面的Partition急剧增加，维护多个文件的顺序读、写时随机IO将无法避免。另外需要注意的是，消息在单个Partition内是有序的，但Partition之间的消息是没有顺序保证的。</p>\n<p>Broker在设计上是无状态的，这使得它可以保持简单。Consumer端需要自己负责消费进度offset的保存，这在Broker滚动清除数据时会有问题，因此它只能做time-based的数据滚动清除，即假定在一定时间内消息一定会被Consumer消费。</p>\n<h2 id=\"Producer和Consumer\"><a href=\"#Producer和Consumer\" class=\"headerlink\" title=\"Producer和Consumer\"></a>Producer和Consumer</h2><p>Producer生成消息时，按照随机、指定或者函数计算的策略，将消息投递到Broker。Consumer在消费消息时会有一个消费者组(Consumer Group)的概念，比如2个消费者消费2个Topic的数据。消费的粒度是Partition级别，即一个Topic的其中一个Partition只会分配给一个Consumer，一个Consumer可能会被分配到多个Partition。</p>\n<p>Consumer Group内各Consumer分配消费任务的过程称为rebalance，这个过程是没有master参与的，论文认为引入master还需要考虑master崩溃的情况增加复杂度。论文阐述的reblance过程的大概思想如下：</p>\n<ul>\n<li>Consumer监听Zookeeper是否有Consumer/Broker的新增或删除，若有触发rebalance；</li>\n<li>当前Consumer移除Zookeeper中分配给它消费的Partition占用数据；</li>\n<li>Consumer从Zookeeper获取待消费的Partition列表和待分配任务的Consumer列表，分别对他们进行排序；</li>\n<li>假设Partition列表为N份，Consumer列表有M个，将N份顺序均分给M个消费者。如将<code>1,2,3,4,5,6</code>分成2份，即<code>1,2,3</code>和<code>4,5,6</code>。</li>\n<li>当前消费者由上一步计算得知它分配到的Partition列表，再去Zookeeper中检测这些Partition是否被其他Consumer占据了消费权，若是则回到第一步重新开始，这种情况一般是Zookeeper消息延迟导致其他Consumer还未进入rebalance导致的。否则Consumer写Zookeeper，将分配到的Partition列表占用方更新为自身，然后启动pull数据线程开始拉Partition的数据消费。</li>\n</ul>\n<p>投递Consumer的策略是at-least-once，Consumer消费完未提交offset后崩溃，会导致消息被重复消费，Consumer端需要自行容错这类问题。这个设计足够简单，避免引入2PC（两阶段提交）实现精准一次消费而使设计变得复杂。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Kafka最初的设计理念，就是重吞吐量而牺牲一致性。它是一个优秀的中间件，但如果你需要在关键业务中使用，可以考虑下阿里系的RocketMQ，或者微信系的PhxQueue。</p>\n<h2 id=\"扩展阅读\"><a href=\"#扩展阅读\" class=\"headerlink\" title=\"扩展阅读\"></a>扩展阅读</h2><p><a href=\"https://cloud.tencent.com/developer/article/1488144\" target=\"_blank\" rel=\"noopener\">聊聊page cache与Kafka之间的事儿</a><br><a href=\"https://zhangjunjia.github.io/2020/01/03/kafka-geekbang-note/\">《Kafka核心技术与实战》专栏笔记</a><br><a href=\"https://manybutfinite.com/post/page-cache-the-affair-between-memory-and-files/\" target=\"_blank\" rel=\"noopener\">Page Cache, the Affair Between Memory and Files</a></p>"},{"title":"Paper阅读:The Google File System","date":"2020-07-08T07:25:29.000Z","comments":1,"_content":"\n记录阅读论文Google File System(GFS)的笔记。\n\n<!--more-->\n\n## 设计目标\n\nGFS的设计目标是：\n> scalable filesystem：大文件、append写居多\n> running on commodity hardware：可容忍硬盘、机器、网络等故障\n> data intensive：数据密集\n\nGFS暴露的文件系统接口如下：\n- 创建/删除：create/delete\n- 读：read\n- 写：write/append/snapshot\n\n## 从接口实现看系统架构\n\n### read\n\n在GFS中，文件由1至多个chunk组成，每个chunk的大小是64MB，类似于下面的结构：\n```\n文件名称：/boo/far（逻辑概念）\n文件内容：[chunk_0, chunk_1, chunk_2]（物理概念）\n```\n\n论文提到chunk是Linux文件系统的真实文件，GFS中所指的分布式文件是由多个chunk组成的逻辑文件。\n>Each chunk replica is stored as a plain Linux file on a chunkserver and is extended only as needed.\n\n![image](https://user-images.githubusercontent.com/4915189/86358259-c3dcb780-bca1-11ea-99d0-f56c957a0571.png)\n（图1 GFS架构，摘自论文）\n\nGFS Client读取分布式文件内容如图1所示，\n- client向master询问特定分布式文件的特定下标的chunk的信息；\n- master在内存中维护`文件名 <> chunk下标数组`的映射，chunk下标数组的元素，存放了该chunk所在chunkserver的机器信息以及该chunk的唯一标识（chunk location）；\n  - master在创建chunk时，会为其生成一个64bit的唯一标识，称之为chunk location；\n  - 出于高可用、负载均衡等考虑，chunk会被replicate到多个chunkserver；\n  - master维护分布式文件目录信息、文件到chunk handle的映射、chunk handle到机器的映射，这些信息称为metadata；\n- client将master返回的信息缓存起来，挑选一个“网络距离最近”的chunkserver请求数据；\n  - 缓存chunk信息失效后，client会重新向master获取；\n  - client会批量读多个chunk的metadata，以减少和master的通信；\n- chunkserver接收到数据读取请求时，根据chunk handle定位到文件读取数据返回；\n  - chunkserver发现chunk handle不存在时，client应失效对该chunk的metadata的缓存；\n  - chunkserver需要维护chunk handle到chunk文件的索引；\n\n读取过程中，client先向master获取metadata，然后再向chunkserver发起真实数据读取请求。master是如何维护metadata的呢？\n- 文件名称到chunk信息的映射是维护在内存中的，在create/delete时更新此映射；\n- chunk存放在哪些chunkserver是由chunkserver主动上报的，chunkserver天生知道它维护了哪些chunk文件，可以通过HeartBeat上报这类信息，当网络分区恢复或者chunkserver重启时它能让master第一时间感知chunk信息的变化。\n\n### write\n\n![image](https://user-images.githubusercontent.com/4915189/86428940-9aaf3c00-bd20-11ea-8b36-5296662f6c90.png)\n（图2 client写数据的过程，摘自论文）\n\n1. client询问要写的chunk的primary replica以及secondary replica所在的chunkserver信息\n    - 持有lease的replica称为primary否则称为secondary，如果没有replica持有lease，master会挑选一个replica授予，chunkserver通过HeartBeat延长lease的失效时间；\n2. client缓存master回复的信息直至expired或者chunkserver回复不持有lease；\n3. client以pipeline的方式将数据推送至所有replica，比如client->C1->C2->C3->C4，pipeline中下一跳的选择是网络距离最近的目标replica，每个replica一收到数据会立即向下一跳转发，数据此时是缓存在内存buffer的还未落盘；\n4. 所有replica收完数据后，client通知primary replica将buffer的数据修改按照提交顺序串行落盘。每个数据修改有一个serial number，这个number是单调递增的用于代表落盘的顺序；\n5. primary落盘成功后，通知所有secondary以相同serial number的次序落盘；\n6. secondary回复primary落盘是否成功；\n7. primary回复client自身以及所有secondary是否落盘成功，任一replica的失败都会导致client重试步骤3到步骤7。\n\nappend操作和write是相似的，不同点在于：\n- 步骤4，primary尝试append数据到末尾，假设append会导致chunk超过64Mb，primary会将当前chunk补齐到64Mb，同时告知所有secondary进行补齐，最后返回错误告知client应该在下一个chunk index去append数据。否则，primary写数据到chunk文件末尾，写成功后通知secondary在哪个chunk的哪个offset写数据，append操作在secondary变成了指定offset的write操作。\n- 步骤7，任一replica的失败同样会导致重试，这可能导致部分replica有多份需要append的数据，client需要实现幂等读取来容忍这种情况。\n\n### create\n\nmaster通过新增chunk来扩充分布式文件，新增chunk的设计要点是：\n- 新增的chunk应该放在哪几台chunkserver？其原则是磁盘利用率最大化、机架容灾、负载均衡。3个replica至少应该分布到2个不同的机架，磁盘空间富余的chunkserver会优先选择，近期创建chunk较少的会优先选择（大量chunk同时创建在同一chunkserver意味着会立即带来较大的写负载）。\n- 新增的chunk文件可以认为是一个空文件，只有在真正写的时候才触发磁盘空间申请。\n\n### delete\n\nclient发起delete，只是在master层面将分布式文件做重命名，例如将文件重命名增加一个`TRASH`的后缀。这些被标识TRASH的分布式文件有一个缓冲期，缓冲期仍可以像正常文件一样访问他们或者回滚，缓冲期后他们会被真正清除。chunkserver通过HeartBeat感知自身负责的chunk文件是否还有分布式文件与其关联，无关联的话chunkserver会将这些chunk文件真正清除。这种延迟删除的垃圾回收机制有以下好处：\n- delete操作是可回滚的；\n- 对于delete请求，master只需要修改分布式文件名称即可返回，这无疑大大减轻master的负载；\n- master扫描metadata并清除TRASH，chunkserver感知并清除chunk文件，这些流程都成为了常规的后台线程，这样一旦有失联的chunkserver重新加入集群，它们也能正确清除文件。\n\n### snapshot\n\n本质上是一种copy-on-write，master通过失效已授予的lease使得client写失败触发重新获取lease，这给了master去通知待写chunk所在的chunkserver去做chunk文件copy的机会，然后用新的copy文件来提供写。\n\n## CAP理论\n\n下面尝试从CAP理论的视角来看GFS的设计。\n\n### consistency\n\n对于master，任意涉及到文件namespace、文件到chunk映射修改的client操作都会写operation log、更新master的metadata内存，且同步到远端机器的operation log才算写成功，论文没有提及具体如何实现，应该也是某种二阶段提交。client写操作对metadata的修改是强一致的，完成后所有client都可以看到最新修改。\n\nmaster有一种shadow的角色，它的借助operation log重放metadata，会轻微落后于master。在master宕机时client可以从shadow读取metadata，它的metadata是弱一致的。\n\n![image](https://user-images.githubusercontent.com/4915189/86441384-b3c6e580-bd3e-11ea-806b-c5ccf9c56723.png)\n（图3 chunk的一致性模型，摘自论文）\n\nGFS对于chunk的一致性有两种定义：\n- consitent：客户端永远能看到一致的数据，无论他们从哪个replica读取数据；\n- defined：当某个chunk发生修改后，client能看到刚刚修改的所有数据。\n\n图3是GFS在几种写下的一致性保证：\n- 串行写：defined\n- 并发写：consistent + undefined（client端无法确认最终到底是哪个写导致的数据变化）\n- 追加写：defined but interspersed with inconsistent（append写只保证at least one，可能append了多次数据，且有的replica会有padding数据）\n- 写失败：inconsistent\n\n每个chunk文件在被修改时其chunk version都会自增，写操作会识别出那些chunk version落后的chunk并跳过写，这些落后的chunk会在垃圾回收过程被回收。每个64Mb的chunk文件的每个64Kb数据block，都会记录一个checksum（持久化到专门的logging文件），读取数据时需校验checksum是否正确来判断数据是否损坏。\n\nmaster对于分布式文件的新增、删除是强一致性的。GFS在master有一个文件锁的设计，对文件加写锁可以防止并发创建同名的分布式文件，对目录加写锁可以防止目录下的文件新增和删除。\n\n### availability\n\nGFS的设计中master是单点的，当监控系统监测到master故障，会从远端存放operation log的机器挑选一台快速启动顶替。故障转移的过程中，master是不可用的，任何依赖master的服务在故障转移过程也是不可用的。master和chunkserver都被设计成可以快速启动的。以master为例，它启动时读取最近一次checkpoint文件（B-Tree格式）和最近一次checkpoint时间点之后的增量operation log文件实现快速启动。\n\n写chunkserver的过程中，如果secondary失败则触发重试，若primary失败则该写操作会被failed掉，由客户端决定是否要重试写。\n\n### partition tolerance\n\nGFS的chunk默认有3个replica，其replicate数量是可调整的。写操作需要所有replica写成功才返回，这对读是有好处的，只需要读任意一份replica即可获取最新数据。当某些replica所在chunkserver宕机、磁盘故障时，GFS会触发re-replication，使得replica数量重归3份。GFS还会进行rebalancing，将replica从磁盘紧张的chunkserver迁移到磁盘富余的chunkserver。\n\n## 总结\n\nGFS是单master多chunkserver的设计，master通过HeartBeat感知chunkserver的数据视图并缓存在内存中。读、写请求都需要先通过master的内存视图定位到具体chunkserver，在向具体chunkserver进行真实数据交换。写chunkserver时，其一chunk replica所在chunkserver会被选为lease，这在某种程度上也是master权限的下放。\n\n## 问题讨论\n\n读paper很重要的一点是要把有问题的地方搞懂，因此提问题无疑是非常重要的。以下是搬运自[Charles的技术博客：GFS](http://oserror.com/distributed/gfs/)关于论文的一些问题：\n>7.1 为什么存储三个副本？而不是两个或者四个？\n>7.2 chunk的大小为何选择64MB？这个选择主要基于哪些考虑？\n>7.3 gfs主要支持追加，改写操作比较少，为什么这么设计？如何设计一个仅支持追加操作的文件系统来构建分布式表格系统bigtable？\n>7.4 为什么要将数据流和控制流分开？如果不分开，如何实现追加流程？\n>7.5 gfs有时会出现重复记录或者padding记录，为什么？\n>7.6 lease是什么？在gfs中起到了什么作用？它与心跳有何区别？\n>7.7 gfs追加过程中如果出现备副本故障，如何处理？如果出现主副本故障，应该如何处理？\n>7.8 gfs master需要存储哪些信息？master的数据结构如何设计？\n>7.9 假设服务一千万个文件，每个文件1GB，master中存储元数据大概占多少内存？\n>7.10 master如何实现高可用性？\n>7.11 负载的影响因素有哪些？如何计算一台机器的负载值？\n>7.12 master新建chunk时如何选择chunkserver？如果新机器上线，负载值特别低，如何避免其他chunkserver同时往这台机器上迁移chunk？\n>7.13 如果chunkserver下线后过一会重新上线，gfs如何处理？\n>7.14 如何实现分布式文件系统的快照操作？\n>7.15 chunkserver数据结构如何设计？\n>7.16 磁盘可能出现位翻转错误，chunkserver如何应对？\n>7.17 chunkserver重启后可能有一些过期的chunk，master如何能够发现？\n\n以下是我个人补充的一些问题：\n1. 为什么不用RAID？\n    - RAID不是commodity hardware，无法做到机器级别、机架级别的容灾；\n1. 写失败后chunk数据不一致GFS是如何处理的？\n    - application-level会检测数据中的checkpoint，来判断写入数据是否一致；\n    - 对于append新增的padding，application-level会识别并丢弃；\n    - 对于append被多次触发，application-level通过unique record id来幂等消费；\n1. data flow的pipeline的拓扑相较tree的拓扑有何好处？\n    - pipeline下一跳结点选择的原则是“网络最近”，这种拓扑能使得out带宽利用到极致，得到比tree拓扑更大的网络吞吐；\n1. 单master设计有什么好处？\n    - 不用维护多master的共识，使得master编程简单化，Kafka中Controller、Coordinator也是单master的设计；\n1. GFS为什么不对chunk文件做cache？\n    - chunk文件普遍比较大，client基本是以streaming的方式去读，重复读一个文件的概率不大，热点文件交给page cache缓存就够了；\n1. consistent but undefined是如何发生的？\n    - 在并发append时：GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data.\n    - 在并发write时：If a write by the application is large or straddles a chunk boundary, GFS client code breaks it down into multiple write operations.\n1. read、overwrite数据时检测出checksum错误会触发什么后续操作？\n    - client接收到error，从其他replica读；master对该chunk replica重新replicate，完成后通知corrupt的replica删除；\n1. master为什么不持久化chunk location？\n    - chunkserver拥有final wordview，对于硬盘故障等导致的chunk丢失能主动感知；chunkserver级别的事件非常多（leave、dead、rename等），这类事件都会导致location变化，若都触发落盘master的I/O可能存在瓶颈；\n1. master的operation log为什么需要checkpoint？\n    - 类似于Redis的aof机制，定期checkpoint可以减少append-only文件的大小便于故障时快速启动master；\n1. lease机制的作用是什么？\n    - 将master的部分权限下放到chunkserver，指定的chunk从chunkserver中挑选一台primary出来做一些核心工作（写指令的排序）；\n1. 创建chunk时，该chunk放置到哪台chunkserver有什么考虑因素？\n    - 磁盘使用较少，最近创建chunk较少，散步到不同的机架；\n1. chunkserver如何限制clone数据的带宽？\n    - 限制从源replica读数据的带宽；\n1. 为什么要使用垃圾回收清除文件？\n    - 假设master主动delete时chunkserver宕机，这无疑增加master的设计复杂度，且这种同步删除的动作也加重了master负载，垃圾回收清除可以认为是异步的；\n1. 如何识别stale的replica？\n    - 每次获取lease时，所有alive的replica的chunk version都会被master增加，落后的chunk version认为是stale的；\n1. data flow为什么不经过master结点？\n    - master是单点设计，要尽可能减小其负载；\n1. master为什么要定期扫描metadata？\n    - re-replication的考虑，找出哪些replica需要重新replicate；\n    - 垃圾回收的考虑，找出哪些file需要过期清除；\n\n## 参考文献\n\n[Google File System论文](https://research.google.com/archive/gfs-sosp2003.pdf)\n[Charles的技术博客：GFS](http://oserror.com/distributed/gfs/)\n[分布式系统笔记(3)-GFS](http://wulc.me/2019/01/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0(3)-GFS/)\n[从 GFS 失败的架构设计来看一致性的重要性](http://blog.itpub.net/31562044/viewspace-2646753/)\n[GFS: Evolution on Fast-forward](https://queue.acm.org/detail.cfm?id=1594206)（强烈推荐阅读这一篇，GFS早期开发者关于其演讲的对话）\n","source":"_posts/2020-07-08-google-file-system-paper.md","raw":"---\ntitle: Paper阅读:The Google File System\ndate: 2020-07-08 15:25:29\ntags: ['Paper阅读']\ncomments: true\ncategories: ['分布式系统']\n---\n\n记录阅读论文Google File System(GFS)的笔记。\n\n<!--more-->\n\n## 设计目标\n\nGFS的设计目标是：\n> scalable filesystem：大文件、append写居多\n> running on commodity hardware：可容忍硬盘、机器、网络等故障\n> data intensive：数据密集\n\nGFS暴露的文件系统接口如下：\n- 创建/删除：create/delete\n- 读：read\n- 写：write/append/snapshot\n\n## 从接口实现看系统架构\n\n### read\n\n在GFS中，文件由1至多个chunk组成，每个chunk的大小是64MB，类似于下面的结构：\n```\n文件名称：/boo/far（逻辑概念）\n文件内容：[chunk_0, chunk_1, chunk_2]（物理概念）\n```\n\n论文提到chunk是Linux文件系统的真实文件，GFS中所指的分布式文件是由多个chunk组成的逻辑文件。\n>Each chunk replica is stored as a plain Linux file on a chunkserver and is extended only as needed.\n\n![image](https://user-images.githubusercontent.com/4915189/86358259-c3dcb780-bca1-11ea-99d0-f56c957a0571.png)\n（图1 GFS架构，摘自论文）\n\nGFS Client读取分布式文件内容如图1所示，\n- client向master询问特定分布式文件的特定下标的chunk的信息；\n- master在内存中维护`文件名 <> chunk下标数组`的映射，chunk下标数组的元素，存放了该chunk所在chunkserver的机器信息以及该chunk的唯一标识（chunk location）；\n  - master在创建chunk时，会为其生成一个64bit的唯一标识，称之为chunk location；\n  - 出于高可用、负载均衡等考虑，chunk会被replicate到多个chunkserver；\n  - master维护分布式文件目录信息、文件到chunk handle的映射、chunk handle到机器的映射，这些信息称为metadata；\n- client将master返回的信息缓存起来，挑选一个“网络距离最近”的chunkserver请求数据；\n  - 缓存chunk信息失效后，client会重新向master获取；\n  - client会批量读多个chunk的metadata，以减少和master的通信；\n- chunkserver接收到数据读取请求时，根据chunk handle定位到文件读取数据返回；\n  - chunkserver发现chunk handle不存在时，client应失效对该chunk的metadata的缓存；\n  - chunkserver需要维护chunk handle到chunk文件的索引；\n\n读取过程中，client先向master获取metadata，然后再向chunkserver发起真实数据读取请求。master是如何维护metadata的呢？\n- 文件名称到chunk信息的映射是维护在内存中的，在create/delete时更新此映射；\n- chunk存放在哪些chunkserver是由chunkserver主动上报的，chunkserver天生知道它维护了哪些chunk文件，可以通过HeartBeat上报这类信息，当网络分区恢复或者chunkserver重启时它能让master第一时间感知chunk信息的变化。\n\n### write\n\n![image](https://user-images.githubusercontent.com/4915189/86428940-9aaf3c00-bd20-11ea-8b36-5296662f6c90.png)\n（图2 client写数据的过程，摘自论文）\n\n1. client询问要写的chunk的primary replica以及secondary replica所在的chunkserver信息\n    - 持有lease的replica称为primary否则称为secondary，如果没有replica持有lease，master会挑选一个replica授予，chunkserver通过HeartBeat延长lease的失效时间；\n2. client缓存master回复的信息直至expired或者chunkserver回复不持有lease；\n3. client以pipeline的方式将数据推送至所有replica，比如client->C1->C2->C3->C4，pipeline中下一跳的选择是网络距离最近的目标replica，每个replica一收到数据会立即向下一跳转发，数据此时是缓存在内存buffer的还未落盘；\n4. 所有replica收完数据后，client通知primary replica将buffer的数据修改按照提交顺序串行落盘。每个数据修改有一个serial number，这个number是单调递增的用于代表落盘的顺序；\n5. primary落盘成功后，通知所有secondary以相同serial number的次序落盘；\n6. secondary回复primary落盘是否成功；\n7. primary回复client自身以及所有secondary是否落盘成功，任一replica的失败都会导致client重试步骤3到步骤7。\n\nappend操作和write是相似的，不同点在于：\n- 步骤4，primary尝试append数据到末尾，假设append会导致chunk超过64Mb，primary会将当前chunk补齐到64Mb，同时告知所有secondary进行补齐，最后返回错误告知client应该在下一个chunk index去append数据。否则，primary写数据到chunk文件末尾，写成功后通知secondary在哪个chunk的哪个offset写数据，append操作在secondary变成了指定offset的write操作。\n- 步骤7，任一replica的失败同样会导致重试，这可能导致部分replica有多份需要append的数据，client需要实现幂等读取来容忍这种情况。\n\n### create\n\nmaster通过新增chunk来扩充分布式文件，新增chunk的设计要点是：\n- 新增的chunk应该放在哪几台chunkserver？其原则是磁盘利用率最大化、机架容灾、负载均衡。3个replica至少应该分布到2个不同的机架，磁盘空间富余的chunkserver会优先选择，近期创建chunk较少的会优先选择（大量chunk同时创建在同一chunkserver意味着会立即带来较大的写负载）。\n- 新增的chunk文件可以认为是一个空文件，只有在真正写的时候才触发磁盘空间申请。\n\n### delete\n\nclient发起delete，只是在master层面将分布式文件做重命名，例如将文件重命名增加一个`TRASH`的后缀。这些被标识TRASH的分布式文件有一个缓冲期，缓冲期仍可以像正常文件一样访问他们或者回滚，缓冲期后他们会被真正清除。chunkserver通过HeartBeat感知自身负责的chunk文件是否还有分布式文件与其关联，无关联的话chunkserver会将这些chunk文件真正清除。这种延迟删除的垃圾回收机制有以下好处：\n- delete操作是可回滚的；\n- 对于delete请求，master只需要修改分布式文件名称即可返回，这无疑大大减轻master的负载；\n- master扫描metadata并清除TRASH，chunkserver感知并清除chunk文件，这些流程都成为了常规的后台线程，这样一旦有失联的chunkserver重新加入集群，它们也能正确清除文件。\n\n### snapshot\n\n本质上是一种copy-on-write，master通过失效已授予的lease使得client写失败触发重新获取lease，这给了master去通知待写chunk所在的chunkserver去做chunk文件copy的机会，然后用新的copy文件来提供写。\n\n## CAP理论\n\n下面尝试从CAP理论的视角来看GFS的设计。\n\n### consistency\n\n对于master，任意涉及到文件namespace、文件到chunk映射修改的client操作都会写operation log、更新master的metadata内存，且同步到远端机器的operation log才算写成功，论文没有提及具体如何实现，应该也是某种二阶段提交。client写操作对metadata的修改是强一致的，完成后所有client都可以看到最新修改。\n\nmaster有一种shadow的角色，它的借助operation log重放metadata，会轻微落后于master。在master宕机时client可以从shadow读取metadata，它的metadata是弱一致的。\n\n![image](https://user-images.githubusercontent.com/4915189/86441384-b3c6e580-bd3e-11ea-806b-c5ccf9c56723.png)\n（图3 chunk的一致性模型，摘自论文）\n\nGFS对于chunk的一致性有两种定义：\n- consitent：客户端永远能看到一致的数据，无论他们从哪个replica读取数据；\n- defined：当某个chunk发生修改后，client能看到刚刚修改的所有数据。\n\n图3是GFS在几种写下的一致性保证：\n- 串行写：defined\n- 并发写：consistent + undefined（client端无法确认最终到底是哪个写导致的数据变化）\n- 追加写：defined but interspersed with inconsistent（append写只保证at least one，可能append了多次数据，且有的replica会有padding数据）\n- 写失败：inconsistent\n\n每个chunk文件在被修改时其chunk version都会自增，写操作会识别出那些chunk version落后的chunk并跳过写，这些落后的chunk会在垃圾回收过程被回收。每个64Mb的chunk文件的每个64Kb数据block，都会记录一个checksum（持久化到专门的logging文件），读取数据时需校验checksum是否正确来判断数据是否损坏。\n\nmaster对于分布式文件的新增、删除是强一致性的。GFS在master有一个文件锁的设计，对文件加写锁可以防止并发创建同名的分布式文件，对目录加写锁可以防止目录下的文件新增和删除。\n\n### availability\n\nGFS的设计中master是单点的，当监控系统监测到master故障，会从远端存放operation log的机器挑选一台快速启动顶替。故障转移的过程中，master是不可用的，任何依赖master的服务在故障转移过程也是不可用的。master和chunkserver都被设计成可以快速启动的。以master为例，它启动时读取最近一次checkpoint文件（B-Tree格式）和最近一次checkpoint时间点之后的增量operation log文件实现快速启动。\n\n写chunkserver的过程中，如果secondary失败则触发重试，若primary失败则该写操作会被failed掉，由客户端决定是否要重试写。\n\n### partition tolerance\n\nGFS的chunk默认有3个replica，其replicate数量是可调整的。写操作需要所有replica写成功才返回，这对读是有好处的，只需要读任意一份replica即可获取最新数据。当某些replica所在chunkserver宕机、磁盘故障时，GFS会触发re-replication，使得replica数量重归3份。GFS还会进行rebalancing，将replica从磁盘紧张的chunkserver迁移到磁盘富余的chunkserver。\n\n## 总结\n\nGFS是单master多chunkserver的设计，master通过HeartBeat感知chunkserver的数据视图并缓存在内存中。读、写请求都需要先通过master的内存视图定位到具体chunkserver，在向具体chunkserver进行真实数据交换。写chunkserver时，其一chunk replica所在chunkserver会被选为lease，这在某种程度上也是master权限的下放。\n\n## 问题讨论\n\n读paper很重要的一点是要把有问题的地方搞懂，因此提问题无疑是非常重要的。以下是搬运自[Charles的技术博客：GFS](http://oserror.com/distributed/gfs/)关于论文的一些问题：\n>7.1 为什么存储三个副本？而不是两个或者四个？\n>7.2 chunk的大小为何选择64MB？这个选择主要基于哪些考虑？\n>7.3 gfs主要支持追加，改写操作比较少，为什么这么设计？如何设计一个仅支持追加操作的文件系统来构建分布式表格系统bigtable？\n>7.4 为什么要将数据流和控制流分开？如果不分开，如何实现追加流程？\n>7.5 gfs有时会出现重复记录或者padding记录，为什么？\n>7.6 lease是什么？在gfs中起到了什么作用？它与心跳有何区别？\n>7.7 gfs追加过程中如果出现备副本故障，如何处理？如果出现主副本故障，应该如何处理？\n>7.8 gfs master需要存储哪些信息？master的数据结构如何设计？\n>7.9 假设服务一千万个文件，每个文件1GB，master中存储元数据大概占多少内存？\n>7.10 master如何实现高可用性？\n>7.11 负载的影响因素有哪些？如何计算一台机器的负载值？\n>7.12 master新建chunk时如何选择chunkserver？如果新机器上线，负载值特别低，如何避免其他chunkserver同时往这台机器上迁移chunk？\n>7.13 如果chunkserver下线后过一会重新上线，gfs如何处理？\n>7.14 如何实现分布式文件系统的快照操作？\n>7.15 chunkserver数据结构如何设计？\n>7.16 磁盘可能出现位翻转错误，chunkserver如何应对？\n>7.17 chunkserver重启后可能有一些过期的chunk，master如何能够发现？\n\n以下是我个人补充的一些问题：\n1. 为什么不用RAID？\n    - RAID不是commodity hardware，无法做到机器级别、机架级别的容灾；\n1. 写失败后chunk数据不一致GFS是如何处理的？\n    - application-level会检测数据中的checkpoint，来判断写入数据是否一致；\n    - 对于append新增的padding，application-level会识别并丢弃；\n    - 对于append被多次触发，application-level通过unique record id来幂等消费；\n1. data flow的pipeline的拓扑相较tree的拓扑有何好处？\n    - pipeline下一跳结点选择的原则是“网络最近”，这种拓扑能使得out带宽利用到极致，得到比tree拓扑更大的网络吞吐；\n1. 单master设计有什么好处？\n    - 不用维护多master的共识，使得master编程简单化，Kafka中Controller、Coordinator也是单master的设计；\n1. GFS为什么不对chunk文件做cache？\n    - chunk文件普遍比较大，client基本是以streaming的方式去读，重复读一个文件的概率不大，热点文件交给page cache缓存就够了；\n1. consistent but undefined是如何发生的？\n    - 在并发append时：GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data.\n    - 在并发write时：If a write by the application is large or straddles a chunk boundary, GFS client code breaks it down into multiple write operations.\n1. read、overwrite数据时检测出checksum错误会触发什么后续操作？\n    - client接收到error，从其他replica读；master对该chunk replica重新replicate，完成后通知corrupt的replica删除；\n1. master为什么不持久化chunk location？\n    - chunkserver拥有final wordview，对于硬盘故障等导致的chunk丢失能主动感知；chunkserver级别的事件非常多（leave、dead、rename等），这类事件都会导致location变化，若都触发落盘master的I/O可能存在瓶颈；\n1. master的operation log为什么需要checkpoint？\n    - 类似于Redis的aof机制，定期checkpoint可以减少append-only文件的大小便于故障时快速启动master；\n1. lease机制的作用是什么？\n    - 将master的部分权限下放到chunkserver，指定的chunk从chunkserver中挑选一台primary出来做一些核心工作（写指令的排序）；\n1. 创建chunk时，该chunk放置到哪台chunkserver有什么考虑因素？\n    - 磁盘使用较少，最近创建chunk较少，散步到不同的机架；\n1. chunkserver如何限制clone数据的带宽？\n    - 限制从源replica读数据的带宽；\n1. 为什么要使用垃圾回收清除文件？\n    - 假设master主动delete时chunkserver宕机，这无疑增加master的设计复杂度，且这种同步删除的动作也加重了master负载，垃圾回收清除可以认为是异步的；\n1. 如何识别stale的replica？\n    - 每次获取lease时，所有alive的replica的chunk version都会被master增加，落后的chunk version认为是stale的；\n1. data flow为什么不经过master结点？\n    - master是单点设计，要尽可能减小其负载；\n1. master为什么要定期扫描metadata？\n    - re-replication的考虑，找出哪些replica需要重新replicate；\n    - 垃圾回收的考虑，找出哪些file需要过期清除；\n\n## 参考文献\n\n[Google File System论文](https://research.google.com/archive/gfs-sosp2003.pdf)\n[Charles的技术博客：GFS](http://oserror.com/distributed/gfs/)\n[分布式系统笔记(3)-GFS](http://wulc.me/2019/01/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0(3)-GFS/)\n[从 GFS 失败的架构设计来看一致性的重要性](http://blog.itpub.net/31562044/viewspace-2646753/)\n[GFS: Evolution on Fast-forward](https://queue.acm.org/detail.cfm?id=1594206)（强烈推荐阅读这一篇，GFS早期开发者关于其演讲的对话）\n","slug":"google-file-system-paper","published":1,"updated":"2022-08-09T15:02:00.681Z","layout":"post","photos":[],"link":"","_id":"cl6mbc166006ligu81brvznhh","content":"<p>记录阅读论文Google File System(GFS)的笔记。</p>\n<a id=\"more\"></a>\n<h2 id=\"设计目标\"><a href=\"#设计目标\" class=\"headerlink\" title=\"设计目标\"></a>设计目标</h2><p>GFS的设计目标是：</p>\n<blockquote>\n<p>scalable filesystem：大文件、append写居多<br>running on commodity hardware：可容忍硬盘、机器、网络等故障<br>data intensive：数据密集</p>\n</blockquote>\n<p>GFS暴露的文件系统接口如下：</p>\n<ul>\n<li>创建/删除：create/delete</li>\n<li>读：read</li>\n<li>写：write/append/snapshot</li>\n</ul>\n<h2 id=\"从接口实现看系统架构\"><a href=\"#从接口实现看系统架构\" class=\"headerlink\" title=\"从接口实现看系统架构\"></a>从接口实现看系统架构</h2><h3 id=\"read\"><a href=\"#read\" class=\"headerlink\" title=\"read\"></a>read</h3><p>在GFS中，文件由1至多个chunk组成，每个chunk的大小是64MB，类似于下面的结构：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">文件名称：/boo/far（逻辑概念）</span><br><span class=\"line\">文件内容：[chunk_0, chunk_1, chunk_2]（物理概念）</span><br></pre></td></tr></table></figure></p>\n<p>论文提到chunk是Linux文件系统的真实文件，GFS中所指的分布式文件是由多个chunk组成的逻辑文件。</p>\n<blockquote>\n<p>Each chunk replica is stored as a plain Linux file on a chunkserver and is extended only as needed.</p>\n</blockquote>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/86358259-c3dcb780-bca1-11ea-99d0-f56c957a0571.png\" alt=\"image\"><br>（图1 GFS架构，摘自论文）</p>\n<p>GFS Client读取分布式文件内容如图1所示，</p>\n<ul>\n<li>client向master询问特定分布式文件的特定下标的chunk的信息；</li>\n<li>master在内存中维护<code>文件名 &lt;&gt; chunk下标数组</code>的映射，chunk下标数组的元素，存放了该chunk所在chunkserver的机器信息以及该chunk的唯一标识（chunk location）；<ul>\n<li>master在创建chunk时，会为其生成一个64bit的唯一标识，称之为chunk location；</li>\n<li>出于高可用、负载均衡等考虑，chunk会被replicate到多个chunkserver；</li>\n<li>master维护分布式文件目录信息、文件到chunk handle的映射、chunk handle到机器的映射，这些信息称为metadata；</li>\n</ul>\n</li>\n<li>client将master返回的信息缓存起来，挑选一个“网络距离最近”的chunkserver请求数据；<ul>\n<li>缓存chunk信息失效后，client会重新向master获取；</li>\n<li>client会批量读多个chunk的metadata，以减少和master的通信；</li>\n</ul>\n</li>\n<li>chunkserver接收到数据读取请求时，根据chunk handle定位到文件读取数据返回；<ul>\n<li>chunkserver发现chunk handle不存在时，client应失效对该chunk的metadata的缓存；</li>\n<li>chunkserver需要维护chunk handle到chunk文件的索引；</li>\n</ul>\n</li>\n</ul>\n<p>读取过程中，client先向master获取metadata，然后再向chunkserver发起真实数据读取请求。master是如何维护metadata的呢？</p>\n<ul>\n<li>文件名称到chunk信息的映射是维护在内存中的，在create/delete时更新此映射；</li>\n<li>chunk存放在哪些chunkserver是由chunkserver主动上报的，chunkserver天生知道它维护了哪些chunk文件，可以通过HeartBeat上报这类信息，当网络分区恢复或者chunkserver重启时它能让master第一时间感知chunk信息的变化。</li>\n</ul>\n<h3 id=\"write\"><a href=\"#write\" class=\"headerlink\" title=\"write\"></a>write</h3><p><img src=\"https://user-images.githubusercontent.com/4915189/86428940-9aaf3c00-bd20-11ea-8b36-5296662f6c90.png\" alt=\"image\"><br>（图2 client写数据的过程，摘自论文）</p>\n<ol>\n<li>client询问要写的chunk的primary replica以及secondary replica所在的chunkserver信息<ul>\n<li>持有lease的replica称为primary否则称为secondary，如果没有replica持有lease，master会挑选一个replica授予，chunkserver通过HeartBeat延长lease的失效时间；</li>\n</ul>\n</li>\n<li>client缓存master回复的信息直至expired或者chunkserver回复不持有lease；</li>\n<li>client以pipeline的方式将数据推送至所有replica，比如client-&gt;C1-&gt;C2-&gt;C3-&gt;C4，pipeline中下一跳的选择是网络距离最近的目标replica，每个replica一收到数据会立即向下一跳转发，数据此时是缓存在内存buffer的还未落盘；</li>\n<li>所有replica收完数据后，client通知primary replica将buffer的数据修改按照提交顺序串行落盘。每个数据修改有一个serial number，这个number是单调递增的用于代表落盘的顺序；</li>\n<li>primary落盘成功后，通知所有secondary以相同serial number的次序落盘；</li>\n<li>secondary回复primary落盘是否成功；</li>\n<li>primary回复client自身以及所有secondary是否落盘成功，任一replica的失败都会导致client重试步骤3到步骤7。</li>\n</ol>\n<p>append操作和write是相似的，不同点在于：</p>\n<ul>\n<li>步骤4，primary尝试append数据到末尾，假设append会导致chunk超过64Mb，primary会将当前chunk补齐到64Mb，同时告知所有secondary进行补齐，最后返回错误告知client应该在下一个chunk index去append数据。否则，primary写数据到chunk文件末尾，写成功后通知secondary在哪个chunk的哪个offset写数据，append操作在secondary变成了指定offset的write操作。</li>\n<li>步骤7，任一replica的失败同样会导致重试，这可能导致部分replica有多份需要append的数据，client需要实现幂等读取来容忍这种情况。</li>\n</ul>\n<h3 id=\"create\"><a href=\"#create\" class=\"headerlink\" title=\"create\"></a>create</h3><p>master通过新增chunk来扩充分布式文件，新增chunk的设计要点是：</p>\n<ul>\n<li>新增的chunk应该放在哪几台chunkserver？其原则是磁盘利用率最大化、机架容灾、负载均衡。3个replica至少应该分布到2个不同的机架，磁盘空间富余的chunkserver会优先选择，近期创建chunk较少的会优先选择（大量chunk同时创建在同一chunkserver意味着会立即带来较大的写负载）。</li>\n<li>新增的chunk文件可以认为是一个空文件，只有在真正写的时候才触发磁盘空间申请。</li>\n</ul>\n<h3 id=\"delete\"><a href=\"#delete\" class=\"headerlink\" title=\"delete\"></a>delete</h3><p>client发起delete，只是在master层面将分布式文件做重命名，例如将文件重命名增加一个<code>TRASH</code>的后缀。这些被标识TRASH的分布式文件有一个缓冲期，缓冲期仍可以像正常文件一样访问他们或者回滚，缓冲期后他们会被真正清除。chunkserver通过HeartBeat感知自身负责的chunk文件是否还有分布式文件与其关联，无关联的话chunkserver会将这些chunk文件真正清除。这种延迟删除的垃圾回收机制有以下好处：</p>\n<ul>\n<li>delete操作是可回滚的；</li>\n<li>对于delete请求，master只需要修改分布式文件名称即可返回，这无疑大大减轻master的负载；</li>\n<li>master扫描metadata并清除TRASH，chunkserver感知并清除chunk文件，这些流程都成为了常规的后台线程，这样一旦有失联的chunkserver重新加入集群，它们也能正确清除文件。</li>\n</ul>\n<h3 id=\"snapshot\"><a href=\"#snapshot\" class=\"headerlink\" title=\"snapshot\"></a>snapshot</h3><p>本质上是一种copy-on-write，master通过失效已授予的lease使得client写失败触发重新获取lease，这给了master去通知待写chunk所在的chunkserver去做chunk文件copy的机会，然后用新的copy文件来提供写。</p>\n<h2 id=\"CAP理论\"><a href=\"#CAP理论\" class=\"headerlink\" title=\"CAP理论\"></a>CAP理论</h2><p>下面尝试从CAP理论的视角来看GFS的设计。</p>\n<h3 id=\"consistency\"><a href=\"#consistency\" class=\"headerlink\" title=\"consistency\"></a>consistency</h3><p>对于master，任意涉及到文件namespace、文件到chunk映射修改的client操作都会写operation log、更新master的metadata内存，且同步到远端机器的operation log才算写成功，论文没有提及具体如何实现，应该也是某种二阶段提交。client写操作对metadata的修改是强一致的，完成后所有client都可以看到最新修改。</p>\n<p>master有一种shadow的角色，它的借助operation log重放metadata，会轻微落后于master。在master宕机时client可以从shadow读取metadata，它的metadata是弱一致的。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/86441384-b3c6e580-bd3e-11ea-806b-c5ccf9c56723.png\" alt=\"image\"><br>（图3 chunk的一致性模型，摘自论文）</p>\n<p>GFS对于chunk的一致性有两种定义：</p>\n<ul>\n<li>consitent：客户端永远能看到一致的数据，无论他们从哪个replica读取数据；</li>\n<li>defined：当某个chunk发生修改后，client能看到刚刚修改的所有数据。</li>\n</ul>\n<p>图3是GFS在几种写下的一致性保证：</p>\n<ul>\n<li>串行写：defined</li>\n<li>并发写：consistent + undefined（client端无法确认最终到底是哪个写导致的数据变化）</li>\n<li>追加写：defined but interspersed with inconsistent（append写只保证at least one，可能append了多次数据，且有的replica会有padding数据）</li>\n<li>写失败：inconsistent</li>\n</ul>\n<p>每个chunk文件在被修改时其chunk version都会自增，写操作会识别出那些chunk version落后的chunk并跳过写，这些落后的chunk会在垃圾回收过程被回收。每个64Mb的chunk文件的每个64Kb数据block，都会记录一个checksum（持久化到专门的logging文件），读取数据时需校验checksum是否正确来判断数据是否损坏。</p>\n<p>master对于分布式文件的新增、删除是强一致性的。GFS在master有一个文件锁的设计，对文件加写锁可以防止并发创建同名的分布式文件，对目录加写锁可以防止目录下的文件新增和删除。</p>\n<h3 id=\"availability\"><a href=\"#availability\" class=\"headerlink\" title=\"availability\"></a>availability</h3><p>GFS的设计中master是单点的，当监控系统监测到master故障，会从远端存放operation log的机器挑选一台快速启动顶替。故障转移的过程中，master是不可用的，任何依赖master的服务在故障转移过程也是不可用的。master和chunkserver都被设计成可以快速启动的。以master为例，它启动时读取最近一次checkpoint文件（B-Tree格式）和最近一次checkpoint时间点之后的增量operation log文件实现快速启动。</p>\n<p>写chunkserver的过程中，如果secondary失败则触发重试，若primary失败则该写操作会被failed掉，由客户端决定是否要重试写。</p>\n<h3 id=\"partition-tolerance\"><a href=\"#partition-tolerance\" class=\"headerlink\" title=\"partition tolerance\"></a>partition tolerance</h3><p>GFS的chunk默认有3个replica，其replicate数量是可调整的。写操作需要所有replica写成功才返回，这对读是有好处的，只需要读任意一份replica即可获取最新数据。当某些replica所在chunkserver宕机、磁盘故障时，GFS会触发re-replication，使得replica数量重归3份。GFS还会进行rebalancing，将replica从磁盘紧张的chunkserver迁移到磁盘富余的chunkserver。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>GFS是单master多chunkserver的设计，master通过HeartBeat感知chunkserver的数据视图并缓存在内存中。读、写请求都需要先通过master的内存视图定位到具体chunkserver，在向具体chunkserver进行真实数据交换。写chunkserver时，其一chunk replica所在chunkserver会被选为lease，这在某种程度上也是master权限的下放。</p>\n<h2 id=\"问题讨论\"><a href=\"#问题讨论\" class=\"headerlink\" title=\"问题讨论\"></a>问题讨论</h2><p>读paper很重要的一点是要把有问题的地方搞懂，因此提问题无疑是非常重要的。以下是搬运自<a href=\"http://oserror.com/distributed/gfs/\" target=\"_blank\" rel=\"noopener\">Charles的技术博客：GFS</a>关于论文的一些问题：</p>\n<blockquote>\n<p>7.1 为什么存储三个副本？而不是两个或者四个？<br>7.2 chunk的大小为何选择64MB？这个选择主要基于哪些考虑？<br>7.3 gfs主要支持追加，改写操作比较少，为什么这么设计？如何设计一个仅支持追加操作的文件系统来构建分布式表格系统bigtable？<br>7.4 为什么要将数据流和控制流分开？如果不分开，如何实现追加流程？<br>7.5 gfs有时会出现重复记录或者padding记录，为什么？<br>7.6 lease是什么？在gfs中起到了什么作用？它与心跳有何区别？<br>7.7 gfs追加过程中如果出现备副本故障，如何处理？如果出现主副本故障，应该如何处理？<br>7.8 gfs master需要存储哪些信息？master的数据结构如何设计？<br>7.9 假设服务一千万个文件，每个文件1GB，master中存储元数据大概占多少内存？<br>7.10 master如何实现高可用性？<br>7.11 负载的影响因素有哪些？如何计算一台机器的负载值？<br>7.12 master新建chunk时如何选择chunkserver？如果新机器上线，负载值特别低，如何避免其他chunkserver同时往这台机器上迁移chunk？<br>7.13 如果chunkserver下线后过一会重新上线，gfs如何处理？<br>7.14 如何实现分布式文件系统的快照操作？<br>7.15 chunkserver数据结构如何设计？<br>7.16 磁盘可能出现位翻转错误，chunkserver如何应对？<br>7.17 chunkserver重启后可能有一些过期的chunk，master如何能够发现？</p>\n</blockquote>\n<p>以下是我个人补充的一些问题：</p>\n<ol>\n<li>为什么不用RAID？<ul>\n<li>RAID不是commodity hardware，无法做到机器级别、机架级别的容灾；</li>\n</ul>\n</li>\n<li>写失败后chunk数据不一致GFS是如何处理的？<ul>\n<li>application-level会检测数据中的checkpoint，来判断写入数据是否一致；</li>\n<li>对于append新增的padding，application-level会识别并丢弃；</li>\n<li>对于append被多次触发，application-level通过unique record id来幂等消费；</li>\n</ul>\n</li>\n<li>data flow的pipeline的拓扑相较tree的拓扑有何好处？<ul>\n<li>pipeline下一跳结点选择的原则是“网络最近”，这种拓扑能使得out带宽利用到极致，得到比tree拓扑更大的网络吞吐；</li>\n</ul>\n</li>\n<li>单master设计有什么好处？<ul>\n<li>不用维护多master的共识，使得master编程简单化，Kafka中Controller、Coordinator也是单master的设计；</li>\n</ul>\n</li>\n<li>GFS为什么不对chunk文件做cache？<ul>\n<li>chunk文件普遍比较大，client基本是以streaming的方式去读，重复读一个文件的概率不大，热点文件交给page cache缓存就够了；</li>\n</ul>\n</li>\n<li>consistent but undefined是如何发生的？<ul>\n<li>在并发append时：GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data.</li>\n<li>在并发write时：If a write by the application is large or straddles a chunk boundary, GFS client code breaks it down into multiple write operations.</li>\n</ul>\n</li>\n<li>read、overwrite数据时检测出checksum错误会触发什么后续操作？<ul>\n<li>client接收到error，从其他replica读；master对该chunk replica重新replicate，完成后通知corrupt的replica删除；</li>\n</ul>\n</li>\n<li>master为什么不持久化chunk location？<ul>\n<li>chunkserver拥有final wordview，对于硬盘故障等导致的chunk丢失能主动感知；chunkserver级别的事件非常多（leave、dead、rename等），这类事件都会导致location变化，若都触发落盘master的I/O可能存在瓶颈；</li>\n</ul>\n</li>\n<li>master的operation log为什么需要checkpoint？<ul>\n<li>类似于Redis的aof机制，定期checkpoint可以减少append-only文件的大小便于故障时快速启动master；</li>\n</ul>\n</li>\n<li>lease机制的作用是什么？<ul>\n<li>将master的部分权限下放到chunkserver，指定的chunk从chunkserver中挑选一台primary出来做一些核心工作（写指令的排序）；</li>\n</ul>\n</li>\n<li>创建chunk时，该chunk放置到哪台chunkserver有什么考虑因素？<ul>\n<li>磁盘使用较少，最近创建chunk较少，散步到不同的机架；</li>\n</ul>\n</li>\n<li>chunkserver如何限制clone数据的带宽？<ul>\n<li>限制从源replica读数据的带宽；</li>\n</ul>\n</li>\n<li>为什么要使用垃圾回收清除文件？<ul>\n<li>假设master主动delete时chunkserver宕机，这无疑增加master的设计复杂度，且这种同步删除的动作也加重了master负载，垃圾回收清除可以认为是异步的；</li>\n</ul>\n</li>\n<li>如何识别stale的replica？<ul>\n<li>每次获取lease时，所有alive的replica的chunk version都会被master增加，落后的chunk version认为是stale的；</li>\n</ul>\n</li>\n<li>data flow为什么不经过master结点？<ul>\n<li>master是单点设计，要尽可能减小其负载；</li>\n</ul>\n</li>\n<li>master为什么要定期扫描metadata？<ul>\n<li>re-replication的考虑，找出哪些replica需要重新replicate；</li>\n<li>垃圾回收的考虑，找出哪些file需要过期清除；</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p><a href=\"https://research.google.com/archive/gfs-sosp2003.pdf\" target=\"_blank\" rel=\"noopener\">Google File System论文</a><br><a href=\"http://oserror.com/distributed/gfs/\" target=\"_blank\" rel=\"noopener\">Charles的技术博客：GFS</a><br><a href=\"http://wulc.me/2019/01/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0(3\" target=\"_blank\" rel=\"noopener\">分布式系统笔记(3)-GFS</a>-GFS/)<br><a href=\"http://blog.itpub.net/31562044/viewspace-2646753/\" target=\"_blank\" rel=\"noopener\">从 GFS 失败的架构设计来看一致性的重要性</a><br><a href=\"https://queue.acm.org/detail.cfm?id=1594206\" target=\"_blank\" rel=\"noopener\">GFS: Evolution on Fast-forward</a>（强烈推荐阅读这一篇，GFS早期开发者关于其演讲的对话）</p>\n","site":{"data":{}},"excerpt":"<p>记录阅读论文Google File System(GFS)的笔记。</p>","more":"<h2 id=\"设计目标\"><a href=\"#设计目标\" class=\"headerlink\" title=\"设计目标\"></a>设计目标</h2><p>GFS的设计目标是：</p>\n<blockquote>\n<p>scalable filesystem：大文件、append写居多<br>running on commodity hardware：可容忍硬盘、机器、网络等故障<br>data intensive：数据密集</p>\n</blockquote>\n<p>GFS暴露的文件系统接口如下：</p>\n<ul>\n<li>创建/删除：create/delete</li>\n<li>读：read</li>\n<li>写：write/append/snapshot</li>\n</ul>\n<h2 id=\"从接口实现看系统架构\"><a href=\"#从接口实现看系统架构\" class=\"headerlink\" title=\"从接口实现看系统架构\"></a>从接口实现看系统架构</h2><h3 id=\"read\"><a href=\"#read\" class=\"headerlink\" title=\"read\"></a>read</h3><p>在GFS中，文件由1至多个chunk组成，每个chunk的大小是64MB，类似于下面的结构：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">文件名称：/boo/far（逻辑概念）</span><br><span class=\"line\">文件内容：[chunk_0, chunk_1, chunk_2]（物理概念）</span><br></pre></td></tr></table></figure></p>\n<p>论文提到chunk是Linux文件系统的真实文件，GFS中所指的分布式文件是由多个chunk组成的逻辑文件。</p>\n<blockquote>\n<p>Each chunk replica is stored as a plain Linux file on a chunkserver and is extended only as needed.</p>\n</blockquote>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/86358259-c3dcb780-bca1-11ea-99d0-f56c957a0571.png\" alt=\"image\"><br>（图1 GFS架构，摘自论文）</p>\n<p>GFS Client读取分布式文件内容如图1所示，</p>\n<ul>\n<li>client向master询问特定分布式文件的特定下标的chunk的信息；</li>\n<li>master在内存中维护<code>文件名 &lt;&gt; chunk下标数组</code>的映射，chunk下标数组的元素，存放了该chunk所在chunkserver的机器信息以及该chunk的唯一标识（chunk location）；<ul>\n<li>master在创建chunk时，会为其生成一个64bit的唯一标识，称之为chunk location；</li>\n<li>出于高可用、负载均衡等考虑，chunk会被replicate到多个chunkserver；</li>\n<li>master维护分布式文件目录信息、文件到chunk handle的映射、chunk handle到机器的映射，这些信息称为metadata；</li>\n</ul>\n</li>\n<li>client将master返回的信息缓存起来，挑选一个“网络距离最近”的chunkserver请求数据；<ul>\n<li>缓存chunk信息失效后，client会重新向master获取；</li>\n<li>client会批量读多个chunk的metadata，以减少和master的通信；</li>\n</ul>\n</li>\n<li>chunkserver接收到数据读取请求时，根据chunk handle定位到文件读取数据返回；<ul>\n<li>chunkserver发现chunk handle不存在时，client应失效对该chunk的metadata的缓存；</li>\n<li>chunkserver需要维护chunk handle到chunk文件的索引；</li>\n</ul>\n</li>\n</ul>\n<p>读取过程中，client先向master获取metadata，然后再向chunkserver发起真实数据读取请求。master是如何维护metadata的呢？</p>\n<ul>\n<li>文件名称到chunk信息的映射是维护在内存中的，在create/delete时更新此映射；</li>\n<li>chunk存放在哪些chunkserver是由chunkserver主动上报的，chunkserver天生知道它维护了哪些chunk文件，可以通过HeartBeat上报这类信息，当网络分区恢复或者chunkserver重启时它能让master第一时间感知chunk信息的变化。</li>\n</ul>\n<h3 id=\"write\"><a href=\"#write\" class=\"headerlink\" title=\"write\"></a>write</h3><p><img src=\"https://user-images.githubusercontent.com/4915189/86428940-9aaf3c00-bd20-11ea-8b36-5296662f6c90.png\" alt=\"image\"><br>（图2 client写数据的过程，摘自论文）</p>\n<ol>\n<li>client询问要写的chunk的primary replica以及secondary replica所在的chunkserver信息<ul>\n<li>持有lease的replica称为primary否则称为secondary，如果没有replica持有lease，master会挑选一个replica授予，chunkserver通过HeartBeat延长lease的失效时间；</li>\n</ul>\n</li>\n<li>client缓存master回复的信息直至expired或者chunkserver回复不持有lease；</li>\n<li>client以pipeline的方式将数据推送至所有replica，比如client-&gt;C1-&gt;C2-&gt;C3-&gt;C4，pipeline中下一跳的选择是网络距离最近的目标replica，每个replica一收到数据会立即向下一跳转发，数据此时是缓存在内存buffer的还未落盘；</li>\n<li>所有replica收完数据后，client通知primary replica将buffer的数据修改按照提交顺序串行落盘。每个数据修改有一个serial number，这个number是单调递增的用于代表落盘的顺序；</li>\n<li>primary落盘成功后，通知所有secondary以相同serial number的次序落盘；</li>\n<li>secondary回复primary落盘是否成功；</li>\n<li>primary回复client自身以及所有secondary是否落盘成功，任一replica的失败都会导致client重试步骤3到步骤7。</li>\n</ol>\n<p>append操作和write是相似的，不同点在于：</p>\n<ul>\n<li>步骤4，primary尝试append数据到末尾，假设append会导致chunk超过64Mb，primary会将当前chunk补齐到64Mb，同时告知所有secondary进行补齐，最后返回错误告知client应该在下一个chunk index去append数据。否则，primary写数据到chunk文件末尾，写成功后通知secondary在哪个chunk的哪个offset写数据，append操作在secondary变成了指定offset的write操作。</li>\n<li>步骤7，任一replica的失败同样会导致重试，这可能导致部分replica有多份需要append的数据，client需要实现幂等读取来容忍这种情况。</li>\n</ul>\n<h3 id=\"create\"><a href=\"#create\" class=\"headerlink\" title=\"create\"></a>create</h3><p>master通过新增chunk来扩充分布式文件，新增chunk的设计要点是：</p>\n<ul>\n<li>新增的chunk应该放在哪几台chunkserver？其原则是磁盘利用率最大化、机架容灾、负载均衡。3个replica至少应该分布到2个不同的机架，磁盘空间富余的chunkserver会优先选择，近期创建chunk较少的会优先选择（大量chunk同时创建在同一chunkserver意味着会立即带来较大的写负载）。</li>\n<li>新增的chunk文件可以认为是一个空文件，只有在真正写的时候才触发磁盘空间申请。</li>\n</ul>\n<h3 id=\"delete\"><a href=\"#delete\" class=\"headerlink\" title=\"delete\"></a>delete</h3><p>client发起delete，只是在master层面将分布式文件做重命名，例如将文件重命名增加一个<code>TRASH</code>的后缀。这些被标识TRASH的分布式文件有一个缓冲期，缓冲期仍可以像正常文件一样访问他们或者回滚，缓冲期后他们会被真正清除。chunkserver通过HeartBeat感知自身负责的chunk文件是否还有分布式文件与其关联，无关联的话chunkserver会将这些chunk文件真正清除。这种延迟删除的垃圾回收机制有以下好处：</p>\n<ul>\n<li>delete操作是可回滚的；</li>\n<li>对于delete请求，master只需要修改分布式文件名称即可返回，这无疑大大减轻master的负载；</li>\n<li>master扫描metadata并清除TRASH，chunkserver感知并清除chunk文件，这些流程都成为了常规的后台线程，这样一旦有失联的chunkserver重新加入集群，它们也能正确清除文件。</li>\n</ul>\n<h3 id=\"snapshot\"><a href=\"#snapshot\" class=\"headerlink\" title=\"snapshot\"></a>snapshot</h3><p>本质上是一种copy-on-write，master通过失效已授予的lease使得client写失败触发重新获取lease，这给了master去通知待写chunk所在的chunkserver去做chunk文件copy的机会，然后用新的copy文件来提供写。</p>\n<h2 id=\"CAP理论\"><a href=\"#CAP理论\" class=\"headerlink\" title=\"CAP理论\"></a>CAP理论</h2><p>下面尝试从CAP理论的视角来看GFS的设计。</p>\n<h3 id=\"consistency\"><a href=\"#consistency\" class=\"headerlink\" title=\"consistency\"></a>consistency</h3><p>对于master，任意涉及到文件namespace、文件到chunk映射修改的client操作都会写operation log、更新master的metadata内存，且同步到远端机器的operation log才算写成功，论文没有提及具体如何实现，应该也是某种二阶段提交。client写操作对metadata的修改是强一致的，完成后所有client都可以看到最新修改。</p>\n<p>master有一种shadow的角色，它的借助operation log重放metadata，会轻微落后于master。在master宕机时client可以从shadow读取metadata，它的metadata是弱一致的。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/86441384-b3c6e580-bd3e-11ea-806b-c5ccf9c56723.png\" alt=\"image\"><br>（图3 chunk的一致性模型，摘自论文）</p>\n<p>GFS对于chunk的一致性有两种定义：</p>\n<ul>\n<li>consitent：客户端永远能看到一致的数据，无论他们从哪个replica读取数据；</li>\n<li>defined：当某个chunk发生修改后，client能看到刚刚修改的所有数据。</li>\n</ul>\n<p>图3是GFS在几种写下的一致性保证：</p>\n<ul>\n<li>串行写：defined</li>\n<li>并发写：consistent + undefined（client端无法确认最终到底是哪个写导致的数据变化）</li>\n<li>追加写：defined but interspersed with inconsistent（append写只保证at least one，可能append了多次数据，且有的replica会有padding数据）</li>\n<li>写失败：inconsistent</li>\n</ul>\n<p>每个chunk文件在被修改时其chunk version都会自增，写操作会识别出那些chunk version落后的chunk并跳过写，这些落后的chunk会在垃圾回收过程被回收。每个64Mb的chunk文件的每个64Kb数据block，都会记录一个checksum（持久化到专门的logging文件），读取数据时需校验checksum是否正确来判断数据是否损坏。</p>\n<p>master对于分布式文件的新增、删除是强一致性的。GFS在master有一个文件锁的设计，对文件加写锁可以防止并发创建同名的分布式文件，对目录加写锁可以防止目录下的文件新增和删除。</p>\n<h3 id=\"availability\"><a href=\"#availability\" class=\"headerlink\" title=\"availability\"></a>availability</h3><p>GFS的设计中master是单点的，当监控系统监测到master故障，会从远端存放operation log的机器挑选一台快速启动顶替。故障转移的过程中，master是不可用的，任何依赖master的服务在故障转移过程也是不可用的。master和chunkserver都被设计成可以快速启动的。以master为例，它启动时读取最近一次checkpoint文件（B-Tree格式）和最近一次checkpoint时间点之后的增量operation log文件实现快速启动。</p>\n<p>写chunkserver的过程中，如果secondary失败则触发重试，若primary失败则该写操作会被failed掉，由客户端决定是否要重试写。</p>\n<h3 id=\"partition-tolerance\"><a href=\"#partition-tolerance\" class=\"headerlink\" title=\"partition tolerance\"></a>partition tolerance</h3><p>GFS的chunk默认有3个replica，其replicate数量是可调整的。写操作需要所有replica写成功才返回，这对读是有好处的，只需要读任意一份replica即可获取最新数据。当某些replica所在chunkserver宕机、磁盘故障时，GFS会触发re-replication，使得replica数量重归3份。GFS还会进行rebalancing，将replica从磁盘紧张的chunkserver迁移到磁盘富余的chunkserver。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>GFS是单master多chunkserver的设计，master通过HeartBeat感知chunkserver的数据视图并缓存在内存中。读、写请求都需要先通过master的内存视图定位到具体chunkserver，在向具体chunkserver进行真实数据交换。写chunkserver时，其一chunk replica所在chunkserver会被选为lease，这在某种程度上也是master权限的下放。</p>\n<h2 id=\"问题讨论\"><a href=\"#问题讨论\" class=\"headerlink\" title=\"问题讨论\"></a>问题讨论</h2><p>读paper很重要的一点是要把有问题的地方搞懂，因此提问题无疑是非常重要的。以下是搬运自<a href=\"http://oserror.com/distributed/gfs/\" target=\"_blank\" rel=\"noopener\">Charles的技术博客：GFS</a>关于论文的一些问题：</p>\n<blockquote>\n<p>7.1 为什么存储三个副本？而不是两个或者四个？<br>7.2 chunk的大小为何选择64MB？这个选择主要基于哪些考虑？<br>7.3 gfs主要支持追加，改写操作比较少，为什么这么设计？如何设计一个仅支持追加操作的文件系统来构建分布式表格系统bigtable？<br>7.4 为什么要将数据流和控制流分开？如果不分开，如何实现追加流程？<br>7.5 gfs有时会出现重复记录或者padding记录，为什么？<br>7.6 lease是什么？在gfs中起到了什么作用？它与心跳有何区别？<br>7.7 gfs追加过程中如果出现备副本故障，如何处理？如果出现主副本故障，应该如何处理？<br>7.8 gfs master需要存储哪些信息？master的数据结构如何设计？<br>7.9 假设服务一千万个文件，每个文件1GB，master中存储元数据大概占多少内存？<br>7.10 master如何实现高可用性？<br>7.11 负载的影响因素有哪些？如何计算一台机器的负载值？<br>7.12 master新建chunk时如何选择chunkserver？如果新机器上线，负载值特别低，如何避免其他chunkserver同时往这台机器上迁移chunk？<br>7.13 如果chunkserver下线后过一会重新上线，gfs如何处理？<br>7.14 如何实现分布式文件系统的快照操作？<br>7.15 chunkserver数据结构如何设计？<br>7.16 磁盘可能出现位翻转错误，chunkserver如何应对？<br>7.17 chunkserver重启后可能有一些过期的chunk，master如何能够发现？</p>\n</blockquote>\n<p>以下是我个人补充的一些问题：</p>\n<ol>\n<li>为什么不用RAID？<ul>\n<li>RAID不是commodity hardware，无法做到机器级别、机架级别的容灾；</li>\n</ul>\n</li>\n<li>写失败后chunk数据不一致GFS是如何处理的？<ul>\n<li>application-level会检测数据中的checkpoint，来判断写入数据是否一致；</li>\n<li>对于append新增的padding，application-level会识别并丢弃；</li>\n<li>对于append被多次触发，application-level通过unique record id来幂等消费；</li>\n</ul>\n</li>\n<li>data flow的pipeline的拓扑相较tree的拓扑有何好处？<ul>\n<li>pipeline下一跳结点选择的原则是“网络最近”，这种拓扑能使得out带宽利用到极致，得到比tree拓扑更大的网络吞吐；</li>\n</ul>\n</li>\n<li>单master设计有什么好处？<ul>\n<li>不用维护多master的共识，使得master编程简单化，Kafka中Controller、Coordinator也是单master的设计；</li>\n</ul>\n</li>\n<li>GFS为什么不对chunk文件做cache？<ul>\n<li>chunk文件普遍比较大，client基本是以streaming的方式去读，重复读一个文件的概率不大，热点文件交给page cache缓存就够了；</li>\n</ul>\n</li>\n<li>consistent but undefined是如何发生的？<ul>\n<li>在并发append时：GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data.</li>\n<li>在并发write时：If a write by the application is large or straddles a chunk boundary, GFS client code breaks it down into multiple write operations.</li>\n</ul>\n</li>\n<li>read、overwrite数据时检测出checksum错误会触发什么后续操作？<ul>\n<li>client接收到error，从其他replica读；master对该chunk replica重新replicate，完成后通知corrupt的replica删除；</li>\n</ul>\n</li>\n<li>master为什么不持久化chunk location？<ul>\n<li>chunkserver拥有final wordview，对于硬盘故障等导致的chunk丢失能主动感知；chunkserver级别的事件非常多（leave、dead、rename等），这类事件都会导致location变化，若都触发落盘master的I/O可能存在瓶颈；</li>\n</ul>\n</li>\n<li>master的operation log为什么需要checkpoint？<ul>\n<li>类似于Redis的aof机制，定期checkpoint可以减少append-only文件的大小便于故障时快速启动master；</li>\n</ul>\n</li>\n<li>lease机制的作用是什么？<ul>\n<li>将master的部分权限下放到chunkserver，指定的chunk从chunkserver中挑选一台primary出来做一些核心工作（写指令的排序）；</li>\n</ul>\n</li>\n<li>创建chunk时，该chunk放置到哪台chunkserver有什么考虑因素？<ul>\n<li>磁盘使用较少，最近创建chunk较少，散步到不同的机架；</li>\n</ul>\n</li>\n<li>chunkserver如何限制clone数据的带宽？<ul>\n<li>限制从源replica读数据的带宽；</li>\n</ul>\n</li>\n<li>为什么要使用垃圾回收清除文件？<ul>\n<li>假设master主动delete时chunkserver宕机，这无疑增加master的设计复杂度，且这种同步删除的动作也加重了master负载，垃圾回收清除可以认为是异步的；</li>\n</ul>\n</li>\n<li>如何识别stale的replica？<ul>\n<li>每次获取lease时，所有alive的replica的chunk version都会被master增加，落后的chunk version认为是stale的；</li>\n</ul>\n</li>\n<li>data flow为什么不经过master结点？<ul>\n<li>master是单点设计，要尽可能减小其负载；</li>\n</ul>\n</li>\n<li>master为什么要定期扫描metadata？<ul>\n<li>re-replication的考虑，找出哪些replica需要重新replicate；</li>\n<li>垃圾回收的考虑，找出哪些file需要过期清除；</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p><a href=\"https://research.google.com/archive/gfs-sosp2003.pdf\" target=\"_blank\" rel=\"noopener\">Google File System论文</a><br><a href=\"http://oserror.com/distributed/gfs/\" target=\"_blank\" rel=\"noopener\">Charles的技术博客：GFS</a><br><a href=\"http://wulc.me/2019/01/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0(3\" target=\"_blank\" rel=\"noopener\">分布式系统笔记(3)-GFS</a>-GFS/)<br><a href=\"http://blog.itpub.net/31562044/viewspace-2646753/\" target=\"_blank\" rel=\"noopener\">从 GFS 失败的架构设计来看一致性的重要性</a><br><a href=\"https://queue.acm.org/detail.cfm?id=1594206\" target=\"_blank\" rel=\"noopener\">GFS: Evolution on Fast-forward</a>（强烈推荐阅读这一篇，GFS早期开发者关于其演讲的对话）</p>"},{"title":"谈谈MQ | 与Page Cache的爱恨情仇","date":"2020-10-09T06:32:25.000Z","comments":1,"_content":"\nKafka和RocketMQ有很多围绕Page Cache的设计，本文带你一探究竟。\n\n<!--more-->\n\n论文[Paper阅读：Kafka: a Distributed Messaging System for Log Processing](https://zhangjunjia.github.io/2020/06/04/kafka-paper/)提到，Kafka Broker若通过`read`调用提供数据给Consumer需要经历以下4个步骤：\n- (1) read data from the storage media to the page cache in an OS\n- (2) copy data in the page cache to an application buffer\n- (3) copy application buffer to another kernel buffer\n- (4) send the kernel buffer to the socket\n\nKafka通过`sendfile`调用规避了步骤(2)和(3)，如果要读的数据也在Cache中，则步骤(1)也是不需要的，这就是Kafka高吞吐量的秘密之一。文章[Efficient data transfer through zero copy](https://developer.ibm.com/articles/j-zerocopy/)详细阐述了`read`和`tranferTo`的差别，概括来讲就是避免了user-space和kernel-space的内存拷贝以及减少user到kernel的来回切换。\n\n![image](https://user-images.githubusercontent.com/4915189/93546442-5a617080-f995-11ea-8adc-80fa8e19e47d.png)\n\n（图1 引用自[Efficient data transfer through zero copy](https://developer.ibm.com/articles/j-zerocopy/)）\n\n在partition较少的情况下，这种模型性能非常优异。Producer写完Page Cache就返回了（底层是`pwrite`系统调用），由Kafka配置的刷盘间隔时间/条数调用`flush`刷盘，Consumer在和Producer的lag不大的前提下也是从Page Cache可以直接取到数据返回，图2虚线框表明了这种情况。\n\n![image](https://user-images.githubusercontent.com/4915189/94356704-d78e9300-00c3-11eb-94bb-b22a14bc3174.png)\n\n（图2 一个partition文件 vs N个partition文件）\n\n但如果一个Broker上有1W甚至是10W级别的partition文件在同时写(producer)和读(consumer)呢？这会带来什么问题？\n- 写时，N个文件各自虽然是在顺序写，但在`flush`刷盘时站在OS的视角变成了随机写（如图2）\n- 进一步的，随着文件增多，`flush`的随机IO对写的吞吐量影响越来越大（寻址时间、磁头移动时间）\n\n针对此问题，RocketMQ从存储模型上做了优化。单Broker支撑大量级的partition（在RocketMQ中称为Queue）时，写依然能做到顺序IO，如下图3所示。\n\n![image](https://user-images.githubusercontent.com/4915189/94389931-c5742980-0183-11eb-9ce2-eef5fb355baa.png)\n（图3 引用自[RocketMQ存储实现分析](http://www.daleizhou.tech/posts/rocketmq-store-commitlog.html)）\n\nKafka在单Broker上，会同时打开N个文件用于消息的生产，N的数量是该Broker上partition的数量。RocketMQ在单Broker上，只会打开一个MappedFile文件，所有queue（等同于Kafka的partition）的消息生产顺序追加到这个文件中，该文件的大小固定为1G。RocketMQ在新建MappedFile时，会做一个预热操作，其关键代码如下：\n```java\npublic void warmMappedFile(FlushDiskType type, int pages) {\n    // ...\n    for (int i = 0, j = 0; i < this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) {\n        byteBuffer.put(i, (byte) 0);\n        // ...\n    }\n    // ...\n    this.mlock();\n}\n```\n\n预热过程做了以下事情：\n- 将1G的MappedFile通过mmap映射到虚拟内存地址空间；\n- 通过`byteBuffer.put(i, (byte) 0)`触发[Demand Paging](https://en.wikipedia.org/wiki/Demand_paging)，将文件的内容真实映射到Page Cache；\n- 使用mlock锁定该文件的Page Cache，防止被OS置换到swap空间；\n\n预热提前占用Page Cache，相比Kafka的`pwrite`按需占用Page Cache的好处是：\n- 节省user和kernel来回切回的时间，mmap后读写只需要内存寻址；\n- 节省disk映射到Page Cache的时间，预热后disk的block和page cache已经形成对应关系，消息生产时一定能命中，不需要有磁盘IO（mlock进一步保证了”一定能命中cache“）；\n\n由于只有一个MappedFile文件提供写，因此Kafka单Broker在大量级partition写时随机IO的问题得到了解决。但这带来了另外一个问题，消费者消息时如何从MappedFile定位到其需要的消息，不可能去做全文件扫描吧？\n\nMappedFile用于存储真实消息Record，RocketMQ维护了另外一个数据结构ConsumerQueue来索引真实的消息。单个ConsumerQueue文件存储30W条到MappedFile文件的消息Record的索引，便于消费者定位真实消息。但这不岂不是带来了新的问题，数据读取需要二次IO，最坏的情况下读MappedFile还会带来随机IO？\n- 最近一个MappedFile和ConsumerQueue，都是mmap映射在Page Cache中的，只要消费者和生产者的lag不大，很大概率能从Page Cache读到需要的消息；\n- 如果消费者的lag太大，RocketMQ建议从slave读取数据（具体细节待展开），有效规避了lag落后太大的消费者污染Page Cache的问题。\n\n参考文献：https://www.jianshu.com/p/771cce379994\n","source":"_posts/2020-10-09-mq-page-cache.md","raw":"---\ntitle: 谈谈MQ | 与Page Cache的爱恨情仇\ndate: 2020-10-09 14:32:25\ntags: ['Kafka', 'Paper阅读']\ncomments: true\ncategories: ['分布式系统']\n---\n\nKafka和RocketMQ有很多围绕Page Cache的设计，本文带你一探究竟。\n\n<!--more-->\n\n论文[Paper阅读：Kafka: a Distributed Messaging System for Log Processing](https://zhangjunjia.github.io/2020/06/04/kafka-paper/)提到，Kafka Broker若通过`read`调用提供数据给Consumer需要经历以下4个步骤：\n- (1) read data from the storage media to the page cache in an OS\n- (2) copy data in the page cache to an application buffer\n- (3) copy application buffer to another kernel buffer\n- (4) send the kernel buffer to the socket\n\nKafka通过`sendfile`调用规避了步骤(2)和(3)，如果要读的数据也在Cache中，则步骤(1)也是不需要的，这就是Kafka高吞吐量的秘密之一。文章[Efficient data transfer through zero copy](https://developer.ibm.com/articles/j-zerocopy/)详细阐述了`read`和`tranferTo`的差别，概括来讲就是避免了user-space和kernel-space的内存拷贝以及减少user到kernel的来回切换。\n\n![image](https://user-images.githubusercontent.com/4915189/93546442-5a617080-f995-11ea-8adc-80fa8e19e47d.png)\n\n（图1 引用自[Efficient data transfer through zero copy](https://developer.ibm.com/articles/j-zerocopy/)）\n\n在partition较少的情况下，这种模型性能非常优异。Producer写完Page Cache就返回了（底层是`pwrite`系统调用），由Kafka配置的刷盘间隔时间/条数调用`flush`刷盘，Consumer在和Producer的lag不大的前提下也是从Page Cache可以直接取到数据返回，图2虚线框表明了这种情况。\n\n![image](https://user-images.githubusercontent.com/4915189/94356704-d78e9300-00c3-11eb-94bb-b22a14bc3174.png)\n\n（图2 一个partition文件 vs N个partition文件）\n\n但如果一个Broker上有1W甚至是10W级别的partition文件在同时写(producer)和读(consumer)呢？这会带来什么问题？\n- 写时，N个文件各自虽然是在顺序写，但在`flush`刷盘时站在OS的视角变成了随机写（如图2）\n- 进一步的，随着文件增多，`flush`的随机IO对写的吞吐量影响越来越大（寻址时间、磁头移动时间）\n\n针对此问题，RocketMQ从存储模型上做了优化。单Broker支撑大量级的partition（在RocketMQ中称为Queue）时，写依然能做到顺序IO，如下图3所示。\n\n![image](https://user-images.githubusercontent.com/4915189/94389931-c5742980-0183-11eb-9ce2-eef5fb355baa.png)\n（图3 引用自[RocketMQ存储实现分析](http://www.daleizhou.tech/posts/rocketmq-store-commitlog.html)）\n\nKafka在单Broker上，会同时打开N个文件用于消息的生产，N的数量是该Broker上partition的数量。RocketMQ在单Broker上，只会打开一个MappedFile文件，所有queue（等同于Kafka的partition）的消息生产顺序追加到这个文件中，该文件的大小固定为1G。RocketMQ在新建MappedFile时，会做一个预热操作，其关键代码如下：\n```java\npublic void warmMappedFile(FlushDiskType type, int pages) {\n    // ...\n    for (int i = 0, j = 0; i < this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) {\n        byteBuffer.put(i, (byte) 0);\n        // ...\n    }\n    // ...\n    this.mlock();\n}\n```\n\n预热过程做了以下事情：\n- 将1G的MappedFile通过mmap映射到虚拟内存地址空间；\n- 通过`byteBuffer.put(i, (byte) 0)`触发[Demand Paging](https://en.wikipedia.org/wiki/Demand_paging)，将文件的内容真实映射到Page Cache；\n- 使用mlock锁定该文件的Page Cache，防止被OS置换到swap空间；\n\n预热提前占用Page Cache，相比Kafka的`pwrite`按需占用Page Cache的好处是：\n- 节省user和kernel来回切回的时间，mmap后读写只需要内存寻址；\n- 节省disk映射到Page Cache的时间，预热后disk的block和page cache已经形成对应关系，消息生产时一定能命中，不需要有磁盘IO（mlock进一步保证了”一定能命中cache“）；\n\n由于只有一个MappedFile文件提供写，因此Kafka单Broker在大量级partition写时随机IO的问题得到了解决。但这带来了另外一个问题，消费者消息时如何从MappedFile定位到其需要的消息，不可能去做全文件扫描吧？\n\nMappedFile用于存储真实消息Record，RocketMQ维护了另外一个数据结构ConsumerQueue来索引真实的消息。单个ConsumerQueue文件存储30W条到MappedFile文件的消息Record的索引，便于消费者定位真实消息。但这不岂不是带来了新的问题，数据读取需要二次IO，最坏的情况下读MappedFile还会带来随机IO？\n- 最近一个MappedFile和ConsumerQueue，都是mmap映射在Page Cache中的，只要消费者和生产者的lag不大，很大概率能从Page Cache读到需要的消息；\n- 如果消费者的lag太大，RocketMQ建议从slave读取数据（具体细节待展开），有效规避了lag落后太大的消费者污染Page Cache的问题。\n\n参考文献：https://www.jianshu.com/p/771cce379994\n","slug":"mq-page-cache","published":1,"updated":"2022-08-09T15:02:00.683Z","layout":"post","photos":[],"link":"","_id":"cl6mbc16k0073igu86m4t94jl","content":"<p>Kafka和RocketMQ有很多围绕Page Cache的设计，本文带你一探究竟。</p>\n<a id=\"more\"></a>\n<p>论文<a href=\"https://zhangjunjia.github.io/2020/06/04/kafka-paper/\">Paper阅读：Kafka: a Distributed Messaging System for Log Processing</a>提到，Kafka Broker若通过<code>read</code>调用提供数据给Consumer需要经历以下4个步骤：</p>\n<ul>\n<li>(1) read data from the storage media to the page cache in an OS</li>\n<li>(2) copy data in the page cache to an application buffer</li>\n<li>(3) copy application buffer to another kernel buffer</li>\n<li>(4) send the kernel buffer to the socket</li>\n</ul>\n<p>Kafka通过<code>sendfile</code>调用规避了步骤(2)和(3)，如果要读的数据也在Cache中，则步骤(1)也是不需要的，这就是Kafka高吞吐量的秘密之一。文章<a href=\"https://developer.ibm.com/articles/j-zerocopy/\" target=\"_blank\" rel=\"noopener\">Efficient data transfer through zero copy</a>详细阐述了<code>read</code>和<code>tranferTo</code>的差别，概括来讲就是避免了user-space和kernel-space的内存拷贝以及减少user到kernel的来回切换。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/93546442-5a617080-f995-11ea-8adc-80fa8e19e47d.png\" alt=\"image\"></p>\n<p>（图1 引用自<a href=\"https://developer.ibm.com/articles/j-zerocopy/\" target=\"_blank\" rel=\"noopener\">Efficient data transfer through zero copy</a>）</p>\n<p>在partition较少的情况下，这种模型性能非常优异。Producer写完Page Cache就返回了（底层是<code>pwrite</code>系统调用），由Kafka配置的刷盘间隔时间/条数调用<code>flush</code>刷盘，Consumer在和Producer的lag不大的前提下也是从Page Cache可以直接取到数据返回，图2虚线框表明了这种情况。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/94356704-d78e9300-00c3-11eb-94bb-b22a14bc3174.png\" alt=\"image\"></p>\n<p>（图2 一个partition文件 vs N个partition文件）</p>\n<p>但如果一个Broker上有1W甚至是10W级别的partition文件在同时写(producer)和读(consumer)呢？这会带来什么问题？</p>\n<ul>\n<li>写时，N个文件各自虽然是在顺序写，但在<code>flush</code>刷盘时站在OS的视角变成了随机写（如图2）</li>\n<li>进一步的，随着文件增多，<code>flush</code>的随机IO对写的吞吐量影响越来越大（寻址时间、磁头移动时间）</li>\n</ul>\n<p>针对此问题，RocketMQ从存储模型上做了优化。单Broker支撑大量级的partition（在RocketMQ中称为Queue）时，写依然能做到顺序IO，如下图3所示。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/94389931-c5742980-0183-11eb-9ce2-eef5fb355baa.png\" alt=\"image\"><br>（图3 引用自<a href=\"http://www.daleizhou.tech/posts/rocketmq-store-commitlog.html\" target=\"_blank\" rel=\"noopener\">RocketMQ存储实现分析</a>）</p>\n<p>Kafka在单Broker上，会同时打开N个文件用于消息的生产，N的数量是该Broker上partition的数量。RocketMQ在单Broker上，只会打开一个MappedFile文件，所有queue（等同于Kafka的partition）的消息生产顺序追加到这个文件中，该文件的大小固定为1G。RocketMQ在新建MappedFile时，会做一个预热操作，其关键代码如下：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">warmMappedFile</span><span class=\"params\">(FlushDiskType type, <span class=\"keyword\">int</span> pages)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>, j = <span class=\"number\">0</span>; i &lt; <span class=\"keyword\">this</span>.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) &#123;</span><br><span class=\"line\">        byteBuffer.put(i, (<span class=\"keyword\">byte</span>) <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"comment\">// ...</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">    <span class=\"keyword\">this</span>.mlock();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>预热过程做了以下事情：</p>\n<ul>\n<li>将1G的MappedFile通过mmap映射到虚拟内存地址空间；</li>\n<li>通过<code>byteBuffer.put(i, (byte) 0)</code>触发<a href=\"https://en.wikipedia.org/wiki/Demand_paging\" target=\"_blank\" rel=\"noopener\">Demand Paging</a>，将文件的内容真实映射到Page Cache；</li>\n<li>使用mlock锁定该文件的Page Cache，防止被OS置换到swap空间；</li>\n</ul>\n<p>预热提前占用Page Cache，相比Kafka的<code>pwrite</code>按需占用Page Cache的好处是：</p>\n<ul>\n<li>节省user和kernel来回切回的时间，mmap后读写只需要内存寻址；</li>\n<li>节省disk映射到Page Cache的时间，预热后disk的block和page cache已经形成对应关系，消息生产时一定能命中，不需要有磁盘IO（mlock进一步保证了”一定能命中cache“）；</li>\n</ul>\n<p>由于只有一个MappedFile文件提供写，因此Kafka单Broker在大量级partition写时随机IO的问题得到了解决。但这带来了另外一个问题，消费者消息时如何从MappedFile定位到其需要的消息，不可能去做全文件扫描吧？</p>\n<p>MappedFile用于存储真实消息Record，RocketMQ维护了另外一个数据结构ConsumerQueue来索引真实的消息。单个ConsumerQueue文件存储30W条到MappedFile文件的消息Record的索引，便于消费者定位真实消息。但这不岂不是带来了新的问题，数据读取需要二次IO，最坏的情况下读MappedFile还会带来随机IO？</p>\n<ul>\n<li>最近一个MappedFile和ConsumerQueue，都是mmap映射在Page Cache中的，只要消费者和生产者的lag不大，很大概率能从Page Cache读到需要的消息；</li>\n<li>如果消费者的lag太大，RocketMQ建议从slave读取数据（具体细节待展开），有效规避了lag落后太大的消费者污染Page Cache的问题。</li>\n</ul>\n<p>参考文献：<a href=\"https://www.jianshu.com/p/771cce379994\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/771cce379994</a></p>\n","site":{"data":{}},"excerpt":"<p>Kafka和RocketMQ有很多围绕Page Cache的设计，本文带你一探究竟。</p>","more":"<p>论文<a href=\"https://zhangjunjia.github.io/2020/06/04/kafka-paper/\">Paper阅读：Kafka: a Distributed Messaging System for Log Processing</a>提到，Kafka Broker若通过<code>read</code>调用提供数据给Consumer需要经历以下4个步骤：</p>\n<ul>\n<li>(1) read data from the storage media to the page cache in an OS</li>\n<li>(2) copy data in the page cache to an application buffer</li>\n<li>(3) copy application buffer to another kernel buffer</li>\n<li>(4) send the kernel buffer to the socket</li>\n</ul>\n<p>Kafka通过<code>sendfile</code>调用规避了步骤(2)和(3)，如果要读的数据也在Cache中，则步骤(1)也是不需要的，这就是Kafka高吞吐量的秘密之一。文章<a href=\"https://developer.ibm.com/articles/j-zerocopy/\" target=\"_blank\" rel=\"noopener\">Efficient data transfer through zero copy</a>详细阐述了<code>read</code>和<code>tranferTo</code>的差别，概括来讲就是避免了user-space和kernel-space的内存拷贝以及减少user到kernel的来回切换。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/93546442-5a617080-f995-11ea-8adc-80fa8e19e47d.png\" alt=\"image\"></p>\n<p>（图1 引用自<a href=\"https://developer.ibm.com/articles/j-zerocopy/\" target=\"_blank\" rel=\"noopener\">Efficient data transfer through zero copy</a>）</p>\n<p>在partition较少的情况下，这种模型性能非常优异。Producer写完Page Cache就返回了（底层是<code>pwrite</code>系统调用），由Kafka配置的刷盘间隔时间/条数调用<code>flush</code>刷盘，Consumer在和Producer的lag不大的前提下也是从Page Cache可以直接取到数据返回，图2虚线框表明了这种情况。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/94356704-d78e9300-00c3-11eb-94bb-b22a14bc3174.png\" alt=\"image\"></p>\n<p>（图2 一个partition文件 vs N个partition文件）</p>\n<p>但如果一个Broker上有1W甚至是10W级别的partition文件在同时写(producer)和读(consumer)呢？这会带来什么问题？</p>\n<ul>\n<li>写时，N个文件各自虽然是在顺序写，但在<code>flush</code>刷盘时站在OS的视角变成了随机写（如图2）</li>\n<li>进一步的，随着文件增多，<code>flush</code>的随机IO对写的吞吐量影响越来越大（寻址时间、磁头移动时间）</li>\n</ul>\n<p>针对此问题，RocketMQ从存储模型上做了优化。单Broker支撑大量级的partition（在RocketMQ中称为Queue）时，写依然能做到顺序IO，如下图3所示。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/94389931-c5742980-0183-11eb-9ce2-eef5fb355baa.png\" alt=\"image\"><br>（图3 引用自<a href=\"http://www.daleizhou.tech/posts/rocketmq-store-commitlog.html\" target=\"_blank\" rel=\"noopener\">RocketMQ存储实现分析</a>）</p>\n<p>Kafka在单Broker上，会同时打开N个文件用于消息的生产，N的数量是该Broker上partition的数量。RocketMQ在单Broker上，只会打开一个MappedFile文件，所有queue（等同于Kafka的partition）的消息生产顺序追加到这个文件中，该文件的大小固定为1G。RocketMQ在新建MappedFile时，会做一个预热操作，其关键代码如下：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">warmMappedFile</span><span class=\"params\">(FlushDiskType type, <span class=\"keyword\">int</span> pages)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>, j = <span class=\"number\">0</span>; i &lt; <span class=\"keyword\">this</span>.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) &#123;</span><br><span class=\"line\">        byteBuffer.put(i, (<span class=\"keyword\">byte</span>) <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"comment\">// ...</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">    <span class=\"keyword\">this</span>.mlock();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>预热过程做了以下事情：</p>\n<ul>\n<li>将1G的MappedFile通过mmap映射到虚拟内存地址空间；</li>\n<li>通过<code>byteBuffer.put(i, (byte) 0)</code>触发<a href=\"https://en.wikipedia.org/wiki/Demand_paging\" target=\"_blank\" rel=\"noopener\">Demand Paging</a>，将文件的内容真实映射到Page Cache；</li>\n<li>使用mlock锁定该文件的Page Cache，防止被OS置换到swap空间；</li>\n</ul>\n<p>预热提前占用Page Cache，相比Kafka的<code>pwrite</code>按需占用Page Cache的好处是：</p>\n<ul>\n<li>节省user和kernel来回切回的时间，mmap后读写只需要内存寻址；</li>\n<li>节省disk映射到Page Cache的时间，预热后disk的block和page cache已经形成对应关系，消息生产时一定能命中，不需要有磁盘IO（mlock进一步保证了”一定能命中cache“）；</li>\n</ul>\n<p>由于只有一个MappedFile文件提供写，因此Kafka单Broker在大量级partition写时随机IO的问题得到了解决。但这带来了另外一个问题，消费者消息时如何从MappedFile定位到其需要的消息，不可能去做全文件扫描吧？</p>\n<p>MappedFile用于存储真实消息Record，RocketMQ维护了另外一个数据结构ConsumerQueue来索引真实的消息。单个ConsumerQueue文件存储30W条到MappedFile文件的消息Record的索引，便于消费者定位真实消息。但这不岂不是带来了新的问题，数据读取需要二次IO，最坏的情况下读MappedFile还会带来随机IO？</p>\n<ul>\n<li>最近一个MappedFile和ConsumerQueue，都是mmap映射在Page Cache中的，只要消费者和生产者的lag不大，很大概率能从Page Cache读到需要的消息；</li>\n<li>如果消费者的lag太大，RocketMQ建议从slave读取数据（具体细节待展开），有效规避了lag落后太大的消费者污染Page Cache的问题。</li>\n</ul>\n<p>参考文献：<a href=\"https://www.jianshu.com/p/771cce379994\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/771cce379994</a></p>"},{"title":"谈谈MQ | 读取数据","date":"2020-11-03T06:06:16.000Z","comments":1,"_content":"\n本文谈谈Kafka和RocketMQ读取数据的差别。\n\n<!--more-->\n\n## Kafka读取数据\n\n![image](https://user-images.githubusercontent.com/4915189/97523900-50904b80-19de-11eb-9cd8-397b8e2f6126.png)\n（图1 Kafka读取数据流程）\n\nKafka读取数据如图1所示。\n- 只有leader副本提供数据读取（写也是leader副本提供，读写不分离）\n- consumer和replica需要告诉leader副本从哪个offset开始读、读多少内容返回\n- leader副本从索引文件中定位符合offset要求的最小offset，但由于Kafka是稀疏索引，所以还需要从前一步确定的offset向后扫描log文件找到符合要求的真实offset，然后从该offset开始读取数据返回\n\nKafka从log读记录的效率受Page Cache的影响，这个在[上一篇](https://github.com/zhangjunjia/zhangjunjia.github.io/issues/23)已经提到了。Kafka从索引文件确定offset，是一个二分查找的过程，在旧版本的Kafka，这个过程是这样的：\n```java\n\n  private def indexSlotRangeFor(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity): (Int, Int) = {\n        // 第1步：如果当前索引为空，直接返回<-1,-1>对\n        if(_entries == 0)\n          return (-1, -1)\n    \n    \n        // 第2步：要查找的位移值不能小于当前最小位移值\n        if(compareIndexEntry(parseEntry(idx, 0), target, searchEntity) > 0)\n          return (-1, 0)\n    \n    \n        // binary search for the entry\n        // 第3步：执行二分查找算法\n        var lo = 0\n        var hi = _entries - 1\n        while(lo < hi) {\n          val mid = ceil(hi/2.0 + lo/2.0).toInt\n          val found = parseEntry(idx, mid)\n          val compareResult = compareIndexEntry(found, target, searchEntity)\n          if(compareResult > 0)\n            hi = mid - 1\n          else if(compareResult < 0)\n            lo = mid\n          else\n            return (mid, mid)\n        }\n    \n    \n        (lo, if (lo == _entries - 1) -1 else lo + 1)\n}\n```\n\nKafka的index文件是通过mmap映射到Page Cache的，上述二分查找代码，对Page Cache是不友好的。\n\n```\npage number: |0|1|2|3|4|5|6|7|8|9|10|11|12 |\nsteps:       |1| | | | | |3| | |4|  |5 |2/6|\n```\n\n假设index文件的大小是13个Page，in-sync replica和consumer大概率都是读取最后的一个Page。如上所示，这时二分查找Page的序号是：#0,6,9,11,12。之所以先从#0开始读，是要确保读取offset不能小于index文件的最小位移。\n\n```\npage number: |0|1|2|3|4|5|6|7|8|9|10|11|12|13 |\nsteps:       |1| | | | | | |3| | | 4|5 | 6|2/7|\n```\n\n最后一个Page随着时间的推移总会被写满，这时会新增#13这个Page。如上所示，此时二分查找page的顺序就变成了#0,7,10,12,13。问题在于，Page Cache是遵循LRU淘汰策略的，Page 7大概率会因为长时间没使用而被淘汰了，此时的二分查找就会产生Page Fault。单个index文件page fault还能接受，Broker上有N个index文件page fault这个代价就高了。有没有一种策略，使得对于较新的消息的二分查找过程，尽可能不产生page fault呢？\n\nKafka官方给出的解决方案是：冷热分离。\n\n![image](https://user-images.githubusercontent.com/4915189/97548775-8519fc80-1a0a-11eb-9473-aabb698f8dee.png)\n（图2 index索引项冷热分离）\n\n假设index文件有10W个稀疏索引，Kafka将最末尾的2个Page大小（8192字节）的索引定义为热区（换算成offsetindex是1024个稀疏索引）。Kafka将待查找offset和热区的第一个索引项做offset比较，若判断到待查找offset在热区，则在热区内做二分查找，否则在冷区内做二分查找。这背后的思想很朴素，最近2个Page大小的热区，大概率还没有被LRU策略淘汰掉。其代码如下：\n\n```java\nprotected def _warmEntries: Int = 8192 / entrySize\n\nprivate def indexSlotRangeFor(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity): (Int, Int) = {\n  // ...\n\n  def binarySearch(begin: Int, end: Int) : (Int, Int) = {\n    // binary search for the entry\n    var lo = begin\n    var hi = end\n    while(lo < hi) {\n      val mid = (lo + hi + 1) >>> 1\n      val found = parseEntry(idx, mid)\n      val compareResult = compareIndexEntry(found, target, searchEntity)\n      if(compareResult > 0)\n        hi = mid - 1\n      else if(compareResult < 0)\n        lo = mid\n      else\n        return (mid, mid)\n    }\n    (lo, if (lo == _entries - 1) -1 else lo + 1)\n  }\n\n  val firstHotEntry = Math.max(0, _entries - 1 - _warmEntries)\n  // 和热区的第一个索引比较，判断是否要在热区内二分查找\n  if(compareIndexEntry(parseEntry(idx, firstHotEntry), target, searchEntity) < 0) {\n    return binarySearch(firstHotEntry, _entries - 1)\n  }\n\n  // 如果小于index文件最小索引退出\n  if(compareIndexEntry(parseEntry(idx, 0), target, searchEntity) > 0)\n    return (-1, 0)\n\n  // 在冷区二分查找\n  binarySearch(0, firstHotEntry)\n}\n```\n\n热区定义为8192字节是一个经验数值，它对应1024个offsetindex索引项，可索引大概4MB大小的消息。最大情况下，这8192字节会包括3个Page，例如`[Page1:2048字节][Page2:4096字节][Page3:2048字节]`。这个数值太大，Page可能已经被LRU策略淘汰，仍会产生page fault那就没价值了；这个数值太小，那就降级为冷区二分查找，仍会出现所提的page新增时page fault的问题。\n\n## RocketMQ读取数据\n\n![image](https://user-images.githubusercontent.com/4915189/97953016-2b367f80-1dda-11eb-88c2-2b906b095ca5.png)\n\n（图3 RocketMQ读取数据）\n\n有别于Kafka的partition级别的leader/follower，RocketMQ是Broker级别的master/slave，slave全量冗余master的数据。读取数据时，如果满足一定条件（数据太旧）会从slave读取，实现了某种程度上的「读写分离」。\n\n```java\n// org.apache.rocketmq.store.DefaultMessageStore#getMessage\nlong diff = maxOffsetPy - maxPhyOffsetPulling;\nlong memory = (long) (StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE\n    * (this.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / 100.0));\ngetResult.setSuggestPullingFromSlave(diff > memory);\n```\n\n什么情况下从slave读取数据？如上所示，\n\n> maxOffsetPy 为当前最大物理偏移量，maxPhyOffsetPulling 为本次消息拉取最大物理偏移量，他们的差即可表示消息堆积量，TOTAL_PHYSICAL_MEMORY_SIZE 表示当前系统物理内存，accessMessageInMemoryMaxRatio 的默认值为 40，以上逻辑即可算出当前消息堆积量是否大于物理内存的 40 %，如果大于则将 suggestPullingFromSlave 设置为 true。\n> 引用自：http://objcoding.com/2019/09/22/rocketmq-read-write-separation/\n\n`setSuggestPullingFromSlave`为true后还会结合其他开关配置项决定是否从slave读取数据，具体可以参考上面引用的链接，但核心逻辑就是上面的代码。consumer无论是从master还是slave读取数据，都需要经历：\n- 从consumerqueue读取位移数据（consumerqueue是mmap在内存中的）\n- 根据位移数据回源到MappedFile读取数据，该MappedFile大概率还在page cache中未被LRU淘汰（如果已经LRU淘汰掉了，能切到slave读冷数据可以避免page fault，这就是核心思思）\n\n从slave读取数据的价值是可以最大化利用master的page cache，使得冷数据的读取不影响到master的性能。slave同步master的数据则与上述过程不同，由于是Broker级别的replicate，因此不需要区分consumerqueue，所有master的数据都需要同步到slave。这个过程中，slave上报的offset作为游标，master根据该游标不断往slave推送新数据，slave接受数据后更新游标重复此过程。\n\n## 参考文献\n\n- RocketMQ主从同步源码分析：http://objcoding.com/2019/09/21/rocketmq-Master-slave-ha/#top\n- RocketMQ主从读写分离机制：http://objcoding.com/2019/09/22/rocketmq-read-write-separation/\n\n","source":"_posts/2020-11-03-mq-read-diff.md","raw":"---\ntitle: 谈谈MQ | 读取数据\ndate: 2020-11-03 14:06:16\ntags: ['Kafka', 'Paper阅读']\ncomments: true\ncategories: ['分布式系统']\n---\n\n本文谈谈Kafka和RocketMQ读取数据的差别。\n\n<!--more-->\n\n## Kafka读取数据\n\n![image](https://user-images.githubusercontent.com/4915189/97523900-50904b80-19de-11eb-9cd8-397b8e2f6126.png)\n（图1 Kafka读取数据流程）\n\nKafka读取数据如图1所示。\n- 只有leader副本提供数据读取（写也是leader副本提供，读写不分离）\n- consumer和replica需要告诉leader副本从哪个offset开始读、读多少内容返回\n- leader副本从索引文件中定位符合offset要求的最小offset，但由于Kafka是稀疏索引，所以还需要从前一步确定的offset向后扫描log文件找到符合要求的真实offset，然后从该offset开始读取数据返回\n\nKafka从log读记录的效率受Page Cache的影响，这个在[上一篇](https://github.com/zhangjunjia/zhangjunjia.github.io/issues/23)已经提到了。Kafka从索引文件确定offset，是一个二分查找的过程，在旧版本的Kafka，这个过程是这样的：\n```java\n\n  private def indexSlotRangeFor(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity): (Int, Int) = {\n        // 第1步：如果当前索引为空，直接返回<-1,-1>对\n        if(_entries == 0)\n          return (-1, -1)\n    \n    \n        // 第2步：要查找的位移值不能小于当前最小位移值\n        if(compareIndexEntry(parseEntry(idx, 0), target, searchEntity) > 0)\n          return (-1, 0)\n    \n    \n        // binary search for the entry\n        // 第3步：执行二分查找算法\n        var lo = 0\n        var hi = _entries - 1\n        while(lo < hi) {\n          val mid = ceil(hi/2.0 + lo/2.0).toInt\n          val found = parseEntry(idx, mid)\n          val compareResult = compareIndexEntry(found, target, searchEntity)\n          if(compareResult > 0)\n            hi = mid - 1\n          else if(compareResult < 0)\n            lo = mid\n          else\n            return (mid, mid)\n        }\n    \n    \n        (lo, if (lo == _entries - 1) -1 else lo + 1)\n}\n```\n\nKafka的index文件是通过mmap映射到Page Cache的，上述二分查找代码，对Page Cache是不友好的。\n\n```\npage number: |0|1|2|3|4|5|6|7|8|9|10|11|12 |\nsteps:       |1| | | | | |3| | |4|  |5 |2/6|\n```\n\n假设index文件的大小是13个Page，in-sync replica和consumer大概率都是读取最后的一个Page。如上所示，这时二分查找Page的序号是：#0,6,9,11,12。之所以先从#0开始读，是要确保读取offset不能小于index文件的最小位移。\n\n```\npage number: |0|1|2|3|4|5|6|7|8|9|10|11|12|13 |\nsteps:       |1| | | | | | |3| | | 4|5 | 6|2/7|\n```\n\n最后一个Page随着时间的推移总会被写满，这时会新增#13这个Page。如上所示，此时二分查找page的顺序就变成了#0,7,10,12,13。问题在于，Page Cache是遵循LRU淘汰策略的，Page 7大概率会因为长时间没使用而被淘汰了，此时的二分查找就会产生Page Fault。单个index文件page fault还能接受，Broker上有N个index文件page fault这个代价就高了。有没有一种策略，使得对于较新的消息的二分查找过程，尽可能不产生page fault呢？\n\nKafka官方给出的解决方案是：冷热分离。\n\n![image](https://user-images.githubusercontent.com/4915189/97548775-8519fc80-1a0a-11eb-9473-aabb698f8dee.png)\n（图2 index索引项冷热分离）\n\n假设index文件有10W个稀疏索引，Kafka将最末尾的2个Page大小（8192字节）的索引定义为热区（换算成offsetindex是1024个稀疏索引）。Kafka将待查找offset和热区的第一个索引项做offset比较，若判断到待查找offset在热区，则在热区内做二分查找，否则在冷区内做二分查找。这背后的思想很朴素，最近2个Page大小的热区，大概率还没有被LRU策略淘汰掉。其代码如下：\n\n```java\nprotected def _warmEntries: Int = 8192 / entrySize\n\nprivate def indexSlotRangeFor(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity): (Int, Int) = {\n  // ...\n\n  def binarySearch(begin: Int, end: Int) : (Int, Int) = {\n    // binary search for the entry\n    var lo = begin\n    var hi = end\n    while(lo < hi) {\n      val mid = (lo + hi + 1) >>> 1\n      val found = parseEntry(idx, mid)\n      val compareResult = compareIndexEntry(found, target, searchEntity)\n      if(compareResult > 0)\n        hi = mid - 1\n      else if(compareResult < 0)\n        lo = mid\n      else\n        return (mid, mid)\n    }\n    (lo, if (lo == _entries - 1) -1 else lo + 1)\n  }\n\n  val firstHotEntry = Math.max(0, _entries - 1 - _warmEntries)\n  // 和热区的第一个索引比较，判断是否要在热区内二分查找\n  if(compareIndexEntry(parseEntry(idx, firstHotEntry), target, searchEntity) < 0) {\n    return binarySearch(firstHotEntry, _entries - 1)\n  }\n\n  // 如果小于index文件最小索引退出\n  if(compareIndexEntry(parseEntry(idx, 0), target, searchEntity) > 0)\n    return (-1, 0)\n\n  // 在冷区二分查找\n  binarySearch(0, firstHotEntry)\n}\n```\n\n热区定义为8192字节是一个经验数值，它对应1024个offsetindex索引项，可索引大概4MB大小的消息。最大情况下，这8192字节会包括3个Page，例如`[Page1:2048字节][Page2:4096字节][Page3:2048字节]`。这个数值太大，Page可能已经被LRU策略淘汰，仍会产生page fault那就没价值了；这个数值太小，那就降级为冷区二分查找，仍会出现所提的page新增时page fault的问题。\n\n## RocketMQ读取数据\n\n![image](https://user-images.githubusercontent.com/4915189/97953016-2b367f80-1dda-11eb-88c2-2b906b095ca5.png)\n\n（图3 RocketMQ读取数据）\n\n有别于Kafka的partition级别的leader/follower，RocketMQ是Broker级别的master/slave，slave全量冗余master的数据。读取数据时，如果满足一定条件（数据太旧）会从slave读取，实现了某种程度上的「读写分离」。\n\n```java\n// org.apache.rocketmq.store.DefaultMessageStore#getMessage\nlong diff = maxOffsetPy - maxPhyOffsetPulling;\nlong memory = (long) (StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE\n    * (this.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / 100.0));\ngetResult.setSuggestPullingFromSlave(diff > memory);\n```\n\n什么情况下从slave读取数据？如上所示，\n\n> maxOffsetPy 为当前最大物理偏移量，maxPhyOffsetPulling 为本次消息拉取最大物理偏移量，他们的差即可表示消息堆积量，TOTAL_PHYSICAL_MEMORY_SIZE 表示当前系统物理内存，accessMessageInMemoryMaxRatio 的默认值为 40，以上逻辑即可算出当前消息堆积量是否大于物理内存的 40 %，如果大于则将 suggestPullingFromSlave 设置为 true。\n> 引用自：http://objcoding.com/2019/09/22/rocketmq-read-write-separation/\n\n`setSuggestPullingFromSlave`为true后还会结合其他开关配置项决定是否从slave读取数据，具体可以参考上面引用的链接，但核心逻辑就是上面的代码。consumer无论是从master还是slave读取数据，都需要经历：\n- 从consumerqueue读取位移数据（consumerqueue是mmap在内存中的）\n- 根据位移数据回源到MappedFile读取数据，该MappedFile大概率还在page cache中未被LRU淘汰（如果已经LRU淘汰掉了，能切到slave读冷数据可以避免page fault，这就是核心思思）\n\n从slave读取数据的价值是可以最大化利用master的page cache，使得冷数据的读取不影响到master的性能。slave同步master的数据则与上述过程不同，由于是Broker级别的replicate，因此不需要区分consumerqueue，所有master的数据都需要同步到slave。这个过程中，slave上报的offset作为游标，master根据该游标不断往slave推送新数据，slave接受数据后更新游标重复此过程。\n\n## 参考文献\n\n- RocketMQ主从同步源码分析：http://objcoding.com/2019/09/21/rocketmq-Master-slave-ha/#top\n- RocketMQ主从读写分离机制：http://objcoding.com/2019/09/22/rocketmq-read-write-separation/\n\n","slug":"mq-read-diff","published":1,"updated":"2022-08-09T15:02:00.684Z","layout":"post","photos":[],"link":"","_id":"cl6mbc16m0075igu8uuyk43s2","content":"<p>本文谈谈Kafka和RocketMQ读取数据的差别。</p>\n<a id=\"more\"></a>\n<h2 id=\"Kafka读取数据\"><a href=\"#Kafka读取数据\" class=\"headerlink\" title=\"Kafka读取数据\"></a>Kafka读取数据</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/97523900-50904b80-19de-11eb-9cd8-397b8e2f6126.png\" alt=\"image\"><br>（图1 Kafka读取数据流程）</p>\n<p>Kafka读取数据如图1所示。</p>\n<ul>\n<li>只有leader副本提供数据读取（写也是leader副本提供，读写不分离）</li>\n<li>consumer和replica需要告诉leader副本从哪个offset开始读、读多少内容返回</li>\n<li>leader副本从索引文件中定位符合offset要求的最小offset，但由于Kafka是稀疏索引，所以还需要从前一步确定的offset向后扫描log文件找到符合要求的真实offset，然后从该offset开始读取数据返回</li>\n</ul>\n<p>Kafka从log读记录的效率受Page Cache的影响，这个在<a href=\"https://github.com/zhangjunjia/zhangjunjia.github.io/issues/23\" target=\"_blank\" rel=\"noopener\">上一篇</a>已经提到了。Kafka从索引文件确定offset，是一个二分查找的过程，在旧版本的Kafka，这个过程是这样的：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">private</span> def <span class=\"title\">indexSlotRangeFor</span><span class=\"params\">(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity)</span>: <span class=\"params\">(Int, Int)</span> </span>= &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 第1步：如果当前索引为空，直接返回&lt;-1,-1&gt;对</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(_entries == <span class=\"number\">0</span>)</span><br><span class=\"line\">          <span class=\"keyword\">return</span> (-<span class=\"number\">1</span>, -<span class=\"number\">1</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">        <span class=\"comment\">// 第2步：要查找的位移值不能小于当前最小位移值</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(compareIndexEntry(parseEntry(idx, <span class=\"number\">0</span>), target, searchEntity) &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">          <span class=\"keyword\">return</span> (-<span class=\"number\">1</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">        <span class=\"comment\">// binary search for the entry</span></span><br><span class=\"line\">        <span class=\"comment\">// 第3步：执行二分查找算法</span></span><br><span class=\"line\">        var lo = <span class=\"number\">0</span></span><br><span class=\"line\">        var hi = _entries - <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(lo &lt; hi) &#123;</span><br><span class=\"line\">          val mid = ceil(hi/<span class=\"number\">2.0</span> + lo/<span class=\"number\">2.0</span>).toInt</span><br><span class=\"line\">          val found = parseEntry(idx, mid)</span><br><span class=\"line\">          val compareResult = compareIndexEntry(found, target, searchEntity)</span><br><span class=\"line\">          <span class=\"keyword\">if</span>(compareResult &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">            hi = mid - <span class=\"number\">1</span></span><br><span class=\"line\">          <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(compareResult &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">            lo = mid</span><br><span class=\"line\">          <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> (mid, mid)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">        (lo, <span class=\"keyword\">if</span> (lo == _entries - <span class=\"number\">1</span>) -<span class=\"number\">1</span> <span class=\"keyword\">else</span> lo + <span class=\"number\">1</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>Kafka的index文件是通过mmap映射到Page Cache的，上述二分查找代码，对Page Cache是不友好的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">page number: |0|1|2|3|4|5|6|7|8|9|10|11|12 |</span><br><span class=\"line\">steps:       |1| | | | | |3| | |4|  |5 |2/6|</span><br></pre></td></tr></table></figure>\n<p>假设index文件的大小是13个Page，in-sync replica和consumer大概率都是读取最后的一个Page。如上所示，这时二分查找Page的序号是：#0,6,9,11,12。之所以先从#0开始读，是要确保读取offset不能小于index文件的最小位移。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">page number: |0|1|2|3|4|5|6|7|8|9|10|11|12|13 |</span><br><span class=\"line\">steps:       |1| | | | | | |3| | | 4|5 | 6|2/7|</span><br></pre></td></tr></table></figure>\n<p>最后一个Page随着时间的推移总会被写满，这时会新增#13这个Page。如上所示，此时二分查找page的顺序就变成了#0,7,10,12,13。问题在于，Page Cache是遵循LRU淘汰策略的，Page 7大概率会因为长时间没使用而被淘汰了，此时的二分查找就会产生Page Fault。单个index文件page fault还能接受，Broker上有N个index文件page fault这个代价就高了。有没有一种策略，使得对于较新的消息的二分查找过程，尽可能不产生page fault呢？</p>\n<p>Kafka官方给出的解决方案是：冷热分离。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/97548775-8519fc80-1a0a-11eb-9473-aabb698f8dee.png\" alt=\"image\"><br>（图2 index索引项冷热分离）</p>\n<p>假设index文件有10W个稀疏索引，Kafka将最末尾的2个Page大小（8192字节）的索引定义为热区（换算成offsetindex是1024个稀疏索引）。Kafka将待查找offset和热区的第一个索引项做offset比较，若判断到待查找offset在热区，则在热区内做二分查找，否则在冷区内做二分查找。这背后的思想很朴素，最近2个Page大小的热区，大概率还没有被LRU策略淘汰掉。其代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">protected</span> def _warmEntries: Int = <span class=\"number\">8192</span> / entrySize</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> def <span class=\"title\">indexSlotRangeFor</span><span class=\"params\">(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity)</span>: <span class=\"params\">(Int, Int)</span> </span>= &#123;</span><br><span class=\"line\">  <span class=\"comment\">// ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\">def <span class=\"title\">binarySearch</span><span class=\"params\">(begin: Int, end: Int)</span> : <span class=\"params\">(Int, Int)</span> </span>= &#123;</span><br><span class=\"line\">    <span class=\"comment\">// binary search for the entry</span></span><br><span class=\"line\">    var lo = begin</span><br><span class=\"line\">    var hi = end</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(lo &lt; hi) &#123;</span><br><span class=\"line\">      val mid = (lo + hi + <span class=\"number\">1</span>) &gt;&gt;&gt; <span class=\"number\">1</span></span><br><span class=\"line\">      val found = parseEntry(idx, mid)</span><br><span class=\"line\">      val compareResult = compareIndexEntry(found, target, searchEntity)</span><br><span class=\"line\">      <span class=\"keyword\">if</span>(compareResult &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        hi = mid - <span class=\"number\">1</span></span><br><span class=\"line\">      <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(compareResult &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        lo = mid</span><br><span class=\"line\">      <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> (mid, mid)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    (lo, <span class=\"keyword\">if</span> (lo == _entries - <span class=\"number\">1</span>) -<span class=\"number\">1</span> <span class=\"keyword\">else</span> lo + <span class=\"number\">1</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  val firstHotEntry = Math.max(<span class=\"number\">0</span>, _entries - <span class=\"number\">1</span> - _warmEntries)</span><br><span class=\"line\">  <span class=\"comment\">// 和热区的第一个索引比较，判断是否要在热区内二分查找</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span>(compareIndexEntry(parseEntry(idx, firstHotEntry), target, searchEntity) &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> binarySearch(firstHotEntry, _entries - <span class=\"number\">1</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 如果小于index文件最小索引退出</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span>(compareIndexEntry(parseEntry(idx, <span class=\"number\">0</span>), target, searchEntity) &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (-<span class=\"number\">1</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 在冷区二分查找</span></span><br><span class=\"line\">  binarySearch(<span class=\"number\">0</span>, firstHotEntry)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>热区定义为8192字节是一个经验数值，它对应1024个offsetindex索引项，可索引大概4MB大小的消息。最大情况下，这8192字节会包括3个Page，例如<code>[Page1:2048字节][Page2:4096字节][Page3:2048字节]</code>。这个数值太大，Page可能已经被LRU策略淘汰，仍会产生page fault那就没价值了；这个数值太小，那就降级为冷区二分查找，仍会出现所提的page新增时page fault的问题。</p>\n<h2 id=\"RocketMQ读取数据\"><a href=\"#RocketMQ读取数据\" class=\"headerlink\" title=\"RocketMQ读取数据\"></a>RocketMQ读取数据</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/97953016-2b367f80-1dda-11eb-88c2-2b906b095ca5.png\" alt=\"image\"></p>\n<p>（图3 RocketMQ读取数据）</p>\n<p>有别于Kafka的partition级别的leader/follower，RocketMQ是Broker级别的master/slave，slave全量冗余master的数据。读取数据时，如果满足一定条件（数据太旧）会从slave读取，实现了某种程度上的「读写分离」。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// org.apache.rocketmq.store.DefaultMessageStore#getMessage</span></span><br><span class=\"line\"><span class=\"keyword\">long</span> diff = maxOffsetPy - maxPhyOffsetPulling;</span><br><span class=\"line\"><span class=\"keyword\">long</span> memory = (<span class=\"keyword\">long</span>) (StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE</span><br><span class=\"line\">    * (<span class=\"keyword\">this</span>.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / <span class=\"number\">100.0</span>));</span><br><span class=\"line\">getResult.setSuggestPullingFromSlave(diff &gt; memory);</span><br></pre></td></tr></table></figure>\n<p>什么情况下从slave读取数据？如上所示，</p>\n<blockquote>\n<p>maxOffsetPy 为当前最大物理偏移量，maxPhyOffsetPulling 为本次消息拉取最大物理偏移量，他们的差即可表示消息堆积量，TOTAL_PHYSICAL_MEMORY_SIZE 表示当前系统物理内存，accessMessageInMemoryMaxRatio 的默认值为 40，以上逻辑即可算出当前消息堆积量是否大于物理内存的 40 %，如果大于则将 suggestPullingFromSlave 设置为 true。<br>引用自：<a href=\"http://objcoding.com/2019/09/22/rocketmq-read-write-separation/\" target=\"_blank\" rel=\"noopener\">http://objcoding.com/2019/09/22/rocketmq-read-write-separation/</a></p>\n</blockquote>\n<p><code>setSuggestPullingFromSlave</code>为true后还会结合其他开关配置项决定是否从slave读取数据，具体可以参考上面引用的链接，但核心逻辑就是上面的代码。consumer无论是从master还是slave读取数据，都需要经历：</p>\n<ul>\n<li>从consumerqueue读取位移数据（consumerqueue是mmap在内存中的）</li>\n<li>根据位移数据回源到MappedFile读取数据，该MappedFile大概率还在page cache中未被LRU淘汰（如果已经LRU淘汰掉了，能切到slave读冷数据可以避免page fault，这就是核心思思）</li>\n</ul>\n<p>从slave读取数据的价值是可以最大化利用master的page cache，使得冷数据的读取不影响到master的性能。slave同步master的数据则与上述过程不同，由于是Broker级别的replicate，因此不需要区分consumerqueue，所有master的数据都需要同步到slave。这个过程中，slave上报的offset作为游标，master根据该游标不断往slave推送新数据，slave接受数据后更新游标重复此过程。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li>RocketMQ主从同步源码分析：<a href=\"http://objcoding.com/2019/09/21/rocketmq-Master-slave-ha/#top\" target=\"_blank\" rel=\"noopener\">http://objcoding.com/2019/09/21/rocketmq-Master-slave-ha/#top</a></li>\n<li>RocketMQ主从读写分离机制：<a href=\"http://objcoding.com/2019/09/22/rocketmq-read-write-separation/\" target=\"_blank\" rel=\"noopener\">http://objcoding.com/2019/09/22/rocketmq-read-write-separation/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>本文谈谈Kafka和RocketMQ读取数据的差别。</p>","more":"<h2 id=\"Kafka读取数据\"><a href=\"#Kafka读取数据\" class=\"headerlink\" title=\"Kafka读取数据\"></a>Kafka读取数据</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/97523900-50904b80-19de-11eb-9cd8-397b8e2f6126.png\" alt=\"image\"><br>（图1 Kafka读取数据流程）</p>\n<p>Kafka读取数据如图1所示。</p>\n<ul>\n<li>只有leader副本提供数据读取（写也是leader副本提供，读写不分离）</li>\n<li>consumer和replica需要告诉leader副本从哪个offset开始读、读多少内容返回</li>\n<li>leader副本从索引文件中定位符合offset要求的最小offset，但由于Kafka是稀疏索引，所以还需要从前一步确定的offset向后扫描log文件找到符合要求的真实offset，然后从该offset开始读取数据返回</li>\n</ul>\n<p>Kafka从log读记录的效率受Page Cache的影响，这个在<a href=\"https://github.com/zhangjunjia/zhangjunjia.github.io/issues/23\" target=\"_blank\" rel=\"noopener\">上一篇</a>已经提到了。Kafka从索引文件确定offset，是一个二分查找的过程，在旧版本的Kafka，这个过程是这样的：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">private</span> def <span class=\"title\">indexSlotRangeFor</span><span class=\"params\">(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity)</span>: <span class=\"params\">(Int, Int)</span> </span>= &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 第1步：如果当前索引为空，直接返回&lt;-1,-1&gt;对</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(_entries == <span class=\"number\">0</span>)</span><br><span class=\"line\">          <span class=\"keyword\">return</span> (-<span class=\"number\">1</span>, -<span class=\"number\">1</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">        <span class=\"comment\">// 第2步：要查找的位移值不能小于当前最小位移值</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(compareIndexEntry(parseEntry(idx, <span class=\"number\">0</span>), target, searchEntity) &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">          <span class=\"keyword\">return</span> (-<span class=\"number\">1</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">        <span class=\"comment\">// binary search for the entry</span></span><br><span class=\"line\">        <span class=\"comment\">// 第3步：执行二分查找算法</span></span><br><span class=\"line\">        var lo = <span class=\"number\">0</span></span><br><span class=\"line\">        var hi = _entries - <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(lo &lt; hi) &#123;</span><br><span class=\"line\">          val mid = ceil(hi/<span class=\"number\">2.0</span> + lo/<span class=\"number\">2.0</span>).toInt</span><br><span class=\"line\">          val found = parseEntry(idx, mid)</span><br><span class=\"line\">          val compareResult = compareIndexEntry(found, target, searchEntity)</span><br><span class=\"line\">          <span class=\"keyword\">if</span>(compareResult &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">            hi = mid - <span class=\"number\">1</span></span><br><span class=\"line\">          <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(compareResult &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">            lo = mid</span><br><span class=\"line\">          <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> (mid, mid)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">        (lo, <span class=\"keyword\">if</span> (lo == _entries - <span class=\"number\">1</span>) -<span class=\"number\">1</span> <span class=\"keyword\">else</span> lo + <span class=\"number\">1</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>Kafka的index文件是通过mmap映射到Page Cache的，上述二分查找代码，对Page Cache是不友好的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">page number: |0|1|2|3|4|5|6|7|8|9|10|11|12 |</span><br><span class=\"line\">steps:       |1| | | | | |3| | |4|  |5 |2/6|</span><br></pre></td></tr></table></figure>\n<p>假设index文件的大小是13个Page，in-sync replica和consumer大概率都是读取最后的一个Page。如上所示，这时二分查找Page的序号是：#0,6,9,11,12。之所以先从#0开始读，是要确保读取offset不能小于index文件的最小位移。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">page number: |0|1|2|3|4|5|6|7|8|9|10|11|12|13 |</span><br><span class=\"line\">steps:       |1| | | | | | |3| | | 4|5 | 6|2/7|</span><br></pre></td></tr></table></figure>\n<p>最后一个Page随着时间的推移总会被写满，这时会新增#13这个Page。如上所示，此时二分查找page的顺序就变成了#0,7,10,12,13。问题在于，Page Cache是遵循LRU淘汰策略的，Page 7大概率会因为长时间没使用而被淘汰了，此时的二分查找就会产生Page Fault。单个index文件page fault还能接受，Broker上有N个index文件page fault这个代价就高了。有没有一种策略，使得对于较新的消息的二分查找过程，尽可能不产生page fault呢？</p>\n<p>Kafka官方给出的解决方案是：冷热分离。</p>\n<p><img src=\"https://user-images.githubusercontent.com/4915189/97548775-8519fc80-1a0a-11eb-9473-aabb698f8dee.png\" alt=\"image\"><br>（图2 index索引项冷热分离）</p>\n<p>假设index文件有10W个稀疏索引，Kafka将最末尾的2个Page大小（8192字节）的索引定义为热区（换算成offsetindex是1024个稀疏索引）。Kafka将待查找offset和热区的第一个索引项做offset比较，若判断到待查找offset在热区，则在热区内做二分查找，否则在冷区内做二分查找。这背后的思想很朴素，最近2个Page大小的热区，大概率还没有被LRU策略淘汰掉。其代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">protected</span> def _warmEntries: Int = <span class=\"number\">8192</span> / entrySize</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> def <span class=\"title\">indexSlotRangeFor</span><span class=\"params\">(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity)</span>: <span class=\"params\">(Int, Int)</span> </span>= &#123;</span><br><span class=\"line\">  <span class=\"comment\">// ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\">def <span class=\"title\">binarySearch</span><span class=\"params\">(begin: Int, end: Int)</span> : <span class=\"params\">(Int, Int)</span> </span>= &#123;</span><br><span class=\"line\">    <span class=\"comment\">// binary search for the entry</span></span><br><span class=\"line\">    var lo = begin</span><br><span class=\"line\">    var hi = end</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(lo &lt; hi) &#123;</span><br><span class=\"line\">      val mid = (lo + hi + <span class=\"number\">1</span>) &gt;&gt;&gt; <span class=\"number\">1</span></span><br><span class=\"line\">      val found = parseEntry(idx, mid)</span><br><span class=\"line\">      val compareResult = compareIndexEntry(found, target, searchEntity)</span><br><span class=\"line\">      <span class=\"keyword\">if</span>(compareResult &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        hi = mid - <span class=\"number\">1</span></span><br><span class=\"line\">      <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(compareResult &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        lo = mid</span><br><span class=\"line\">      <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> (mid, mid)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    (lo, <span class=\"keyword\">if</span> (lo == _entries - <span class=\"number\">1</span>) -<span class=\"number\">1</span> <span class=\"keyword\">else</span> lo + <span class=\"number\">1</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  val firstHotEntry = Math.max(<span class=\"number\">0</span>, _entries - <span class=\"number\">1</span> - _warmEntries)</span><br><span class=\"line\">  <span class=\"comment\">// 和热区的第一个索引比较，判断是否要在热区内二分查找</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span>(compareIndexEntry(parseEntry(idx, firstHotEntry), target, searchEntity) &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> binarySearch(firstHotEntry, _entries - <span class=\"number\">1</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 如果小于index文件最小索引退出</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span>(compareIndexEntry(parseEntry(idx, <span class=\"number\">0</span>), target, searchEntity) &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (-<span class=\"number\">1</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 在冷区二分查找</span></span><br><span class=\"line\">  binarySearch(<span class=\"number\">0</span>, firstHotEntry)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>热区定义为8192字节是一个经验数值，它对应1024个offsetindex索引项，可索引大概4MB大小的消息。最大情况下，这8192字节会包括3个Page，例如<code>[Page1:2048字节][Page2:4096字节][Page3:2048字节]</code>。这个数值太大，Page可能已经被LRU策略淘汰，仍会产生page fault那就没价值了；这个数值太小，那就降级为冷区二分查找，仍会出现所提的page新增时page fault的问题。</p>\n<h2 id=\"RocketMQ读取数据\"><a href=\"#RocketMQ读取数据\" class=\"headerlink\" title=\"RocketMQ读取数据\"></a>RocketMQ读取数据</h2><p><img src=\"https://user-images.githubusercontent.com/4915189/97953016-2b367f80-1dda-11eb-88c2-2b906b095ca5.png\" alt=\"image\"></p>\n<p>（图3 RocketMQ读取数据）</p>\n<p>有别于Kafka的partition级别的leader/follower，RocketMQ是Broker级别的master/slave，slave全量冗余master的数据。读取数据时，如果满足一定条件（数据太旧）会从slave读取，实现了某种程度上的「读写分离」。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// org.apache.rocketmq.store.DefaultMessageStore#getMessage</span></span><br><span class=\"line\"><span class=\"keyword\">long</span> diff = maxOffsetPy - maxPhyOffsetPulling;</span><br><span class=\"line\"><span class=\"keyword\">long</span> memory = (<span class=\"keyword\">long</span>) (StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE</span><br><span class=\"line\">    * (<span class=\"keyword\">this</span>.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / <span class=\"number\">100.0</span>));</span><br><span class=\"line\">getResult.setSuggestPullingFromSlave(diff &gt; memory);</span><br></pre></td></tr></table></figure>\n<p>什么情况下从slave读取数据？如上所示，</p>\n<blockquote>\n<p>maxOffsetPy 为当前最大物理偏移量，maxPhyOffsetPulling 为本次消息拉取最大物理偏移量，他们的差即可表示消息堆积量，TOTAL_PHYSICAL_MEMORY_SIZE 表示当前系统物理内存，accessMessageInMemoryMaxRatio 的默认值为 40，以上逻辑即可算出当前消息堆积量是否大于物理内存的 40 %，如果大于则将 suggestPullingFromSlave 设置为 true。<br>引用自：<a href=\"http://objcoding.com/2019/09/22/rocketmq-read-write-separation/\" target=\"_blank\" rel=\"noopener\">http://objcoding.com/2019/09/22/rocketmq-read-write-separation/</a></p>\n</blockquote>\n<p><code>setSuggestPullingFromSlave</code>为true后还会结合其他开关配置项决定是否从slave读取数据，具体可以参考上面引用的链接，但核心逻辑就是上面的代码。consumer无论是从master还是slave读取数据，都需要经历：</p>\n<ul>\n<li>从consumerqueue读取位移数据（consumerqueue是mmap在内存中的）</li>\n<li>根据位移数据回源到MappedFile读取数据，该MappedFile大概率还在page cache中未被LRU淘汰（如果已经LRU淘汰掉了，能切到slave读冷数据可以避免page fault，这就是核心思思）</li>\n</ul>\n<p>从slave读取数据的价值是可以最大化利用master的page cache，使得冷数据的读取不影响到master的性能。slave同步master的数据则与上述过程不同，由于是Broker级别的replicate，因此不需要区分consumerqueue，所有master的数据都需要同步到slave。这个过程中，slave上报的offset作为游标，master根据该游标不断往slave推送新数据，slave接受数据后更新游标重复此过程。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li>RocketMQ主从同步源码分析：<a href=\"http://objcoding.com/2019/09/21/rocketmq-Master-slave-ha/#top\" target=\"_blank\" rel=\"noopener\">http://objcoding.com/2019/09/21/rocketmq-Master-slave-ha/#top</a></li>\n<li>RocketMQ主从读写分离机制：<a href=\"http://objcoding.com/2019/09/22/rocketmq-read-write-separation/\" target=\"_blank\" rel=\"noopener\">http://objcoding.com/2019/09/22/rocketmq-read-write-separation/</a></li>\n</ul>"}],"PostAsset":[],"PostCategory":[{"post_id":"cl6mbc1140000igu8btsx9tt2","category_id":"cl6mbc11i0002igu8aorsae0e","_id":"cl6mbc128000cigu8oi7ns1mb"},{"post_id":"cl6mbc123000aigu8cxeefykl","category_id":"cl6mbc11i0002igu8aorsae0e","_id":"cl6mbc12h000higu88gs07l1x"},{"post_id":"cl6mbc11d0001igu8nqkm1ee9","category_id":"cl6mbc11z0007igu8f851dyc6","_id":"cl6mbc12p000ligu8ad1rc496"},{"post_id":"cl6mbc12b000figu8ckry5wjn","category_id":"cl6mbc129000digu8a8972l4u","_id":"cl6mbc12s000oigu8qnua4fko"},{"post_id":"cl6mbc11o0004igu8e3alkbq6","category_id":"cl6mbc129000digu8a8972l4u","_id":"cl6mbc12w000tigu8qwdipt0v"},{"post_id":"cl6mbc12f000gigu8qecu1wzt","category_id":"cl6mbc129000digu8a8972l4u","_id":"cl6mbc12y000wigu8xbul8f1c"},{"post_id":"cl6mbc11r0005igu8izbhzlfo","category_id":"cl6mbc11z0007igu8f851dyc6","_id":"cl6mbc130000zigu8d6jqvinn"},{"post_id":"cl6mbc12q000nigu8aa2cniom","category_id":"cl6mbc11z0007igu8f851dyc6","_id":"cl6mbc1320013igu8vzvd4rzc"},{"post_id":"cl6mbc11v0006igu8jw5xqhr3","category_id":"cl6mbc12t000qigu8brjdhe8g","_id":"cl6mbc1340016igu8ua17i0aj"},{"post_id":"cl6mbc12x000vigu8duqsea4c","category_id":"cl6mbc129000digu8a8972l4u","_id":"cl6mbc1370019igu8f8sp837x"},{"post_id":"cl6mbc12z000yigu8qsnbdljq","category_id":"cl6mbc129000digu8a8972l4u","_id":"cl6mbc139001cigu8q20gif2c"},{"post_id":"cl6mbc127000bigu8zmto99ta","category_id":"cl6mbc129000digu8a8972l4u","_id":"cl6mbc13d001higu8hba8m1ui"},{"post_id":"cl6mbc1320012igu801pp69ha","category_id":"cl6mbc12t000qigu8brjdhe8g","_id":"cl6mbc13e001kigu8mobn3xw9"},{"post_id":"cl6mbc1340015igu8ia5xygqs","category_id":"cl6mbc11i0002igu8aorsae0e","_id":"cl6mbc13g001oigu84le1h8mr"},{"post_id":"cl6mbc1360018igu853srrix8","category_id":"cl6mbc129000digu8a8972l4u","_id":"cl6mbc13i001sigu86z5wxjxl"},{"post_id":"cl6mbc12l000kigu809vtoo9r","category_id":"cl6mbc1330014igu8lmd5euz4","_id":"cl6mbc13k001vigu8e64drh3n"},{"post_id":"cl6mbc138001bigu8j7txwago","category_id":"cl6mbc11z0007igu8f851dyc6","_id":"cl6mbc13m001zigu8bdtujo00"},{"post_id":"cl6mbc13c001gigu8ru64jmav","category_id":"cl6mbc11z0007igu8f851dyc6","_id":"cl6mbc13o0022igu8xhdtnkvh"},{"post_id":"cl6mbc12v000sigu8ewkd61th","category_id":"cl6mbc13a001digu822mcfrjx","_id":"cl6mbc13s0027igu8emdblpnk"},{"post_id":"cl6mbc13f001nigu82z7yf3yd","category_id":"cl6mbc11i0002igu8aorsae0e","_id":"cl6mbc13v002aigu8fkf19h3a"},{"post_id":"cl6mbc13h001rigu8n29rgkoq","category_id":"cl6mbc11i0002igu8aorsae0e","_id":"cl6mbc13x002eigu8oxage9kf"},{"post_id":"cl6mbc13j001uigu8pbclxga8","category_id":"cl6mbc11z0007igu8f851dyc6","_id":"cl6mbc13y002higu8j9wnvfic"},{"post_id":"cl6mbc13e001jigu8bpsmot7n","category_id":"cl6mbc13h001qigu87zjfcchw","_id":"cl6mbc142002ligu8k04etupb"},{"post_id":"cl6mbc13n0021igu80fw84f00","category_id":"cl6mbc129000digu8a8972l4u","_id":"cl6mbc143002oigu85a06sfa3"},{"post_id":"cl6mbc13r0026igu801rp59dp","category_id":"cl6mbc13h001qigu87zjfcchw","_id":"cl6mbc145002sigu8c68nkyev"},{"post_id":"cl6mbc13u0029igu8m62yhoxg","category_id":"cl6mbc11i0002igu8aorsae0e","_id":"cl6mbc147002vigu8atd6awow"},{"post_id":"cl6mbc13l001yigu81qn2dp05","category_id":"cl6mbc13q0025igu87o476n81","_id":"cl6mbc149002zigu8nnc2loe9"},{"post_id":"cl6mbc13w002digu82xugx110","category_id":"cl6mbc13q0025igu87o476n81","_id":"cl6mbc14c0033igu8iutsqfgo"},{"post_id":"cl6mbc13x002gigu82p77vda1","category_id":"cl6mbc12t000qigu8brjdhe8g","_id":"cl6mbc14e0037igu8qmb988nu"},{"post_id":"cl6mbc141002kigu8x8as7cg0","category_id":"cl6mbc11z0007igu8f851dyc6","_id":"cl6mbc14g003bigu8xzfesqq3"},{"post_id":"cl6mbc142002nigu8oe0tskr5","category_id":"cl6mbc11z0007igu8f851dyc6","_id":"cl6mbc14j003eigu8mxxvuowt"},{"post_id":"cl6mbc148002yigu8fy800kgo","category_id":"cl6mbc13h001qigu87zjfcchw","_id":"cl6mbc14n003jigu801jqx2a9"},{"post_id":"cl6mbc144002rigu8xoy42hcd","category_id":"cl6mbc148002xigu8vp3r7m51","_id":"cl6mbc14p003migu8zwdmabnu"},{"post_id":"cl6mbc14f003aigu81z0g4d3h","category_id":"cl6mbc13q0025igu87o476n81","_id":"cl6mbc14s003rigu87nqvm72f"},{"post_id":"cl6mbc146002uigu8v3jlcu0a","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc14u003uigu8etcb5l3g"},{"post_id":"cl6mbc14h003digu84v608hkt","category_id":"cl6mbc11i0002igu8aorsae0e","_id":"cl6mbc14w003yigu8370mlzj9"},{"post_id":"cl6mbc14b0032igu87qrh5z3u","category_id":"cl6mbc14j003figu8fuadmhca","_id":"cl6mbc14x0041igu82azlap3c"},{"post_id":"cl6mbc14o003ligu8mr8fwgs4","category_id":"cl6mbc13q0025igu87o476n81","_id":"cl6mbc14z0045igu827s757u1"},{"post_id":"cl6mbc14r003qigu8m8s7jfy8","category_id":"cl6mbc148002xigu8vp3r7m51","_id":"cl6mbc1500048igu8lf1byocl"},{"post_id":"cl6mbc14d0035igu85lypq9v0","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc153004cigu88ou51sqc"},{"post_id":"cl6mbc14t003tigu810dcam5k","category_id":"cl6mbc14j003figu8fuadmhca","_id":"cl6mbc155004figu8mskmafes"},{"post_id":"cl6mbc14v003xigu8isolajcu","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc156004higu82ewv20ax"},{"post_id":"cl6mbc14m003iigu8gbdl7xys","category_id":"cl6mbc14u003vigu89075fcxo","_id":"cl6mbc157004kigu840707or0"},{"post_id":"cl6mbc14w0040igu86ug16jyg","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc157004migu83t939x0u"},{"post_id":"cl6mbc14y0044igu8nm2o4pju","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc158004pigu88o94wfp8"},{"post_id":"cl6mbc1500047igu8tdg9iu8v","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc158004rigu8j5fbj6wg"},{"post_id":"cl6mbc151004bigu89cr87x0w","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc159004tigu8z235oa9u"},{"post_id":"cl6mbc154004eigu8uwqroltp","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc15a004vigu8i1ggjrqi"},{"post_id":"cl6mbc160006eigu8odjgcm03","category_id":"cl6mbc14j003figu8fuadmhca","_id":"cl6mbc165006jigu831xpwybr"},{"post_id":"cl6mbc161006figu86qvt7r7i","category_id":"cl6mbc14e0036igu85zusy7y0","_id":"cl6mbc167006migu8aorvn96x"},{"post_id":"cl6mbc163006higu8z1e5n727","category_id":"cl6mbc11i0002igu8aorsae0e","_id":"cl6mbc168006pigu8x4dv5bwg"},{"post_id":"cl6mbc164006iigu8ztymq0hs","category_id":"cl6mbc14j003figu8fuadmhca","_id":"cl6mbc168006rigu8yx84f3na"},{"post_id":"cl6mbc166006ligu81brvznhh","category_id":"cl6mbc14j003figu8fuadmhca","_id":"cl6mbc16a006uigu8rpaqso6e"},{"post_id":"cl6mbc16k0073igu86m4t94jl","category_id":"cl6mbc14j003figu8fuadmhca","_id":"cl6mbc16o0078igu8bkde6vcr"},{"post_id":"cl6mbc16m0075igu8uuyk43s2","category_id":"cl6mbc14j003figu8fuadmhca","_id":"cl6mbc16p007aigu84up9hu9e"}],"PostTag":[{"post_id":"cl6mbc1140000igu8btsx9tt2","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc1220009igu8t54m0lk7"},{"post_id":"cl6mbc11d0001igu8nqkm1ee9","tag_id":"cl6mbc1200008igu888fmp2je","_id":"cl6mbc12q000migu8bowh8n2o"},{"post_id":"cl6mbc11d0001igu8nqkm1ee9","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc12s000pigu85oko80ck"},{"post_id":"cl6mbc11o0004igu8e3alkbq6","tag_id":"cl6mbc12j000jigu8vsdh2yd3","_id":"cl6mbc12w000uigu8ozuw86ak"},{"post_id":"cl6mbc11r0005igu8izbhzlfo","tag_id":"cl6mbc12u000rigu8v0ky3z0y","_id":"cl6mbc1310011igu83upsbfwn"},{"post_id":"cl6mbc11v0006igu8jw5xqhr3","tag_id":"cl6mbc1310010igu8a57ah2li","_id":"cl6mbc137001aigu8mwu12v71"},{"post_id":"cl6mbc1340015igu8ia5xygqs","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc13a001eigu8phr3cm3p"},{"post_id":"cl6mbc123000aigu8cxeefykl","tag_id":"cl6mbc1350017igu895g4ad30","_id":"cl6mbc13d001iigu8cllsyvkw"},{"post_id":"cl6mbc123000aigu8cxeefykl","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc13f001ligu8vv5s3063"},{"post_id":"cl6mbc138001bigu8j7txwago","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc13h001pigu803qgtqb0"},{"post_id":"cl6mbc138001bigu8j7txwago","tag_id":"cl6mbc1350017igu895g4ad30","_id":"cl6mbc13j001tigu8vphkeqmk"},{"post_id":"cl6mbc13c001gigu8ru64jmav","tag_id":"cl6mbc1350017igu895g4ad30","_id":"cl6mbc13l001xigu8awdrc1ar"},{"post_id":"cl6mbc127000bigu8zmto99ta","tag_id":"cl6mbc13b001figu8rrk33ub0","_id":"cl6mbc13n0020igu8s5f95mmb"},{"post_id":"cl6mbc13f001nigu82z7yf3yd","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc13p0024igu8t9615wda"},{"post_id":"cl6mbc13h001rigu8n29rgkoq","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc13t0028igu8t1ryg0a1"},{"post_id":"cl6mbc12b000figu8ckry5wjn","tag_id":"cl6mbc13f001migu84nn3p0fp","_id":"cl6mbc13v002cigu80sjf6jsd"},{"post_id":"cl6mbc12f000gigu8qecu1wzt","tag_id":"cl6mbc1350017igu895g4ad30","_id":"cl6mbc13x002figu8woy9cx0z"},{"post_id":"cl6mbc12f000gigu8qecu1wzt","tag_id":"cl6mbc13o0023igu807xtnjz0","_id":"cl6mbc13y002iigu8871lbs9n"},{"post_id":"cl6mbc13u0029igu8m62yhoxg","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc142002migu8mkh1zkhv"},{"post_id":"cl6mbc13w002digu82xugx110","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc143002pigu83wh88ly3"},{"post_id":"cl6mbc12l000kigu809vtoo9r","tag_id":"cl6mbc13v002bigu8sv5o5c42","_id":"cl6mbc146002tigu8ge3inshq"},{"post_id":"cl6mbc13x002gigu82p77vda1","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc147002wigu8j857xjr1"},{"post_id":"cl6mbc141002kigu8x8as7cg0","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc14a0031igu82lo2wrog"},{"post_id":"cl6mbc12q000nigu8aa2cniom","tag_id":"cl6mbc1200008igu888fmp2je","_id":"cl6mbc14c0034igu8vumay58r"},{"post_id":"cl6mbc12q000nigu8aa2cniom","tag_id":"cl6mbc13z002jigu852eepv9b","_id":"cl6mbc14f0039igu8tof2tgfq"},{"post_id":"cl6mbc142002nigu8oe0tskr5","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc14h003cigu8xab88aoa"},{"post_id":"cl6mbc12v000sigu8ewkd61th","tag_id":"cl6mbc144002qigu8u8zll5h5","_id":"cl6mbc14k003higu8sk243r6t"},{"post_id":"cl6mbc12x000vigu8duqsea4c","tag_id":"cl6mbc13f001migu84nn3p0fp","_id":"cl6mbc14n003kigu8nfj454dp"},{"post_id":"cl6mbc12z000yigu8qsnbdljq","tag_id":"cl6mbc14e0038igu8vmtksbzr","_id":"cl6mbc14q003nigu8avxdowk1"},{"post_id":"cl6mbc14h003digu84v608hkt","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc14t003sigu86779t5xn"},{"post_id":"cl6mbc1320012igu801pp69ha","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc14w003zigu8nfe4hr52"},{"post_id":"cl6mbc1320012igu801pp69ha","tag_id":"cl6mbc14k003gigu8srja4n74","_id":"cl6mbc14x0042igu8rm44xekr"},{"post_id":"cl6mbc1320012igu801pp69ha","tag_id":"cl6mbc1350017igu895g4ad30","_id":"cl6mbc14z0046igu8zauxtrnm"},{"post_id":"cl6mbc1360018igu853srrix8","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc1510049igu8xseuh2k1"},{"post_id":"cl6mbc1360018igu853srrix8","tag_id":"cl6mbc14v003wigu8mt8r2qq3","_id":"cl6mbc153004digu88zwgl25r"},{"post_id":"cl6mbc13e001jigu8bpsmot7n","tag_id":"cl6mbc11m0003igu8i51e0fxq","_id":"cl6mbc156004gigu82jb3ro7a"},{"post_id":"cl6mbc13e001jigu8bpsmot7n","tag_id":"cl6mbc1350017igu895g4ad30","_id":"cl6mbc157004jigu873acs5ql"},{"post_id":"cl6mbc13e001jigu8bpsmot7n","tag_id":"cl6mbc13o0023igu807xtnjz0","_id":"cl6mbc157004ligu8ezuc97t7"},{"post_id":"cl6mbc13j001uigu8pbclxga8","tag_id":"cl6mbc151004aigu8b0yfxqwm","_id":"cl6mbc158004oigu86cb7w4t4"},{"post_id":"cl6mbc13l001yigu81qn2dp05","tag_id":"cl6mbc156004iigu8iifmp4pa","_id":"cl6mbc158004qigu8zj0cinf9"},{"post_id":"cl6mbc13n0021igu80fw84f00","tag_id":"cl6mbc158004nigu8jvgtdxy4","_id":"cl6mbc159004uigu8b4vgukyp"},{"post_id":"cl6mbc13r0026igu801rp59dp","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc15b004yigu8ry1ff4zn"},{"post_id":"cl6mbc13r0026igu801rp59dp","tag_id":"cl6mbc159004sigu8xozjc4ev","_id":"cl6mbc15b004zigu82pjkguga"},{"post_id":"cl6mbc13r0026igu801rp59dp","tag_id":"cl6mbc14k003gigu8srja4n74","_id":"cl6mbc15c0051igu8shgl4rsh"},{"post_id":"cl6mbc144002rigu8xoy42hcd","tag_id":"cl6mbc15a004xigu8k20rrwl9","_id":"cl6mbc15c0052igu8zsuu4254"},{"post_id":"cl6mbc146002uigu8v3jlcu0a","tag_id":"cl6mbc15a004xigu8k20rrwl9","_id":"cl6mbc15d0055igu8kn1js7j4"},{"post_id":"cl6mbc146002uigu8v3jlcu0a","tag_id":"cl6mbc15c0053igu87icvwpj6","_id":"cl6mbc15d0056igu8hbdg8iyg"},{"post_id":"cl6mbc148002yigu8fy800kgo","tag_id":"cl6mbc14k003gigu8srja4n74","_id":"cl6mbc15e0058igu8slvp0oc4"},{"post_id":"cl6mbc14b0032igu87qrh5z3u","tag_id":"cl6mbc15d0057igu8hajiba95","_id":"cl6mbc15e005aigu80b6wjykq"},{"post_id":"cl6mbc14d0035igu85lypq9v0","tag_id":"cl6mbc15c0053igu87icvwpj6","_id":"cl6mbc15i005figu8j9fs0clh"},{"post_id":"cl6mbc14d0035igu85lypq9v0","tag_id":"cl6mbc15a004xigu8k20rrwl9","_id":"cl6mbc15j005gigu8k1r9kff0"},{"post_id":"cl6mbc14d0035igu85lypq9v0","tag_id":"cl6mbc15d0057igu8hajiba95","_id":"cl6mbc15k005iigu8ayg7r5ac"},{"post_id":"cl6mbc14d0035igu85lypq9v0","tag_id":"cl6mbc15g005digu8lyzwloig","_id":"cl6mbc15k005jigu83z475skw"},{"post_id":"cl6mbc14f003aigu81z0g4d3h","tag_id":"cl6mbc15g005eigu8ew6o19wf","_id":"cl6mbc15l005ligu803s2tt7l"},{"post_id":"cl6mbc14m003iigu8gbdl7xys","tag_id":"cl6mbc15j005higu860wwtcys","_id":"cl6mbc15m005migu85r2dorn0"},{"post_id":"cl6mbc14o003ligu8mr8fwgs4","tag_id":"cl6mbc15g005eigu8ew6o19wf","_id":"cl6mbc15n005pigu8tzq9bc7f"},{"post_id":"cl6mbc14o003ligu8mr8fwgs4","tag_id":"cl6mbc156004iigu8iifmp4pa","_id":"cl6mbc15o005qigu8ey8q56ql"},{"post_id":"cl6mbc14r003qigu8m8s7jfy8","tag_id":"cl6mbc15a004xigu8k20rrwl9","_id":"cl6mbc15p005sigu8vg9w2q7k"},{"post_id":"cl6mbc14t003tigu810dcam5k","tag_id":"cl6mbc15o005rigu8hyg4qkos","_id":"cl6mbc15p005uigu8b3nd8ptp"},{"post_id":"cl6mbc14v003xigu8isolajcu","tag_id":"cl6mbc15p005tigu8turv09tf","_id":"cl6mbc15q005wigu8jduc0ved"},{"post_id":"cl6mbc14w0040igu86ug16jyg","tag_id":"cl6mbc15p005tigu8turv09tf","_id":"cl6mbc15r005yigu8bb2mui73"},{"post_id":"cl6mbc14y0044igu8nm2o4pju","tag_id":"cl6mbc15r005xigu8jta1ah6j","_id":"cl6mbc15t0061igu8yu2d76vf"},{"post_id":"cl6mbc14y0044igu8nm2o4pju","tag_id":"cl6mbc15s005zigu8jnyi611v","_id":"cl6mbc15t0062igu8w8chlxy9"},{"post_id":"cl6mbc1500047igu8tdg9iu8v","tag_id":"cl6mbc15p005tigu8turv09tf","_id":"cl6mbc15u0064igu87ncqb2a9"},{"post_id":"cl6mbc151004bigu89cr87x0w","tag_id":"cl6mbc15p005tigu8turv09tf","_id":"cl6mbc15w0069igu8p8belw0e"},{"post_id":"cl6mbc151004bigu89cr87x0w","tag_id":"cl6mbc15a004xigu8k20rrwl9","_id":"cl6mbc15x006aigu8n9lrshsd"},{"post_id":"cl6mbc151004bigu89cr87x0w","tag_id":"cl6mbc15d0057igu8hajiba95","_id":"cl6mbc15x006bigu8rbr20j23"},{"post_id":"cl6mbc151004bigu89cr87x0w","tag_id":"cl6mbc15o005rigu8hyg4qkos","_id":"cl6mbc15x006cigu89xkxtxvb"},{"post_id":"cl6mbc154004eigu8uwqroltp","tag_id":"cl6mbc15p005tigu8turv09tf","_id":"cl6mbc15x006digu8mynv0zuh"},{"post_id":"cl6mbc163006higu8z1e5n727","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc166006kigu8k22px19d"},{"post_id":"cl6mbc163006higu8z1e5n727","tag_id":"cl6mbc15p005tigu8turv09tf","_id":"cl6mbc168006oigu8ejwdqtx3"},{"post_id":"cl6mbc164006iigu8ztymq0hs","tag_id":"cl6mbc15o005rigu8hyg4qkos","_id":"cl6mbc168006qigu8f2cu6e3p"},{"post_id":"cl6mbc164006iigu8ztymq0hs","tag_id":"cl6mbc15r005xigu8jta1ah6j","_id":"cl6mbc16a006tigu8zuqhsope"},{"post_id":"cl6mbc166006ligu81brvznhh","tag_id":"cl6mbc15r005xigu8jta1ah6j","_id":"cl6mbc16b006vigu81wrjhph4"},{"post_id":"cl6mbc160006eigu8odjgcm03","tag_id":"cl6mbc12a000eigu8hn7jlwfb","_id":"cl6mbc16c006xigu84yrx0haa"},{"post_id":"cl6mbc160006eigu8odjgcm03","tag_id":"cl6mbc162006gigu8vvt9o7tb","_id":"cl6mbc16c006yigu8grn9w441"},{"post_id":"cl6mbc160006eigu8odjgcm03","tag_id":"cl6mbc167006nigu8pauooa5i","_id":"cl6mbc16d006zigu826oxt26m"},{"post_id":"cl6mbc161006figu86qvt7r7i","tag_id":"cl6mbc169006sigu82kfkiq7r","_id":"cl6mbc16d0070igu8ulnztvms"},{"post_id":"cl6mbc161006figu86qvt7r7i","tag_id":"cl6mbc16b006wigu85kpwq1pb","_id":"cl6mbc16d0071igu86dcy72pc"},{"post_id":"cl6mbc16k0073igu86m4t94jl","tag_id":"cl6mbc15o005rigu8hyg4qkos","_id":"cl6mbc16n0076igu82d0ud3xp"},{"post_id":"cl6mbc16k0073igu86m4t94jl","tag_id":"cl6mbc15r005xigu8jta1ah6j","_id":"cl6mbc16o0077igu8gj5en2fy"},{"post_id":"cl6mbc16m0075igu8uuyk43s2","tag_id":"cl6mbc15o005rigu8hyg4qkos","_id":"cl6mbc16p0079igu8fmz85ihq"},{"post_id":"cl6mbc16m0075igu8uuyk43s2","tag_id":"cl6mbc15r005xigu8jta1ah6j","_id":"cl6mbc16p007bigu87ouhuia2"}],"Tag":[{"name":"C/C++","_id":"cl6mbc11m0003igu8i51e0fxq"},{"name":"HBase","_id":"cl6mbc1200008igu888fmp2je"},{"name":"Java","_id":"cl6mbc12a000eigu8hn7jlwfb"},{"name":"Maven","_id":"cl6mbc12j000jigu8vsdh2yd3"},{"name":"Spring","_id":"cl6mbc12u000rigu8v0ky3z0y"},{"name":"操作系统","_id":"cl6mbc1310010igu8a57ah2li"},{"name":"Linux","_id":"cl6mbc1350017igu895g4ad30"},{"name":"LVM","_id":"cl6mbc13b001figu8rrk33ub0"},{"name":"SVN","_id":"cl6mbc13f001migu84nn3p0fp"},{"name":"Network","_id":"cl6mbc13o0023igu807xtnjz0"},{"name":"信息安全","_id":"cl6mbc13v002bigu8sv5o5c42"},{"name":"Hadoop","_id":"cl6mbc13z002jigu852eepv9b"},{"name":"职场","_id":"cl6mbc144002qigu8u8zll5h5"},{"name":"Docker","_id":"cl6mbc14e0038igu8vmtksbzr"},{"name":"TCP/IP","_id":"cl6mbc14k003gigu8srja4n74"},{"name":"Eclipse","_id":"cl6mbc14v003wigu8mt8r2qq3"},{"name":"Beaglebone","_id":"cl6mbc151004aigu8b0yfxqwm"},{"name":"动态规划","_id":"cl6mbc156004iigu8iifmp4pa"},{"name":"Tomcat","_id":"cl6mbc158004nigu8jvgtdxy4"},{"name":"Mina","_id":"cl6mbc159004sigu8xozjc4ev"},{"name":"MySQL","_id":"cl6mbc15a004xigu8k20rrwl9"},{"name":"数据库","_id":"cl6mbc15c0053igu87icvwpj6"},{"name":"Redis","_id":"cl6mbc15d0057igu8hajiba95"},{"name":"HDFS","_id":"cl6mbc15g005digu8lyzwloig"},{"name":"Algorithm","_id":"cl6mbc15g005eigu8ew6o19wf"},{"name":"B-Tree","_id":"cl6mbc15j005higu860wwtcys"},{"name":"Kafka","_id":"cl6mbc15o005rigu8hyg4qkos"},{"name":"系统设计","_id":"cl6mbc15p005tigu8turv09tf"},{"name":"Paper阅读","_id":"cl6mbc15r005xigu8jta1ah6j"},{"name":"Memcached","_id":"cl6mbc15s005zigu8jnyi611v"},{"name":"ChronicleMap","_id":"cl6mbc162006gigu8vvt9o7tb"},{"name":"ApacheIgnite","_id":"cl6mbc167006nigu8pauooa5i"},{"name":"CQRS","_id":"cl6mbc169006sigu82kfkiq7r"},{"name":"EventSourcing","_id":"cl6mbc16b006wigu85kpwq1pb"}]}}